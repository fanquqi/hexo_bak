{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/uploads/fanquanqing.jpg","path":"uploads/fanquanqing.jpg","modified":1,"renderable":0},{"_id":"source/uploads/wechat.png","path":"uploads/wechat.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.gitignore","hash":"32ea93f21d8693d5d8fa4eef1c51a21ad0670047","modified":1496391322000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1496391322000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1496391322000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1496391322000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1496391322000},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1496391322000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1496391322000},{"_id":"themes/next/.travis.yml","hash":"c42d9608c8c7fe90de7b1581a8dc3886e90c179e","modified":1496391322000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1496391322000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1496391322000},{"_id":"themes/next/README.en.md","hash":"4ece25ee5f64447cd522e54cb0fffd9a375f0bd4","modified":1496391322000},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1496391322000},{"_id":"themes/next/bower.json","hash":"be0a430362cb73a7e3cf9ecf51a67edf8214b637","modified":1496391322000},{"_id":"themes/next/_config.yml","hash":"92c455a4d33673d9a127c8bc85e927a74e763001","modified":1498129214000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1496391322000},{"_id":"themes/next/package.json","hash":"7e87b2621104b39a30488654c2a8a0c6a563574b","modified":1496391322000},{"_id":"source/_posts/Blog收藏.md","hash":"32851c4bd3885be8c8ec0f557eb47fe9ae87ec10","modified":1502178762000},{"_id":"source/_posts/Django之入门学习.md","hash":"4ca2f6188b63e171db4f4b6fdb946997ffa71dc2","modified":1500008111000},{"_id":"source/_posts/ELK搭建.md","hash":"9b8712c972b855994b6c9f56c906ede145d0bffe","modified":1500973413000},{"_id":"source/_posts/ELK问题处理汇总.md","hash":"1502cc80fb5a65987293fb397963b174f237aff0","modified":1502072569000},{"_id":"source/_posts/ElasticSearch之template,mapping,setting修改.md","hash":"abd48d5b1b26530f9654948ec5a0b96e4d93c67c","modified":1500973090000},{"_id":"source/_posts/Elasticsearch调优实战过程.md","hash":"3ecbb4ba3468891487d2e8e2e10cab8aff3752d2","modified":1501585769000},{"_id":"source/_posts/HTML-CSS.md","hash":"0e9237a52d7cd6b6dce403ba87f1c1471c0677d6","modified":1501746290000},{"_id":"source/_posts/Logstash优化.md","hash":"a2afa8d4aae5e5e05910cd9d8991d54f9e8c6b71","modified":1497520454000},{"_id":"source/_posts/Git使用总结.md","hash":"ff4a7cb35f66b512302c996a1dcf7a6d399a736f","modified":1500519017000},{"_id":"source/_posts/Mac-gihub-pages-hexo搭建博客.md","hash":"3a8bfa21ed8b68f88aa4c88fc9ca8628e1dd0510","modified":1496663744000},{"_id":"source/_posts/Mac软件使用.md","hash":"57aff359f965e119ab9231f701d75168a8275dc0","modified":1498128504000},{"_id":"source/_posts/MySQL使用记录.md","hash":"9dfc44c3a3932db9bf7b4e7967182186eb51f999","modified":1501745824000},{"_id":"source/_posts/MySQL问题查找-状态查看.md","hash":"136d966c60e0527f8244e2c22075df51a31aa748","modified":1502163803000},{"_id":"source/_posts/PXE网络引导批量安装操作系统.md","hash":"9dd880c289d4b487922f9bfcded79039a52069a5","modified":1501818007000},{"_id":"source/_posts/curl查看接口各阶段响应时间.md","hash":"3f750933148f5801f4c58d3e31c33a5d5ac54976","modified":1497585849000},{"_id":"source/_posts/docker命令.md","hash":"0f9300f09d969a38f384b57b3bfa933dcc119f2f","modified":1498552599000},{"_id":"source/_posts/docker是什么.md","hash":"c6ee726c91726dfca9931a9d2060d47c60961289","modified":1498203947000},{"_id":"source/_posts/falcon问题处理.md","hash":"c9fa7256ada564266082ac1bf701cf42aee4d25b","modified":1498196762000},{"_id":"source/_posts/file-beat接入ELK.md","hash":"9fcb103b92547dce326d2cf1a72a92cab01a20c0","modified":1501663040000},{"_id":"source/_posts/javascripts记录.md","hash":"b2636776e41b63ee8f770127d06569cb07d0772e","modified":1499336571000},{"_id":"source/_posts/influxdb使用笔记.md","hash":"5f2978183aa97c26e49481717a14d7d8d35a1931","modified":1499838265000},{"_id":"source/_posts/nginx之location-upstream-rewrite.md","hash":"a9117a86ef6edfe9c41ecdd51b3cc1fd152a2438","modified":1502248431000},{"_id":"source/_posts/lsof十几个实例.md","hash":"0144646eff7e2301407ce36f1fb04d599a946b2d","modified":1497517373000},{"_id":"source/_posts/mysql误删除表恢复.md","hash":"125f1682d0950dffbf022d35eebecc15e7767fc1","modified":1502071521000},{"_id":"source/_posts/nginx之HTTPS配置.md","hash":"6403698c67f561a60afe606d2d13ef5415250d6b","modified":1500531635000},{"_id":"source/_posts/nginx之安装配置.md","hash":"9a04e5920d0469da08030938dce261783b92408d","modified":1501586008000},{"_id":"source/_posts/nginx之请求限流限速问题.md","hash":"d5ebfb2772503c3693fe4d8cb00626182107a171","modified":1501746346000},{"_id":"source/_posts/openvpn安装.md","hash":"6b5aedadf949be4a2e0152c444ac2c974d327d83","modified":1498358367000},{"_id":"source/_posts/rpm包制作.md","hash":"1dd7312ed98c30da0412793a43be2d164f457907","modified":1497586139000},{"_id":"source/_posts/shell脚本检测硬盘.md","hash":"300ccd16527aec71c78457d7d1d9f2d96ff6947b","modified":1498355866000},{"_id":"source/_posts/shell脚本自动安装zabbix-agent.md","hash":"da63e7301a42eb8b1c70e0e6c64adaed44da0836","modified":1498355548000},{"_id":"source/_posts/shell命令之xargs与exec.md","hash":"72b94b7a9b96c6ae3e4089cf5dc2af6393116456","modified":1498549270000},{"_id":"source/_posts/socket解读.md","hash":"88fb5defe285621e44767ce9f02c5d3d48266d73","modified":1502097990000},{"_id":"source/_posts/sublime使用.md","hash":"76092b9847a8623a2c39cd6cc0638142ac63148c","modified":1496998782000},{"_id":"source/_posts/uwsgi-worker监控脚本.md","hash":"fdb4e015915cd1174afb3f8cc9f7d762d790121e","modified":1497250986000},{"_id":"source/_posts/uwsgi笔记.md","hash":"ffdf66e14f2a624878a1826372eac2c96d80033f","modified":1500451777000},{"_id":"source/_posts/ucloud-API使用.md","hash":"11f3b9bcc66b36f7a8cc270e1a98ea2a1096118d","modified":1501746369000},{"_id":"source/_posts/zabbix迁移到open-falcon.md","hash":"7458c832f785d97235a156c3965e478afaa9c946","modified":1501746123000},{"_id":"source/_posts/几种mysql迁移.md","hash":"06d6afee772fb5d3d67732c6d32ce7bee6780646","modified":1498809967000},{"_id":"source/_posts/效率神器Alfred使用.md","hash":"5caff0681e97782530494f540de3aa7e2ac1542e","modified":1498128801000},{"_id":"source/_posts/记一次PHP服务部署.md","hash":"69b5bf36acd44914e5e9af7fc73aee6b71f7248f","modified":1500970756000},{"_id":"source/_posts/记录主机history.md","hash":"fdbe01ca54e675ef6ffbf378884d691822e8df33","modified":1501663365000},{"_id":"source/_posts/运维工具之sar命令.md","hash":"0b465e228a178af839d69cefeb07ee9809113e36","modified":1498197850000},{"_id":"source/categories/index.md","hash":"69584a15f94707e555a72d029452dd4cedc79730","modified":1496500517000},{"_id":"source/tags/index.md","hash":"539795e699ed3876440c347371ab787d89de0137","modified":1496556298000},{"_id":"source/uploads/fanquanqing.jpg","hash":"f8d92148cd2f8c1e3bdf5f1a29dd91b0a6133fea","modified":1496545784000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"fdd63b77472612337309eb93ec415a059b90756b","modified":1496391322000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1496391322000},{"_id":"source/uploads/wechat.png","hash":"b97c6aaf275e06d0fdd5e50954310b267170e5aa","modified":1496651656000},{"_id":"themes/next/languages/de.yml","hash":"306db8c865630f32c6b6260ade9d3209fbec8011","modified":1496391322000},{"_id":"themes/next/languages/default.yml","hash":"4cc6aeb1ac09a58330e494c8771773758ab354af","modified":1496391322000},{"_id":"themes/next/languages/en.yml","hash":"e7def07a709ef55684490b700a06998c67f35f39","modified":1496391322000},{"_id":"themes/next/languages/id.yml","hash":"2835ea80dadf093fcf47edd957680973f1fb6b85","modified":1496391322000},{"_id":"themes/next/languages/ja.yml","hash":"1c3a05ab80a6f8be63268b66da6f19da7aa2c638","modified":1496391322000},{"_id":"themes/next/languages/fr-FR.yml","hash":"24180322c83587a153cea110e74e96eacc3355ad","modified":1496391322000},{"_id":"themes/next/languages/ko.yml","hash":"be150543379150f78329815af427bf152c0e9431","modified":1496391322000},{"_id":"themes/next/languages/pt-BR.yml","hash":"958e49571818a34fdf4af3232a07a024050f8f4e","modified":1496391322000},{"_id":"themes/next/languages/pt.yml","hash":"36c8f60dacbe5d27d84d0e0d6974d7679f928da0","modified":1496391322000},{"_id":"themes/next/languages/ru.yml","hash":"1549a7c2fe23caa7cbedcd0aa2b77c46e57caf27","modified":1496391322000},{"_id":"themes/next/languages/zh-hk.yml","hash":"1c917997413bf566cb79e0975789f3c9c9128ccd","modified":1496391322000},{"_id":"themes/next/languages/zh-tw.yml","hash":"0b2c18aa76570364003c8d1cd429fa158ae89022","modified":1496391322000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"3c0c7dfd0256457ee24df9e9879226c58cb084b5","modified":1496394066000},{"_id":"themes/next/layout/_layout.swig","hash":"98910163f4bb2856692fdbb55d6e82233fb0c24e","modified":1496391322000},{"_id":"themes/next/layout/archive.swig","hash":"5de4dca06b05d99e4f6bad617a4b8f4f3592fb01","modified":1496391322000},{"_id":"themes/next/layout/category.swig","hash":"82e7bc278559b4335ad974659104eaaf04863032","modified":1496391322000},{"_id":"themes/next/layout/index.swig","hash":"03e8a2cda03bad42ac0cb827025eb81f95d496a2","modified":1496391322000},{"_id":"themes/next/layout/post.swig","hash":"2d5f8d7f0a96b611e2d5a5e4d111fc17726a990f","modified":1496391322000},{"_id":"themes/next/layout/page.swig","hash":"baa667bc801349d5c4984c0f172973d3780400df","modified":1496391322000},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1496391322000},{"_id":"themes/next/layout/tag.swig","hash":"2e73ee478e981092ea9a5d10dd472a9461db395b","modified":1496391322000},{"_id":"themes/next/layout/schedule.swig","hash":"f93c53f6fd5c712584f6efba6f770c30fa8a3e80","modified":1496391322000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1496391322000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1496391322000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1496391322000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1496391322000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1496391322000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1496391322000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1496391322000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1496391322000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"b16fcbf0efd20c018d7545257a8533c497ea7647","modified":1496391322000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1496391322000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"a2b213c1a7c37cd6e4749f2018371f4c1f4f0d23","modified":1496391322000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1496391322000},{"_id":"themes/next/layout/_macro/post.swig","hash":"9481f43ed356e00df7b519e92ad0becebc9e1505","modified":1496391322000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"1c7d3c975e499b9aa3119d6724b030b7b00fc87e","modified":1496558249000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1496391322000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6a7eb93d8aa7d4baa472890bd666b921f449d8af","modified":1496391322000},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1496391322000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1496391322000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1496391322000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1496391322000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1496391322000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1496391322000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9baf90f7c40b3b10f288e9268c3191e895890cea","modified":1496391322000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1496391322000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1496391322000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1496391322000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1496391322000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1496391322000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1496391322000},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1496391322000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1496391322000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1496391322000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1496391322000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1496391322000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1496391322000},{"_id":"themes/next/scripts/tags/note.js","hash":"21b102db8a01c7b15ae2c0ea3ef3d4cf807ec6ed","modified":1496391322000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1496391322000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1496391322000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1496391322000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1496391322000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1496391322000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1496391322000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1496391322000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1496391322000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1496391322000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1496391322000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1496391322000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1496391322000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1496391322000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1496391322000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1496391322000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1496391322000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1496391322000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1496391322000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1496391322000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1496391322000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1496391322000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1496391322000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1496391322000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1496391322000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1496391322000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1496391322000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1496391322000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1496391322000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1496391322000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1496391322000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1496391322000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1496391322000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"3358d11b9a26185a2d36c96049e4340e701646e4","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1496391322000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1496391322000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1496391322000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1496391322000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1496391322000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1496391322000},{"_id":"themes/next/layout/_third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1496391322000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"abb92620197a16ed2c0775edf18a0f044a82256e","modified":1496558328000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"1d0d01aaeb7bcde3671263d736718f8837c20182","modified":1496391322000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"af9dd8a4aed7d06cf47b363eebff48850888566c","modified":1496391322000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1496391322000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1496391322000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1496391322000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"1f349aa30dd1f7022f7d07a1f085eea5ace3f26d","modified":1496391322000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1496391322000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1496391322000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1496391322000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1496391322000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"06f432f328a5b8a9ef0dbd5301b002aba600b4ce","modified":1496391322000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d6a793bcada68d4b6c58392546bc48a482e4a7d3","modified":1496391322000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1496391322000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1496391322000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1496391322000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1496391322000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1496391322000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1496391322000},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1496391322000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1496391322000},{"_id":"themes/next/source/js/src/post-details.js","hash":"af7a417dd1cb02465a7b98211653e7c6192e6d55","modified":1496391322000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1496391322000},{"_id":"themes/next/source/js/src/utils.js","hash":"b2ea56de27fddc6d9118051da384f781cd93951d","modified":1496391322000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1496391322000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1496391322000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"3587602ad777b031628bb5944864d1a4fcfea4ac","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1496391322000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1496391322000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1496391322000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1496391322000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1496391322000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1496391322000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1496391322000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1496391322000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1496391322000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1496391322000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1496391322000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1496391322000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1496391322000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1496391322000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1496391322000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1496391322000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1496391322000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1496391322000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1496391322000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1496391322000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1496391322000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1496391322000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1496391322000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"59ad08bcc6fe9793594869ac2b4c525021453e78","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"ef089a407c90e58eca10c49bc47ec978f96e03ba","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1496391322000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1496391322000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"7804e31c44717c9a9ddf0f8482b9b9c1a0f74538","modified":1496391322000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1496391322000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1496391322000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1496391322000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1496391322000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1496391322000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1496391322000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"d9c0b3dc9158e717fde36f554709e6c3a22b5f85","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1496391322000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1496391322000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1496391322000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1496391322000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1496391322000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"38e48f275ad00daa9dcdcb8d9b44e576acda4707","modified":1496391322000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1496391322000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"740d37f428b8f4574a76fc95cc25e50e0565f45e","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"88c7d75646b66b168213190ee4cd874609afd5e3","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"ed88c8b51d0517759c777e71a6bfbe2907bcd994","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"08a500b2984f109b751f3697ca33172d1340591a","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-wordcount.styl","hash":"4fda5d38c6c8d910e3bf5c74a48a8d4a3f3dc73d","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"468bc734f47209096588ef1a8e55e60a3b12aa63","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a2ec22ef4a6817bbb2abe8660fcd99fe4ca0cc5e","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"dd310c2d999185e881db007360176ee2f811df10","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1496391322000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"bb3be8374c31c372ed0995bd8030d2b920d581de","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1496391322000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1496391322000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1496391322000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1496391322000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1496391322000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1496391322000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1496391322000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1496391322000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1496391322000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1496391322000},{"_id":"public/atom.xml","hash":"8030448fb81d56080426e6c8db71c814ed73ae40","modified":1502248457783},{"_id":"public/content.json","hash":"185bb1beefa03408b8f00b89b1d69e3589a6a552","modified":1502248457832},{"_id":"public/search.xml","hash":"05de5a79a1aa57c772d693961480835e2b43848f","modified":1502248457832},{"_id":"public/categories/index.html","hash":"ad0c85fdf88bd035ce9fc129a327337c59e45143","modified":1502248457851},{"_id":"public/tags/index.html","hash":"dbdc8d98b95e03475e2dfdff29a0b26423130709","modified":1502248457851},{"_id":"public/2017/08/04/mysql误删除表恢复/index.html","hash":"f28bcca659fcf25645ab9c6053c4589e336c87fb","modified":1502248457851},{"_id":"public/2017/08/02/MySQL问题查找-状态查看/index.html","hash":"7ed970695a7037b1e6264adb62a13b3ccbe1f37d","modified":1502248457851},{"_id":"public/2017/07/20/nginx之请求限流限速问题/index.html","hash":"d667b7e43668a17a752dd314e93f1f393cf4ba31","modified":1502248457851},{"_id":"public/2017/07/18/socket解读/index.html","hash":"cea35253e9f1e8d35e7f4ed3cabfa573c6984e67","modified":1502248457851},{"_id":"public/2017/07/13/MySQL使用记录/index.html","hash":"95e408327efa190d0d6323de5faa586fbb715a7e","modified":1502248457851},{"_id":"public/2017/07/13/uwsgi笔记/index.html","hash":"820a19701429295ff181b0fa92fca309aea93c39","modified":1502248457851},{"_id":"public/2017/07/12/记录主机history/index.html","hash":"c4abb56a82ea21196fc1581671b6a228367f4221","modified":1502248457851},{"_id":"public/2017/07/11/ucloud-API使用/index.html","hash":"0a3c3383795f0f05f6bf9ed7a17ecebe20e6821b","modified":1502248457851},{"_id":"public/2017/07/08/nginx之location-upstream-rewrite/index.html","hash":"f4935f892f4ccc6cb6030da3358a4a74cc00a971","modified":1502248457851},{"_id":"public/2017/07/07/nginx之HTTPS配置/index.html","hash":"5716d412a7c34ffe3ef96372770bda14b9261dc7","modified":1502248457851},{"_id":"public/2017/07/06/influxdb使用笔记/index.html","hash":"71b22958ba8e9be9684591ea79c995c2fa2a7cc7","modified":1502248457851},{"_id":"public/2017/07/06/nginx之安装配置/index.html","hash":"c0c478382ffff65e28180780c1ddad897e95feb2","modified":1502248457852},{"_id":"public/2017/07/05/记一次PHP服务部署/index.html","hash":"3a6f268300d0c35f381cce5dcd4eadc4dbdca0ba","modified":1502248457852},{"_id":"public/2017/06/30/Git使用总结/index.html","hash":"b0fb378b8e18865d27ee43adf0d99290ff69943e","modified":1502248457852},{"_id":"public/2017/06/27/javascripts记录/index.html","hash":"e82d3ec6d199c94a136527c1d1de235bf308d40d","modified":1502248457852},{"_id":"public/2017/06/27/HTML-CSS/index.html","hash":"139df28b62dc5eb208b8d8d43cb814c9604d42f2","modified":1502248457852},{"_id":"public/2017/06/25/openvpn安装/index.html","hash":"dba7126ba4ab87ce422a1eda14da4245a6dc4377","modified":1502248457852},{"_id":"public/2017/06/25/shell脚本检测硬盘/index.html","hash":"0c06b007532e2cf29380bbaf7582684ea54c7944","modified":1502248457852},{"_id":"public/2017/06/25/shell脚本自动安装zabbix-agent/index.html","hash":"aac9fc831237cbadeddc2aa86d84f5cf91c47e63","modified":1502248457852},{"_id":"public/2017/06/23/docker命令/index.html","hash":"a909dcd095d613e4645d12422fb78709d071d445","modified":1502248457852},{"_id":"public/2017/06/23/docker是什么/index.html","hash":"ca2e402c0d28d3cf9f8804c8575401b5246609b6","modified":1502248457852},{"_id":"public/2017/06/23/shell命令之xargs与exec/index.html","hash":"904df02d4aa2198207460d46c080a0ef36c8e840","modified":1502248457852},{"_id":"public/2017/06/21/效率神器Alfred使用/index.html","hash":"404442b38005199d1f89447b0accab5e4dd786c9","modified":1502248457852},{"_id":"public/2017/06/16/几种mysql迁移/index.html","hash":"60e604ebb5f26a7c16b58bd92920cb4c36a3ad28","modified":1502248457852},{"_id":"public/2017/06/16/rpm包制作/index.html","hash":"2a72b38dffc550d5fcf2daf87423165b172e98d7","modified":1502248457852},{"_id":"public/2017/06/16/curl查看接口各阶段响应时间/index.html","hash":"78c5c297442df0ea247d76c45d5ab0451ae16f53","modified":1502248457852},{"_id":"public/2017/06/15/Logstash优化/index.html","hash":"9cff47d2af35e95a59961467435bc30465a9a08f","modified":1502248457852},{"_id":"public/2017/06/14/Django之入门学习/index.html","hash":"11a97a152c1deadf0f3bb2e8da3321153ac31bb6","modified":1502248457853},{"_id":"public/2017/06/13/Blog收藏/index.html","hash":"ad8c78cbb7964f65b821d8a1096025b37a4a207b","modified":1502248457853},{"_id":"public/2017/06/12/uwsgi-worker监控脚本/index.html","hash":"d5088f62fa16978c6cc9c6f891ce1c85947374a1","modified":1502248457853},{"_id":"public/2017/06/09/运维工具之sar命令/index.html","hash":"52f662eb60cd1edc24e11fcdcf9b9518f2ec624d","modified":1502248457853},{"_id":"public/2017/06/08/falcon问题处理/index.html","hash":"d2ead81885d368f41b483be1433a69a421efae7c","modified":1502248457853},{"_id":"public/2017/06/08/sublime使用/index.html","hash":"4b06d1d517b106e34268cb3f39a724af12066241","modified":1502248457853},{"_id":"public/2017/06/06/zabbix迁移到open-falcon/index.html","hash":"083edca476fba9777a03d31244649bd6e37150b3","modified":1502248457853},{"_id":"public/2017/06/06/Mac软件使用/index.html","hash":"e96ac695141b52cbe58e909e4ccb0cdf6085114d","modified":1502248457853},{"_id":"public/2017/06/06/lsof十几个实例/index.html","hash":"985ef832ddc9672744c5a321ffb283e1aa119e6c","modified":1502248457853},{"_id":"public/2017/06/06/file-beat接入ELK/index.html","hash":"32ee68ac4fbe92dd5c38f5eed5c9cf5585339cc9","modified":1502248457853},{"_id":"public/2017/06/06/Elasticsearch调优实战过程/index.html","hash":"18d3ebd7f591770e1362f73f65da5deea7855453","modified":1502248457853},{"_id":"public/2017/06/05/ELK问题处理汇总/index.html","hash":"1ce7247b76f581a2a03accaeb2a04ec7870e70f0","modified":1502248457853},{"_id":"public/2017/06/05/ELK搭建/index.html","hash":"b0619fbc6f0ba5ce30ab8ce13fa82a0130da725c","modified":1502248457853},{"_id":"public/2017/06/05/ElasticSearch之template,mapping,setting修改/index.html","hash":"4db1c5b2e7f9e2e74a8041a9442c41f120ca943b","modified":1502248457853},{"_id":"public/2017/06/03/Mac-gihub-pages-hexo搭建博客/index.html","hash":"33c0d2fc2965d22e16d1d064e02e3fcc93536ee4","modified":1502248457853},{"_id":"public/2016/08/03/PXE网络引导批量安装操作系统/index.html","hash":"1cd78de18a2ce8bfae3b468747c0219790cd69ed","modified":1502248457853},{"_id":"public/archives/index.html","hash":"eaf4aab7fcfa315fd072a6dcde530bd4336b9666","modified":1502248457853},{"_id":"public/archives/page/2/index.html","hash":"3c85b3b9a97523382ded9177bc372f85989615c9","modified":1502248457854},{"_id":"public/archives/page/3/index.html","hash":"8d222162cb7d7589401122db84bba03773aca4d8","modified":1502248457854},{"_id":"public/archives/page/4/index.html","hash":"ef4c6e7ff47690d6dfeebd0da516e813aaf417cc","modified":1502248457854},{"_id":"public/archives/page/5/index.html","hash":"1035a6cc90df3a8d3f0bb93e153bcec1c81937ea","modified":1502248457854},{"_id":"public/archives/2016/index.html","hash":"b94d314d20025ee54d01fb2f88b001bf275bcf57","modified":1502248457854},{"_id":"public/archives/2016/08/index.html","hash":"430566efbbd04b581c013a69ee4e5b1385017d2b","modified":1502248457854},{"_id":"public/archives/2017/index.html","hash":"ed2a0cbcff628b5403475af0213ab4bcd1360913","modified":1502248457854},{"_id":"public/archives/2017/page/2/index.html","hash":"d7ad44fc099e39bfa1e97b344f74b8c5046a804d","modified":1502248457854},{"_id":"public/archives/2017/page/3/index.html","hash":"61920dca1b3a794bb1f2d8f104a40fa2cac65541","modified":1502248457854},{"_id":"public/archives/2017/page/4/index.html","hash":"76e580574794085e132169a3ef9b42d233bd755f","modified":1502248457854},{"_id":"public/archives/2017/page/5/index.html","hash":"4e6bc8de5c280d33c89126545c6f73c5d547d753","modified":1502248457854},{"_id":"public/archives/2017/06/index.html","hash":"0d8da1c7b27620bbf98a7e9537ae2cbc683d9546","modified":1502248457855},{"_id":"public/archives/2017/06/page/2/index.html","hash":"da1975386f092ce12502759b42ad748fa7591003","modified":1502248457855},{"_id":"public/archives/2017/06/page/3/index.html","hash":"b8775c85f5688cb4ae43bb8099f2ebe19b57d8af","modified":1502248457855},{"_id":"public/archives/2017/07/index.html","hash":"834bf457a29c079787e617411ffd1a052c787fe9","modified":1502248457855},{"_id":"public/archives/2017/07/page/2/index.html","hash":"1373a98624ff8af415a3a9d8c545dab83eba6821","modified":1502248457855},{"_id":"public/archives/2017/08/index.html","hash":"f7647f73430fdc278a4e8d3f9e93ae57a309b30d","modified":1502248457855},{"_id":"public/categories/运维工具/index.html","hash":"3e4c358ca94f72ed908e042399a28c466638f1cf","modified":1502248457855},{"_id":"public/categories/Django/index.html","hash":"3df7837cae8abcab8f70216e63ff5e3d0b55234f","modified":1502248457855},{"_id":"public/categories/前端/index.html","hash":"285f8f337a73b0a75e133da6763ded020f940012","modified":1502248457855},{"_id":"public/categories/基础运维/index.html","hash":"33f9dbb86e6f57c05d81b108dfbc27b9ceb1b948","modified":1502248457855},{"_id":"public/categories/基础运维/page/2/index.html","hash":"8eba602c929cf7677533ec80619d1e7023f48fda","modified":1502248457855},{"_id":"public/categories/hexo/index.html","hash":"ca784abc81f505f4748f9c60598b3e92a2f08a15","modified":1502248457855},{"_id":"public/categories/git/index.html","hash":"a527dee19864e614fabcaf4ea175c48ee13bda14","modified":1502248457855},{"_id":"public/categories/数据库/index.html","hash":"79c18b7e68d09aeb2980ff5dfb771258c9b8c93a","modified":1502248457855},{"_id":"public/categories/docker/index.html","hash":"b9ceed3a4634b3250801e5c30ceb8b4365699eb1","modified":1502248457855},{"_id":"public/categories/监控/index.html","hash":"fd531fe0a23d35771cbaeacad48232ac93f36b86","modified":1502248457855},{"_id":"public/categories/influxdb/index.html","hash":"4c6e8c15a4b33d73b2c5f5dea28e0e1d8763ef47","modified":1502248457855},{"_id":"public/categories/shell/index.html","hash":"6cc5cdcb2aaf514bd5c60de7474e7a00e90c3a56","modified":1502248457855},{"_id":"public/categories/脚本/index.html","hash":"04ed6aef94433fcbc7b13170ee3578e60fc7b7fb","modified":1502248457855},{"_id":"public/categories/python/index.html","hash":"e396ae0b73a06e903ca3b5f6224ae898d8a0cd3e","modified":1502248457855},{"_id":"public/index.html","hash":"06576bd7cfddf5e7a3bca6bd574c92f89a441458","modified":1502248457855},{"_id":"public/page/2/index.html","hash":"0cd75b68dc33b4df33cdbcd799b0b514fd957736","modified":1502248457855},{"_id":"public/page/3/index.html","hash":"e8f0dcb41bc1298cbf2c488129b4249d9bd3bca5","modified":1502248457855},{"_id":"public/page/4/index.html","hash":"5050067a8d0a4e42efac410982d328af2c070319","modified":1502248457855},{"_id":"public/page/5/index.html","hash":"0dc802da6b2e81dc90cb1dd97e8b8c6d9c0688cc","modified":1502248457855},{"_id":"public/tags/ELK/index.html","hash":"ecbc8b815b00f9822f107e923cf568001b3d4add","modified":1502248457856},{"_id":"public/tags/Django/index.html","hash":"cbb3c152cf9b9a6c52503ca093bb8e408e4f114e","modified":1502248457856},{"_id":"public/tags/HTML-CSS/index.html","hash":"90ab82606fb296e55cab027703f4ebfeab1e27e4","modified":1502248457856},{"_id":"public/tags/ElasticSearch/index.html","hash":"3cd8c3a712359a96db1d93f69752edb57bbc2729","modified":1502248457856},{"_id":"public/tags/ELK-logstash/index.html","hash":"44456ad3af634a5499be1a7155bdfd1b01513d88","modified":1502248457856},{"_id":"public/tags/hexo/index.html","hash":"47459f039ecc8bbec37e00863134c3903af1b5d5","modified":1502248457856},{"_id":"public/tags/Mac/index.html","hash":"856dfae87c86caa1539112ca2af19809b66bdb58","modified":1502248457856},{"_id":"public/tags/git/index.html","hash":"161e8c156ade35f301a915e0b1060dfc50ce3e40","modified":1502248457856},{"_id":"public/tags/MySQL/index.html","hash":"39860752942947f01b73420910dcddbdb8e971ec","modified":1502248457856},{"_id":"public/tags/mysql/index.html","hash":"c5c60dfb17145eaf0bb6d93935a6f05c9433e03f","modified":1502248457856},{"_id":"public/tags/PXE/index.html","hash":"7c5eaa6f5f770d5fe4f1d5048e8004f2f5ec9bb8","modified":1502248457856},{"_id":"public/tags/curl/index.html","hash":"e330d4a81e9f3fc4c6e557c667c198264dafad71","modified":1502248457856},{"_id":"public/tags/docker/index.html","hash":"64062c4f7e51808303c6b2e5e23160a54dc25fc2","modified":1502248457856},{"_id":"public/tags/falcon-监控/index.html","hash":"ac6f87159c28e66480580b925eee8ed87e5538cc","modified":1502248457856},{"_id":"public/tags/javascripts/index.html","hash":"15162fa4e38019165aa41685019c2a6398061558","modified":1502248457856},{"_id":"public/tags/ELK-filebeat-kafka/index.html","hash":"cb1d56d8d199f9d7924d3fa81c7e51636f9cb0a0","modified":1502248457856},{"_id":"public/tags/nginx/index.html","hash":"7e802f97e34fb37150e4f9d9475fd0984cd72406","modified":1502248457856},{"_id":"public/tags/influxdb/index.html","hash":"6dd6f277a3c54c7641c96b4e817bc736233ea65e","modified":1502248457856},{"_id":"public/tags/lsof/index.html","hash":"d29d28d63aef7c6b4f7aaaa6e711ff4af4d41a57","modified":1502248457856},{"_id":"public/tags/rpm/index.html","hash":"923871d0662db5b8cd024b0ba48979c16fd28d0f","modified":1502248457857},{"_id":"public/tags/openvpn/index.html","hash":"09f89f5164b12f48c225f281fb07659abd6d1b39","modified":1502248457857},{"_id":"public/tags/shell-脚本/index.html","hash":"1b1bc2e2a7d6968053a1e924c06d6e0117a33775","modified":1502248457857},{"_id":"public/tags/shell/index.html","hash":"f18e2ee251a9d35d2a3c8e73e3aa9d22ba3438cd","modified":1502248457857},{"_id":"public/tags/socket/index.html","hash":"fcd0ace2d85d459b375cbea541c1418da22cc940","modified":1502248457857},{"_id":"public/tags/sublime/index.html","hash":"1ef783575edf3e78e02b02f05b2262d253a04cd7","modified":1502248457857},{"_id":"public/tags/scripts-监控/index.html","hash":"9cb47891e13eef6d2efcbc0713a2967984a6b898","modified":1502248457857},{"_id":"public/tags/uwsgi/index.html","hash":"5f6057cf7c1542be35c25c533f915a907194e704","modified":1502248457857},{"_id":"public/tags/python/index.html","hash":"5aab26776af7b013fc71de9ff5f7f3c5c05099fa","modified":1502248457857},{"_id":"public/tags/sar/index.html","hash":"b1f59c3d91fc2809e76fa686356a2858cc127bfe","modified":1502248457857},{"_id":"public/tags/bash/index.html","hash":"05c0a1e13b7a356614987cdaa1bcf3bfc408bd01","modified":1502248457857},{"_id":"public/tags/PHP/index.html","hash":"f433784c1a9d39ececbe1f8ff833b9137a83ea24","modified":1502248457857},{"_id":"public/uploads/fanquanqing.jpg","hash":"f8d92148cd2f8c1e3bdf5f1a29dd91b0a6133fea","modified":1502248457870},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1502248457870},{"_id":"public/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1502248457870},{"_id":"public/uploads/wechat.png","hash":"b97c6aaf275e06d0fdd5e50954310b267170e5aa","modified":1502248457871},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1502248457871},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1502248457871},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1502248457871},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1502248457871},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1502248457871},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1502248457871},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1502248457871},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1502248457871},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1502248457871},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1502248457871},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1502248457871},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1502248457871},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1502248457871},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1502248457874},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1502248457874},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1502248457874},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1502248457875},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1502248457875},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1502248457875},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1502248457875},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1502248457875},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1502248457875},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1502248457875},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1502248457875},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1502248457875},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1502248457875},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1502248458762},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1502248458770},{"_id":"public/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1502248458787},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1502248458787},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1502248458787},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1502248458787},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1502248458787},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1502248458787},{"_id":"public/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1502248458787},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1502248458787},{"_id":"public/js/src/post-details.js","hash":"af7a417dd1cb02465a7b98211653e7c6192e6d55","modified":1502248458787},{"_id":"public/js/src/utils.js","hash":"b2ea56de27fddc6d9118051da384f781cd93951d","modified":1502248458787},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1502248458787},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1502248458788},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1502248458788},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"3587602ad777b031628bb5944864d1a4fcfea4ac","modified":1502248458788},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1502248458788},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1502248458788},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1502248458788},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1502248458788},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1502248458788},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1502248458788},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1502248458788},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1502248458788},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1502248458788},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1502248458788},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1502248458788},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1502248458789},{"_id":"public/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1502248458789},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1502248458789},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1502248458789},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1502248458789},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1502248458789},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1502248458789},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1502248458789},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1502248458789},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1502248458789},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1502248458789},{"_id":"public/css/main.css","hash":"12e25daab77b9cbd8c355c0681344d6128314900","modified":1502248458790},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1502248458790},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1502248458790},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1502248458790},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1502248458790},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1502248458790},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1502248458790},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1502248458790},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1502248458790},{"_id":"public/lib/Han/dist/han.min.css","hash":"d9c0b3dc9158e717fde36f554709e6c3a22b5f85","modified":1502248458790},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1502248458790},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1502248458790},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1502248458790},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1502248458790},{"_id":"public/lib/Han/dist/han.css","hash":"38e48f275ad00daa9dcdcb8d9b44e576acda4707","modified":1502248458790},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1502248458791},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1502248458791},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1502248458791},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1502248458791},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1502248458791},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1502248458791},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1502248458792},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1502248458828}],"Category":[{"name":"运维工具","_id":"cj64fxv4q00038tzzpsq5ggav"},{"name":"Django","_id":"cj64fxv5300088tzznli09y2y"},{"name":"前端","_id":"cj64fxv5e000l8tzz8zvdoiop"},{"name":"基础运维","_id":"cj64fxv5i000r8tzzybcucdgw"},{"name":"hexo","_id":"cj64fxv5n000y8tzzu5xxkjo0"},{"name":"git","_id":"cj64fxv5t00158tzztgyp0ys5"},{"name":"数据库","_id":"cj64fxv5w001b8tzz3afcjqsq"},{"name":"docker","_id":"cj64fxv5x001j8tzzt3h3inef"},{"name":"监控","_id":"cj64fxv5y001n8tzzisceexlh"},{"name":"influxdb","_id":"cj64fxvbe002i8tzzjaxs1amo"},{"name":"shell","_id":"cj64fxvby00388tzzjq3o2uz1"},{"name":"脚本","_id":"cj64fxvc9003n8tzzgrs5wnwm"},{"name":"python","_id":"cj64fxvch00408tzznf0hywjn"}],"Data":[],"Page":[{"title":"分类","date":"2017-06-03T14:17:53.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2017-06-03 22:17:53\ntype: \"categories\"\n---\n","updated":"2017-06-03T14:35:17.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cj64fxvb000288tzzbvuqbm1h","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2017-06-03T14:29:35.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-06-03 22:29:35\ntype: tags\n---\n","updated":"2017-06-04T06:04:58.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cj64fxvb4002a8tzz7ffdit4d","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Blog收藏","date":"2017-06-13T09:34:37.000Z","_content":"以上的博客并无排名，只是随着自己发现的时间排序\n## 架构\n- [酷壳](http://coolshell.cn/)\n- [峰云](http://blog.xiaorui.cc/)\n- [徐亮偉架构师之路](http://www.xuliangwei.com/)\n\n## 运维\n- [流水理鱼](https://www.iamle.com/)\n- [pmars](http://www.xiaoh.me/) \n- [reboot](http://blog.51reboot.com/)\n- [阿小信的博客](http://axiaoxin.com/)\n\n## 安全\n- [离别歌](https://www.leavesongs.com/)\n\n## 前端\n\n- [进击的马斯特](http://pinkyjie.com/)\n\n- [Jerry Qu](https://imququ.com/)\n\n## python\n- [alex](http://www.cnblogs.com/alex3714/)\n\n\n\n## 系统管理员资源大全\n- [系统管理员资源大全](https://my.oschina.net/HeAlvin/blog/378262)\n","source":"_posts/Blog收藏.md","raw":"---\ntitle: Blog收藏\ndate: 2017-06-13 17:34:37\ntags: \n---\n以上的博客并无排名，只是随着自己发现的时间排序\n## 架构\n- [酷壳](http://coolshell.cn/)\n- [峰云](http://blog.xiaorui.cc/)\n- [徐亮偉架构师之路](http://www.xuliangwei.com/)\n\n## 运维\n- [流水理鱼](https://www.iamle.com/)\n- [pmars](http://www.xiaoh.me/) \n- [reboot](http://blog.51reboot.com/)\n- [阿小信的博客](http://axiaoxin.com/)\n\n## 安全\n- [离别歌](https://www.leavesongs.com/)\n\n## 前端\n\n- [进击的马斯特](http://pinkyjie.com/)\n\n- [Jerry Qu](https://imququ.com/)\n\n## python\n- [alex](http://www.cnblogs.com/alex3714/)\n\n\n\n## 系统管理员资源大全\n- [系统管理员资源大全](https://my.oschina.net/HeAlvin/blog/378262)\n","slug":"Blog收藏","published":1,"updated":"2017-08-08T07:52:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv4g00008tzzj4l4r8ff","content":"<p>以上的博客并无排名，只是随着自己发现的时间排序</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><ul>\n<li><a href=\"http://coolshell.cn/\" target=\"_blank\" rel=\"external\">酷壳</a></li>\n<li><a href=\"http://blog.xiaorui.cc/\" target=\"_blank\" rel=\"external\">峰云</a></li>\n<li><a href=\"http://www.xuliangwei.com/\" target=\"_blank\" rel=\"external\">徐亮偉架构师之路</a></li>\n</ul>\n<h2 id=\"运维\"><a href=\"#运维\" class=\"headerlink\" title=\"运维\"></a>运维</h2><ul>\n<li><a href=\"https://www.iamle.com/\" target=\"_blank\" rel=\"external\">流水理鱼</a></li>\n<li><a href=\"http://www.xiaoh.me/\" target=\"_blank\" rel=\"external\">pmars</a> </li>\n<li><a href=\"http://blog.51reboot.com/\" target=\"_blank\" rel=\"external\">reboot</a></li>\n<li><a href=\"http://axiaoxin.com/\" target=\"_blank\" rel=\"external\">阿小信的博客</a></li>\n</ul>\n<h2 id=\"安全\"><a href=\"#安全\" class=\"headerlink\" title=\"安全\"></a>安全</h2><ul>\n<li><a href=\"https://www.leavesongs.com/\" target=\"_blank\" rel=\"external\">离别歌</a></li>\n</ul>\n<h2 id=\"前端\"><a href=\"#前端\" class=\"headerlink\" title=\"前端\"></a>前端</h2><ul>\n<li><p><a href=\"http://pinkyjie.com/\" target=\"_blank\" rel=\"external\">进击的马斯特</a></p>\n</li>\n<li><p><a href=\"https://imququ.com/\" target=\"_blank\" rel=\"external\">Jerry Qu</a></p>\n</li>\n</ul>\n<h2 id=\"python\"><a href=\"#python\" class=\"headerlink\" title=\"python\"></a>python</h2><ul>\n<li><a href=\"http://www.cnblogs.com/alex3714/\" target=\"_blank\" rel=\"external\">alex</a></li>\n</ul>\n<h2 id=\"系统管理员资源大全\"><a href=\"#系统管理员资源大全\" class=\"headerlink\" title=\"系统管理员资源大全\"></a>系统管理员资源大全</h2><ul>\n<li><a href=\"https://my.oschina.net/HeAlvin/blog/378262\" target=\"_blank\" rel=\"external\">系统管理员资源大全</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>以上的博客并无排名，只是随着自己发现的时间排序</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><ul>\n<li><a href=\"http://coolshell.cn/\" target=\"_blank\" rel=\"external\">酷壳</a></li>\n<li><a href=\"http://blog.xiaorui.cc/\" target=\"_blank\" rel=\"external\">峰云</a></li>\n<li><a href=\"http://www.xuliangwei.com/\" target=\"_blank\" rel=\"external\">徐亮偉架构师之路</a></li>\n</ul>\n<h2 id=\"运维\"><a href=\"#运维\" class=\"headerlink\" title=\"运维\"></a>运维</h2><ul>\n<li><a href=\"https://www.iamle.com/\" target=\"_blank\" rel=\"external\">流水理鱼</a></li>\n<li><a href=\"http://www.xiaoh.me/\" target=\"_blank\" rel=\"external\">pmars</a> </li>\n<li><a href=\"http://blog.51reboot.com/\" target=\"_blank\" rel=\"external\">reboot</a></li>\n<li><a href=\"http://axiaoxin.com/\" target=\"_blank\" rel=\"external\">阿小信的博客</a></li>\n</ul>\n<h2 id=\"安全\"><a href=\"#安全\" class=\"headerlink\" title=\"安全\"></a>安全</h2><ul>\n<li><a href=\"https://www.leavesongs.com/\" target=\"_blank\" rel=\"external\">离别歌</a></li>\n</ul>\n<h2 id=\"前端\"><a href=\"#前端\" class=\"headerlink\" title=\"前端\"></a>前端</h2><ul>\n<li><p><a href=\"http://pinkyjie.com/\" target=\"_blank\" rel=\"external\">进击的马斯特</a></p>\n</li>\n<li><p><a href=\"https://imququ.com/\" target=\"_blank\" rel=\"external\">Jerry Qu</a></p>\n</li>\n</ul>\n<h2 id=\"python\"><a href=\"#python\" class=\"headerlink\" title=\"python\"></a>python</h2><ul>\n<li><a href=\"http://www.cnblogs.com/alex3714/\" target=\"_blank\" rel=\"external\">alex</a></li>\n</ul>\n<h2 id=\"系统管理员资源大全\"><a href=\"#系统管理员资源大全\" class=\"headerlink\" title=\"系统管理员资源大全\"></a>系统管理员资源大全</h2><ul>\n<li><a href=\"https://my.oschina.net/HeAlvin/blog/378262\" target=\"_blank\" rel=\"external\">系统管理员资源大全</a></li>\n</ul>\n"},{"title":"ELK搭建","date":"2017-06-05T08:42:39.000Z","_content":"\n> 我来之前公司是有一套ELK服务的，但是不知道为何，没有推广起来，之前的运维都离职，原因不得而知，但是公司每天日志量还是挺大的分析起来十分费力，每天上完线之后有问题就得去机器上tail -f 各种grep  AWK sort 定位问题有点慢。另外考虑到所有的nginx_access,elapsed，filelog，searchlog等都被收集到Hadoop的Hbase中，所以我想从中间截一下，用logstash把日志收集到ES集群，然后通过kibana展示出来\n\n# 软件版本\n\n版本：（ELK版本相互很依赖，所以一定要注意看`README.txt` 不要做无用功）\n\n* Logstash：2.3.2\n* elasticsearch: 2.3.2\n* kibana: kibana-4.3.1-linux-x64\n\n[升级教程](http://jerrymin.blog.51cto.com/3002256/1927481)\n\n## 部署过程\n> 刚开始的架构比较简单，只是logstash + ES集群(三个节点) + kibana\n> \n## Elasticsearch部署\n\n### 解压到/usr/local/\n```\nunzip elasticsearch-2.3.2.zip -d /usr/local/\n```\n\n\n**插件安装**\n\n1. Elasticsearch插件安装方式（推荐）\n \n\n**head 插件安装**\nElasticSearch-Head 是一个与Elastic集群（Cluster）相交互的Web前台。\n\nES-Head的主要作用\n\n它展现ES集群的拓扑结构，并且可以通过它来进行索引（Index）和节点（Node）级别的操作\n它提供一组针对集群的查询API，并将结果以json和表格形式返回\n它提供一些快捷菜单，用以展现集群的各种状态\n\n在Elasticsearch目录下\n```\n./bin/plugin install mobz/elasticsearch-head\n\n```\n![](http://or2jd66dq.bkt.clouddn.com/elastic_head.png)\n**kopf 插件安装**\nKopf是一个ElasticSearch的管理工具，它也提供了对ES集群操作的API。\n\n\n```\ncd /usr/local/ELK/elasticsearch-2.3.2 && ./plugin install lmenezes/elasticsearch-kopf\n启动\nopen http://localhost:9200/_plugin/kopf\n\n```\n\n![](http://or2jd66dq.bkt.clouddn.com/elastic_kopf.png)\n\n插件访问方式\nhttp://localhost:9200/_plugin/head \nhttp://localhost:9200/_plugin/koph\n\n\n2. 下载安装方式\n\n从https://github.com/mobz/elasticsearch-head下载ZIP包。\n在 elasticsearch  目录下创建目录plugins/head/ 并且将刚刚解压的elasticsearch-head-master目录下所有内容COPY到当前创建的plugins/head/目录下即可。\n\n \n### 配置文件修改   \n\nnode1\n```\n17: cluster.name: cy_es_cluster           #集群名字（各节点一致）\n 23: node.name: node-1                    #节点名称\n 43: bootstrap.mlockall: true             #锁住内存\n 54: network.host: 10.***.1               #本机内网地址\n 58: http.port: 9200\n 60: http.cors.enrue\n 61: http.cors.allow-origin: \"/.*/\"\n 71: discovery.zen.ping.unicast.hosts: [\"10.***.1:9300\", “10.***.2:9300”, “10.***.3:9300\"]\n 75: discovery.zen.minimum_master_nodes: 2\n```\n\nnode2\n\n```\ngrep -n '^ [a-Z]' /usr/local/elasticsearch-2.3.2/config/elasticsearch.yml\n 17: cluster.name: cy_es_cluster           #集群名字（各节点一致）\n 23: node.name: node-2                     #节点名称\n 33: path.data: /data2/ES                 \n 37: path.logs: /data2/ES/logs          \n 43: bootstrap.mlockall: true              #锁住内存\n 54: network.host: 10.***.2                #本机内网地址\n 58: http.port: 9200                       #端口\n 60: http.cors.enabled: true               #kibana3 需要打开 kibana4忽略\n 61: http.cors.allow-origin: \"/.*/“        #kibana3 需要打开 kibana4忽略\n 73: discovery.zen.ping.unicast.hosts: [\"10.***.1:9300\", “10.***.2:9300”, “10.***.3:9300\"]  #集群discovery      \n 77: discovery.zen.minimum_master_nodes: 2   #最小集群节点数目\n```\n       \n新加node3在 ,配置一致\n    * 启动  nohup /usr/local/elasticsearch-2.3.2/bin/elasticsearch -Des.insecure.allow.root=true &\n    * 启动 systemctl start kibana.service\n    * 查看各节点启动情况 http://10.***.01:9200/_plugin/head/\n\n\n\n## logstash部署\n \n```   \ntar -zxvf  logstash-all-plugins-2.3.2.tar.gz -C /usr/local/\nvim /usr/local/logstash-2.3.2/conf/main.conf 修改配置文件 包括input filter output \n 配置文件详解\n input {\n         file {\n         path => \"/home/chunyu/backup/nginx_log/access.log-*\"   日志文件可以模糊匹配\n         type => “nginx_access\"                                                       类型 在后面output匹配用\n         ignore_older => 14400                                                          读取4小时之内文件\n         exclude => \"*.lzma\"                                                               不包括.lzma 结尾的文件\n          }\n }\n 注意在这遇到过匹配日志日期结尾的情况，例如test.2016-07-03-access.log 匹配为*.%{yyyy}-%{MM}-%{dd}-access.log反复不生效，遂采取ignore_older, 没有在官方找到匹配日期的方式。\n\n filter {\n if [type] == \"nginx_access\" {\n      grok {        \n           patterns_dir => \"/usr/local/logstash-2.3.2/patterns/nginx\"  指定grok匹配文件\n           match => {\n                     \"message\" => \"%{NGINXACCESS}\"\n           }\n           }\n       geoip {\n     source => \"clientip\"\n   }\n         }\n        }\n grok 正则表达式需要自己编写 对照nginx log format  和nginx具体日志在grok debugger中写完 粘贴到/usr/local/logstash/patterns/nginx中即可\n\n\noutput {\n    if [type] == \"nginx_access\" {\n     elasticsearch {\n              hosts => [\"10.***.01:9200\"]\n              index => \"logstash-nginx_access-%{+YYYY.MM.dd}\"\n             }\n         }\n         }\n```\noutput就是把logstash数据输出给elastic search 注意这个index 便是 kibana中setting要输入的\n\n### grok表达式\n> 注意，使用过程中有的情况会出现grok失效的情况，类似状态码为500 的时候或者某种情况，你所要过滤的字段在日志中是空的，可以使用“|”等提高容错性。\n以nginx_access.log实例\n(注意按照自己的日志format灵活变动)\n[grokdebug地址](http://grokdebug.herokuapp.com/)\n\nnginx_access.log 格式\n\n```\nlog_format main '$remote_addr - - [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" [$request_time, $upstream_response_time] $host ($remote_port) \"sid=$cookie_sessionid\"';\n```\n\n\n对应grok表达式\n```\nNGINXACCESS %{IPORHOST:clientip} - - \\[%{HTTPDATE:time_local}\\] \\\"%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:status:float} %{NUMBER:body_bytes_sent:float}\\ (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} \\[%{NUMBER:request_time:float}\\, (%{NUMBER:upstream_response_time:float}|-)] %{IPORHOST:host} \\(%{NUMBER:remote_port}\\) %{QS}\n```\n\n## kibana 部署 \n\ntar -zxvf kibana-4.1.1-linux-x64.tar.gz -C /usr/local/\ngrep -n \"^ [a-Z]\" /usr/local/ELK/kibana-4.3.1-linux-x64/config/kibana.yml\n          12: elasticsearch.url: \"http://10.***.1:9200” 只需要输入elastic search地址 端口 即可\n\n启动 nohup /usr/local/ELK/kibana-4.3.1-linux-x64/bin/kibana &\n登录 10.215.33.36:5601通过—>settings设置index —>查看discovery —>制作visualize —>设置dashboard 达到日志可视化\n\n![图表显示](http://or2jd66dq.bkt.clouddn.com/kibana%E5%9B%BE%E8%A1%A8%E6%98%BE%E7%A4%BA.png)\n\n## 问题处理\n\n1. **地图配置**\nkibana地图配置：\n默认的地图不能显示，所以我们换成了高德地图\n先下载GeoIP库\n```\nwget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz\ngunzip GeoLiteCity.dat.gz\n```\nvim conf/main.conf 添加下图内容\n\n![](http://or2jd66dq.bkt.clouddn.com/logs_map_logstash_conf.png)\n\n\n重启logstash\n\nkibana修改\n```\nvim ./src/ui/public/vislib/visualizations/_map.js +11 \n注释  url: 'https://otile{s}-s.mqcdn.com/tiles/1.0.0/map/{z}/{x}/{y}.jpeg',\n添加  url: 'http://webrd0{s}.is.autonavi.com/appmaptile?lang=zh_cn&size=1&scale=1&style=7&x={x}&y={y}&z={z}',   （style=6为卫星地图7为普通地图）\nvim ./src/ui/autoload.js +35\n末尾 添加  'ui/vislib'\n重启kibana\n```\n之后打开logs.chunyu.me setting重置 但是还是没有地图显示，界面为白板，报错 \nGoogle一下需要改elastic search模板\n更改方法：打开 logstash  main.conf配置文件 需要把output 的index 改为logstash开头使用elasticsearch默认模板即可\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-15%20%E4%B8%8B%E5%8D%886.37.57.png)\n\n重启logstash\n效果图\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-15%20%E4%B8%8B%E5%8D%886.39.17.png)\n\n## lucene语法\n> ELK中，kibana或者grafana用来展示数据，Elasticsearch是搜索引擎也是存储中心，它是构建在Lucene之上的，所以过滤器语法和Lucene相同。\n\n\n版本：（ELK版本相互很依赖，所以一定要注意看README.txt 不要做无用功）\n\n* Logstash：2.3.2\n* elasticsearch: 2.3.2\n* kibana: kibana-4.3.1-linux-x64\n\n[参考链接1](https://kibana.logstash.es/content/elasticsearch/api/search.html)\n[参考链接2](https://segmentfault.com/a/1190000002972420)\n\n`全文搜索`\n500\n显示带有500 的内容\n\n`短语搜索`\n使用双引号包起来\n\"like Gecko\"\n\n`字段`\n\n也可以按页面左侧显示的字段搜索\n\n限定字段全文搜索:field:value\n\n`精确搜索`：关键字加上双引号 filed:\"value\"\n\nstatus:404 搜索http状态码为404的文档\n字段本身是否存在\n\n`_exists_`:http：返回结果中需要有http字段\n\n`_missing_`:http：不能含有http字段\n通配符\n\n? 匹配单个字符\n\n* 匹配0到多个字符\nkiba?a, el*search\n\n? * 不能用作第一个字符，例如：?text *text\n\n正则\n\nes支持部分正则功能\n\nmesg:/mes{2}ages?/\n模糊搜索\n\n~:在一个单词后面加上~启用模糊搜索\n\nfirst~ 也能匹配到 frist\n\n还可以指定需要多少相似度\n\ncromm~0.3 会匹配到 from 和 chrome\n\n数值范围0.0 ~ 1.0，默认0.5，越大越接近搜索的原始值\n近似搜索\n\n在短语后面加上~\n\n\"select where\"~3 表示 select 和 where 中间隔着3个单词以内\n范围搜索\n\n数值和时间类型的字段可以对某一范围进行查询\n\nlength:[100 TO 200]\n\ndate:{\"now-6h\" TO \"now\"}\n\n[ ] 表示端点数值包含在范围内，{ } 表示端点数值不包含在范围内\n逻辑操作\n\nAND\n\nOR\n\nNOT\n+：搜索结果中必须包含此项\n\n-：不能含有此项\n+android -OPPO 包含android 不包含OPPO \n+apache -jakarta test：结果中必须存在apache，不能有jakarta，test可有可无 \n\n","source":"_posts/ELK搭建.md","raw":"---\ntitle: ELK搭建\ndate: 2017-06-05 16:42:39\ntags: ELK \ncategories: 运维工具\n\n---\n\n> 我来之前公司是有一套ELK服务的，但是不知道为何，没有推广起来，之前的运维都离职，原因不得而知，但是公司每天日志量还是挺大的分析起来十分费力，每天上完线之后有问题就得去机器上tail -f 各种grep  AWK sort 定位问题有点慢。另外考虑到所有的nginx_access,elapsed，filelog，searchlog等都被收集到Hadoop的Hbase中，所以我想从中间截一下，用logstash把日志收集到ES集群，然后通过kibana展示出来\n\n# 软件版本\n\n版本：（ELK版本相互很依赖，所以一定要注意看`README.txt` 不要做无用功）\n\n* Logstash：2.3.2\n* elasticsearch: 2.3.2\n* kibana: kibana-4.3.1-linux-x64\n\n[升级教程](http://jerrymin.blog.51cto.com/3002256/1927481)\n\n## 部署过程\n> 刚开始的架构比较简单，只是logstash + ES集群(三个节点) + kibana\n> \n## Elasticsearch部署\n\n### 解压到/usr/local/\n```\nunzip elasticsearch-2.3.2.zip -d /usr/local/\n```\n\n\n**插件安装**\n\n1. Elasticsearch插件安装方式（推荐）\n \n\n**head 插件安装**\nElasticSearch-Head 是一个与Elastic集群（Cluster）相交互的Web前台。\n\nES-Head的主要作用\n\n它展现ES集群的拓扑结构，并且可以通过它来进行索引（Index）和节点（Node）级别的操作\n它提供一组针对集群的查询API，并将结果以json和表格形式返回\n它提供一些快捷菜单，用以展现集群的各种状态\n\n在Elasticsearch目录下\n```\n./bin/plugin install mobz/elasticsearch-head\n\n```\n![](http://or2jd66dq.bkt.clouddn.com/elastic_head.png)\n**kopf 插件安装**\nKopf是一个ElasticSearch的管理工具，它也提供了对ES集群操作的API。\n\n\n```\ncd /usr/local/ELK/elasticsearch-2.3.2 && ./plugin install lmenezes/elasticsearch-kopf\n启动\nopen http://localhost:9200/_plugin/kopf\n\n```\n\n![](http://or2jd66dq.bkt.clouddn.com/elastic_kopf.png)\n\n插件访问方式\nhttp://localhost:9200/_plugin/head \nhttp://localhost:9200/_plugin/koph\n\n\n2. 下载安装方式\n\n从https://github.com/mobz/elasticsearch-head下载ZIP包。\n在 elasticsearch  目录下创建目录plugins/head/ 并且将刚刚解压的elasticsearch-head-master目录下所有内容COPY到当前创建的plugins/head/目录下即可。\n\n \n### 配置文件修改   \n\nnode1\n```\n17: cluster.name: cy_es_cluster           #集群名字（各节点一致）\n 23: node.name: node-1                    #节点名称\n 43: bootstrap.mlockall: true             #锁住内存\n 54: network.host: 10.***.1               #本机内网地址\n 58: http.port: 9200\n 60: http.cors.enrue\n 61: http.cors.allow-origin: \"/.*/\"\n 71: discovery.zen.ping.unicast.hosts: [\"10.***.1:9300\", “10.***.2:9300”, “10.***.3:9300\"]\n 75: discovery.zen.minimum_master_nodes: 2\n```\n\nnode2\n\n```\ngrep -n '^ [a-Z]' /usr/local/elasticsearch-2.3.2/config/elasticsearch.yml\n 17: cluster.name: cy_es_cluster           #集群名字（各节点一致）\n 23: node.name: node-2                     #节点名称\n 33: path.data: /data2/ES                 \n 37: path.logs: /data2/ES/logs          \n 43: bootstrap.mlockall: true              #锁住内存\n 54: network.host: 10.***.2                #本机内网地址\n 58: http.port: 9200                       #端口\n 60: http.cors.enabled: true               #kibana3 需要打开 kibana4忽略\n 61: http.cors.allow-origin: \"/.*/“        #kibana3 需要打开 kibana4忽略\n 73: discovery.zen.ping.unicast.hosts: [\"10.***.1:9300\", “10.***.2:9300”, “10.***.3:9300\"]  #集群discovery      \n 77: discovery.zen.minimum_master_nodes: 2   #最小集群节点数目\n```\n       \n新加node3在 ,配置一致\n    * 启动  nohup /usr/local/elasticsearch-2.3.2/bin/elasticsearch -Des.insecure.allow.root=true &\n    * 启动 systemctl start kibana.service\n    * 查看各节点启动情况 http://10.***.01:9200/_plugin/head/\n\n\n\n## logstash部署\n \n```   \ntar -zxvf  logstash-all-plugins-2.3.2.tar.gz -C /usr/local/\nvim /usr/local/logstash-2.3.2/conf/main.conf 修改配置文件 包括input filter output \n 配置文件详解\n input {\n         file {\n         path => \"/home/chunyu/backup/nginx_log/access.log-*\"   日志文件可以模糊匹配\n         type => “nginx_access\"                                                       类型 在后面output匹配用\n         ignore_older => 14400                                                          读取4小时之内文件\n         exclude => \"*.lzma\"                                                               不包括.lzma 结尾的文件\n          }\n }\n 注意在这遇到过匹配日志日期结尾的情况，例如test.2016-07-03-access.log 匹配为*.%{yyyy}-%{MM}-%{dd}-access.log反复不生效，遂采取ignore_older, 没有在官方找到匹配日期的方式。\n\n filter {\n if [type] == \"nginx_access\" {\n      grok {        \n           patterns_dir => \"/usr/local/logstash-2.3.2/patterns/nginx\"  指定grok匹配文件\n           match => {\n                     \"message\" => \"%{NGINXACCESS}\"\n           }\n           }\n       geoip {\n     source => \"clientip\"\n   }\n         }\n        }\n grok 正则表达式需要自己编写 对照nginx log format  和nginx具体日志在grok debugger中写完 粘贴到/usr/local/logstash/patterns/nginx中即可\n\n\noutput {\n    if [type] == \"nginx_access\" {\n     elasticsearch {\n              hosts => [\"10.***.01:9200\"]\n              index => \"logstash-nginx_access-%{+YYYY.MM.dd}\"\n             }\n         }\n         }\n```\noutput就是把logstash数据输出给elastic search 注意这个index 便是 kibana中setting要输入的\n\n### grok表达式\n> 注意，使用过程中有的情况会出现grok失效的情况，类似状态码为500 的时候或者某种情况，你所要过滤的字段在日志中是空的，可以使用“|”等提高容错性。\n以nginx_access.log实例\n(注意按照自己的日志format灵活变动)\n[grokdebug地址](http://grokdebug.herokuapp.com/)\n\nnginx_access.log 格式\n\n```\nlog_format main '$remote_addr - - [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" [$request_time, $upstream_response_time] $host ($remote_port) \"sid=$cookie_sessionid\"';\n```\n\n\n对应grok表达式\n```\nNGINXACCESS %{IPORHOST:clientip} - - \\[%{HTTPDATE:time_local}\\] \\\"%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\\\" %{NUMBER:status:float} %{NUMBER:body_bytes_sent:float}\\ (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} \\[%{NUMBER:request_time:float}\\, (%{NUMBER:upstream_response_time:float}|-)] %{IPORHOST:host} \\(%{NUMBER:remote_port}\\) %{QS}\n```\n\n## kibana 部署 \n\ntar -zxvf kibana-4.1.1-linux-x64.tar.gz -C /usr/local/\ngrep -n \"^ [a-Z]\" /usr/local/ELK/kibana-4.3.1-linux-x64/config/kibana.yml\n          12: elasticsearch.url: \"http://10.***.1:9200” 只需要输入elastic search地址 端口 即可\n\n启动 nohup /usr/local/ELK/kibana-4.3.1-linux-x64/bin/kibana &\n登录 10.215.33.36:5601通过—>settings设置index —>查看discovery —>制作visualize —>设置dashboard 达到日志可视化\n\n![图表显示](http://or2jd66dq.bkt.clouddn.com/kibana%E5%9B%BE%E8%A1%A8%E6%98%BE%E7%A4%BA.png)\n\n## 问题处理\n\n1. **地图配置**\nkibana地图配置：\n默认的地图不能显示，所以我们换成了高德地图\n先下载GeoIP库\n```\nwget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz\ngunzip GeoLiteCity.dat.gz\n```\nvim conf/main.conf 添加下图内容\n\n![](http://or2jd66dq.bkt.clouddn.com/logs_map_logstash_conf.png)\n\n\n重启logstash\n\nkibana修改\n```\nvim ./src/ui/public/vislib/visualizations/_map.js +11 \n注释  url: 'https://otile{s}-s.mqcdn.com/tiles/1.0.0/map/{z}/{x}/{y}.jpeg',\n添加  url: 'http://webrd0{s}.is.autonavi.com/appmaptile?lang=zh_cn&size=1&scale=1&style=7&x={x}&y={y}&z={z}',   （style=6为卫星地图7为普通地图）\nvim ./src/ui/autoload.js +35\n末尾 添加  'ui/vislib'\n重启kibana\n```\n之后打开logs.chunyu.me setting重置 但是还是没有地图显示，界面为白板，报错 \nGoogle一下需要改elastic search模板\n更改方法：打开 logstash  main.conf配置文件 需要把output 的index 改为logstash开头使用elasticsearch默认模板即可\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-15%20%E4%B8%8B%E5%8D%886.37.57.png)\n\n重启logstash\n效果图\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-15%20%E4%B8%8B%E5%8D%886.39.17.png)\n\n## lucene语法\n> ELK中，kibana或者grafana用来展示数据，Elasticsearch是搜索引擎也是存储中心，它是构建在Lucene之上的，所以过滤器语法和Lucene相同。\n\n\n版本：（ELK版本相互很依赖，所以一定要注意看README.txt 不要做无用功）\n\n* Logstash：2.3.2\n* elasticsearch: 2.3.2\n* kibana: kibana-4.3.1-linux-x64\n\n[参考链接1](https://kibana.logstash.es/content/elasticsearch/api/search.html)\n[参考链接2](https://segmentfault.com/a/1190000002972420)\n\n`全文搜索`\n500\n显示带有500 的内容\n\n`短语搜索`\n使用双引号包起来\n\"like Gecko\"\n\n`字段`\n\n也可以按页面左侧显示的字段搜索\n\n限定字段全文搜索:field:value\n\n`精确搜索`：关键字加上双引号 filed:\"value\"\n\nstatus:404 搜索http状态码为404的文档\n字段本身是否存在\n\n`_exists_`:http：返回结果中需要有http字段\n\n`_missing_`:http：不能含有http字段\n通配符\n\n? 匹配单个字符\n\n* 匹配0到多个字符\nkiba?a, el*search\n\n? * 不能用作第一个字符，例如：?text *text\n\n正则\n\nes支持部分正则功能\n\nmesg:/mes{2}ages?/\n模糊搜索\n\n~:在一个单词后面加上~启用模糊搜索\n\nfirst~ 也能匹配到 frist\n\n还可以指定需要多少相似度\n\ncromm~0.3 会匹配到 from 和 chrome\n\n数值范围0.0 ~ 1.0，默认0.5，越大越接近搜索的原始值\n近似搜索\n\n在短语后面加上~\n\n\"select where\"~3 表示 select 和 where 中间隔着3个单词以内\n范围搜索\n\n数值和时间类型的字段可以对某一范围进行查询\n\nlength:[100 TO 200]\n\ndate:{\"now-6h\" TO \"now\"}\n\n[ ] 表示端点数值包含在范围内，{ } 表示端点数值不包含在范围内\n逻辑操作\n\nAND\n\nOR\n\nNOT\n+：搜索结果中必须包含此项\n\n-：不能含有此项\n+android -OPPO 包含android 不包含OPPO \n+apache -jakarta test：结果中必须存在apache，不能有jakarta，test可有可无 \n\n","slug":"ELK搭建","published":1,"updated":"2017-07-25T09:03:33.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv4m00018tzzufuyrc7p","content":"<blockquote>\n<p>我来之前公司是有一套ELK服务的，但是不知道为何，没有推广起来，之前的运维都离职，原因不得而知，但是公司每天日志量还是挺大的分析起来十分费力，每天上完线之后有问题就得去机器上tail -f 各种grep  AWK sort 定位问题有点慢。另外考虑到所有的nginx_access,elapsed，filelog，searchlog等都被收集到Hadoop的Hbase中，所以我想从中间截一下，用logstash把日志收集到ES集群，然后通过kibana展示出来</p>\n</blockquote>\n<h1 id=\"软件版本\"><a href=\"#软件版本\" class=\"headerlink\" title=\"软件版本\"></a>软件版本</h1><p>版本：（ELK版本相互很依赖，所以一定要注意看<code>README.txt</code> 不要做无用功）</p>\n<ul>\n<li>Logstash：2.3.2</li>\n<li>elasticsearch: 2.3.2</li>\n<li>kibana: kibana-4.3.1-linux-x64</li>\n</ul>\n<p><a href=\"http://jerrymin.blog.51cto.com/3002256/1927481\" target=\"_blank\" rel=\"external\">升级教程</a></p>\n<h2 id=\"部署过程\"><a href=\"#部署过程\" class=\"headerlink\" title=\"部署过程\"></a>部署过程</h2><blockquote>\n<p>刚开始的架构比较简单，只是logstash + ES集群(三个节点) + kibana</p>\n<h2 id=\"elasticsearch部署\"><a href=\"#Elasticsearch部署\" class=\"headerlink\" title=\"Elasticsearch部署\"></a>Elasticsearch部署</h2></blockquote>\n<h3 id=\"解压到usrlocal\"><a href=\"#解压到-usr-local\" class=\"headerlink\" title=\"解压到/usr/local/\"></a>解压到/usr/local/</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">unzip elasticsearch-2.3.2.zip -d /usr/local/</div></pre></td></tr></table></figure>\n<p><strong>插件安装</strong></p>\n<ol>\n<li>Elasticsearch插件安装方式（推荐）</li>\n</ol>\n<p><strong>head 插件安装</strong><br>ElasticSearch-Head 是一个与Elastic集群（Cluster）相交互的Web前台。</p>\n<p>ES-Head的主要作用</p>\n<p>它展现ES集群的拓扑结构，并且可以通过它来进行索引（Index）和节点（Node）级别的操作<br>它提供一组针对集群的查询API，并将结果以json和表格形式返回<br>它提供一些快捷菜单，用以展现集群的各种状态</p>\n<p>在Elasticsearch目录下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./bin/plugin install mobz/elasticsearch-head</div></pre></td></tr></table></figure></p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/elastic_head.png\" alt=\"\"><br><strong>kopf 插件安装</strong><br>Kopf是一个ElasticSearch的管理工具，它也提供了对ES集群操作的API。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd /usr/local/ELK/elasticsearch-2.3.2 &amp;&amp; ./plugin install lmenezes/elasticsearch-kopf</div><div class=\"line\">启动</div><div class=\"line\">open http://localhost:9200/_plugin/kopf</div></pre></td></tr></table></figure>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/elastic_kopf.png\" alt=\"\"></p>\n<p>插件访问方式<br><a href=\"http://localhost:9200/_plugin/head\" target=\"_blank\" rel=\"external\">http://localhost:9200/_plugin/head</a><br><a href=\"http://localhost:9200/_plugin/koph\" target=\"_blank\" rel=\"external\">http://localhost:9200/_plugin/koph</a></p>\n<ol>\n<li>下载安装方式</li>\n</ol>\n<p>从<a href=\"https://github.com/mobz/elasticsearch-head下载ZIP包。\" target=\"_blank\" rel=\"external\">https://github.com/mobz/elasticsearch-head下载ZIP包。</a><br>在 elasticsearch  目录下创建目录plugins/head/ 并且将刚刚解压的elasticsearch-head-master目录下所有内容COPY到当前创建的plugins/head/目录下即可。</p>\n<h3 id=\"配置文件修改\"><a href=\"#配置文件修改\" class=\"headerlink\" title=\"配置文件修改\"></a>配置文件修改</h3><p>node1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">17: cluster.name: cy_es_cluster           #集群名字（各节点一致）</div><div class=\"line\"> 23: node.name: node-1                    #节点名称</div><div class=\"line\"> 43: bootstrap.mlockall: true             #锁住内存</div><div class=\"line\"> 54: network.host: 10.***.1               #本机内网地址</div><div class=\"line\"> 58: http.port: 9200</div><div class=\"line\"> 60: http.cors.enrue</div><div class=\"line\"> 61: http.cors.allow-origin: &quot;/.*/&quot;</div><div class=\"line\"> 71: discovery.zen.ping.unicast.hosts: [&quot;10.***.1:9300&quot;, “10.***.2:9300”, “10.***.3:9300&quot;]</div><div class=\"line\"> 75: discovery.zen.minimum_master_nodes: 2</div></pre></td></tr></table></figure></p>\n<p>node2</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">grep -n &apos;^ [a-Z]&apos; /usr/local/elasticsearch-2.3.2/config/elasticsearch.yml</div><div class=\"line\"> 17: cluster.name: cy_es_cluster           #集群名字（各节点一致）</div><div class=\"line\"> 23: node.name: node-2                     #节点名称</div><div class=\"line\"> 33: path.data: /data2/ES                 </div><div class=\"line\"> 37: path.logs: /data2/ES/logs          </div><div class=\"line\"> 43: bootstrap.mlockall: true              #锁住内存</div><div class=\"line\"> 54: network.host: 10.***.2                #本机内网地址</div><div class=\"line\"> 58: http.port: 9200                       #端口</div><div class=\"line\"> 60: http.cors.enabled: true               #kibana3 需要打开 kibana4忽略</div><div class=\"line\"> 61: http.cors.allow-origin: &quot;/.*/“        #kibana3 需要打开 kibana4忽略</div><div class=\"line\"> 73: discovery.zen.ping.unicast.hosts: [&quot;10.***.1:9300&quot;, “10.***.2:9300”, “10.***.3:9300&quot;]  #集群discovery      </div><div class=\"line\"> 77: discovery.zen.minimum_master_nodes: 2   #最小集群节点数目</div></pre></td></tr></table></figure>\n<p>新加node3在 ,配置一致</p>\n<pre><code>* 启动  nohup /usr/local/elasticsearch-2.3.2/bin/elasticsearch -Des.insecure.allow.root=true &amp;\n* 启动 systemctl start kibana.service\n* 查看各节点启动情况 http://10.***.01:9200/_plugin/head/\n</code></pre><h2 id=\"logstash部署\"><a href=\"#logstash部署\" class=\"headerlink\" title=\"logstash部署\"></a>logstash部署</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div></pre></td><td class=\"code\"><pre><div class=\"line\">tar -zxvf  logstash-all-plugins-2.3.2.tar.gz -C /usr/local/</div><div class=\"line\">vim /usr/local/logstash-2.3.2/conf/main.conf 修改配置文件 包括input filter output </div><div class=\"line\"> 配置文件详解</div><div class=\"line\"> input &#123;</div><div class=\"line\">         file &#123;</div><div class=\"line\">         path =&gt; &quot;/home/chunyu/backup/nginx_log/access.log-*&quot;   日志文件可以模糊匹配</div><div class=\"line\">         type =&gt; “nginx_access&quot;                                                       类型 在后面output匹配用</div><div class=\"line\">         ignore_older =&gt; 14400                                                          读取4小时之内文件</div><div class=\"line\">         exclude =&gt; &quot;*.lzma&quot;                                                               不包括.lzma 结尾的文件</div><div class=\"line\">          &#125;</div><div class=\"line\"> &#125;</div><div class=\"line\"> 注意在这遇到过匹配日志日期结尾的情况，例如test.2016-07-03-access.log 匹配为*.%&#123;yyyy&#125;-%&#123;MM&#125;-%&#123;dd&#125;-access.log反复不生效，遂采取ignore_older, 没有在官方找到匹配日期的方式。</div><div class=\"line\"></div><div class=\"line\"> filter &#123;</div><div class=\"line\"> if [type] == &quot;nginx_access&quot; &#123;</div><div class=\"line\">      grok &#123;        </div><div class=\"line\">           patterns_dir =&gt; &quot;/usr/local/logstash-2.3.2/patterns/nginx&quot;  指定grok匹配文件</div><div class=\"line\">           match =&gt; &#123;</div><div class=\"line\">                     &quot;message&quot; =&gt; &quot;%&#123;NGINXACCESS&#125;&quot;</div><div class=\"line\">           &#125;</div><div class=\"line\">           &#125;</div><div class=\"line\">       geoip &#123;</div><div class=\"line\">     source =&gt; &quot;clientip&quot;</div><div class=\"line\">   &#125;</div><div class=\"line\">         &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\"> grok 正则表达式需要自己编写 对照nginx log format  和nginx具体日志在grok debugger中写完 粘贴到/usr/local/logstash/patterns/nginx中即可</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">output &#123;</div><div class=\"line\">    if [type] == &quot;nginx_access&quot; &#123;</div><div class=\"line\">     elasticsearch &#123;</div><div class=\"line\">              hosts =&gt; [&quot;10.***.01:9200&quot;]</div><div class=\"line\">              index =&gt; &quot;logstash-nginx_access-%&#123;+YYYY.MM.dd&#125;&quot;</div><div class=\"line\">             &#125;</div><div class=\"line\">         &#125;</div><div class=\"line\">         &#125;</div></pre></td></tr></table></figure>\n<p>output就是把logstash数据输出给elastic search 注意这个index 便是 kibana中setting要输入的</p>\n<h3 id=\"grok表达式\"><a href=\"#grok表达式\" class=\"headerlink\" title=\"grok表达式\"></a>grok表达式</h3><blockquote>\n<p>注意，使用过程中有的情况会出现grok失效的情况，类似状态码为500 的时候或者某种情况，你所要过滤的字段在日志中是空的，可以使用“|”等提高容错性。<br>以nginx_access.log实例<br>(注意按照自己的日志format灵活变动)<br><a href=\"http://grokdebug.herokuapp.com/\" target=\"_blank\" rel=\"external\">grokdebug地址</a></p>\n</blockquote>\n<p>nginx_access.log 格式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">log_format main &apos;$remote_addr - - [$time_local] &quot;$request&quot; $status $body_bytes_sent &quot;$http_referer&quot; &apos;</div><div class=\"line\">                      &apos;&quot;$http_user_agent&quot; [$request_time, $upstream_response_time] $host ($remote_port) &quot;sid=$cookie_sessionid&quot;&apos;;</div></pre></td></tr></table></figure>\n<p>对应grok表达式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">NGINXACCESS %&#123;IPORHOST:clientip&#125; - - \\[%&#123;HTTPDATE:time_local&#125;\\] \\&quot;%&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;\\&quot; %&#123;NUMBER:status:float&#125; %&#123;NUMBER:body_bytes_sent:float&#125;\\ (?:\\&quot;(?:%&#123;URI:referrer&#125;|-)\\&quot;|%&#123;QS:referrer&#125;) %&#123;QS:agent&#125; \\[%&#123;NUMBER:request_time:float&#125;\\, (%&#123;NUMBER:upstream_response_time:float&#125;|-)] %&#123;IPORHOST:host&#125; \\(%&#123;NUMBER:remote_port&#125;\\) %&#123;QS&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"kibana-部署\"><a href=\"#kibana-部署\" class=\"headerlink\" title=\"kibana 部署\"></a>kibana 部署</h2><p>tar -zxvf kibana-4.1.1-linux-x64.tar.gz -C /usr/local/<br>grep -n “^ [a-Z]” /usr/local/ELK/kibana-4.3.1-linux-x64/config/kibana.yml<br>          12: elasticsearch.url: “<a href=\"http://10.***.1:9200”\" target=\"_blank\" rel=\"external\">http://10.***.1:9200”</a> 只需要输入elastic search地址 端口 即可</p>\n<p>启动 nohup /usr/local/ELK/kibana-4.3.1-linux-x64/bin/kibana &amp;<br>登录 10.215.33.36:5601通过—&gt;settings设置index —&gt;查看discovery —&gt;制作visualize —&gt;设置dashboard 达到日志可视化</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/kibana%E5%9B%BE%E8%A1%A8%E6%98%BE%E7%A4%BA.png\" alt=\"图表显示\"></p>\n<h2 id=\"问题处理\"><a href=\"#问题处理\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h2><ol>\n<li><strong>地图配置</strong><br>kibana地图配置：<br>默认的地图不能显示，所以我们换成了高德地图<br>先下载GeoIP库<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz</div><div class=\"line\">gunzip GeoLiteCity.dat.gz</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>vim conf/main.conf 添加下图内容</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/logs_map_logstash_conf.png\" alt=\"\"></p>\n<p>重启logstash</p>\n<p>kibana修改<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim ./src/ui/public/vislib/visualizations/_map.js +11 </div><div class=\"line\">注释  url: &apos;https://otile&#123;s&#125;-s.mqcdn.com/tiles/1.0.0/map/&#123;z&#125;/&#123;x&#125;/&#123;y&#125;.jpeg&apos;,</div><div class=\"line\">添加  url: &apos;http://webrd0&#123;s&#125;.is.autonavi.com/appmaptile?lang=zh_cn&amp;size=1&amp;scale=1&amp;style=7&amp;x=&#123;x&#125;&amp;y=&#123;y&#125;&amp;z=&#123;z&#125;&apos;,   （style=6为卫星地图7为普通地图）</div><div class=\"line\">vim ./src/ui/autoload.js +35</div><div class=\"line\">末尾 添加  &apos;ui/vislib&apos;</div><div class=\"line\">重启kibana</div></pre></td></tr></table></figure></p>\n<p>之后打开logs.chunyu.me setting重置 但是还是没有地图显示，界面为白板，报错<br>Google一下需要改elastic search模板<br>更改方法：打开 logstash  main.conf配置文件 需要把output 的index 改为logstash开头使用elasticsearch默认模板即可</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-15%20%E4%B8%8B%E5%8D%886.37.57.png\" alt=\"\"></p>\n<p>重启logstash<br>效果图</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-15%20%E4%B8%8B%E5%8D%886.39.17.png\" alt=\"\"></p>\n<h2 id=\"lucene语法\"><a href=\"#lucene语法\" class=\"headerlink\" title=\"lucene语法\"></a>lucene语法</h2><blockquote>\n<p>ELK中，kibana或者grafana用来展示数据，Elasticsearch是搜索引擎也是存储中心，它是构建在Lucene之上的，所以过滤器语法和Lucene相同。</p>\n</blockquote>\n<p>版本：（ELK版本相互很依赖，所以一定要注意看README.txt 不要做无用功）</p>\n<ul>\n<li>Logstash：2.3.2</li>\n<li>elasticsearch: 2.3.2</li>\n<li>kibana: kibana-4.3.1-linux-x64</li>\n</ul>\n<p><a href=\"https://kibana.logstash.es/content/elasticsearch/api/search.html\" target=\"_blank\" rel=\"external\">参考链接1</a><br><a href=\"https://segmentfault.com/a/1190000002972420\" target=\"_blank\" rel=\"external\">参考链接2</a></p>\n<p><code>全文搜索</code><br>500<br>显示带有500 的内容</p>\n<p><code>短语搜索</code><br>使用双引号包起来<br>“like Gecko”</p>\n<p><code>字段</code></p>\n<p>也可以按页面左侧显示的字段搜索</p>\n<p>限定字段全文搜索:field:value</p>\n<p><code>精确搜索</code>：关键字加上双引号 filed:”value”</p>\n<p>status:404 搜索http状态码为404的文档<br>字段本身是否存在</p>\n<p><code>_exists_</code>:http：返回结果中需要有http字段</p>\n<p><code>_missing_</code>:http：不能含有http字段<br>通配符</p>\n<p>? 匹配单个字符</p>\n<ul>\n<li>匹配0到多个字符<br>kiba?a, el*search</li>\n</ul>\n<p>? <em> 不能用作第一个字符，例如：?text </em>text</p>\n<p>正则</p>\n<p>es支持部分正则功能</p>\n<p>mesg:/mes{2}ages?/<br>模糊搜索</p>\n<p>~:在一个单词后面加上~启用模糊搜索</p>\n<p>first~ 也能匹配到 frist</p>\n<p>还可以指定需要多少相似度</p>\n<p>cromm~0.3 会匹配到 from 和 chrome</p>\n<p>数值范围0.0 ~ 1.0，默认0.5，越大越接近搜索的原始值<br>近似搜索</p>\n<p>在短语后面加上~</p>\n<p>“select where”~3 表示 select 和 where 中间隔着3个单词以内<br>范围搜索</p>\n<p>数值和时间类型的字段可以对某一范围进行查询</p>\n<p>length:[100 TO 200]</p>\n<p>date:{“now-6h” TO “now”}</p>\n<p>[ ] 表示端点数值包含在范围内，{ } 表示端点数值不包含在范围内<br>逻辑操作</p>\n<p>AND</p>\n<p>OR</p>\n<p>NOT<br>+：搜索结果中必须包含此项</p>\n<p>-：不能含有此项<br>+android -OPPO 包含android 不包含OPPO<br>+apache -jakarta test：结果中必须存在apache，不能有jakarta，test可有可无</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>我来之前公司是有一套ELK服务的，但是不知道为何，没有推广起来，之前的运维都离职，原因不得而知，但是公司每天日志量还是挺大的分析起来十分费力，每天上完线之后有问题就得去机器上tail -f 各种grep  AWK sort 定位问题有点慢。另外考虑到所有的nginx_access,elapsed，filelog，searchlog等都被收集到Hadoop的Hbase中，所以我想从中间截一下，用logstash把日志收集到ES集群，然后通过kibana展示出来</p>\n</blockquote>\n<h1 id=\"软件版本\"><a href=\"#软件版本\" class=\"headerlink\" title=\"软件版本\"></a>软件版本</h1><p>版本：（ELK版本相互很依赖，所以一定要注意看<code>README.txt</code> 不要做无用功）</p>\n<ul>\n<li>Logstash：2.3.2</li>\n<li>elasticsearch: 2.3.2</li>\n<li>kibana: kibana-4.3.1-linux-x64</li>\n</ul>\n<p><a href=\"http://jerrymin.blog.51cto.com/3002256/1927481\" target=\"_blank\" rel=\"external\">升级教程</a></p>\n<h2 id=\"部署过程\"><a href=\"#部署过程\" class=\"headerlink\" title=\"部署过程\"></a>部署过程</h2><blockquote>\n<p>刚开始的架构比较简单，只是logstash + ES集群(三个节点) + kibana</p>\n<h2 id=\"Elasticsearch部署\"><a href=\"#Elasticsearch部署\" class=\"headerlink\" title=\"Elasticsearch部署\"></a>Elasticsearch部署</h2></blockquote>\n<h3 id=\"解压到-usr-local\"><a href=\"#解压到-usr-local\" class=\"headerlink\" title=\"解压到/usr/local/\"></a>解压到/usr/local/</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">unzip elasticsearch-2.3.2.zip -d /usr/local/</div></pre></td></tr></table></figure>\n<p><strong>插件安装</strong></p>\n<ol>\n<li>Elasticsearch插件安装方式（推荐）</li>\n</ol>\n<p><strong>head 插件安装</strong><br>ElasticSearch-Head 是一个与Elastic集群（Cluster）相交互的Web前台。</p>\n<p>ES-Head的主要作用</p>\n<p>它展现ES集群的拓扑结构，并且可以通过它来进行索引（Index）和节点（Node）级别的操作<br>它提供一组针对集群的查询API，并将结果以json和表格形式返回<br>它提供一些快捷菜单，用以展现集群的各种状态</p>\n<p>在Elasticsearch目录下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./bin/plugin install mobz/elasticsearch-head</div></pre></td></tr></table></figure></p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/elastic_head.png\" alt=\"\"><br><strong>kopf 插件安装</strong><br>Kopf是一个ElasticSearch的管理工具，它也提供了对ES集群操作的API。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd /usr/local/ELK/elasticsearch-2.3.2 &amp;&amp; ./plugin install lmenezes/elasticsearch-kopf</div><div class=\"line\">启动</div><div class=\"line\">open http://localhost:9200/_plugin/kopf</div></pre></td></tr></table></figure>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/elastic_kopf.png\" alt=\"\"></p>\n<p>插件访问方式<br><a href=\"http://localhost:9200/_plugin/head\" target=\"_blank\" rel=\"external\">http://localhost:9200/_plugin/head</a><br><a href=\"http://localhost:9200/_plugin/koph\" target=\"_blank\" rel=\"external\">http://localhost:9200/_plugin/koph</a></p>\n<ol>\n<li>下载安装方式</li>\n</ol>\n<p>从<a href=\"https://github.com/mobz/elasticsearch-head下载ZIP包。\" target=\"_blank\" rel=\"external\">https://github.com/mobz/elasticsearch-head下载ZIP包。</a><br>在 elasticsearch  目录下创建目录plugins/head/ 并且将刚刚解压的elasticsearch-head-master目录下所有内容COPY到当前创建的plugins/head/目录下即可。</p>\n<h3 id=\"配置文件修改\"><a href=\"#配置文件修改\" class=\"headerlink\" title=\"配置文件修改\"></a>配置文件修改</h3><p>node1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">17: cluster.name: cy_es_cluster           #集群名字（各节点一致）</div><div class=\"line\"> 23: node.name: node-1                    #节点名称</div><div class=\"line\"> 43: bootstrap.mlockall: true             #锁住内存</div><div class=\"line\"> 54: network.host: 10.***.1               #本机内网地址</div><div class=\"line\"> 58: http.port: 9200</div><div class=\"line\"> 60: http.cors.enrue</div><div class=\"line\"> 61: http.cors.allow-origin: &quot;/.*/&quot;</div><div class=\"line\"> 71: discovery.zen.ping.unicast.hosts: [&quot;10.***.1:9300&quot;, “10.***.2:9300”, “10.***.3:9300&quot;]</div><div class=\"line\"> 75: discovery.zen.minimum_master_nodes: 2</div></pre></td></tr></table></figure></p>\n<p>node2</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">grep -n &apos;^ [a-Z]&apos; /usr/local/elasticsearch-2.3.2/config/elasticsearch.yml</div><div class=\"line\"> 17: cluster.name: cy_es_cluster           #集群名字（各节点一致）</div><div class=\"line\"> 23: node.name: node-2                     #节点名称</div><div class=\"line\"> 33: path.data: /data2/ES                 </div><div class=\"line\"> 37: path.logs: /data2/ES/logs          </div><div class=\"line\"> 43: bootstrap.mlockall: true              #锁住内存</div><div class=\"line\"> 54: network.host: 10.***.2                #本机内网地址</div><div class=\"line\"> 58: http.port: 9200                       #端口</div><div class=\"line\"> 60: http.cors.enabled: true               #kibana3 需要打开 kibana4忽略</div><div class=\"line\"> 61: http.cors.allow-origin: &quot;/.*/“        #kibana3 需要打开 kibana4忽略</div><div class=\"line\"> 73: discovery.zen.ping.unicast.hosts: [&quot;10.***.1:9300&quot;, “10.***.2:9300”, “10.***.3:9300&quot;]  #集群discovery      </div><div class=\"line\"> 77: discovery.zen.minimum_master_nodes: 2   #最小集群节点数目</div></pre></td></tr></table></figure>\n<p>新加node3在 ,配置一致</p>\n<pre><code>* 启动  nohup /usr/local/elasticsearch-2.3.2/bin/elasticsearch -Des.insecure.allow.root=true &amp;\n* 启动 systemctl start kibana.service\n* 查看各节点启动情况 http://10.***.01:9200/_plugin/head/\n</code></pre><h2 id=\"logstash部署\"><a href=\"#logstash部署\" class=\"headerlink\" title=\"logstash部署\"></a>logstash部署</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div></pre></td><td class=\"code\"><pre><div class=\"line\">tar -zxvf  logstash-all-plugins-2.3.2.tar.gz -C /usr/local/</div><div class=\"line\">vim /usr/local/logstash-2.3.2/conf/main.conf 修改配置文件 包括input filter output </div><div class=\"line\"> 配置文件详解</div><div class=\"line\"> input &#123;</div><div class=\"line\">         file &#123;</div><div class=\"line\">         path =&gt; &quot;/home/chunyu/backup/nginx_log/access.log-*&quot;   日志文件可以模糊匹配</div><div class=\"line\">         type =&gt; “nginx_access&quot;                                                       类型 在后面output匹配用</div><div class=\"line\">         ignore_older =&gt; 14400                                                          读取4小时之内文件</div><div class=\"line\">         exclude =&gt; &quot;*.lzma&quot;                                                               不包括.lzma 结尾的文件</div><div class=\"line\">          &#125;</div><div class=\"line\"> &#125;</div><div class=\"line\"> 注意在这遇到过匹配日志日期结尾的情况，例如test.2016-07-03-access.log 匹配为*.%&#123;yyyy&#125;-%&#123;MM&#125;-%&#123;dd&#125;-access.log反复不生效，遂采取ignore_older, 没有在官方找到匹配日期的方式。</div><div class=\"line\"></div><div class=\"line\"> filter &#123;</div><div class=\"line\"> if [type] == &quot;nginx_access&quot; &#123;</div><div class=\"line\">      grok &#123;        </div><div class=\"line\">           patterns_dir =&gt; &quot;/usr/local/logstash-2.3.2/patterns/nginx&quot;  指定grok匹配文件</div><div class=\"line\">           match =&gt; &#123;</div><div class=\"line\">                     &quot;message&quot; =&gt; &quot;%&#123;NGINXACCESS&#125;&quot;</div><div class=\"line\">           &#125;</div><div class=\"line\">           &#125;</div><div class=\"line\">       geoip &#123;</div><div class=\"line\">     source =&gt; &quot;clientip&quot;</div><div class=\"line\">   &#125;</div><div class=\"line\">         &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\"> grok 正则表达式需要自己编写 对照nginx log format  和nginx具体日志在grok debugger中写完 粘贴到/usr/local/logstash/patterns/nginx中即可</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">output &#123;</div><div class=\"line\">    if [type] == &quot;nginx_access&quot; &#123;</div><div class=\"line\">     elasticsearch &#123;</div><div class=\"line\">              hosts =&gt; [&quot;10.***.01:9200&quot;]</div><div class=\"line\">              index =&gt; &quot;logstash-nginx_access-%&#123;+YYYY.MM.dd&#125;&quot;</div><div class=\"line\">             &#125;</div><div class=\"line\">         &#125;</div><div class=\"line\">         &#125;</div></pre></td></tr></table></figure>\n<p>output就是把logstash数据输出给elastic search 注意这个index 便是 kibana中setting要输入的</p>\n<h3 id=\"grok表达式\"><a href=\"#grok表达式\" class=\"headerlink\" title=\"grok表达式\"></a>grok表达式</h3><blockquote>\n<p>注意，使用过程中有的情况会出现grok失效的情况，类似状态码为500 的时候或者某种情况，你所要过滤的字段在日志中是空的，可以使用“|”等提高容错性。<br>以nginx_access.log实例<br>(注意按照自己的日志format灵活变动)<br><a href=\"http://grokdebug.herokuapp.com/\" target=\"_blank\" rel=\"external\">grokdebug地址</a></p>\n</blockquote>\n<p>nginx_access.log 格式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">log_format main &apos;$remote_addr - - [$time_local] &quot;$request&quot; $status $body_bytes_sent &quot;$http_referer&quot; &apos;</div><div class=\"line\">                      &apos;&quot;$http_user_agent&quot; [$request_time, $upstream_response_time] $host ($remote_port) &quot;sid=$cookie_sessionid&quot;&apos;;</div></pre></td></tr></table></figure>\n<p>对应grok表达式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">NGINXACCESS %&#123;IPORHOST:clientip&#125; - - \\[%&#123;HTTPDATE:time_local&#125;\\] \\&quot;%&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;\\&quot; %&#123;NUMBER:status:float&#125; %&#123;NUMBER:body_bytes_sent:float&#125;\\ (?:\\&quot;(?:%&#123;URI:referrer&#125;|-)\\&quot;|%&#123;QS:referrer&#125;) %&#123;QS:agent&#125; \\[%&#123;NUMBER:request_time:float&#125;\\, (%&#123;NUMBER:upstream_response_time:float&#125;|-)] %&#123;IPORHOST:host&#125; \\(%&#123;NUMBER:remote_port&#125;\\) %&#123;QS&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"kibana-部署\"><a href=\"#kibana-部署\" class=\"headerlink\" title=\"kibana 部署\"></a>kibana 部署</h2><p>tar -zxvf kibana-4.1.1-linux-x64.tar.gz -C /usr/local/<br>grep -n “^ [a-Z]” /usr/local/ELK/kibana-4.3.1-linux-x64/config/kibana.yml<br>          12: elasticsearch.url: “<a href=\"http://10.***.1:9200”\" target=\"_blank\" rel=\"external\">http://10.***.1:9200”</a> 只需要输入elastic search地址 端口 即可</p>\n<p>启动 nohup /usr/local/ELK/kibana-4.3.1-linux-x64/bin/kibana &amp;<br>登录 10.215.33.36:5601通过—&gt;settings设置index —&gt;查看discovery —&gt;制作visualize —&gt;设置dashboard 达到日志可视化</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/kibana%E5%9B%BE%E8%A1%A8%E6%98%BE%E7%A4%BA.png\" alt=\"图表显示\"></p>\n<h2 id=\"问题处理\"><a href=\"#问题处理\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h2><ol>\n<li><strong>地图配置</strong><br>kibana地图配置：<br>默认的地图不能显示，所以我们换成了高德地图<br>先下载GeoIP库<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz</div><div class=\"line\">gunzip GeoLiteCity.dat.gz</div></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>vim conf/main.conf 添加下图内容</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/logs_map_logstash_conf.png\" alt=\"\"></p>\n<p>重启logstash</p>\n<p>kibana修改<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim ./src/ui/public/vislib/visualizations/_map.js +11 </div><div class=\"line\">注释  url: &apos;https://otile&#123;s&#125;-s.mqcdn.com/tiles/1.0.0/map/&#123;z&#125;/&#123;x&#125;/&#123;y&#125;.jpeg&apos;,</div><div class=\"line\">添加  url: &apos;http://webrd0&#123;s&#125;.is.autonavi.com/appmaptile?lang=zh_cn&amp;size=1&amp;scale=1&amp;style=7&amp;x=&#123;x&#125;&amp;y=&#123;y&#125;&amp;z=&#123;z&#125;&apos;,   （style=6为卫星地图7为普通地图）</div><div class=\"line\">vim ./src/ui/autoload.js +35</div><div class=\"line\">末尾 添加  &apos;ui/vislib&apos;</div><div class=\"line\">重启kibana</div></pre></td></tr></table></figure></p>\n<p>之后打开logs.chunyu.me setting重置 但是还是没有地图显示，界面为白板，报错<br>Google一下需要改elastic search模板<br>更改方法：打开 logstash  main.conf配置文件 需要把output 的index 改为logstash开头使用elasticsearch默认模板即可</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-15%20%E4%B8%8B%E5%8D%886.37.57.png\" alt=\"\"></p>\n<p>重启logstash<br>效果图</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-15%20%E4%B8%8B%E5%8D%886.39.17.png\" alt=\"\"></p>\n<h2 id=\"lucene语法\"><a href=\"#lucene语法\" class=\"headerlink\" title=\"lucene语法\"></a>lucene语法</h2><blockquote>\n<p>ELK中，kibana或者grafana用来展示数据，Elasticsearch是搜索引擎也是存储中心，它是构建在Lucene之上的，所以过滤器语法和Lucene相同。</p>\n</blockquote>\n<p>版本：（ELK版本相互很依赖，所以一定要注意看README.txt 不要做无用功）</p>\n<ul>\n<li>Logstash：2.3.2</li>\n<li>elasticsearch: 2.3.2</li>\n<li>kibana: kibana-4.3.1-linux-x64</li>\n</ul>\n<p><a href=\"https://kibana.logstash.es/content/elasticsearch/api/search.html\" target=\"_blank\" rel=\"external\">参考链接1</a><br><a href=\"https://segmentfault.com/a/1190000002972420\" target=\"_blank\" rel=\"external\">参考链接2</a></p>\n<p><code>全文搜索</code><br>500<br>显示带有500 的内容</p>\n<p><code>短语搜索</code><br>使用双引号包起来<br>“like Gecko”</p>\n<p><code>字段</code></p>\n<p>也可以按页面左侧显示的字段搜索</p>\n<p>限定字段全文搜索:field:value</p>\n<p><code>精确搜索</code>：关键字加上双引号 filed:”value”</p>\n<p>status:404 搜索http状态码为404的文档<br>字段本身是否存在</p>\n<p><code>_exists_</code>:http：返回结果中需要有http字段</p>\n<p><code>_missing_</code>:http：不能含有http字段<br>通配符</p>\n<p>? 匹配单个字符</p>\n<ul>\n<li>匹配0到多个字符<br>kiba?a, el*search</li>\n</ul>\n<p>? <em> 不能用作第一个字符，例如：?text </em>text</p>\n<p>正则</p>\n<p>es支持部分正则功能</p>\n<p>mesg:/mes{2}ages?/<br>模糊搜索</p>\n<p>~:在一个单词后面加上~启用模糊搜索</p>\n<p>first~ 也能匹配到 frist</p>\n<p>还可以指定需要多少相似度</p>\n<p>cromm~0.3 会匹配到 from 和 chrome</p>\n<p>数值范围0.0 ~ 1.0，默认0.5，越大越接近搜索的原始值<br>近似搜索</p>\n<p>在短语后面加上~</p>\n<p>“select where”~3 表示 select 和 where 中间隔着3个单词以内<br>范围搜索</p>\n<p>数值和时间类型的字段可以对某一范围进行查询</p>\n<p>length:[100 TO 200]</p>\n<p>date:{“now-6h” TO “now”}</p>\n<p>[ ] 表示端点数值包含在范围内，{ } 表示端点数值不包含在范围内<br>逻辑操作</p>\n<p>AND</p>\n<p>OR</p>\n<p>NOT<br>+：搜索结果中必须包含此项</p>\n<p>-：不能含有此项<br>+android -OPPO 包含android 不包含OPPO<br>+apache -jakarta test：结果中必须存在apache，不能有jakarta，test可有可无</p>\n"},{"title":"Django之入门学习","date":"2017-06-14T02:36:07.000Z","_content":"> 自己动手从0开始\n\npython版本：3.5.1\nDjango版本：1.9.5\n\n# 安装初始化\n## python3\n\n```\nyum groupinstall 'Development Tools'\nyum install zlib-devel bzip2-devel openssl-devel ncurese-devel\nwget https://www.python.org/ftp/python/3.5.1/Python-3.5.1.tar.xz && mv Python-3.5.1.tar.xz /usr/local/ && cd /usr/local\ntar -Jxvf Python-3.5.1.tar.xz &&  cd Python-3.5.1\n./configure --prefix=/usr/local/python3\nmake && make install \nln -s /usr/local/python3/bin/python3.5 /usr/bin/python3\nln -s /usr/local/python3/bin/pip3 /usr/bin/pip3\n# \npython3 -m venv myvenv\n\n```\n\n## django安装\n```\nsource myvenv/bin/activate\npip install django==1.9.5\n```\n\n### 生成项目\n\n```\ndjango-admin.py startproject mysite\n```\n\n`mysite`目录结构如下\n\n```\nmysite\n├───manage.py\n└───mysite\n        settings.py\n        urls.py\n        wsgi.py\n        __init__.py\n```\n\n- manage.py是管理网站的脚本，可以使用它来启动一个简单的web服务器，这个对于开发调试非常有用。\n- setting.py是工程的核心配置文件。\n- urls.py是路径配置文件，可以配置URL到实际Controller的映射关系。\n\n\n\n### 配置更改\n更给`settings.py`语言，时区\n\n```\nLANGUAGE_CODE = 'zh-cn'\nTIME_ZONE = 'Asia/Shanghai'\n```\n\n数据库不用改 先使用默认的sqlite3,\n生成数据库\n```\npython manage.py migrate\n```\nrunserver 看下，可以再浏览器访问下 ip:8000\npython manage.py runserver 0.0.0.0:8000\n\n### 创建应用\n\ndjango 中 工程(project)与应用(application)概念要分清，我们使用 `django-admin.py manage.py startproject mysite`创建`mysite`的是工程.\n下边使用`python manage.py startapp blog` 创建的`blog`是应用，一个工程可以包括很多个应用。\n\n创建应用\n`python manage.py startapp blog`\n现在整个工程目录结构如下\n```\n.\n├── blog\n│   ├── admin.py\n│   ├── apps.py\n│   ├── __init__.py\n│   ├── migrations\n│   │   └── __init__.py\n│   ├── models.py\n│   ├── tests.py\n│   └── views.py\n├── db.sqlite3\n├── manage.py\n└── mysite\n    ├── __init__.py\n    ├── __pycache__\n    │   ├── __init__.cpython-35.pyc\n    │   ├── settings.cpython-35.pyc\n    │   ├── urls.cpython-35.pyc\n    │   └── wsgi.cpython-35.pyc\n    ├── settings.py\n    ├── urls.py\n    └── wsgi.py\n```\n\n然后，我们需要把这个应用在`settings.py`注册一下。\n```\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'blog',\n]\n```\n","source":"_posts/Django之入门学习.md","raw":"---\ntitle: Django之入门学习\ndate: 2017-06-14 10:36:07\ntags: Django\ncategories: Django\n---\n> 自己动手从0开始\n\npython版本：3.5.1\nDjango版本：1.9.5\n\n# 安装初始化\n## python3\n\n```\nyum groupinstall 'Development Tools'\nyum install zlib-devel bzip2-devel openssl-devel ncurese-devel\nwget https://www.python.org/ftp/python/3.5.1/Python-3.5.1.tar.xz && mv Python-3.5.1.tar.xz /usr/local/ && cd /usr/local\ntar -Jxvf Python-3.5.1.tar.xz &&  cd Python-3.5.1\n./configure --prefix=/usr/local/python3\nmake && make install \nln -s /usr/local/python3/bin/python3.5 /usr/bin/python3\nln -s /usr/local/python3/bin/pip3 /usr/bin/pip3\n# \npython3 -m venv myvenv\n\n```\n\n## django安装\n```\nsource myvenv/bin/activate\npip install django==1.9.5\n```\n\n### 生成项目\n\n```\ndjango-admin.py startproject mysite\n```\n\n`mysite`目录结构如下\n\n```\nmysite\n├───manage.py\n└───mysite\n        settings.py\n        urls.py\n        wsgi.py\n        __init__.py\n```\n\n- manage.py是管理网站的脚本，可以使用它来启动一个简单的web服务器，这个对于开发调试非常有用。\n- setting.py是工程的核心配置文件。\n- urls.py是路径配置文件，可以配置URL到实际Controller的映射关系。\n\n\n\n### 配置更改\n更给`settings.py`语言，时区\n\n```\nLANGUAGE_CODE = 'zh-cn'\nTIME_ZONE = 'Asia/Shanghai'\n```\n\n数据库不用改 先使用默认的sqlite3,\n生成数据库\n```\npython manage.py migrate\n```\nrunserver 看下，可以再浏览器访问下 ip:8000\npython manage.py runserver 0.0.0.0:8000\n\n### 创建应用\n\ndjango 中 工程(project)与应用(application)概念要分清，我们使用 `django-admin.py manage.py startproject mysite`创建`mysite`的是工程.\n下边使用`python manage.py startapp blog` 创建的`blog`是应用，一个工程可以包括很多个应用。\n\n创建应用\n`python manage.py startapp blog`\n现在整个工程目录结构如下\n```\n.\n├── blog\n│   ├── admin.py\n│   ├── apps.py\n│   ├── __init__.py\n│   ├── migrations\n│   │   └── __init__.py\n│   ├── models.py\n│   ├── tests.py\n│   └── views.py\n├── db.sqlite3\n├── manage.py\n└── mysite\n    ├── __init__.py\n    ├── __pycache__\n    │   ├── __init__.cpython-35.pyc\n    │   ├── settings.cpython-35.pyc\n    │   ├── urls.cpython-35.pyc\n    │   └── wsgi.cpython-35.pyc\n    ├── settings.py\n    ├── urls.py\n    └── wsgi.py\n```\n\n然后，我们需要把这个应用在`settings.py`注册一下。\n```\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'blog',\n]\n```\n","slug":"Django之入门学习","published":1,"updated":"2017-07-14T04:55:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv4p00028tzzh90lobmp","content":"<blockquote>\n<p>自己动手从0开始</p>\n</blockquote>\n<p>python版本：3.5.1<br>Django版本：1.9.5</p>\n<h1 id=\"安装初始化\"><a href=\"#安装初始化\" class=\"headerlink\" title=\"安装初始化\"></a>安装初始化</h1><h2 id=\"python3\"><a href=\"#python3\" class=\"headerlink\" title=\"python3\"></a>python3</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum groupinstall &apos;Development Tools&apos;</div><div class=\"line\">yum install zlib-devel bzip2-devel openssl-devel ncurese-devel</div><div class=\"line\">wget https://www.python.org/ftp/python/3.5.1/Python-3.5.1.tar.xz &amp;&amp; mv Python-3.5.1.tar.xz /usr/local/ &amp;&amp; cd /usr/local</div><div class=\"line\">tar -Jxvf Python-3.5.1.tar.xz &amp;&amp;  cd Python-3.5.1</div><div class=\"line\">./configure --prefix=/usr/local/python3</div><div class=\"line\">make &amp;&amp; make install </div><div class=\"line\">ln -s /usr/local/python3/bin/python3.5 /usr/bin/python3</div><div class=\"line\">ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3</div><div class=\"line\"># </div><div class=\"line\">python3 -m venv myvenv</div></pre></td></tr></table></figure>\n<h2 id=\"django安装\"><a href=\"#django安装\" class=\"headerlink\" title=\"django安装\"></a>django安装</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">source myvenv/bin/activate</div><div class=\"line\">pip install django==1.9.5</div></pre></td></tr></table></figure>\n<h3 id=\"生成项目\"><a href=\"#生成项目\" class=\"headerlink\" title=\"生成项目\"></a>生成项目</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">django-admin.py startproject mysite</div></pre></td></tr></table></figure>\n<p><code>mysite</code>目录结构如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysite</div><div class=\"line\">├───manage.py</div><div class=\"line\">└───mysite</div><div class=\"line\">        settings.py</div><div class=\"line\">        urls.py</div><div class=\"line\">        wsgi.py</div><div class=\"line\">        __init__.py</div></pre></td></tr></table></figure>\n<ul>\n<li>manage.py是管理网站的脚本，可以使用它来启动一个简单的web服务器，这个对于开发调试非常有用。</li>\n<li>setting.py是工程的核心配置文件。</li>\n<li>urls.py是路径配置文件，可以配置URL到实际Controller的映射关系。</li>\n</ul>\n<h3 id=\"配置更改\"><a href=\"#配置更改\" class=\"headerlink\" title=\"配置更改\"></a>配置更改</h3><p>更给<code>settings.py</code>语言，时区</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">LANGUAGE_CODE = &apos;zh-cn&apos;</div><div class=\"line\">TIME_ZONE = &apos;Asia/Shanghai&apos;</div></pre></td></tr></table></figure>\n<p>数据库不用改 先使用默认的sqlite3,<br>生成数据库<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">python manage.py migrate</div></pre></td></tr></table></figure></p>\n<p>runserver 看下，可以再浏览器访问下 ip:8000<br>python manage.py runserver 0.0.0.0:8000</p>\n<h3 id=\"创建应用\"><a href=\"#创建应用\" class=\"headerlink\" title=\"创建应用\"></a>创建应用</h3><p>django 中 工程(project)与应用(application)概念要分清，我们使用 <code>django-admin.py manage.py startproject mysite</code>创建<code>mysite</code>的是工程.<br>下边使用<code>python manage.py startapp blog</code> 创建的<code>blog</code>是应用，一个工程可以包括很多个应用。</p>\n<p>创建应用<br><code>python manage.py startapp blog</code><br>现在整个工程目录结构如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">.</div><div class=\"line\">├── blog</div><div class=\"line\">│   ├── admin.py</div><div class=\"line\">│   ├── apps.py</div><div class=\"line\">│   ├── __init__.py</div><div class=\"line\">│   ├── migrations</div><div class=\"line\">│   │   └── __init__.py</div><div class=\"line\">│   ├── models.py</div><div class=\"line\">│   ├── tests.py</div><div class=\"line\">│   └── views.py</div><div class=\"line\">├── db.sqlite3</div><div class=\"line\">├── manage.py</div><div class=\"line\">└── mysite</div><div class=\"line\">    ├── __init__.py</div><div class=\"line\">    ├── __pycache__</div><div class=\"line\">    │   ├── __init__.cpython-35.pyc</div><div class=\"line\">    │   ├── settings.cpython-35.pyc</div><div class=\"line\">    │   ├── urls.cpython-35.pyc</div><div class=\"line\">    │   └── wsgi.cpython-35.pyc</div><div class=\"line\">    ├── settings.py</div><div class=\"line\">    ├── urls.py</div><div class=\"line\">    └── wsgi.py</div></pre></td></tr></table></figure></p>\n<p>然后，我们需要把这个应用在<code>settings.py</code>注册一下。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">INSTALLED_APPS = [</div><div class=\"line\">    &apos;django.contrib.admin&apos;,</div><div class=\"line\">    &apos;django.contrib.auth&apos;,</div><div class=\"line\">    &apos;django.contrib.contenttypes&apos;,</div><div class=\"line\">    &apos;django.contrib.sessions&apos;,</div><div class=\"line\">    &apos;django.contrib.messages&apos;,</div><div class=\"line\">    &apos;django.contrib.staticfiles&apos;,</div><div class=\"line\">    &apos;blog&apos;,</div><div class=\"line\">]</div></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>自己动手从0开始</p>\n</blockquote>\n<p>python版本：3.5.1<br>Django版本：1.9.5</p>\n<h1 id=\"安装初始化\"><a href=\"#安装初始化\" class=\"headerlink\" title=\"安装初始化\"></a>安装初始化</h1><h2 id=\"python3\"><a href=\"#python3\" class=\"headerlink\" title=\"python3\"></a>python3</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum groupinstall &apos;Development Tools&apos;</div><div class=\"line\">yum install zlib-devel bzip2-devel openssl-devel ncurese-devel</div><div class=\"line\">wget https://www.python.org/ftp/python/3.5.1/Python-3.5.1.tar.xz &amp;&amp; mv Python-3.5.1.tar.xz /usr/local/ &amp;&amp; cd /usr/local</div><div class=\"line\">tar -Jxvf Python-3.5.1.tar.xz &amp;&amp;  cd Python-3.5.1</div><div class=\"line\">./configure --prefix=/usr/local/python3</div><div class=\"line\">make &amp;&amp; make install </div><div class=\"line\">ln -s /usr/local/python3/bin/python3.5 /usr/bin/python3</div><div class=\"line\">ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3</div><div class=\"line\"># </div><div class=\"line\">python3 -m venv myvenv</div></pre></td></tr></table></figure>\n<h2 id=\"django安装\"><a href=\"#django安装\" class=\"headerlink\" title=\"django安装\"></a>django安装</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">source myvenv/bin/activate</div><div class=\"line\">pip install django==1.9.5</div></pre></td></tr></table></figure>\n<h3 id=\"生成项目\"><a href=\"#生成项目\" class=\"headerlink\" title=\"生成项目\"></a>生成项目</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">django-admin.py startproject mysite</div></pre></td></tr></table></figure>\n<p><code>mysite</code>目录结构如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysite</div><div class=\"line\">├───manage.py</div><div class=\"line\">└───mysite</div><div class=\"line\">        settings.py</div><div class=\"line\">        urls.py</div><div class=\"line\">        wsgi.py</div><div class=\"line\">        __init__.py</div></pre></td></tr></table></figure>\n<ul>\n<li>manage.py是管理网站的脚本，可以使用它来启动一个简单的web服务器，这个对于开发调试非常有用。</li>\n<li>setting.py是工程的核心配置文件。</li>\n<li>urls.py是路径配置文件，可以配置URL到实际Controller的映射关系。</li>\n</ul>\n<h3 id=\"配置更改\"><a href=\"#配置更改\" class=\"headerlink\" title=\"配置更改\"></a>配置更改</h3><p>更给<code>settings.py</code>语言，时区</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">LANGUAGE_CODE = &apos;zh-cn&apos;</div><div class=\"line\">TIME_ZONE = &apos;Asia/Shanghai&apos;</div></pre></td></tr></table></figure>\n<p>数据库不用改 先使用默认的sqlite3,<br>生成数据库<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">python manage.py migrate</div></pre></td></tr></table></figure></p>\n<p>runserver 看下，可以再浏览器访问下 ip:8000<br>python manage.py runserver 0.0.0.0:8000</p>\n<h3 id=\"创建应用\"><a href=\"#创建应用\" class=\"headerlink\" title=\"创建应用\"></a>创建应用</h3><p>django 中 工程(project)与应用(application)概念要分清，我们使用 <code>django-admin.py manage.py startproject mysite</code>创建<code>mysite</code>的是工程.<br>下边使用<code>python manage.py startapp blog</code> 创建的<code>blog</code>是应用，一个工程可以包括很多个应用。</p>\n<p>创建应用<br><code>python manage.py startapp blog</code><br>现在整个工程目录结构如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">.</div><div class=\"line\">├── blog</div><div class=\"line\">│   ├── admin.py</div><div class=\"line\">│   ├── apps.py</div><div class=\"line\">│   ├── __init__.py</div><div class=\"line\">│   ├── migrations</div><div class=\"line\">│   │   └── __init__.py</div><div class=\"line\">│   ├── models.py</div><div class=\"line\">│   ├── tests.py</div><div class=\"line\">│   └── views.py</div><div class=\"line\">├── db.sqlite3</div><div class=\"line\">├── manage.py</div><div class=\"line\">└── mysite</div><div class=\"line\">    ├── __init__.py</div><div class=\"line\">    ├── __pycache__</div><div class=\"line\">    │   ├── __init__.cpython-35.pyc</div><div class=\"line\">    │   ├── settings.cpython-35.pyc</div><div class=\"line\">    │   ├── urls.cpython-35.pyc</div><div class=\"line\">    │   └── wsgi.cpython-35.pyc</div><div class=\"line\">    ├── settings.py</div><div class=\"line\">    ├── urls.py</div><div class=\"line\">    └── wsgi.py</div></pre></td></tr></table></figure></p>\n<p>然后，我们需要把这个应用在<code>settings.py</code>注册一下。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">INSTALLED_APPS = [</div><div class=\"line\">    &apos;django.contrib.admin&apos;,</div><div class=\"line\">    &apos;django.contrib.auth&apos;,</div><div class=\"line\">    &apos;django.contrib.contenttypes&apos;,</div><div class=\"line\">    &apos;django.contrib.sessions&apos;,</div><div class=\"line\">    &apos;django.contrib.messages&apos;,</div><div class=\"line\">    &apos;django.contrib.staticfiles&apos;,</div><div class=\"line\">    &apos;blog&apos;,</div><div class=\"line\">]</div></pre></td></tr></table></figure></p>\n"},{"title":"ELK问题处理汇总","date":"2017-06-05T08:46:11.000Z","_content":"\n## 1. Field data loading is forbidden on [FIELDNAME]  \n\n> 问题描述： 当我们在kibana画图时，有的nginx_access 日志中的有一部分字段是不能用的，在grafana中也不可以，但是别的索引文件可以，比如elapsed_log,search_log,错误如下图所示\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-05%20%E4%B8%8B%E5%8D%887.06.50.png)\n### 问题原因\n\n问题原因就是我们索引的设置中 `\"fielddata\" : { \"format\" : \"disabled\" }` 这个设置存在导致的结果就是\n\n- Field data loading is forbidden on type\n- Field data loading is forbidden on path\n- Field data loading is forbidden on host\n\n查看索引settings\n```\ncurl 10.215.33.36:9200/logstash-*/_mapping\n```\n查看确实存在`\"mapping\":{\"fielddata\":{\"format\":\"disabled\"}`这种设置，\n\n### 解决过程\n\n修改mapping，ES的索引是已建成就固定的，中途修改只能是 建新索引-->数据导入-->旧索引删除。 所以我们可以直接修改template，等到第二天自动更新的时候新的索引设置就会正常了。\n具体操作记录在[ES使用](https://fanquqi.github.io/2017/06/05/ElasticSearch%E4%BD%BF%E7%94%A8/)的template更新中。\n\n参考：https://github.com/elastic/elasticsearch/issues/15267\n\n\n---------\n\n\n\n## 2. 修改字段类型\n> 数据通过logstash 的grok过滤之后，传输到ES当中，ES是可以自动发现的，自动生成mapping，并不用事先设置mapping，很方便。默认会把所有的字段设置成string,但是有的时候我们需要float等数据类型，怎么更改？？\n\n当前看有两种方式：\n1. 直接修改mapping。\n2. 在logstash grok的时候指定数据类型。\n    + 类似于这种`%{NUMBER:status:float}` ,`NUMBER`是grok支持的数据类型，`status`是自定义字段名称, `float`即为字段类型。但是这个可能不会立即生效。\n\n\n## 3. mapping 冲突解决\n> 问题2中第二种方法修改完字段类型之后，刷新索引，会造成新老数据的类型不一致导致冲突。\n\n参考: https://dev.sobeslavsky.net/kibana-how-to-solve-mapping-conflict/\n其实完全不用理会 等到老的索引过期被删掉就好了\n\n\n## 4. 自动删除索引脚本\n> 收集的日志每天量很大有200多G，自己的三个ES节点存储有限，所以留存维持大约三四天的新鲜日志,需要编写个脚本定期删除索引。\n\n```\n#!/bin/bash\ntoday=`date +%Y.%m.%d`;\necho \"今天是${today}\"\n# 获得要删除的日期\n# 不指定参数时，默认删除3天前的数据（因为是凌晨删除，所以不含当天）\ndaynum=3\n# 当参数个数大于1时，提示参数错误\nif [ $# -gt 1 ] ;then\n        echo \"要么不传参数，要么只传1个参数!\"\n        exit 101;\nfi\n# 当参数个数为1时，获取指定的参数\nif [ $# == 1 ] ;then\n        daynum=$1\nfi\nesday=`date -d '-'\"${daynum}\"' day' +%Y.%m.%d`;\necho \"${daynum}天前是${esday}\"\ncurl -XDELETE http://localhost:9200/logstash-nginx_access-${esday}\ncurl -XDELETE http://localhost:9200/elapsed_log-${esday}\ncurl -XDELETE http://localhost:9200/file_log-${esday}\ncurl -XDELETE http://localhost:9200/info_log-${esday}\ncurl -XDELETE http://localhost:9200/search.log-${esday}\n\necho \"${today}执行完成\"\n# echo curl -XDELETE http://localhost:9200/aaa-*-${esday}\n```\n\n内容如上，然后写进cron每天执行就好了。\n\n## 5. logstash 插入json 格式数据\n>大数据那边search_log 是json格式的，安装普通的input插入就会有问题。\n\n修改配置文件 input 中的 file 中 加入 codec => json { charset => \"UTF-8” }\n![](http://or2jd66dq.bkt.clouddn.com/logstash_json.png)\n\n## 6. ES各节点内存分配\n- 配置位置：/usr/local/elasticsearch-2.3.2/bin/elasticsearch.in.sh  \n- 三个节点 md6：16G     md10：16G     md11:32G\n![](http://or2jd66dq.bkt.clouddn.com/ES%E5%86%85%E5%AD%98%E8%B0%83%E6%95%B4.png)\n\n## 7. elasticsearch 节点安全重启\n> elasticsearch集群，有时候可能需要修改配置，增删硬件等操作，需要对节点进行升级等操作。但是服务不能停，如果直接kill掉节点，可能导致数据丢失。而且集群会认为该节点挂掉了，就开始转移数据（这个过程相当好资源，经历过两次，直接kill掉某一节点后集群开始relocation，网卡被打满，正常请求很多超时），当重启之后，它又会恢复数据，如果你当前的数据量已经很大了，这是很耗费机器和网络资源的。\n\n- 第一步：先暂停集群的shard自动均衡\n```\n curl -XPUT http://192.168.1.2:9200/_cluster/settings -d'\n\n        {\n\n        \"transient\" : {\n\n        \"cluster.routing.allocation.enable\" : \"none\"\n\n            }        \n\n        }'\n```\n- 第二步：kill要升级的节点\n```\nps aux |grep elasticsearch |awk '{print $2}' |xargs kill\n```\n- 第三步：恢复集群的shard自动均衡\n```\ncurl -XPUT http://192.168.1.2/_cluster/settings -d'\n\n        {\n\n        \"transient\" : {\n\n        \"cluster.routing.allocation.enable\" : \"all\"\n\n        }\n\n        }'\n```\n\n## 8. 误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点 集群状态如下图所示 此时kibana上面已经没有数据\n> ES某个节点数据被老大误删除\n![](http://or2jd66dq.bkt.clouddn.com/ES%E8%8A%82%E7%82%B9%E8%A2%AB%E8%AF%AF%E5%88%A0%E9%99%A4.png)\n重启elasticsearch 各个节点之后还是没有数据插入。\n`解决办法：`\n* 需要删除坏的索引数据 就是今天的数据 具体方法：找到今天的索引elapsed_log-2016.11.03==>点击\"动作\"==>点击 “删除”  之后Unassigned 节点会消失， 刷新一下 kibana上数据出现。\n\n## 9. Elasticsearch high disk watermark 问题\n\n问题描述：因为我们每个节点都不是单独只提供一个服务，每台机器的配置和硬盘大小都不尽一致，内存啥的可以很好的处理，但是硬盘大小怎么分配？\n比如说有一台机器600G硬盘，剩下两台2T硬盘，这种，如果平均分配恐怕是不行了，小磁盘爆了大磁盘还没有存一半。怎么办？\n\n`问题解决` ES在你想到这个问题之前就已经想到了。操作如下\n\n```\ncurl -XPUT 10.215.33.36:9200/_cluster/settings -d '{\n  \"transient\": {\n    \"cluster.routing.allocation.disk.watermark.low\": \"80%\",\n    \"cluster.routing.allocation.disk.watermark.high\": \"80gb\",\n    \"cluster.info.update.interval\": \"1m\"\n  }\n}'\n```\n\n解读下这三个参数。\n`cluster.routing.allocation.disk.watermark.low`  Controls the low watermark for disk usage. It defaults to 85%.如果磁盘使用查过85% 就不回新建分片到这个节点上了，保证磁盘不会被撑爆。\n`cluster.routing.allocation.disk.watermark.high` Controls the high watermark. It defaults to 90%.默认值百分之90。如果某节点磁盘使用到达90% ES会自动把此节点上的分片转移到别的节点。也可以设置成某个数值类似上文`50gb`\n`cluster.info.update.interval` How often Elasticsearch should check on disk usage for each node in the cluster. Defaults to 30s. 多久检查一次磁盘用量，默认值30s.由于我们不可能在1分钟内写几十GB数据所以这个可以设置的稍长一些。\n\n## 10. 时区问题处理\n\n之前看到过有人说ELK的失去问题，类似kibana显示出来时间与真实时间差8小时，我一直没有遇到，直到今天。。。\n`问题描述`: 事情的经过是这样的，我给ES扩容,然后修改了template（目的在给集群优化一下，提高下集群的QPS）但是导致之前grok失效了，第二天来了发现grafana中爬虫统计数据就到今天8点整，然后我意识到自己昨天的操作有问题，然后删除今天的数据重新导入。奇怪的事儿发生了。。我明明删除了几天的nginx_access日志的index但是kibana中还是有到今天八点的数据，我仔细一看今天的数据存在了昨天的索引当中。如下图\n![](http://or2jd66dq.bkt.clouddn.com/kibanaUTC.png)\n然后我特别不解为啥ES会在8点钟新建一个索引？？？\n为啥？\n\n其实是logstash在ES建立的索引，它每天0点建立一个新的索引，kibana也接受这种设定, 在查询和展示时根据用户的时区进行处理。\n这导致了, 对于东八区, 2017-07-27日, 8点之前, 只有logstash-2017.07.26这个index, 到8点的时候, 创建新的index logstash-2017.07.27, 即, 对于我们这个时区的人来说, 一天的数据存在了两个index里面\n**修改方案一**\n\n更改logstash的设定,使用localtime\n\n**修改方案二** \n\n不做修改，接受\n\n## 11. 重建索引\n之前ELK就是给运维自己用，可以随便折腾，索引都是直接删除，或者配置好template等第二天重建索引再看新的数据，但是PM和CTO有时候都看grafana上的数据，运维操作就要求更规范了啊，其实不是给他们看，我们自己就该严格要求自己，下边记录下重建索引的的过程。\n","source":"_posts/ELK问题处理汇总.md","raw":"---\ntitle: ELK问题处理汇总\ndate: 2017-06-05 16:46:11\ntags: ELK\ncategories: 运维工具\n---\n\n## 1. Field data loading is forbidden on [FIELDNAME]  \n\n> 问题描述： 当我们在kibana画图时，有的nginx_access 日志中的有一部分字段是不能用的，在grafana中也不可以，但是别的索引文件可以，比如elapsed_log,search_log,错误如下图所示\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-05%20%E4%B8%8B%E5%8D%887.06.50.png)\n### 问题原因\n\n问题原因就是我们索引的设置中 `\"fielddata\" : { \"format\" : \"disabled\" }` 这个设置存在导致的结果就是\n\n- Field data loading is forbidden on type\n- Field data loading is forbidden on path\n- Field data loading is forbidden on host\n\n查看索引settings\n```\ncurl 10.215.33.36:9200/logstash-*/_mapping\n```\n查看确实存在`\"mapping\":{\"fielddata\":{\"format\":\"disabled\"}`这种设置，\n\n### 解决过程\n\n修改mapping，ES的索引是已建成就固定的，中途修改只能是 建新索引-->数据导入-->旧索引删除。 所以我们可以直接修改template，等到第二天自动更新的时候新的索引设置就会正常了。\n具体操作记录在[ES使用](https://fanquqi.github.io/2017/06/05/ElasticSearch%E4%BD%BF%E7%94%A8/)的template更新中。\n\n参考：https://github.com/elastic/elasticsearch/issues/15267\n\n\n---------\n\n\n\n## 2. 修改字段类型\n> 数据通过logstash 的grok过滤之后，传输到ES当中，ES是可以自动发现的，自动生成mapping，并不用事先设置mapping，很方便。默认会把所有的字段设置成string,但是有的时候我们需要float等数据类型，怎么更改？？\n\n当前看有两种方式：\n1. 直接修改mapping。\n2. 在logstash grok的时候指定数据类型。\n    + 类似于这种`%{NUMBER:status:float}` ,`NUMBER`是grok支持的数据类型，`status`是自定义字段名称, `float`即为字段类型。但是这个可能不会立即生效。\n\n\n## 3. mapping 冲突解决\n> 问题2中第二种方法修改完字段类型之后，刷新索引，会造成新老数据的类型不一致导致冲突。\n\n参考: https://dev.sobeslavsky.net/kibana-how-to-solve-mapping-conflict/\n其实完全不用理会 等到老的索引过期被删掉就好了\n\n\n## 4. 自动删除索引脚本\n> 收集的日志每天量很大有200多G，自己的三个ES节点存储有限，所以留存维持大约三四天的新鲜日志,需要编写个脚本定期删除索引。\n\n```\n#!/bin/bash\ntoday=`date +%Y.%m.%d`;\necho \"今天是${today}\"\n# 获得要删除的日期\n# 不指定参数时，默认删除3天前的数据（因为是凌晨删除，所以不含当天）\ndaynum=3\n# 当参数个数大于1时，提示参数错误\nif [ $# -gt 1 ] ;then\n        echo \"要么不传参数，要么只传1个参数!\"\n        exit 101;\nfi\n# 当参数个数为1时，获取指定的参数\nif [ $# == 1 ] ;then\n        daynum=$1\nfi\nesday=`date -d '-'\"${daynum}\"' day' +%Y.%m.%d`;\necho \"${daynum}天前是${esday}\"\ncurl -XDELETE http://localhost:9200/logstash-nginx_access-${esday}\ncurl -XDELETE http://localhost:9200/elapsed_log-${esday}\ncurl -XDELETE http://localhost:9200/file_log-${esday}\ncurl -XDELETE http://localhost:9200/info_log-${esday}\ncurl -XDELETE http://localhost:9200/search.log-${esday}\n\necho \"${today}执行完成\"\n# echo curl -XDELETE http://localhost:9200/aaa-*-${esday}\n```\n\n内容如上，然后写进cron每天执行就好了。\n\n## 5. logstash 插入json 格式数据\n>大数据那边search_log 是json格式的，安装普通的input插入就会有问题。\n\n修改配置文件 input 中的 file 中 加入 codec => json { charset => \"UTF-8” }\n![](http://or2jd66dq.bkt.clouddn.com/logstash_json.png)\n\n## 6. ES各节点内存分配\n- 配置位置：/usr/local/elasticsearch-2.3.2/bin/elasticsearch.in.sh  \n- 三个节点 md6：16G     md10：16G     md11:32G\n![](http://or2jd66dq.bkt.clouddn.com/ES%E5%86%85%E5%AD%98%E8%B0%83%E6%95%B4.png)\n\n## 7. elasticsearch 节点安全重启\n> elasticsearch集群，有时候可能需要修改配置，增删硬件等操作，需要对节点进行升级等操作。但是服务不能停，如果直接kill掉节点，可能导致数据丢失。而且集群会认为该节点挂掉了，就开始转移数据（这个过程相当好资源，经历过两次，直接kill掉某一节点后集群开始relocation，网卡被打满，正常请求很多超时），当重启之后，它又会恢复数据，如果你当前的数据量已经很大了，这是很耗费机器和网络资源的。\n\n- 第一步：先暂停集群的shard自动均衡\n```\n curl -XPUT http://192.168.1.2:9200/_cluster/settings -d'\n\n        {\n\n        \"transient\" : {\n\n        \"cluster.routing.allocation.enable\" : \"none\"\n\n            }        \n\n        }'\n```\n- 第二步：kill要升级的节点\n```\nps aux |grep elasticsearch |awk '{print $2}' |xargs kill\n```\n- 第三步：恢复集群的shard自动均衡\n```\ncurl -XPUT http://192.168.1.2/_cluster/settings -d'\n\n        {\n\n        \"transient\" : {\n\n        \"cluster.routing.allocation.enable\" : \"all\"\n\n        }\n\n        }'\n```\n\n## 8. 误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点 集群状态如下图所示 此时kibana上面已经没有数据\n> ES某个节点数据被老大误删除\n![](http://or2jd66dq.bkt.clouddn.com/ES%E8%8A%82%E7%82%B9%E8%A2%AB%E8%AF%AF%E5%88%A0%E9%99%A4.png)\n重启elasticsearch 各个节点之后还是没有数据插入。\n`解决办法：`\n* 需要删除坏的索引数据 就是今天的数据 具体方法：找到今天的索引elapsed_log-2016.11.03==>点击\"动作\"==>点击 “删除”  之后Unassigned 节点会消失， 刷新一下 kibana上数据出现。\n\n## 9. Elasticsearch high disk watermark 问题\n\n问题描述：因为我们每个节点都不是单独只提供一个服务，每台机器的配置和硬盘大小都不尽一致，内存啥的可以很好的处理，但是硬盘大小怎么分配？\n比如说有一台机器600G硬盘，剩下两台2T硬盘，这种，如果平均分配恐怕是不行了，小磁盘爆了大磁盘还没有存一半。怎么办？\n\n`问题解决` ES在你想到这个问题之前就已经想到了。操作如下\n\n```\ncurl -XPUT 10.215.33.36:9200/_cluster/settings -d '{\n  \"transient\": {\n    \"cluster.routing.allocation.disk.watermark.low\": \"80%\",\n    \"cluster.routing.allocation.disk.watermark.high\": \"80gb\",\n    \"cluster.info.update.interval\": \"1m\"\n  }\n}'\n```\n\n解读下这三个参数。\n`cluster.routing.allocation.disk.watermark.low`  Controls the low watermark for disk usage. It defaults to 85%.如果磁盘使用查过85% 就不回新建分片到这个节点上了，保证磁盘不会被撑爆。\n`cluster.routing.allocation.disk.watermark.high` Controls the high watermark. It defaults to 90%.默认值百分之90。如果某节点磁盘使用到达90% ES会自动把此节点上的分片转移到别的节点。也可以设置成某个数值类似上文`50gb`\n`cluster.info.update.interval` How often Elasticsearch should check on disk usage for each node in the cluster. Defaults to 30s. 多久检查一次磁盘用量，默认值30s.由于我们不可能在1分钟内写几十GB数据所以这个可以设置的稍长一些。\n\n## 10. 时区问题处理\n\n之前看到过有人说ELK的失去问题，类似kibana显示出来时间与真实时间差8小时，我一直没有遇到，直到今天。。。\n`问题描述`: 事情的经过是这样的，我给ES扩容,然后修改了template（目的在给集群优化一下，提高下集群的QPS）但是导致之前grok失效了，第二天来了发现grafana中爬虫统计数据就到今天8点整，然后我意识到自己昨天的操作有问题，然后删除今天的数据重新导入。奇怪的事儿发生了。。我明明删除了几天的nginx_access日志的index但是kibana中还是有到今天八点的数据，我仔细一看今天的数据存在了昨天的索引当中。如下图\n![](http://or2jd66dq.bkt.clouddn.com/kibanaUTC.png)\n然后我特别不解为啥ES会在8点钟新建一个索引？？？\n为啥？\n\n其实是logstash在ES建立的索引，它每天0点建立一个新的索引，kibana也接受这种设定, 在查询和展示时根据用户的时区进行处理。\n这导致了, 对于东八区, 2017-07-27日, 8点之前, 只有logstash-2017.07.26这个index, 到8点的时候, 创建新的index logstash-2017.07.27, 即, 对于我们这个时区的人来说, 一天的数据存在了两个index里面\n**修改方案一**\n\n更改logstash的设定,使用localtime\n\n**修改方案二** \n\n不做修改，接受\n\n## 11. 重建索引\n之前ELK就是给运维自己用，可以随便折腾，索引都是直接删除，或者配置好template等第二天重建索引再看新的数据，但是PM和CTO有时候都看grafana上的数据，运维操作就要求更规范了啊，其实不是给他们看，我们自己就该严格要求自己，下边记录下重建索引的的过程。\n","slug":"ELK问题处理汇总","published":1,"updated":"2017-08-07T02:22:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv4v00058tzzp6fibc1h","content":"<h2 id=\"1-field-data-loading-is-forbidden-on-fieldname\"><a href=\"#1-Field-data-loading-is-forbidden-on-FIELDNAME\" class=\"headerlink\" title=\"1. Field data loading is forbidden on [FIELDNAME]\"></a>1. Field data loading is forbidden on [FIELDNAME]</h2><blockquote>\n<p>问题描述： 当我们在kibana画图时，有的nginx_access 日志中的有一部分字段是不能用的，在grafana中也不可以，但是别的索引文件可以，比如elapsed_log,search_log,错误如下图所示</p>\n</blockquote>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-05%20%E4%B8%8B%E5%8D%887.06.50.png\" alt=\"\"></p>\n<h3 id=\"问题原因\"><a href=\"#问题原因\" class=\"headerlink\" title=\"问题原因\"></a>问题原因</h3><p>问题原因就是我们索引的设置中 <code>&quot;fielddata&quot; : { &quot;format&quot; : &quot;disabled&quot; }</code> 这个设置存在导致的结果就是</p>\n<ul>\n<li>Field data loading is forbidden on type</li>\n<li>Field data loading is forbidden on path</li>\n<li>Field data loading is forbidden on host</li>\n</ul>\n<p>查看索引settings<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl 10.215.33.36:9200/logstash-*/_mapping</div></pre></td></tr></table></figure></p>\n<p>查看确实存在<code>&quot;mapping&quot;:{&quot;fielddata&quot;:{&quot;format&quot;:&quot;disabled&quot;}</code>这种设置，</p>\n<h3 id=\"解决过程\"><a href=\"#解决过程\" class=\"headerlink\" title=\"解决过程\"></a>解决过程</h3><p>修改mapping，ES的索引是已建成就固定的，中途修改只能是 建新索引–&gt;数据导入–&gt;旧索引删除。 所以我们可以直接修改template，等到第二天自动更新的时候新的索引设置就会正常了。<br>具体操作记录在<a href=\"https://fanquqi.github.io/2017/06/05/ElasticSearch%E4%BD%BF%E7%94%A8/\" target=\"_blank\" rel=\"external\">ES使用</a>的template更新中。</p>\n<p>参考：<a href=\"https://github.com/elastic/elasticsearch/issues/15267\" target=\"_blank\" rel=\"external\">https://github.com/elastic/elasticsearch/issues/15267</a></p>\n<hr>\n<h2 id=\"2-修改字段类型\"><a href=\"#2-修改字段类型\" class=\"headerlink\" title=\"2. 修改字段类型\"></a>2. 修改字段类型</h2><blockquote>\n<p>数据通过logstash 的grok过滤之后，传输到ES当中，ES是可以自动发现的，自动生成mapping，并不用事先设置mapping，很方便。默认会把所有的字段设置成string,但是有的时候我们需要float等数据类型，怎么更改？？</p>\n</blockquote>\n<p>当前看有两种方式：</p>\n<ol>\n<li>直接修改mapping。</li>\n<li>在logstash grok的时候指定数据类型。<ul>\n<li>类似于这种<code>%{NUMBER:status:float}</code> ,<code>NUMBER</code>是grok支持的数据类型，<code>status</code>是自定义字段名称, <code>float</code>即为字段类型。但是这个可能不会立即生效。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-mapping-冲突解决\"><a href=\"#3-mapping-冲突解决\" class=\"headerlink\" title=\"3. mapping 冲突解决\"></a>3. mapping 冲突解决</h2><blockquote>\n<p>问题2中第二种方法修改完字段类型之后，刷新索引，会造成新老数据的类型不一致导致冲突。</p>\n</blockquote>\n<p>参考: <a href=\"https://dev.sobeslavsky.net/kibana-how-to-solve-mapping-conflict/\" target=\"_blank\" rel=\"external\">https://dev.sobeslavsky.net/kibana-how-to-solve-mapping-conflict/</a><br>其实完全不用理会 等到老的索引过期被删掉就好了</p>\n<h2 id=\"4-自动删除索引脚本\"><a href=\"#4-自动删除索引脚本\" class=\"headerlink\" title=\"4. 自动删除索引脚本\"></a>4. 自动删除索引脚本</h2><blockquote>\n<p>收集的日志每天量很大有200多G，自己的三个ES节点存储有限，所以留存维持大约三四天的新鲜日志,需要编写个脚本定期删除索引。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/bash</div><div class=\"line\">today=`date +%Y.%m.%d`;</div><div class=\"line\">echo &quot;今天是$&#123;today&#125;&quot;</div><div class=\"line\"># 获得要删除的日期</div><div class=\"line\"># 不指定参数时，默认删除3天前的数据（因为是凌晨删除，所以不含当天）</div><div class=\"line\">daynum=3</div><div class=\"line\"># 当参数个数大于1时，提示参数错误</div><div class=\"line\">if [ $# -gt 1 ] ;then</div><div class=\"line\">        echo &quot;要么不传参数，要么只传1个参数!&quot;</div><div class=\"line\">        exit 101;</div><div class=\"line\">fi</div><div class=\"line\"># 当参数个数为1时，获取指定的参数</div><div class=\"line\">if [ $# == 1 ] ;then</div><div class=\"line\">        daynum=$1</div><div class=\"line\">fi</div><div class=\"line\">esday=`date -d &apos;-&apos;&quot;$&#123;daynum&#125;&quot;&apos; day&apos; +%Y.%m.%d`;</div><div class=\"line\">echo &quot;$&#123;daynum&#125;天前是$&#123;esday&#125;&quot;</div><div class=\"line\">curl -XDELETE http://localhost:9200/logstash-nginx_access-$&#123;esday&#125;</div><div class=\"line\">curl -XDELETE http://localhost:9200/elapsed_log-$&#123;esday&#125;</div><div class=\"line\">curl -XDELETE http://localhost:9200/file_log-$&#123;esday&#125;</div><div class=\"line\">curl -XDELETE http://localhost:9200/info_log-$&#123;esday&#125;</div><div class=\"line\">curl -XDELETE http://localhost:9200/search.log-$&#123;esday&#125;</div><div class=\"line\"></div><div class=\"line\">echo &quot;$&#123;today&#125;执行完成&quot;</div><div class=\"line\"># echo curl -XDELETE http://localhost:9200/aaa-*-$&#123;esday&#125;</div></pre></td></tr></table></figure>\n<p>内容如上，然后写进cron每天执行就好了。</p>\n<h2 id=\"5-logstash-插入json-格式数据\"><a href=\"#5-logstash-插入json-格式数据\" class=\"headerlink\" title=\"5. logstash 插入json 格式数据\"></a>5. logstash 插入json 格式数据</h2><blockquote>\n<p>大数据那边search_log 是json格式的，安装普通的input插入就会有问题。</p>\n</blockquote>\n<p>修改配置文件 input 中的 file 中 加入 codec =&gt; json { charset =&gt; “UTF-8” }<br><img src=\"http://or2jd66dq.bkt.clouddn.com/logstash_json.png\" alt=\"\"></p>\n<h2 id=\"6-es各节点内存分配\"><a href=\"#6-ES各节点内存分配\" class=\"headerlink\" title=\"6. ES各节点内存分配\"></a>6. ES各节点内存分配</h2><ul>\n<li>配置位置：/usr/local/elasticsearch-2.3.2/bin/elasticsearch.in.sh  </li>\n<li>三个节点 md6：16G     md10：16G     md11:32G<br><img src=\"http://or2jd66dq.bkt.clouddn.com/ES%E5%86%85%E5%AD%98%E8%B0%83%E6%95%B4.png\" alt=\"\"></li>\n</ul>\n<h2 id=\"7-elasticsearch-节点安全重启\"><a href=\"#7-elasticsearch-节点安全重启\" class=\"headerlink\" title=\"7. elasticsearch 节点安全重启\"></a>7. elasticsearch 节点安全重启</h2><blockquote>\n<p>elasticsearch集群，有时候可能需要修改配置，增删硬件等操作，需要对节点进行升级等操作。但是服务不能停，如果直接kill掉节点，可能导致数据丢失。而且集群会认为该节点挂掉了，就开始转移数据（这个过程相当好资源，经历过两次，直接kill掉某一节点后集群开始relocation，网卡被打满，正常请求很多超时），当重启之后，它又会恢复数据，如果你当前的数据量已经很大了，这是很耗费机器和网络资源的。</p>\n</blockquote>\n<ul>\n<li><p>第一步：先暂停集群的shard自动均衡</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPUT http://192.168.1.2:9200/_cluster/settings -d&apos;</div><div class=\"line\"></div><div class=\"line\">       &#123;</div><div class=\"line\"></div><div class=\"line\">       &quot;transient&quot; : &#123;</div><div class=\"line\"></div><div class=\"line\">       &quot;cluster.routing.allocation.enable&quot; : &quot;none&quot;</div><div class=\"line\"></div><div class=\"line\">           &#125;        </div><div class=\"line\"></div><div class=\"line\">       &#125;&apos;</div></pre></td></tr></table></figure>\n</li>\n<li><p>第二步：kill要升级的节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ps aux |grep elasticsearch |awk &apos;&#123;print $2&#125;&apos; |xargs kill</div></pre></td></tr></table></figure>\n</li>\n<li><p>第三步：恢复集群的shard自动均衡</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPUT http://192.168.1.2/_cluster/settings -d&apos;</div><div class=\"line\"></div><div class=\"line\">        &#123;</div><div class=\"line\"></div><div class=\"line\">        &quot;transient&quot; : &#123;</div><div class=\"line\"></div><div class=\"line\">        &quot;cluster.routing.allocation.enable&quot; : &quot;all&quot;</div><div class=\"line\"></div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        &#125;&apos;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"8-误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点-集群状态如下图所示-此时kibana上面已经没有数据\"><a href=\"#8-误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点-集群状态如下图所示-此时kibana上面已经没有数据\" class=\"headerlink\" title=\"8. 误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点 集群状态如下图所示 此时kibana上面已经没有数据\"></a>8. 误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点 集群状态如下图所示 此时kibana上面已经没有数据</h2><blockquote>\n<p>ES某个节点数据被老大误删除<br><img src=\"http://or2jd66dq.bkt.clouddn.com/ES%E8%8A%82%E7%82%B9%E8%A2%AB%E8%AF%AF%E5%88%A0%E9%99%A4.png\" alt=\"\"><br>重启elasticsearch 各个节点之后还是没有数据插入。<br><code>解决办法：</code></p>\n<ul>\n<li>需要删除坏的索引数据 就是今天的数据 具体方法：找到今天的索引elapsed_log-2016.11.03==&gt;点击”动作”==&gt;点击 “删除”  之后Unassigned 节点会消失， 刷新一下 kibana上数据出现。</li>\n</ul>\n</blockquote>\n<h2 id=\"9-elasticsearch-high-disk-watermark-问题\"><a href=\"#9-Elasticsearch-high-disk-watermark-问题\" class=\"headerlink\" title=\"9. Elasticsearch high disk watermark 问题\"></a>9. Elasticsearch high disk watermark 问题</h2><p>问题描述：因为我们每个节点都不是单独只提供一个服务，每台机器的配置和硬盘大小都不尽一致，内存啥的可以很好的处理，但是硬盘大小怎么分配？<br>比如说有一台机器600G硬盘，剩下两台2T硬盘，这种，如果平均分配恐怕是不行了，小磁盘爆了大磁盘还没有存一半。怎么办？</p>\n<p><code>问题解决</code> ES在你想到这个问题之前就已经想到了。操作如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPUT 10.215.33.36:9200/_cluster/settings -d &apos;&#123;</div><div class=\"line\">  &quot;transient&quot;: &#123;</div><div class=\"line\">    &quot;cluster.routing.allocation.disk.watermark.low&quot;: &quot;80%&quot;,</div><div class=\"line\">    &quot;cluster.routing.allocation.disk.watermark.high&quot;: &quot;80gb&quot;,</div><div class=\"line\">    &quot;cluster.info.update.interval&quot;: &quot;1m&quot;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;&apos;</div></pre></td></tr></table></figure>\n<p>解读下这三个参数。<br><code>cluster.routing.allocation.disk.watermark.low</code>  Controls the low watermark for disk usage. It defaults to 85%.如果磁盘使用查过85% 就不回新建分片到这个节点上了，保证磁盘不会被撑爆。<br><code>cluster.routing.allocation.disk.watermark.high</code> Controls the high watermark. It defaults to 90%.默认值百分之90。如果某节点磁盘使用到达90% ES会自动把此节点上的分片转移到别的节点。也可以设置成某个数值类似上文<code>50gb</code><br><code>cluster.info.update.interval</code> How often Elasticsearch should check on disk usage for each node in the cluster. Defaults to 30s. 多久检查一次磁盘用量，默认值30s.由于我们不可能在1分钟内写几十GB数据所以这个可以设置的稍长一些。</p>\n<h2 id=\"10-时区问题处理\"><a href=\"#10-时区问题处理\" class=\"headerlink\" title=\"10. 时区问题处理\"></a>10. 时区问题处理</h2><p>之前看到过有人说ELK的失去问题，类似kibana显示出来时间与真实时间差8小时，我一直没有遇到，直到今天。。。<br><code>问题描述</code>: 事情的经过是这样的，我给ES扩容,然后修改了template（目的在给集群优化一下，提高下集群的QPS）但是导致之前grok失效了，第二天来了发现grafana中爬虫统计数据就到今天8点整，然后我意识到自己昨天的操作有问题，然后删除今天的数据重新导入。奇怪的事儿发生了。。我明明删除了几天的nginx_access日志的index但是kibana中还是有到今天八点的数据，我仔细一看今天的数据存在了昨天的索引当中。如下图<br><img src=\"http://or2jd66dq.bkt.clouddn.com/kibanaUTC.png\" alt=\"\"><br>然后我特别不解为啥ES会在8点钟新建一个索引？？？<br>为啥？</p>\n<p>其实是logstash在ES建立的索引，它每天0点建立一个新的索引，kibana也接受这种设定, 在查询和展示时根据用户的时区进行处理。<br>这导致了, 对于东八区, 2017-07-27日, 8点之前, 只有logstash-2017.07.26这个index, 到8点的时候, 创建新的index logstash-2017.07.27, 即, 对于我们这个时区的人来说, 一天的数据存在了两个index里面<br><strong>修改方案一</strong></p>\n<p>更改logstash的设定,使用localtime</p>\n<p><strong>修改方案二</strong> </p>\n<p>不做修改，接受</p>\n<h2 id=\"11-重建索引\"><a href=\"#11-重建索引\" class=\"headerlink\" title=\"11. 重建索引\"></a>11. 重建索引</h2><p>之前ELK就是给运维自己用，可以随便折腾，索引都是直接删除，或者配置好template等第二天重建索引再看新的数据，但是PM和CTO有时候都看grafana上的数据，运维操作就要求更规范了啊，其实不是给他们看，我们自己就该严格要求自己，下边记录下重建索引的的过程。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-Field-data-loading-is-forbidden-on-FIELDNAME\"><a href=\"#1-Field-data-loading-is-forbidden-on-FIELDNAME\" class=\"headerlink\" title=\"1. Field data loading is forbidden on [FIELDNAME]\"></a>1. Field data loading is forbidden on [FIELDNAME]</h2><blockquote>\n<p>问题描述： 当我们在kibana画图时，有的nginx_access 日志中的有一部分字段是不能用的，在grafana中也不可以，但是别的索引文件可以，比如elapsed_log,search_log,错误如下图所示</p>\n</blockquote>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-05%20%E4%B8%8B%E5%8D%887.06.50.png\" alt=\"\"></p>\n<h3 id=\"问题原因\"><a href=\"#问题原因\" class=\"headerlink\" title=\"问题原因\"></a>问题原因</h3><p>问题原因就是我们索引的设置中 <code>&quot;fielddata&quot; : { &quot;format&quot; : &quot;disabled&quot; }</code> 这个设置存在导致的结果就是</p>\n<ul>\n<li>Field data loading is forbidden on type</li>\n<li>Field data loading is forbidden on path</li>\n<li>Field data loading is forbidden on host</li>\n</ul>\n<p>查看索引settings<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl 10.215.33.36:9200/logstash-*/_mapping</div></pre></td></tr></table></figure></p>\n<p>查看确实存在<code>&quot;mapping&quot;:{&quot;fielddata&quot;:{&quot;format&quot;:&quot;disabled&quot;}</code>这种设置，</p>\n<h3 id=\"解决过程\"><a href=\"#解决过程\" class=\"headerlink\" title=\"解决过程\"></a>解决过程</h3><p>修改mapping，ES的索引是已建成就固定的，中途修改只能是 建新索引–&gt;数据导入–&gt;旧索引删除。 所以我们可以直接修改template，等到第二天自动更新的时候新的索引设置就会正常了。<br>具体操作记录在<a href=\"https://fanquqi.github.io/2017/06/05/ElasticSearch%E4%BD%BF%E7%94%A8/\" target=\"_blank\" rel=\"external\">ES使用</a>的template更新中。</p>\n<p>参考：<a href=\"https://github.com/elastic/elasticsearch/issues/15267\" target=\"_blank\" rel=\"external\">https://github.com/elastic/elasticsearch/issues/15267</a></p>\n<hr>\n<h2 id=\"2-修改字段类型\"><a href=\"#2-修改字段类型\" class=\"headerlink\" title=\"2. 修改字段类型\"></a>2. 修改字段类型</h2><blockquote>\n<p>数据通过logstash 的grok过滤之后，传输到ES当中，ES是可以自动发现的，自动生成mapping，并不用事先设置mapping，很方便。默认会把所有的字段设置成string,但是有的时候我们需要float等数据类型，怎么更改？？</p>\n</blockquote>\n<p>当前看有两种方式：</p>\n<ol>\n<li>直接修改mapping。</li>\n<li>在logstash grok的时候指定数据类型。<ul>\n<li>类似于这种<code>%{NUMBER:status:float}</code> ,<code>NUMBER</code>是grok支持的数据类型，<code>status</code>是自定义字段名称, <code>float</code>即为字段类型。但是这个可能不会立即生效。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-mapping-冲突解决\"><a href=\"#3-mapping-冲突解决\" class=\"headerlink\" title=\"3. mapping 冲突解决\"></a>3. mapping 冲突解决</h2><blockquote>\n<p>问题2中第二种方法修改完字段类型之后，刷新索引，会造成新老数据的类型不一致导致冲突。</p>\n</blockquote>\n<p>参考: <a href=\"https://dev.sobeslavsky.net/kibana-how-to-solve-mapping-conflict/\" target=\"_blank\" rel=\"external\">https://dev.sobeslavsky.net/kibana-how-to-solve-mapping-conflict/</a><br>其实完全不用理会 等到老的索引过期被删掉就好了</p>\n<h2 id=\"4-自动删除索引脚本\"><a href=\"#4-自动删除索引脚本\" class=\"headerlink\" title=\"4. 自动删除索引脚本\"></a>4. 自动删除索引脚本</h2><blockquote>\n<p>收集的日志每天量很大有200多G，自己的三个ES节点存储有限，所以留存维持大约三四天的新鲜日志,需要编写个脚本定期删除索引。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/bash</div><div class=\"line\">today=`date +%Y.%m.%d`;</div><div class=\"line\">echo &quot;今天是$&#123;today&#125;&quot;</div><div class=\"line\"># 获得要删除的日期</div><div class=\"line\"># 不指定参数时，默认删除3天前的数据（因为是凌晨删除，所以不含当天）</div><div class=\"line\">daynum=3</div><div class=\"line\"># 当参数个数大于1时，提示参数错误</div><div class=\"line\">if [ $# -gt 1 ] ;then</div><div class=\"line\">        echo &quot;要么不传参数，要么只传1个参数!&quot;</div><div class=\"line\">        exit 101;</div><div class=\"line\">fi</div><div class=\"line\"># 当参数个数为1时，获取指定的参数</div><div class=\"line\">if [ $# == 1 ] ;then</div><div class=\"line\">        daynum=$1</div><div class=\"line\">fi</div><div class=\"line\">esday=`date -d &apos;-&apos;&quot;$&#123;daynum&#125;&quot;&apos; day&apos; +%Y.%m.%d`;</div><div class=\"line\">echo &quot;$&#123;daynum&#125;天前是$&#123;esday&#125;&quot;</div><div class=\"line\">curl -XDELETE http://localhost:9200/logstash-nginx_access-$&#123;esday&#125;</div><div class=\"line\">curl -XDELETE http://localhost:9200/elapsed_log-$&#123;esday&#125;</div><div class=\"line\">curl -XDELETE http://localhost:9200/file_log-$&#123;esday&#125;</div><div class=\"line\">curl -XDELETE http://localhost:9200/info_log-$&#123;esday&#125;</div><div class=\"line\">curl -XDELETE http://localhost:9200/search.log-$&#123;esday&#125;</div><div class=\"line\"></div><div class=\"line\">echo &quot;$&#123;today&#125;执行完成&quot;</div><div class=\"line\"># echo curl -XDELETE http://localhost:9200/aaa-*-$&#123;esday&#125;</div></pre></td></tr></table></figure>\n<p>内容如上，然后写进cron每天执行就好了。</p>\n<h2 id=\"5-logstash-插入json-格式数据\"><a href=\"#5-logstash-插入json-格式数据\" class=\"headerlink\" title=\"5. logstash 插入json 格式数据\"></a>5. logstash 插入json 格式数据</h2><blockquote>\n<p>大数据那边search_log 是json格式的，安装普通的input插入就会有问题。</p>\n</blockquote>\n<p>修改配置文件 input 中的 file 中 加入 codec =&gt; json { charset =&gt; “UTF-8” }<br><img src=\"http://or2jd66dq.bkt.clouddn.com/logstash_json.png\" alt=\"\"></p>\n<h2 id=\"6-ES各节点内存分配\"><a href=\"#6-ES各节点内存分配\" class=\"headerlink\" title=\"6. ES各节点内存分配\"></a>6. ES各节点内存分配</h2><ul>\n<li>配置位置：/usr/local/elasticsearch-2.3.2/bin/elasticsearch.in.sh  </li>\n<li>三个节点 md6：16G     md10：16G     md11:32G<br><img src=\"http://or2jd66dq.bkt.clouddn.com/ES%E5%86%85%E5%AD%98%E8%B0%83%E6%95%B4.png\" alt=\"\"></li>\n</ul>\n<h2 id=\"7-elasticsearch-节点安全重启\"><a href=\"#7-elasticsearch-节点安全重启\" class=\"headerlink\" title=\"7. elasticsearch 节点安全重启\"></a>7. elasticsearch 节点安全重启</h2><blockquote>\n<p>elasticsearch集群，有时候可能需要修改配置，增删硬件等操作，需要对节点进行升级等操作。但是服务不能停，如果直接kill掉节点，可能导致数据丢失。而且集群会认为该节点挂掉了，就开始转移数据（这个过程相当好资源，经历过两次，直接kill掉某一节点后集群开始relocation，网卡被打满，正常请求很多超时），当重启之后，它又会恢复数据，如果你当前的数据量已经很大了，这是很耗费机器和网络资源的。</p>\n</blockquote>\n<ul>\n<li><p>第一步：先暂停集群的shard自动均衡</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPUT http://192.168.1.2:9200/_cluster/settings -d&apos;</div><div class=\"line\"></div><div class=\"line\">       &#123;</div><div class=\"line\"></div><div class=\"line\">       &quot;transient&quot; : &#123;</div><div class=\"line\"></div><div class=\"line\">       &quot;cluster.routing.allocation.enable&quot; : &quot;none&quot;</div><div class=\"line\"></div><div class=\"line\">           &#125;        </div><div class=\"line\"></div><div class=\"line\">       &#125;&apos;</div></pre></td></tr></table></figure>\n</li>\n<li><p>第二步：kill要升级的节点</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ps aux |grep elasticsearch |awk &apos;&#123;print $2&#125;&apos; |xargs kill</div></pre></td></tr></table></figure>\n</li>\n<li><p>第三步：恢复集群的shard自动均衡</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPUT http://192.168.1.2/_cluster/settings -d&apos;</div><div class=\"line\"></div><div class=\"line\">        &#123;</div><div class=\"line\"></div><div class=\"line\">        &quot;transient&quot; : &#123;</div><div class=\"line\"></div><div class=\"line\">        &quot;cluster.routing.allocation.enable&quot; : &quot;all&quot;</div><div class=\"line\"></div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">        &#125;&apos;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"8-误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点-集群状态如下图所示-此时kibana上面已经没有数据\"><a href=\"#8-误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点-集群状态如下图所示-此时kibana上面已经没有数据\" class=\"headerlink\" title=\"8. 误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点 集群状态如下图所示 此时kibana上面已经没有数据\"></a>8. 误删除node2的存储文件导致elasticsearch集群出现问题出现坏节点 集群状态如下图所示 此时kibana上面已经没有数据</h2><blockquote>\n<p>ES某个节点数据被老大误删除<br><img src=\"http://or2jd66dq.bkt.clouddn.com/ES%E8%8A%82%E7%82%B9%E8%A2%AB%E8%AF%AF%E5%88%A0%E9%99%A4.png\" alt=\"\"><br>重启elasticsearch 各个节点之后还是没有数据插入。<br><code>解决办法：</code></p>\n<ul>\n<li>需要删除坏的索引数据 就是今天的数据 具体方法：找到今天的索引elapsed_log-2016.11.03==&gt;点击”动作”==&gt;点击 “删除”  之后Unassigned 节点会消失， 刷新一下 kibana上数据出现。</li>\n</ul>\n</blockquote>\n<h2 id=\"9-Elasticsearch-high-disk-watermark-问题\"><a href=\"#9-Elasticsearch-high-disk-watermark-问题\" class=\"headerlink\" title=\"9. Elasticsearch high disk watermark 问题\"></a>9. Elasticsearch high disk watermark 问题</h2><p>问题描述：因为我们每个节点都不是单独只提供一个服务，每台机器的配置和硬盘大小都不尽一致，内存啥的可以很好的处理，但是硬盘大小怎么分配？<br>比如说有一台机器600G硬盘，剩下两台2T硬盘，这种，如果平均分配恐怕是不行了，小磁盘爆了大磁盘还没有存一半。怎么办？</p>\n<p><code>问题解决</code> ES在你想到这个问题之前就已经想到了。操作如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPUT 10.215.33.36:9200/_cluster/settings -d &apos;&#123;</div><div class=\"line\">  &quot;transient&quot;: &#123;</div><div class=\"line\">    &quot;cluster.routing.allocation.disk.watermark.low&quot;: &quot;80%&quot;,</div><div class=\"line\">    &quot;cluster.routing.allocation.disk.watermark.high&quot;: &quot;80gb&quot;,</div><div class=\"line\">    &quot;cluster.info.update.interval&quot;: &quot;1m&quot;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;&apos;</div></pre></td></tr></table></figure>\n<p>解读下这三个参数。<br><code>cluster.routing.allocation.disk.watermark.low</code>  Controls the low watermark for disk usage. It defaults to 85%.如果磁盘使用查过85% 就不回新建分片到这个节点上了，保证磁盘不会被撑爆。<br><code>cluster.routing.allocation.disk.watermark.high</code> Controls the high watermark. It defaults to 90%.默认值百分之90。如果某节点磁盘使用到达90% ES会自动把此节点上的分片转移到别的节点。也可以设置成某个数值类似上文<code>50gb</code><br><code>cluster.info.update.interval</code> How often Elasticsearch should check on disk usage for each node in the cluster. Defaults to 30s. 多久检查一次磁盘用量，默认值30s.由于我们不可能在1分钟内写几十GB数据所以这个可以设置的稍长一些。</p>\n<h2 id=\"10-时区问题处理\"><a href=\"#10-时区问题处理\" class=\"headerlink\" title=\"10. 时区问题处理\"></a>10. 时区问题处理</h2><p>之前看到过有人说ELK的失去问题，类似kibana显示出来时间与真实时间差8小时，我一直没有遇到，直到今天。。。<br><code>问题描述</code>: 事情的经过是这样的，我给ES扩容,然后修改了template（目的在给集群优化一下，提高下集群的QPS）但是导致之前grok失效了，第二天来了发现grafana中爬虫统计数据就到今天8点整，然后我意识到自己昨天的操作有问题，然后删除今天的数据重新导入。奇怪的事儿发生了。。我明明删除了几天的nginx_access日志的index但是kibana中还是有到今天八点的数据，我仔细一看今天的数据存在了昨天的索引当中。如下图<br><img src=\"http://or2jd66dq.bkt.clouddn.com/kibanaUTC.png\" alt=\"\"><br>然后我特别不解为啥ES会在8点钟新建一个索引？？？<br>为啥？</p>\n<p>其实是logstash在ES建立的索引，它每天0点建立一个新的索引，kibana也接受这种设定, 在查询和展示时根据用户的时区进行处理。<br>这导致了, 对于东八区, 2017-07-27日, 8点之前, 只有logstash-2017.07.26这个index, 到8点的时候, 创建新的index logstash-2017.07.27, 即, 对于我们这个时区的人来说, 一天的数据存在了两个index里面<br><strong>修改方案一</strong></p>\n<p>更改logstash的设定,使用localtime</p>\n<p><strong>修改方案二</strong> </p>\n<p>不做修改，接受</p>\n<h2 id=\"11-重建索引\"><a href=\"#11-重建索引\" class=\"headerlink\" title=\"11. 重建索引\"></a>11. 重建索引</h2><p>之前ELK就是给运维自己用，可以随便折腾，索引都是直接删除，或者配置好template等第二天重建索引再看新的数据，但是PM和CTO有时候都看grafana上的数据，运维操作就要求更规范了啊，其实不是给他们看，我们自己就该严格要求自己，下边记录下重建索引的的过程。</p>\n"},{"title":"ElasticSearch使用","date":"2017-06-05T07:18:39.000Z","_content":"\n# ElasticSearch之template,mapping,setting修改\n\n> 自搭建ELK以来一直跟elasticsearch打交道，但是只停留在基本会用，其他并没有更深入研究，其中发现问题越来越多，从之前字段自动analyzed ，导致画图是字段不能用，到后来分片问题。所以是时候study，mark一下。\n\n## 基本命令\nES提供了丰富的API给我们使用通常我们可以使用curl来在线操作。也可以在kopf插件中操作（操作要谨慎）\n例如： \n```\ncurl -XGET 'http://elasticsearch.example.com:9200/_all/_settings?pretty'\n```\n\n参考：http://spuder.github.io/2015/elasticsearch-commands/\n\n\n## template 不重启更改\n\n> 刚开始的时候，每次实验都去改/etc/elasticsearch/elasticsearch.yml配置文件。事实上在template里修改settings更方便而且灵活！当然最主要的，还是调节里面的properties设定，合理的控制store和analyze了。\nlogstash 模板\n\n- 查看template\n    + curl -XGET http://10.215.33.36:9200/_template\n\n- 更改默认分片数量（[参考链接](http://spuder.github.io/2015/elasticsearch-default-shards/)）\n\n> 索引分片数量是将一个索引一致性拆分成为n个部分，这样可以平均的存储到每个ES节点，方便更好的存储与查询。\n\n### 查看默认template \n```\ncurl elasticsearch.example.com:9200/_template/logstash?pretty\n```\n结果显示如下\n```\n{\n  \"logstash\" : {\n    \"order\" : 0,\n    \"template\" : \"logstash-*\",\n    \"settings\" : {\n      \"index\" : {\n        \"refresh_interval\" : \"5s\"\n      }\n    },\n    \"mappings\" : {\n      \"_default_\" : {\n        \"dynamic_templates\" : [ {\n          \"message_field\" : {\n            \"mapping\" : {\n              \"fielddata\" : {\n                \"format\" : \"disabled\"\n              },\n              \"index\" : \"not_analyzed\",\n              \"omit_norms\" : true,\n              \"type\" : \"string\"\n            },\n            \"match_mapping_type\" : \"string\",\n            \"match\" : \"message\"\n          }\n        }, {\n          \"string_fields\" : {\n            \"mapping\" : {\n              \"fielddata\" : {\n                \"format\" : \"disabled\"\n              },\n              \"index\" : \"not_analyzed\",\n              \"omit_norms\" : true,\n              \"type\" : \"string\",\n              \"fields\" : {\n                \"raw\" : {\n                  \"ignore_above\" : 256,\n                  \"index\" : \"not_analyzed\",\n                  \"type\" : \"string\"\n                }\n              }\n            },\n            \"match_mapping_type\" : \"string\",\n            \"match\" : \"*\"\n          }\n        } ],\n        \"_all\" : {\n          \"omit_norms\" : true,\n          \"enabled\" : true\n        },\n        \"properties\" : {\n          \"@timestamp\" : {\n            \"type\" : \"date\"\n          },\n          \"geoip\" : {\n            \"dynamic\" : true,\n            \"properties\" : {\n              \"ip\" : {\n                \"type\" : \"ip\"\n              },\n              \"latitude\" : {\n                \"type\" : \"float\"\n              },\n              \"location\" : {\n                \"type\" : \"geo_point\"\n              },\n              \"longitude\" : {\n                \"type\" : \"float\"\n              }\n            }\n          },\n          \"@version\" : {\n            \"index\" : \"not_analyzed\",\n            \"type\" : \"string\"\n          }\n        }\n      }\n    },\n    \"aliases\" : { }\n  }\n}\n```\n\n### 修改template，上传 \n我们需要把这个json 重定向到一个文件中，其中没有用的部分去掉，加上需要改动的地方  \n```\ncurl http://10.215.33.36:9200/_template/logstash?pretty > logstash_template.json\n```\n修改完的json如下`(最好把修改之前的配置备份下，这是运维的基本)`\n\n```\n{\n    \"template\" : \"logstash-*\",\n    \"settings\" : {\n      \"number_of_shards\": 5\n    },\n    \"mappings\" : {\n      \"_default_\" : {\n        \"dynamic_templates\" : [ {\n          \"date_fields\" : {\n            \"mapping\" : {\n              \"format\" : \"dateOptionalTime\",\n              \"doc_values\" : true,\n              \"type\" : \"date\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"date\"\n          }\n        }, {\n          \"byte_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"byte\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"byte\"\n          }\n        }, {\n          \"double_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"double\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"double\"\n          }\n        }, {\n          \"float_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"float\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"float\"\n          }\n        }, {\n          \"integer_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"integer\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"integer\"\n          }\n        }, {\n          \"long_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"long\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"long\"\n          }\n        }, {\n          \"short_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"short\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"short\"\n          }\n        }, {\n          \"string_fields\" : {\n            \"mapping\" : {\n              \"index\" : \"not_analyzed\",\n              \"omit_norms\" : true,\n              \"doc_values\" : true,\n              \"type\" : \"string\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"string\"\n          }\n        } ],\n        \"properties\" : {\n          \"@version\" : {\n            \"index\" : \"not_analyzed\",\n            \"doc_values\" : true,\n            \"type\" : \"string\"\n          }\n        },\n        \"_all\" : {\n          \"enabled\" : true\n        }\n      }\n    },\n    \"aliases\" : { }\n\n}\n```\n最后需要把这个配置push上去，方法如下`注意加\"@\"`\n```\ncurl -XPUT http://10.215.33.36:9200/_template/logstash -d \"@logstash_template_new.json\"\n```\n\n第二天就可以看到5个分片`因为建好的index 配置是更改不了的 除非新建个新的把数据迁移下，我们没有这么着急，不如等到第二天`\n\n\n\n## setting 不重启更改\n- 配置副本数量\n    - curl -XPUT http://10.215.33.36:9200/_settings -d '{\"index\":{\"number_of_replicas\":2}}'\n\n\n## mapping 不重启更改\n- 查看 nginx_access index的节点\n    + 注意要在端口号后面加上索引的具体名称，支持正则，查看所有直接为空\n    + curl -XGET '10.215.33.36:9200/logstash-nginx_access-*/_mapping?pretty'\n\n- 更改属性\n    + curl -XPOST '10.215.33.36:9200/logstash-nginx_access-*/_mapping' -d '{\"mapping\" :{\"type\" : \"string\", \"index\" : \"not_analyzed\"}}'\n\n\n\n","source":"_posts/ElasticSearch之template,mapping,setting修改.md","raw":"---\ntitle: ElasticSearch使用\ndate: 2017-06-05 15:18:39\ntags: ElasticSearch\ncategories: 运维工具\n---\n\n# ElasticSearch之template,mapping,setting修改\n\n> 自搭建ELK以来一直跟elasticsearch打交道，但是只停留在基本会用，其他并没有更深入研究，其中发现问题越来越多，从之前字段自动analyzed ，导致画图是字段不能用，到后来分片问题。所以是时候study，mark一下。\n\n## 基本命令\nES提供了丰富的API给我们使用通常我们可以使用curl来在线操作。也可以在kopf插件中操作（操作要谨慎）\n例如： \n```\ncurl -XGET 'http://elasticsearch.example.com:9200/_all/_settings?pretty'\n```\n\n参考：http://spuder.github.io/2015/elasticsearch-commands/\n\n\n## template 不重启更改\n\n> 刚开始的时候，每次实验都去改/etc/elasticsearch/elasticsearch.yml配置文件。事实上在template里修改settings更方便而且灵活！当然最主要的，还是调节里面的properties设定，合理的控制store和analyze了。\nlogstash 模板\n\n- 查看template\n    + curl -XGET http://10.215.33.36:9200/_template\n\n- 更改默认分片数量（[参考链接](http://spuder.github.io/2015/elasticsearch-default-shards/)）\n\n> 索引分片数量是将一个索引一致性拆分成为n个部分，这样可以平均的存储到每个ES节点，方便更好的存储与查询。\n\n### 查看默认template \n```\ncurl elasticsearch.example.com:9200/_template/logstash?pretty\n```\n结果显示如下\n```\n{\n  \"logstash\" : {\n    \"order\" : 0,\n    \"template\" : \"logstash-*\",\n    \"settings\" : {\n      \"index\" : {\n        \"refresh_interval\" : \"5s\"\n      }\n    },\n    \"mappings\" : {\n      \"_default_\" : {\n        \"dynamic_templates\" : [ {\n          \"message_field\" : {\n            \"mapping\" : {\n              \"fielddata\" : {\n                \"format\" : \"disabled\"\n              },\n              \"index\" : \"not_analyzed\",\n              \"omit_norms\" : true,\n              \"type\" : \"string\"\n            },\n            \"match_mapping_type\" : \"string\",\n            \"match\" : \"message\"\n          }\n        }, {\n          \"string_fields\" : {\n            \"mapping\" : {\n              \"fielddata\" : {\n                \"format\" : \"disabled\"\n              },\n              \"index\" : \"not_analyzed\",\n              \"omit_norms\" : true,\n              \"type\" : \"string\",\n              \"fields\" : {\n                \"raw\" : {\n                  \"ignore_above\" : 256,\n                  \"index\" : \"not_analyzed\",\n                  \"type\" : \"string\"\n                }\n              }\n            },\n            \"match_mapping_type\" : \"string\",\n            \"match\" : \"*\"\n          }\n        } ],\n        \"_all\" : {\n          \"omit_norms\" : true,\n          \"enabled\" : true\n        },\n        \"properties\" : {\n          \"@timestamp\" : {\n            \"type\" : \"date\"\n          },\n          \"geoip\" : {\n            \"dynamic\" : true,\n            \"properties\" : {\n              \"ip\" : {\n                \"type\" : \"ip\"\n              },\n              \"latitude\" : {\n                \"type\" : \"float\"\n              },\n              \"location\" : {\n                \"type\" : \"geo_point\"\n              },\n              \"longitude\" : {\n                \"type\" : \"float\"\n              }\n            }\n          },\n          \"@version\" : {\n            \"index\" : \"not_analyzed\",\n            \"type\" : \"string\"\n          }\n        }\n      }\n    },\n    \"aliases\" : { }\n  }\n}\n```\n\n### 修改template，上传 \n我们需要把这个json 重定向到一个文件中，其中没有用的部分去掉，加上需要改动的地方  \n```\ncurl http://10.215.33.36:9200/_template/logstash?pretty > logstash_template.json\n```\n修改完的json如下`(最好把修改之前的配置备份下，这是运维的基本)`\n\n```\n{\n    \"template\" : \"logstash-*\",\n    \"settings\" : {\n      \"number_of_shards\": 5\n    },\n    \"mappings\" : {\n      \"_default_\" : {\n        \"dynamic_templates\" : [ {\n          \"date_fields\" : {\n            \"mapping\" : {\n              \"format\" : \"dateOptionalTime\",\n              \"doc_values\" : true,\n              \"type\" : \"date\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"date\"\n          }\n        }, {\n          \"byte_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"byte\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"byte\"\n          }\n        }, {\n          \"double_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"double\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"double\"\n          }\n        }, {\n          \"float_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"float\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"float\"\n          }\n        }, {\n          \"integer_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"integer\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"integer\"\n          }\n        }, {\n          \"long_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"long\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"long\"\n          }\n        }, {\n          \"short_fields\" : {\n            \"mapping\" : {\n              \"doc_values\" : true,\n              \"type\" : \"short\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"short\"\n          }\n        }, {\n          \"string_fields\" : {\n            \"mapping\" : {\n              \"index\" : \"not_analyzed\",\n              \"omit_norms\" : true,\n              \"doc_values\" : true,\n              \"type\" : \"string\"\n            },\n            \"match\" : \"*\",\n            \"match_mapping_type\" : \"string\"\n          }\n        } ],\n        \"properties\" : {\n          \"@version\" : {\n            \"index\" : \"not_analyzed\",\n            \"doc_values\" : true,\n            \"type\" : \"string\"\n          }\n        },\n        \"_all\" : {\n          \"enabled\" : true\n        }\n      }\n    },\n    \"aliases\" : { }\n\n}\n```\n最后需要把这个配置push上去，方法如下`注意加\"@\"`\n```\ncurl -XPUT http://10.215.33.36:9200/_template/logstash -d \"@logstash_template_new.json\"\n```\n\n第二天就可以看到5个分片`因为建好的index 配置是更改不了的 除非新建个新的把数据迁移下，我们没有这么着急，不如等到第二天`\n\n\n\n## setting 不重启更改\n- 配置副本数量\n    - curl -XPUT http://10.215.33.36:9200/_settings -d '{\"index\":{\"number_of_replicas\":2}}'\n\n\n## mapping 不重启更改\n- 查看 nginx_access index的节点\n    + 注意要在端口号后面加上索引的具体名称，支持正则，查看所有直接为空\n    + curl -XGET '10.215.33.36:9200/logstash-nginx_access-*/_mapping?pretty'\n\n- 更改属性\n    + curl -XPOST '10.215.33.36:9200/logstash-nginx_access-*/_mapping' -d '{\"mapping\" :{\"type\" : \"string\", \"index\" : \"not_analyzed\"}}'\n\n\n\n","slug":"ElasticSearch之template,mapping,setting修改","published":1,"updated":"2017-07-25T08:58:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv4y00068tzznrkapc4c","content":"<h1 id=\"elasticsearch之templatemappingsetting修改\"><a href=\"#ElasticSearch之template-mapping-setting修改\" class=\"headerlink\" title=\"ElasticSearch之template,mapping,setting修改\"></a>ElasticSearch之template,mapping,setting修改</h1><blockquote>\n<p>自搭建ELK以来一直跟elasticsearch打交道，但是只停留在基本会用，其他并没有更深入研究，其中发现问题越来越多，从之前字段自动analyzed ，导致画图是字段不能用，到后来分片问题。所以是时候study，mark一下。</p>\n</blockquote>\n<h2 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h2><p>ES提供了丰富的API给我们使用通常我们可以使用curl来在线操作。也可以在kopf插件中操作（操作要谨慎）<br>例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XGET &apos;http://elasticsearch.example.com:9200/_all/_settings?pretty&apos;</div></pre></td></tr></table></figure></p>\n<p>参考：<a href=\"http://spuder.github.io/2015/elasticsearch-commands/\" target=\"_blank\" rel=\"external\">http://spuder.github.io/2015/elasticsearch-commands/</a></p>\n<h2 id=\"template-不重启更改\"><a href=\"#template-不重启更改\" class=\"headerlink\" title=\"template 不重启更改\"></a>template 不重启更改</h2><blockquote>\n<p>刚开始的时候，每次实验都去改/etc/elasticsearch/elasticsearch.yml配置文件。事实上在template里修改settings更方便而且灵活！当然最主要的，还是调节里面的properties设定，合理的控制store和analyze了。<br>logstash 模板</p>\n</blockquote>\n<ul>\n<li><p>查看template</p>\n<ul>\n<li>curl -XGET <a href=\"http://10.215.33.36:9200/_template\" target=\"_blank\" rel=\"external\">http://10.215.33.36:9200/_template</a></li>\n</ul>\n</li>\n<li><p>更改默认分片数量（<a href=\"http://spuder.github.io/2015/elasticsearch-default-shards/\" target=\"_blank\" rel=\"external\">参考链接</a>）</p>\n</li>\n</ul>\n<blockquote>\n<p>索引分片数量是将一个索引一致性拆分成为n个部分，这样可以平均的存储到每个ES节点，方便更好的存储与查询。</p>\n</blockquote>\n<h3 id=\"查看默认template\"><a href=\"#查看默认template\" class=\"headerlink\" title=\"查看默认template\"></a>查看默认template</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl elasticsearch.example.com:9200/_template/logstash?pretty</div></pre></td></tr></table></figure>\n<p>结果显示如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;logstash&quot; : &#123;</div><div class=\"line\">    &quot;order&quot; : 0,</div><div class=\"line\">    &quot;template&quot; : &quot;logstash-*&quot;,</div><div class=\"line\">    &quot;settings&quot; : &#123;</div><div class=\"line\">      &quot;index&quot; : &#123;</div><div class=\"line\">        &quot;refresh_interval&quot; : &quot;5s&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;mappings&quot; : &#123;</div><div class=\"line\">      &quot;_default_&quot; : &#123;</div><div class=\"line\">        &quot;dynamic_templates&quot; : [ &#123;</div><div class=\"line\">          &quot;message_field&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;fielddata&quot; : &#123;</div><div class=\"line\">                &quot;format&quot; : &quot;disabled&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">              &quot;omit_norms&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;string&quot;,</div><div class=\"line\">            &quot;match&quot; : &quot;message&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;string_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;fielddata&quot; : &#123;</div><div class=\"line\">                &quot;format&quot; : &quot;disabled&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">              &quot;omit_norms&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;string&quot;,</div><div class=\"line\">              &quot;fields&quot; : &#123;</div><div class=\"line\">                &quot;raw&quot; : &#123;</div><div class=\"line\">                  &quot;ignore_above&quot; : 256,</div><div class=\"line\">                  &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">                  &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">                &#125;</div><div class=\"line\">              &#125;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;string&quot;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125; ],</div><div class=\"line\">        &quot;_all&quot; : &#123;</div><div class=\"line\">          &quot;omit_norms&quot; : true,</div><div class=\"line\">          &quot;enabled&quot; : true</div><div class=\"line\">        &#125;,</div><div class=\"line\">        &quot;properties&quot; : &#123;</div><div class=\"line\">          &quot;@timestamp&quot; : &#123;</div><div class=\"line\">            &quot;type&quot; : &quot;date&quot;</div><div class=\"line\">          &#125;,</div><div class=\"line\">          &quot;geoip&quot; : &#123;</div><div class=\"line\">            &quot;dynamic&quot; : true,</div><div class=\"line\">            &quot;properties&quot; : &#123;</div><div class=\"line\">              &quot;ip&quot; : &#123;</div><div class=\"line\">                &quot;type&quot; : &quot;ip&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;latitude&quot; : &#123;</div><div class=\"line\">                &quot;type&quot; : &quot;float&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;location&quot; : &#123;</div><div class=\"line\">                &quot;type&quot; : &quot;geo_point&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;longitude&quot; : &#123;</div><div class=\"line\">                &quot;type&quot; : &quot;float&quot;</div><div class=\"line\">              &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">          &#125;,</div><div class=\"line\">          &quot;@version&quot; : &#123;</div><div class=\"line\">            &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">            &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;aliases&quot; : &#123; &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h3 id=\"修改template上传\"><a href=\"#修改template，上传\" class=\"headerlink\" title=\"修改template，上传\"></a>修改template，上传</h3><p>我们需要把这个json 重定向到一个文件中，其中没有用的部分去掉，加上需要改动的地方<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl http://10.215.33.36:9200/_template/logstash?pretty &gt; logstash_template.json</div></pre></td></tr></table></figure></p>\n<p>修改完的json如下<code>(最好把修改之前的配置备份下，这是运维的基本)</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    &quot;template&quot; : &quot;logstash-*&quot;,</div><div class=\"line\">    &quot;settings&quot; : &#123;</div><div class=\"line\">      &quot;number_of_shards&quot;: 5</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;mappings&quot; : &#123;</div><div class=\"line\">      &quot;_default_&quot; : &#123;</div><div class=\"line\">        &quot;dynamic_templates&quot; : [ &#123;</div><div class=\"line\">          &quot;date_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;format&quot; : &quot;dateOptionalTime&quot;,</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;date&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;date&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;byte_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;byte&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;byte&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;double_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;double&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;double&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;float_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;float&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;float&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;integer_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;integer&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;integer&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;long_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;long&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;long&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;short_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;short&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;short&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;string_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">              &quot;omit_norms&quot; : true,</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;string&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125; ],</div><div class=\"line\">        &quot;properties&quot; : &#123;</div><div class=\"line\">          &quot;@version&quot; : &#123;</div><div class=\"line\">            &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">            &quot;doc_values&quot; : true,</div><div class=\"line\">            &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;,</div><div class=\"line\">        &quot;_all&quot; : &#123;</div><div class=\"line\">          &quot;enabled&quot; : true</div><div class=\"line\">        &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;aliases&quot; : &#123; &#125;</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>最后需要把这个配置push上去，方法如下<code>注意加&quot;@&quot;</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPUT http://10.215.33.36:9200/_template/logstash -d &quot;@logstash_template_new.json&quot;</div></pre></td></tr></table></figure></p>\n<p>第二天就可以看到5个分片<code>因为建好的index 配置是更改不了的 除非新建个新的把数据迁移下，我们没有这么着急，不如等到第二天</code></p>\n<h2 id=\"setting-不重启更改\"><a href=\"#setting-不重启更改\" class=\"headerlink\" title=\"setting 不重启更改\"></a>setting 不重启更改</h2><ul>\n<li>配置副本数量<ul>\n<li>curl -XPUT <a href=\"http://10.215.33.36:9200/_settings\" target=\"_blank\" rel=\"external\">http://10.215.33.36:9200/_settings</a> -d ‘{“index”:{“number_of_replicas”:2}}’</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"mapping-不重启更改\"><a href=\"#mapping-不重启更改\" class=\"headerlink\" title=\"mapping 不重启更改\"></a>mapping 不重启更改</h2><ul>\n<li><p>查看 nginx_access index的节点</p>\n<ul>\n<li>注意要在端口号后面加上索引的具体名称，支持正则，查看所有直接为空</li>\n<li>curl -XGET ‘10.215.33.36:9200/logstash-nginx_access-*/_mapping?pretty’</li>\n</ul>\n</li>\n<li><p>更改属性</p>\n<ul>\n<li>curl -XPOST ‘10.215.33.36:9200/logstash-nginx_access-*/_mapping’ -d ‘{“mapping” :{“type” : “string”, “index” : “not_analyzed”}}’</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ElasticSearch之template-mapping-setting修改\"><a href=\"#ElasticSearch之template-mapping-setting修改\" class=\"headerlink\" title=\"ElasticSearch之template,mapping,setting修改\"></a>ElasticSearch之template,mapping,setting修改</h1><blockquote>\n<p>自搭建ELK以来一直跟elasticsearch打交道，但是只停留在基本会用，其他并没有更深入研究，其中发现问题越来越多，从之前字段自动analyzed ，导致画图是字段不能用，到后来分片问题。所以是时候study，mark一下。</p>\n</blockquote>\n<h2 id=\"基本命令\"><a href=\"#基本命令\" class=\"headerlink\" title=\"基本命令\"></a>基本命令</h2><p>ES提供了丰富的API给我们使用通常我们可以使用curl来在线操作。也可以在kopf插件中操作（操作要谨慎）<br>例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XGET &apos;http://elasticsearch.example.com:9200/_all/_settings?pretty&apos;</div></pre></td></tr></table></figure></p>\n<p>参考：<a href=\"http://spuder.github.io/2015/elasticsearch-commands/\" target=\"_blank\" rel=\"external\">http://spuder.github.io/2015/elasticsearch-commands/</a></p>\n<h2 id=\"template-不重启更改\"><a href=\"#template-不重启更改\" class=\"headerlink\" title=\"template 不重启更改\"></a>template 不重启更改</h2><blockquote>\n<p>刚开始的时候，每次实验都去改/etc/elasticsearch/elasticsearch.yml配置文件。事实上在template里修改settings更方便而且灵活！当然最主要的，还是调节里面的properties设定，合理的控制store和analyze了。<br>logstash 模板</p>\n</blockquote>\n<ul>\n<li><p>查看template</p>\n<ul>\n<li>curl -XGET <a href=\"http://10.215.33.36:9200/_template\" target=\"_blank\" rel=\"external\">http://10.215.33.36:9200/_template</a></li>\n</ul>\n</li>\n<li><p>更改默认分片数量（<a href=\"http://spuder.github.io/2015/elasticsearch-default-shards/\" target=\"_blank\" rel=\"external\">参考链接</a>）</p>\n</li>\n</ul>\n<blockquote>\n<p>索引分片数量是将一个索引一致性拆分成为n个部分，这样可以平均的存储到每个ES节点，方便更好的存储与查询。</p>\n</blockquote>\n<h3 id=\"查看默认template\"><a href=\"#查看默认template\" class=\"headerlink\" title=\"查看默认template\"></a>查看默认template</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl elasticsearch.example.com:9200/_template/logstash?pretty</div></pre></td></tr></table></figure>\n<p>结果显示如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;logstash&quot; : &#123;</div><div class=\"line\">    &quot;order&quot; : 0,</div><div class=\"line\">    &quot;template&quot; : &quot;logstash-*&quot;,</div><div class=\"line\">    &quot;settings&quot; : &#123;</div><div class=\"line\">      &quot;index&quot; : &#123;</div><div class=\"line\">        &quot;refresh_interval&quot; : &quot;5s&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;mappings&quot; : &#123;</div><div class=\"line\">      &quot;_default_&quot; : &#123;</div><div class=\"line\">        &quot;dynamic_templates&quot; : [ &#123;</div><div class=\"line\">          &quot;message_field&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;fielddata&quot; : &#123;</div><div class=\"line\">                &quot;format&quot; : &quot;disabled&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">              &quot;omit_norms&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;string&quot;,</div><div class=\"line\">            &quot;match&quot; : &quot;message&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;string_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;fielddata&quot; : &#123;</div><div class=\"line\">                &quot;format&quot; : &quot;disabled&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">              &quot;omit_norms&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;string&quot;,</div><div class=\"line\">              &quot;fields&quot; : &#123;</div><div class=\"line\">                &quot;raw&quot; : &#123;</div><div class=\"line\">                  &quot;ignore_above&quot; : 256,</div><div class=\"line\">                  &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">                  &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">                &#125;</div><div class=\"line\">              &#125;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;string&quot;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125; ],</div><div class=\"line\">        &quot;_all&quot; : &#123;</div><div class=\"line\">          &quot;omit_norms&quot; : true,</div><div class=\"line\">          &quot;enabled&quot; : true</div><div class=\"line\">        &#125;,</div><div class=\"line\">        &quot;properties&quot; : &#123;</div><div class=\"line\">          &quot;@timestamp&quot; : &#123;</div><div class=\"line\">            &quot;type&quot; : &quot;date&quot;</div><div class=\"line\">          &#125;,</div><div class=\"line\">          &quot;geoip&quot; : &#123;</div><div class=\"line\">            &quot;dynamic&quot; : true,</div><div class=\"line\">            &quot;properties&quot; : &#123;</div><div class=\"line\">              &quot;ip&quot; : &#123;</div><div class=\"line\">                &quot;type&quot; : &quot;ip&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;latitude&quot; : &#123;</div><div class=\"line\">                &quot;type&quot; : &quot;float&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;location&quot; : &#123;</div><div class=\"line\">                &quot;type&quot; : &quot;geo_point&quot;</div><div class=\"line\">              &#125;,</div><div class=\"line\">              &quot;longitude&quot; : &#123;</div><div class=\"line\">                &quot;type&quot; : &quot;float&quot;</div><div class=\"line\">              &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">          &#125;,</div><div class=\"line\">          &quot;@version&quot; : &#123;</div><div class=\"line\">            &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">            &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;aliases&quot; : &#123; &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h3 id=\"修改template，上传\"><a href=\"#修改template，上传\" class=\"headerlink\" title=\"修改template，上传\"></a>修改template，上传</h3><p>我们需要把这个json 重定向到一个文件中，其中没有用的部分去掉，加上需要改动的地方<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl http://10.215.33.36:9200/_template/logstash?pretty &gt; logstash_template.json</div></pre></td></tr></table></figure></p>\n<p>修改完的json如下<code>(最好把修改之前的配置备份下，这是运维的基本)</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    &quot;template&quot; : &quot;logstash-*&quot;,</div><div class=\"line\">    &quot;settings&quot; : &#123;</div><div class=\"line\">      &quot;number_of_shards&quot;: 5</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;mappings&quot; : &#123;</div><div class=\"line\">      &quot;_default_&quot; : &#123;</div><div class=\"line\">        &quot;dynamic_templates&quot; : [ &#123;</div><div class=\"line\">          &quot;date_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;format&quot; : &quot;dateOptionalTime&quot;,</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;date&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;date&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;byte_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;byte&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;byte&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;double_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;double&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;double&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;float_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;float&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;float&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;integer_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;integer&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;integer&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;long_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;long&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;long&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;short_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;short&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;short&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;, &#123;</div><div class=\"line\">          &quot;string_fields&quot; : &#123;</div><div class=\"line\">            &quot;mapping&quot; : &#123;</div><div class=\"line\">              &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">              &quot;omit_norms&quot; : true,</div><div class=\"line\">              &quot;doc_values&quot; : true,</div><div class=\"line\">              &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">            &#125;,</div><div class=\"line\">            &quot;match&quot; : &quot;*&quot;,</div><div class=\"line\">            &quot;match_mapping_type&quot; : &quot;string&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125; ],</div><div class=\"line\">        &quot;properties&quot; : &#123;</div><div class=\"line\">          &quot;@version&quot; : &#123;</div><div class=\"line\">            &quot;index&quot; : &quot;not_analyzed&quot;,</div><div class=\"line\">            &quot;doc_values&quot; : true,</div><div class=\"line\">            &quot;type&quot; : &quot;string&quot;</div><div class=\"line\">          &#125;</div><div class=\"line\">        &#125;,</div><div class=\"line\">        &quot;_all&quot; : &#123;</div><div class=\"line\">          &quot;enabled&quot; : true</div><div class=\"line\">        &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    &quot;aliases&quot; : &#123; &#125;</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>最后需要把这个配置push上去，方法如下<code>注意加&quot;@&quot;</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPUT http://10.215.33.36:9200/_template/logstash -d &quot;@logstash_template_new.json&quot;</div></pre></td></tr></table></figure></p>\n<p>第二天就可以看到5个分片<code>因为建好的index 配置是更改不了的 除非新建个新的把数据迁移下，我们没有这么着急，不如等到第二天</code></p>\n<h2 id=\"setting-不重启更改\"><a href=\"#setting-不重启更改\" class=\"headerlink\" title=\"setting 不重启更改\"></a>setting 不重启更改</h2><ul>\n<li>配置副本数量<ul>\n<li>curl -XPUT <a href=\"http://10.215.33.36:9200/_settings\" target=\"_blank\" rel=\"external\">http://10.215.33.36:9200/_settings</a> -d ‘{“index”:{“number_of_replicas”:2}}’</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"mapping-不重启更改\"><a href=\"#mapping-不重启更改\" class=\"headerlink\" title=\"mapping 不重启更改\"></a>mapping 不重启更改</h2><ul>\n<li><p>查看 nginx_access index的节点</p>\n<ul>\n<li>注意要在端口号后面加上索引的具体名称，支持正则，查看所有直接为空</li>\n<li>curl -XGET ‘10.215.33.36:9200/logstash-nginx_access-*/_mapping?pretty’</li>\n</ul>\n</li>\n<li><p>更改属性</p>\n<ul>\n<li>curl -XPOST ‘10.215.33.36:9200/logstash-nginx_access-*/_mapping’ -d ‘{“mapping” :{“type” : “string”, “index” : “not_analyzed”}}’</li>\n</ul>\n</li>\n</ul>\n"},{"title":"ElasticSearch调优实战过程","date":"2017-06-06T05:57:27.000Z","_content":"\n目前的集群有三个节点，配置如下\n![](http://or2jd66dq.bkt.clouddn.com/kopfESnodestatus.png)\n可以看到三个节点都是master 都是data节点，分工并不明确分配的内存和磁盘不尽相同。现在的集群还是处于一个半原始的状态，没有做太多的优化，正好最近要扩容集群，我顺便优化一下，打算新开一台机器，把新节点用docker起，慢慢换，一步一步来。\n\n\n关于集群的设置可以直接通过API传上去，也可以通过kopf插件更改(建议新手)\n\n## 优化一 合理规划节点分片 \n\nES使得创建大量索引和超大量分片非常地容易，但更重要的是理解每个索引和分片都是一笔开销。所以什么都得辩证得看，能结合业务做到合适是最重要的。索引分片就是把索引数据切分成多个小的索引块，这些小的索引块能够分发到同一个集群中的不同节点。在检索时，检索的结果是该索引每个分片上检索结果的总和(尽管在某些场景中“总和”并不成立：单个分片有可能存储了所有的目标数据)。默认情况下，ElasticSearch会为每个索引创建5个主分片，就算是单结点集群亦是如此。像这样的冗余就称为过度分配：这种场景下，这种分配方式似乎是多此一举，而且只会在索引数据(把文档分发到多个分片上)和检索(必须从多个分片上查询数据然后全并结果)的时候增加复杂度，乐享其成的是，这些复杂的事情是自动处理的，但是为什么ElasticSearch要这样做呢？\n\n## 优化二 限制内存使用\n\n> [参照官网](https://www.elastic.co/guide/cn/elasticsearch/guide/current/_limiting_memory_usage.html)\n> 一旦分析字符串被加载到 fielddata ，他们会一直在那里，直到被驱逐（或者节点崩溃）。由于这个原因，留意内存的使用情况，了解它是如何以及何时加载的，怎样限制对集群的影响是很重要的。\n\n\n## 优化三 缓存 \n[参考地址](https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-5/54_README.html)\n清空缓存\ncurl -XPOST 'localhost:9200/_cache/clear'\n\n未完待续。。。\n","source":"_posts/Elasticsearch调优实战过程.md","raw":"---\ntitle: ElasticSearch调优实战过程\ndate: 2017-06-06 13:57:27\ntags: ElasticSearch\n---\n\n目前的集群有三个节点，配置如下\n![](http://or2jd66dq.bkt.clouddn.com/kopfESnodestatus.png)\n可以看到三个节点都是master 都是data节点，分工并不明确分配的内存和磁盘不尽相同。现在的集群还是处于一个半原始的状态，没有做太多的优化，正好最近要扩容集群，我顺便优化一下，打算新开一台机器，把新节点用docker起，慢慢换，一步一步来。\n\n\n关于集群的设置可以直接通过API传上去，也可以通过kopf插件更改(建议新手)\n\n## 优化一 合理规划节点分片 \n\nES使得创建大量索引和超大量分片非常地容易，但更重要的是理解每个索引和分片都是一笔开销。所以什么都得辩证得看，能结合业务做到合适是最重要的。索引分片就是把索引数据切分成多个小的索引块，这些小的索引块能够分发到同一个集群中的不同节点。在检索时，检索的结果是该索引每个分片上检索结果的总和(尽管在某些场景中“总和”并不成立：单个分片有可能存储了所有的目标数据)。默认情况下，ElasticSearch会为每个索引创建5个主分片，就算是单结点集群亦是如此。像这样的冗余就称为过度分配：这种场景下，这种分配方式似乎是多此一举，而且只会在索引数据(把文档分发到多个分片上)和检索(必须从多个分片上查询数据然后全并结果)的时候增加复杂度，乐享其成的是，这些复杂的事情是自动处理的，但是为什么ElasticSearch要这样做呢？\n\n## 优化二 限制内存使用\n\n> [参照官网](https://www.elastic.co/guide/cn/elasticsearch/guide/current/_limiting_memory_usage.html)\n> 一旦分析字符串被加载到 fielddata ，他们会一直在那里，直到被驱逐（或者节点崩溃）。由于这个原因，留意内存的使用情况，了解它是如何以及何时加载的，怎样限制对集群的影响是很重要的。\n\n\n## 优化三 缓存 \n[参考地址](https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-5/54_README.html)\n清空缓存\ncurl -XPOST 'localhost:9200/_cache/clear'\n\n未完待续。。。\n","slug":"Elasticsearch调优实战过程","published":1,"updated":"2017-08-01T11:09:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv4z00078tzzmp2vfnxp","content":"<p>目前的集群有三个节点，配置如下<br><img src=\"http://or2jd66dq.bkt.clouddn.com/kopfESnodestatus.png\" alt=\"\"><br>可以看到三个节点都是master 都是data节点，分工并不明确分配的内存和磁盘不尽相同。现在的集群还是处于一个半原始的状态，没有做太多的优化，正好最近要扩容集群，我顺便优化一下，打算新开一台机器，把新节点用docker起，慢慢换，一步一步来。</p>\n<p>关于集群的设置可以直接通过API传上去，也可以通过kopf插件更改(建议新手)</p>\n<h2 id=\"优化一-合理规划节点分片\"><a href=\"#优化一-合理规划节点分片\" class=\"headerlink\" title=\"优化一 合理规划节点分片\"></a>优化一 合理规划节点分片</h2><p>ES使得创建大量索引和超大量分片非常地容易，但更重要的是理解每个索引和分片都是一笔开销。所以什么都得辩证得看，能结合业务做到合适是最重要的。索引分片就是把索引数据切分成多个小的索引块，这些小的索引块能够分发到同一个集群中的不同节点。在检索时，检索的结果是该索引每个分片上检索结果的总和(尽管在某些场景中“总和”并不成立：单个分片有可能存储了所有的目标数据)。默认情况下，ElasticSearch会为每个索引创建5个主分片，就算是单结点集群亦是如此。像这样的冗余就称为过度分配：这种场景下，这种分配方式似乎是多此一举，而且只会在索引数据(把文档分发到多个分片上)和检索(必须从多个分片上查询数据然后全并结果)的时候增加复杂度，乐享其成的是，这些复杂的事情是自动处理的，但是为什么ElasticSearch要这样做呢？</p>\n<h2 id=\"优化二-限制内存使用\"><a href=\"#优化二-限制内存使用\" class=\"headerlink\" title=\"优化二 限制内存使用\"></a>优化二 限制内存使用</h2><blockquote>\n<p><a href=\"https://www.elastic.co/guide/cn/elasticsearch/guide/current/_limiting_memory_usage.html\" target=\"_blank\" rel=\"external\">参照官网</a><br>一旦分析字符串被加载到 fielddata ，他们会一直在那里，直到被驱逐（或者节点崩溃）。由于这个原因，留意内存的使用情况，了解它是如何以及何时加载的，怎样限制对集群的影响是很重要的。</p>\n</blockquote>\n<h2 id=\"优化三-缓存\"><a href=\"#优化三-缓存\" class=\"headerlink\" title=\"优化三 缓存\"></a>优化三 缓存</h2><p><a href=\"https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-5/54_README.html\" target=\"_blank\" rel=\"external\">参考地址</a><br>清空缓存<br>curl -XPOST ‘localhost:9200/_cache/clear’</p>\n<p>未完待续。。。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>目前的集群有三个节点，配置如下<br><img src=\"http://or2jd66dq.bkt.clouddn.com/kopfESnodestatus.png\" alt=\"\"><br>可以看到三个节点都是master 都是data节点，分工并不明确分配的内存和磁盘不尽相同。现在的集群还是处于一个半原始的状态，没有做太多的优化，正好最近要扩容集群，我顺便优化一下，打算新开一台机器，把新节点用docker起，慢慢换，一步一步来。</p>\n<p>关于集群的设置可以直接通过API传上去，也可以通过kopf插件更改(建议新手)</p>\n<h2 id=\"优化一-合理规划节点分片\"><a href=\"#优化一-合理规划节点分片\" class=\"headerlink\" title=\"优化一 合理规划节点分片\"></a>优化一 合理规划节点分片</h2><p>ES使得创建大量索引和超大量分片非常地容易，但更重要的是理解每个索引和分片都是一笔开销。所以什么都得辩证得看，能结合业务做到合适是最重要的。索引分片就是把索引数据切分成多个小的索引块，这些小的索引块能够分发到同一个集群中的不同节点。在检索时，检索的结果是该索引每个分片上检索结果的总和(尽管在某些场景中“总和”并不成立：单个分片有可能存储了所有的目标数据)。默认情况下，ElasticSearch会为每个索引创建5个主分片，就算是单结点集群亦是如此。像这样的冗余就称为过度分配：这种场景下，这种分配方式似乎是多此一举，而且只会在索引数据(把文档分发到多个分片上)和检索(必须从多个分片上查询数据然后全并结果)的时候增加复杂度，乐享其成的是，这些复杂的事情是自动处理的，但是为什么ElasticSearch要这样做呢？</p>\n<h2 id=\"优化二-限制内存使用\"><a href=\"#优化二-限制内存使用\" class=\"headerlink\" title=\"优化二 限制内存使用\"></a>优化二 限制内存使用</h2><blockquote>\n<p><a href=\"https://www.elastic.co/guide/cn/elasticsearch/guide/current/_limiting_memory_usage.html\" target=\"_blank\" rel=\"external\">参照官网</a><br>一旦分析字符串被加载到 fielddata ，他们会一直在那里，直到被驱逐（或者节点崩溃）。由于这个原因，留意内存的使用情况，了解它是如何以及何时加载的，怎样限制对集群的影响是很重要的。</p>\n</blockquote>\n<h2 id=\"优化三-缓存\"><a href=\"#优化三-缓存\" class=\"headerlink\" title=\"优化三 缓存\"></a>优化三 缓存</h2><p><a href=\"https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-5/54_README.html\" target=\"_blank\" rel=\"external\">参考地址</a><br>清空缓存<br>curl -XPOST ‘localhost:9200/_cache/clear’</p>\n<p>未完待续。。。</p>\n"},{"title":"HTML/CSS","date":"2017-06-27T08:37:22.000Z","_content":"> 熟悉前端是我一直以来的理想，有时间就看下总结下。。。\n\n```\n<html>\n\n<head>\n<style type=\"text/css\">\nh1 {color: red}\np {color: blue}\n</style>\n</head>\n\n<body>\n<h1>header 1</h1>\n<p>A paragraph.</p>\n</body>\n\n</html>\n```\n\n小白时期不了解HTML与CSS是怎么配合的，看上面代码 `<head>`标签中的CSS 声明`h1`颜色为红 `p` 颜色为蓝，其实就是把各个标签的样式在这个里面做一个总的约束，不用写到各个标签当中了。 提高了效率。\n\n<!DOCTYPE html>\n<html>\n<head>\n    <title>test</title>\n    <script type=\"text/javascript\">\n        alert('Hello, world!')\n    </script>>\n</head>\n<body>\n\n</body>\n</html>>\n\n","source":"_posts/HTML-CSS.md","raw":"---\ntitle: HTML/CSS\ndate: 2017-06-27 16:37:22\ntags: HTML,CSS\ncategories: 前端\n---\n> 熟悉前端是我一直以来的理想，有时间就看下总结下。。。\n\n```\n<html>\n\n<head>\n<style type=\"text/css\">\nh1 {color: red}\np {color: blue}\n</style>\n</head>\n\n<body>\n<h1>header 1</h1>\n<p>A paragraph.</p>\n</body>\n\n</html>\n```\n\n小白时期不了解HTML与CSS是怎么配合的，看上面代码 `<head>`标签中的CSS 声明`h1`颜色为红 `p` 颜色为蓝，其实就是把各个标签的样式在这个里面做一个总的约束，不用写到各个标签当中了。 提高了效率。\n\n<!DOCTYPE html>\n<html>\n<head>\n    <title>test</title>\n    <script type=\"text/javascript\">\n        alert('Hello, world!')\n    </script>>\n</head>\n<body>\n\n</body>\n</html>>\n\n","slug":"HTML-CSS","published":1,"updated":"2017-08-03T07:44:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv55000b8tzz1gr9qpvg","content":"<blockquote>\n<p>熟悉前端是我一直以来的理想，有时间就看下总结下。。。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;html&gt;</div><div class=\"line\"></div><div class=\"line\">&lt;head&gt;</div><div class=\"line\">&lt;style type=&quot;text/css&quot;&gt;</div><div class=\"line\">h1 &#123;color: red&#125;</div><div class=\"line\">p &#123;color: blue&#125;</div><div class=\"line\">&lt;/style&gt;</div><div class=\"line\">&lt;/head&gt;</div><div class=\"line\"></div><div class=\"line\">&lt;body&gt;</div><div class=\"line\">&lt;h1&gt;header 1&lt;/h1&gt;</div><div class=\"line\">&lt;p&gt;A paragraph.&lt;/p&gt;</div><div class=\"line\">&lt;/body&gt;</div><div class=\"line\"></div><div class=\"line\">&lt;/html&gt;</div></pre></td></tr></table></figure>\n<p>小白时期不了解HTML与CSS是怎么配合的，看上面代码 <code>&lt;head&gt;</code>标签中的CSS 声明<code>h1</code>颜色为红 <code>p</code> 颜色为蓝，其实就是把各个标签的样式在这个里面做一个总的约束，不用写到各个标签当中了。 提高了效率。</p>\n<p>&lt;!DOCTYPE html&gt;</p>\n<p><html></html></p>\n<p><head><br>    <title>test</title><br>    <script type=\"text/javascript\"><br>        alert(‘Hello, world!’)<br>    </script>&gt;<br></head></p>\n<body>\n\n<p></p></body><br>&gt;<p></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>熟悉前端是我一直以来的理想，有时间就看下总结下。。。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;html&gt;</div><div class=\"line\"></div><div class=\"line\">&lt;head&gt;</div><div class=\"line\">&lt;style type=&quot;text/css&quot;&gt;</div><div class=\"line\">h1 &#123;color: red&#125;</div><div class=\"line\">p &#123;color: blue&#125;</div><div class=\"line\">&lt;/style&gt;</div><div class=\"line\">&lt;/head&gt;</div><div class=\"line\"></div><div class=\"line\">&lt;body&gt;</div><div class=\"line\">&lt;h1&gt;header 1&lt;/h1&gt;</div><div class=\"line\">&lt;p&gt;A paragraph.&lt;/p&gt;</div><div class=\"line\">&lt;/body&gt;</div><div class=\"line\"></div><div class=\"line\">&lt;/html&gt;</div></pre></td></tr></table></figure>\n<p>小白时期不了解HTML与CSS是怎么配合的，看上面代码 <code>&lt;head&gt;</code>标签中的CSS 声明<code>h1</code>颜色为红 <code>p</code> 颜色为蓝，其实就是把各个标签的样式在这个里面做一个总的约束，不用写到各个标签当中了。 提高了效率。</p>\n<p>&lt;!DOCTYPE html&gt;</p>\n<p><html></html></p>\n<p><head><br>    <title>test</title><br>    <script type=\"text/javascript\"><br>        alert(‘Hello, world!’)<br>    </script>&gt;<br></head></p>\n<body>\n\n<p></p></body><br>&gt;<p></p>\n"},{"title":"Logstash优化","date":"2017-06-15T07:59:39.000Z","_content":"\n> 之前部署的ELK只加了nginx_access, elapsed两个日志，每天的日志量有400G左右，架构可以撑住。但是现在又引入了一些新的日志，并且随着SEO部门的来临。每天晚上服务都被爬虫爬。日志量也翻了两三翻。产生了日志延时的问题。有的延时能有几个小时。\n![](http://or2jd66dq.bkt.clouddn.com/kibana%E5%BB%B6%E6%97%B6.png)\n看kibana中上传的时间跟日志里的时间差距好几个小时。说明日志已经阻塞了。\n\n## 问题分析\n\n这期间机器负载啥的一直也没有报警，ES集群也很健康，所以初步估计是logstash遇到了瓶颈。因为我们有grok，之前就听说这个过滤会对速度影响很大，还有geoip等。\n\n## 解决办法\n\n我第一想到的是，收集日志换成`filebeat`然后像之前加的syslog一样放到kafka缓冲一下，再用logstash插入到ES，但是无奈，机器资源有限，kafka又是直接写问加你系统，运维机的磁盘已经很满了，在扩容磁盘之前是无望了。所以现在只能优化一下logstash，坚持到磁盘扩容。\n\n## logstash优化\n\n- 加大内存\n- 增加线程\n- 减少grok或者去掉geoip定位\n\n另外更改@timestamp 参考:http://udn.yyuap.com/doc/logstash-best-practice-cn/filter/date.html\n为了防止每次延时比较大的时候图像显示不准确。\n","source":"_posts/Logstash优化.md","raw":"---\ntitle: Logstash优化\ndate: 2017-06-15 15:59:39\ntags: ELK, logstash\ncategories: 基础运维\n---\n\n> 之前部署的ELK只加了nginx_access, elapsed两个日志，每天的日志量有400G左右，架构可以撑住。但是现在又引入了一些新的日志，并且随着SEO部门的来临。每天晚上服务都被爬虫爬。日志量也翻了两三翻。产生了日志延时的问题。有的延时能有几个小时。\n![](http://or2jd66dq.bkt.clouddn.com/kibana%E5%BB%B6%E6%97%B6.png)\n看kibana中上传的时间跟日志里的时间差距好几个小时。说明日志已经阻塞了。\n\n## 问题分析\n\n这期间机器负载啥的一直也没有报警，ES集群也很健康，所以初步估计是logstash遇到了瓶颈。因为我们有grok，之前就听说这个过滤会对速度影响很大，还有geoip等。\n\n## 解决办法\n\n我第一想到的是，收集日志换成`filebeat`然后像之前加的syslog一样放到kafka缓冲一下，再用logstash插入到ES，但是无奈，机器资源有限，kafka又是直接写问加你系统，运维机的磁盘已经很满了，在扩容磁盘之前是无望了。所以现在只能优化一下logstash，坚持到磁盘扩容。\n\n## logstash优化\n\n- 加大内存\n- 增加线程\n- 减少grok或者去掉geoip定位\n\n另外更改@timestamp 参考:http://udn.yyuap.com/doc/logstash-best-practice-cn/filter/date.html\n为了防止每次延时比较大的时候图像显示不准确。\n","slug":"Logstash优化","published":1,"updated":"2017-06-15T09:54:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv58000d8tzzrnlzzi7w","content":"<blockquote>\n<p>之前部署的ELK只加了nginx_access, elapsed两个日志，每天的日志量有400G左右，架构可以撑住。但是现在又引入了一些新的日志，并且随着SEO部门的来临。每天晚上服务都被爬虫爬。日志量也翻了两三翻。产生了日志延时的问题。有的延时能有几个小时。<br><img src=\"http://or2jd66dq.bkt.clouddn.com/kibana%E5%BB%B6%E6%97%B6.png\" alt=\"\"><br>看kibana中上传的时间跟日志里的时间差距好几个小时。说明日志已经阻塞了。</p>\n</blockquote>\n<h2 id=\"问题分析\"><a href=\"#问题分析\" class=\"headerlink\" title=\"问题分析\"></a>问题分析</h2><p>这期间机器负载啥的一直也没有报警，ES集群也很健康，所以初步估计是logstash遇到了瓶颈。因为我们有grok，之前就听说这个过滤会对速度影响很大，还有geoip等。</p>\n<h2 id=\"解决办法\"><a href=\"#解决办法\" class=\"headerlink\" title=\"解决办法\"></a>解决办法</h2><p>我第一想到的是，收集日志换成<code>filebeat</code>然后像之前加的syslog一样放到kafka缓冲一下，再用logstash插入到ES，但是无奈，机器资源有限，kafka又是直接写问加你系统，运维机的磁盘已经很满了，在扩容磁盘之前是无望了。所以现在只能优化一下logstash，坚持到磁盘扩容。</p>\n<h2 id=\"logstash优化\"><a href=\"#logstash优化\" class=\"headerlink\" title=\"logstash优化\"></a>logstash优化</h2><ul>\n<li>加大内存</li>\n<li>增加线程</li>\n<li>减少grok或者去掉geoip定位</li>\n</ul>\n<p>另外更改@timestamp 参考:<a href=\"http://udn.yyuap.com/doc/logstash-best-practice-cn/filter/date.html\" target=\"_blank\" rel=\"external\">http://udn.yyuap.com/doc/logstash-best-practice-cn/filter/date.html</a><br>为了防止每次延时比较大的时候图像显示不准确。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>之前部署的ELK只加了nginx_access, elapsed两个日志，每天的日志量有400G左右，架构可以撑住。但是现在又引入了一些新的日志，并且随着SEO部门的来临。每天晚上服务都被爬虫爬。日志量也翻了两三翻。产生了日志延时的问题。有的延时能有几个小时。<br><img src=\"http://or2jd66dq.bkt.clouddn.com/kibana%E5%BB%B6%E6%97%B6.png\" alt=\"\"><br>看kibana中上传的时间跟日志里的时间差距好几个小时。说明日志已经阻塞了。</p>\n</blockquote>\n<h2 id=\"问题分析\"><a href=\"#问题分析\" class=\"headerlink\" title=\"问题分析\"></a>问题分析</h2><p>这期间机器负载啥的一直也没有报警，ES集群也很健康，所以初步估计是logstash遇到了瓶颈。因为我们有grok，之前就听说这个过滤会对速度影响很大，还有geoip等。</p>\n<h2 id=\"解决办法\"><a href=\"#解决办法\" class=\"headerlink\" title=\"解决办法\"></a>解决办法</h2><p>我第一想到的是，收集日志换成<code>filebeat</code>然后像之前加的syslog一样放到kafka缓冲一下，再用logstash插入到ES，但是无奈，机器资源有限，kafka又是直接写问加你系统，运维机的磁盘已经很满了，在扩容磁盘之前是无望了。所以现在只能优化一下logstash，坚持到磁盘扩容。</p>\n<h2 id=\"logstash优化\"><a href=\"#logstash优化\" class=\"headerlink\" title=\"logstash优化\"></a>logstash优化</h2><ul>\n<li>加大内存</li>\n<li>增加线程</li>\n<li>减少grok或者去掉geoip定位</li>\n</ul>\n<p>另外更改@timestamp 参考:<a href=\"http://udn.yyuap.com/doc/logstash-best-practice-cn/filter/date.html\" target=\"_blank\" rel=\"external\">http://udn.yyuap.com/doc/logstash-best-practice-cn/filter/date.html</a><br>为了防止每次延时比较大的时候图像显示不准确。</p>\n"},{"title":"Mac+gihub pages+hexo搭建博客","date":"2017-06-03T14:48:39.000Z","_content":"\n\n# Mac下使用github+hexo建博客\n\n \n> 很早之前就想建个博客，纠结于怎么建，有的同学使用LNMP，使用wordpress,Django，首先得有个服务器，还是不够方便。近期使用github托管一些平常使用的代码或者设置，而且平常习惯使用markdown写笔记，所以就想直接用github_pages+hexo建个博客。\n\n**下边是过程。**\n \n \n\n* * *\n\n## 安装过程\n\n**首先**需要在Mac本地把git装好，公钥传到github，然后装好node，npm\n\n```\n- brew install nodejs\n- brew install npm \n- npm install -g hexo-cli\n- (看下安装目录，可以做个软链到/usr/bin/)\n- ln -s /usr/local/lib/node_modules/hexo-cli/bin/hexo /usr/bin/hexo\n```\n\n**然后**再自己Mac上建一个工作取名**Blog**，在github上面新建个工程参考[github-pages官网](https://pages.github.com/)必须以 **git用户名.github.io**这种格式命名工程名。之后再**Blog** 目录下clone该工程。\n\n```\n- mkdir Blog\n- cd Blog && git clone https://github.com/fanquqi/fanquqi.github.io.git\n```\n\n## 在本地建立站点\n\n安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。\n[Hexo相关操作参考](https://hexo.io/zh-cn/docs)\n\n```\n$ hexo init <folder>\n$ cd <folder>\n$ npm install\n```\n\n所以以上的`<folder>`我们 用Blog代替\n操作可以改为这样,因为上文中我们已经手动建了一个`Blog`文件夹\n\n```\ncd Blog \nhexo init \nnpm install\n```\n\n新建完成后我们的文件夹目录如下：\n\n```\n.\n├── _config.yml\n├── package.json\n├── scaffolds\n├── scripts\n├── source\n|   ├── _drafts\n|   └── _posts\n└── themes\n\n```\n\n之后运行 hexo start 可以在http://localhost:4000 看到自己的页面\n\n**关联github**\n>设置好本地之后,需要关联github，以后就可以在本地写作，传到github上了\n\n\n修改_config.yml,在最后加上(注意不能有tab，':'后必须有个空格)\n\n```\ndeploy:\n  type: git\n  repository: https://github.com/fanquqi/fanquqi.github.io.git\n  branch: master\n```\n\n在blog文件夹目录下执行生成静态页面命令：\n\n```\n$ hexo generate     或者：hexo g\n```\n如果出现如下报错\n\n```\nERROR Local hexo not found in ~/blog\nERROR Try runing: 'npm install hexo --save'\n```\n\n执行\n```\nnpm install hexo --save\n```\n如果没有出现略过此步\n\n然后deploy 一下 同步到远程github\n```\nhexo deploy\n```\n如果出现一下报错 没有找到git\n\n``` \n➜  Blog hexo deploy\nERROR Deployer not found: git\n```\n\n安装hexo-deploy-git\n\n```\n➜  Blog npm install hexo-deployer-git --save\nhexo-site@0.0.0 /Users/fanquanqing/workspace/Blog\n└─┬ hexo-deployer-git@0.3.0\n  └── moment@2.18.1\n```\n\n之后再次执行hexo generate和hexo deploy命令\n如果没有报错，你就可以在https://fanquqi.github.io  看到之前自己4000端口相同的内容了。好棒哦。。。\n\n------\n\n##安装theme\n\n>主题可以到hexo官网下载 [https://hexo.io/themes/ ](https://hexo.io/themes/) \n这里以Next为例。\n\n```\ncd Blog && git clone https://github.com/iissnan/hexo-theme-next themes/next\n#替换Blog/_config.yml themes: landscape 为 themes: next\nhexo clean //清除缓存\nhexo generata\nhexo deploy\nhexo start\n```\n配置查看[http://theme-next.iissnan.com/getting-started.html ](http://theme-next.iissnan.com/getting-started.html)\n**搜索功能添加**\n\n```\n# 安装hexo-generator-searchdb(给博客添加搜索功能)\n➜  Blog npm install hexo-generator-searchdb --save\nhexo-site@0.0.0 /Users/fanquanqing/workspace/Blog\n└─┬ hexo-generator-searchdb@1.0.7\n  └── striptags@3.0.1\n#修改_config.yml,添加\nsearch:\n  path: search.xml\n  field: post\n  format: html\n  limit: 10000\n```\n\nhexo start发现问题\n```\n➜  Blog hexo s\nERROR Plugin load failed: hexo-generator-searchdb\n```\n查看插件hexo-generator-searchdb 中的Redmine  发现node 需要降级到4.2.2以下\n\n```\nnpm install -g n\nn 4.2.2\n```\n\n\n## menu 添加\n\n> 默认的有：首页，归档，分类，标签，关于, 但是next主题默认只显示了首页 归档和标签。\n> 以** categories** 添加为例(tags 也是如此)\n\n1.新建categories page \n```\nhexo new page \"categories\"\n```\n会在source下面生成一个categories目录。\n\n2.修改index.md\n\n打开categories文件夹中的index.md页面，在头部添加 – type: “categories” （为了点击的时候链接生效）\n修改完之后\n```\n---\ntitle: 分类\ndate: 2017-06-03 22:17:53\ntype: \"categories\"\n---\n```\n\n3.在hexo > theme > next > _config.yml 中修改menu下的categorues,去掉前面井号注释。\n\n\n\n## 文章发表\n发表步骤如下\n- 新建文章\n    + hexo new urlooker使用\n- 编辑文章\n    + 直接vim 或者用自己的markdown编辑器编辑，这里需要提醒下添加**tags**和 **categories** 使用\n    + hexo中有Front-matter这个概念，是文件最上方以 — 分隔的区域，用于指定个别文件的变量。\n```\n---\ntitle: urlooker使用\ndate: 2017-06-02 18:57:50\ntags: open-falcon\ncategoris: 监控\n---\n```\n\n举例如上\n\n## 添加评论功能\n\n> 多说在2017.6.1停止服务了，比较尴尬，但是新的next 集成了友言的评论功能，设置非常方便\n\n- 注册[友言官网](http://www.uyan.cc/)，在管理后台记下UID\n- 添加UID到_config.yml 格式为\n\n```\nyouyan_uid: 2323232\n```\n\n## 静态文件处理\n> 好像github-pages 最大存储为300M 所以不能尽情的存储，最好吧静态图片放到外面，我直接放到了七牛云存储上，每个图片生成一个外链，很方便。\n\n\n重新部署下hexo即可。\n\n\n\n\n好了，现在就可以随时markdown了。\n\n\n参考：\n- https://madongqiang2201.github.io/\n- http://theme-next.iissnan.com/getting-started.html\n- http://jeasonstudio.github.io/2016/05/26/Mac%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8EGitHub-Page%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2/\n\n","source":"_posts/Mac-gihub-pages-hexo搭建博客.md","raw":"---\ntitle: Mac+gihub pages+hexo搭建博客\ndate: 2017-06-03 22:48:39\ntags: hexo \ncategories: hexo \n---\n\n\n# Mac下使用github+hexo建博客\n\n \n> 很早之前就想建个博客，纠结于怎么建，有的同学使用LNMP，使用wordpress,Django，首先得有个服务器，还是不够方便。近期使用github托管一些平常使用的代码或者设置，而且平常习惯使用markdown写笔记，所以就想直接用github_pages+hexo建个博客。\n\n**下边是过程。**\n \n \n\n* * *\n\n## 安装过程\n\n**首先**需要在Mac本地把git装好，公钥传到github，然后装好node，npm\n\n```\n- brew install nodejs\n- brew install npm \n- npm install -g hexo-cli\n- (看下安装目录，可以做个软链到/usr/bin/)\n- ln -s /usr/local/lib/node_modules/hexo-cli/bin/hexo /usr/bin/hexo\n```\n\n**然后**再自己Mac上建一个工作取名**Blog**，在github上面新建个工程参考[github-pages官网](https://pages.github.com/)必须以 **git用户名.github.io**这种格式命名工程名。之后再**Blog** 目录下clone该工程。\n\n```\n- mkdir Blog\n- cd Blog && git clone https://github.com/fanquqi/fanquqi.github.io.git\n```\n\n## 在本地建立站点\n\n安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。\n[Hexo相关操作参考](https://hexo.io/zh-cn/docs)\n\n```\n$ hexo init <folder>\n$ cd <folder>\n$ npm install\n```\n\n所以以上的`<folder>`我们 用Blog代替\n操作可以改为这样,因为上文中我们已经手动建了一个`Blog`文件夹\n\n```\ncd Blog \nhexo init \nnpm install\n```\n\n新建完成后我们的文件夹目录如下：\n\n```\n.\n├── _config.yml\n├── package.json\n├── scaffolds\n├── scripts\n├── source\n|   ├── _drafts\n|   └── _posts\n└── themes\n\n```\n\n之后运行 hexo start 可以在http://localhost:4000 看到自己的页面\n\n**关联github**\n>设置好本地之后,需要关联github，以后就可以在本地写作，传到github上了\n\n\n修改_config.yml,在最后加上(注意不能有tab，':'后必须有个空格)\n\n```\ndeploy:\n  type: git\n  repository: https://github.com/fanquqi/fanquqi.github.io.git\n  branch: master\n```\n\n在blog文件夹目录下执行生成静态页面命令：\n\n```\n$ hexo generate     或者：hexo g\n```\n如果出现如下报错\n\n```\nERROR Local hexo not found in ~/blog\nERROR Try runing: 'npm install hexo --save'\n```\n\n执行\n```\nnpm install hexo --save\n```\n如果没有出现略过此步\n\n然后deploy 一下 同步到远程github\n```\nhexo deploy\n```\n如果出现一下报错 没有找到git\n\n``` \n➜  Blog hexo deploy\nERROR Deployer not found: git\n```\n\n安装hexo-deploy-git\n\n```\n➜  Blog npm install hexo-deployer-git --save\nhexo-site@0.0.0 /Users/fanquanqing/workspace/Blog\n└─┬ hexo-deployer-git@0.3.0\n  └── moment@2.18.1\n```\n\n之后再次执行hexo generate和hexo deploy命令\n如果没有报错，你就可以在https://fanquqi.github.io  看到之前自己4000端口相同的内容了。好棒哦。。。\n\n------\n\n##安装theme\n\n>主题可以到hexo官网下载 [https://hexo.io/themes/ ](https://hexo.io/themes/) \n这里以Next为例。\n\n```\ncd Blog && git clone https://github.com/iissnan/hexo-theme-next themes/next\n#替换Blog/_config.yml themes: landscape 为 themes: next\nhexo clean //清除缓存\nhexo generata\nhexo deploy\nhexo start\n```\n配置查看[http://theme-next.iissnan.com/getting-started.html ](http://theme-next.iissnan.com/getting-started.html)\n**搜索功能添加**\n\n```\n# 安装hexo-generator-searchdb(给博客添加搜索功能)\n➜  Blog npm install hexo-generator-searchdb --save\nhexo-site@0.0.0 /Users/fanquanqing/workspace/Blog\n└─┬ hexo-generator-searchdb@1.0.7\n  └── striptags@3.0.1\n#修改_config.yml,添加\nsearch:\n  path: search.xml\n  field: post\n  format: html\n  limit: 10000\n```\n\nhexo start发现问题\n```\n➜  Blog hexo s\nERROR Plugin load failed: hexo-generator-searchdb\n```\n查看插件hexo-generator-searchdb 中的Redmine  发现node 需要降级到4.2.2以下\n\n```\nnpm install -g n\nn 4.2.2\n```\n\n\n## menu 添加\n\n> 默认的有：首页，归档，分类，标签，关于, 但是next主题默认只显示了首页 归档和标签。\n> 以** categories** 添加为例(tags 也是如此)\n\n1.新建categories page \n```\nhexo new page \"categories\"\n```\n会在source下面生成一个categories目录。\n\n2.修改index.md\n\n打开categories文件夹中的index.md页面，在头部添加 – type: “categories” （为了点击的时候链接生效）\n修改完之后\n```\n---\ntitle: 分类\ndate: 2017-06-03 22:17:53\ntype: \"categories\"\n---\n```\n\n3.在hexo > theme > next > _config.yml 中修改menu下的categorues,去掉前面井号注释。\n\n\n\n## 文章发表\n发表步骤如下\n- 新建文章\n    + hexo new urlooker使用\n- 编辑文章\n    + 直接vim 或者用自己的markdown编辑器编辑，这里需要提醒下添加**tags**和 **categories** 使用\n    + hexo中有Front-matter这个概念，是文件最上方以 — 分隔的区域，用于指定个别文件的变量。\n```\n---\ntitle: urlooker使用\ndate: 2017-06-02 18:57:50\ntags: open-falcon\ncategoris: 监控\n---\n```\n\n举例如上\n\n## 添加评论功能\n\n> 多说在2017.6.1停止服务了，比较尴尬，但是新的next 集成了友言的评论功能，设置非常方便\n\n- 注册[友言官网](http://www.uyan.cc/)，在管理后台记下UID\n- 添加UID到_config.yml 格式为\n\n```\nyouyan_uid: 2323232\n```\n\n## 静态文件处理\n> 好像github-pages 最大存储为300M 所以不能尽情的存储，最好吧静态图片放到外面，我直接放到了七牛云存储上，每个图片生成一个外链，很方便。\n\n\n重新部署下hexo即可。\n\n\n\n\n好了，现在就可以随时markdown了。\n\n\n参考：\n- https://madongqiang2201.github.io/\n- http://theme-next.iissnan.com/getting-started.html\n- http://jeasonstudio.github.io/2016/05/26/Mac%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8EGitHub-Page%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2/\n\n","slug":"Mac-gihub-pages-hexo搭建博客","published":1,"updated":"2017-06-05T11:55:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5b000h8tzzscancgx0","content":"<h1 id=\"mac下使用githubhexo建博客\"><a href=\"#Mac下使用github-hexo建博客\" class=\"headerlink\" title=\"Mac下使用github+hexo建博客\"></a>Mac下使用github+hexo建博客</h1><blockquote>\n<p>很早之前就想建个博客，纠结于怎么建，有的同学使用LNMP，使用wordpress,Django，首先得有个服务器，还是不够方便。近期使用github托管一些平常使用的代码或者设置，而且平常习惯使用markdown写笔记，所以就想直接用github_pages+hexo建个博客。</p>\n</blockquote>\n<p><strong>下边是过程。</strong></p>\n<hr>\n<h2 id=\"安装过程\"><a href=\"#安装过程\" class=\"headerlink\" title=\"安装过程\"></a>安装过程</h2><p><strong>首先</strong>需要在Mac本地把git装好，公钥传到github，然后装好node，npm</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">- brew install nodejs</div><div class=\"line\">- brew install npm </div><div class=\"line\">- npm install -g hexo-cli</div><div class=\"line\">- (看下安装目录，可以做个软链到/usr/bin/)</div><div class=\"line\">- ln -s /usr/local/lib/node_modules/hexo-cli/bin/hexo /usr/bin/hexo</div></pre></td></tr></table></figure>\n<p><strong>然后</strong>再自己Mac上建一个工作取名<strong>Blog</strong>，在github上面新建个工程参考<a href=\"https://pages.github.com/\" target=\"_blank\" rel=\"external\">github-pages官网</a>必须以 <strong>git用户名.github.io</strong>这种格式命名工程名。之后再<strong>Blog</strong> 目录下clone该工程。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">- mkdir Blog</div><div class=\"line\">- cd Blog &amp;&amp; git clone https://github.com/fanquqi/fanquqi.github.io.git</div></pre></td></tr></table></figure>\n<h2 id=\"在本地建立站点\"><a href=\"#在本地建立站点\" class=\"headerlink\" title=\"在本地建立站点\"></a>在本地建立站点</h2><p>安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。<br><a href=\"https://hexo.io/zh-cn/docs\" target=\"_blank\" rel=\"external\">Hexo相关操作参考</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo init &lt;folder&gt;</div><div class=\"line\">$ cd &lt;folder&gt;</div><div class=\"line\">$ npm install</div></pre></td></tr></table></figure>\n<p>所以以上的<code>&lt;folder&gt;</code>我们 用Blog代替<br>操作可以改为这样,因为上文中我们已经手动建了一个<code>Blog</code>文件夹</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd Blog </div><div class=\"line\">hexo init </div><div class=\"line\">npm install</div></pre></td></tr></table></figure>\n<p>新建完成后我们的文件夹目录如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">.</div><div class=\"line\">├── _config.yml</div><div class=\"line\">├── package.json</div><div class=\"line\">├── scaffolds</div><div class=\"line\">├── scripts</div><div class=\"line\">├── source</div><div class=\"line\">|   ├── _drafts</div><div class=\"line\">|   └── _posts</div><div class=\"line\">└── themes</div></pre></td></tr></table></figure>\n<p>之后运行 hexo start 可以在<a href=\"http://localhost:4000\" target=\"_blank\" rel=\"external\">http://localhost:4000</a> 看到自己的页面</p>\n<p><strong>关联github</strong></p>\n<blockquote>\n<p>设置好本地之后,需要关联github，以后就可以在本地写作，传到github上了</p>\n</blockquote>\n<p>修改_config.yml,在最后加上(注意不能有tab，’:’后必须有个空格)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">deploy:</div><div class=\"line\">  type: git</div><div class=\"line\">  repository: https://github.com/fanquqi/fanquqi.github.io.git</div><div class=\"line\">  branch: master</div></pre></td></tr></table></figure>\n<p>在blog文件夹目录下执行生成静态页面命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate     或者：hexo g</div></pre></td></tr></table></figure>\n<p>如果出现如下报错</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ERROR Local hexo not found in ~/blog</div><div class=\"line\">ERROR Try runing: &apos;npm install hexo --save&apos;</div></pre></td></tr></table></figure>\n<p>执行<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">npm install hexo --save</div></pre></td></tr></table></figure></p>\n<p>如果没有出现略过此步</p>\n<p>然后deploy 一下 同步到远程github<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">hexo deploy</div></pre></td></tr></table></figure></p>\n<p>如果出现一下报错 没有找到git</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  Blog hexo deploy</div><div class=\"line\">ERROR Deployer not found: git</div></pre></td></tr></table></figure>\n<p>安装hexo-deploy-git</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  Blog npm install hexo-deployer-git --save</div><div class=\"line\">hexo-site@0.0.0 /Users/fanquanqing/workspace/Blog</div><div class=\"line\">└─┬ hexo-deployer-git@0.3.0</div><div class=\"line\">  └── moment@2.18.1</div></pre></td></tr></table></figure>\n<p>之后再次执行hexo generate和hexo deploy命令<br>如果没有报错，你就可以在<a href=\"https://fanquqi.github.io\" target=\"_blank\" rel=\"external\">https://fanquqi.github.io</a>  看到之前自己4000端口相同的内容了。好棒哦。。。</p>\n<hr>\n<p>##安装theme</p>\n<blockquote>\n<p>主题可以到hexo官网下载 <a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"external\">https://hexo.io/themes/ </a><br>这里以Next为例。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd Blog &amp;&amp; git clone https://github.com/iissnan/hexo-theme-next themes/next</div><div class=\"line\">#替换Blog/_config.yml themes: landscape 为 themes: next</div><div class=\"line\">hexo clean //清除缓存</div><div class=\"line\">hexo generata</div><div class=\"line\">hexo deploy</div><div class=\"line\">hexo start</div></pre></td></tr></table></figure>\n<p>配置查看<a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"external\">http://theme-next.iissnan.com/getting-started.html </a><br><strong>搜索功能添加</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 安装hexo-generator-searchdb(给博客添加搜索功能)</div><div class=\"line\">➜  Blog npm install hexo-generator-searchdb --save</div><div class=\"line\">hexo-site@0.0.0 /Users/fanquanqing/workspace/Blog</div><div class=\"line\">└─┬ hexo-generator-searchdb@1.0.7</div><div class=\"line\">  └── striptags@3.0.1</div><div class=\"line\">#修改_config.yml,添加</div><div class=\"line\">search:</div><div class=\"line\">  path: search.xml</div><div class=\"line\">  field: post</div><div class=\"line\">  format: html</div><div class=\"line\">  limit: 10000</div></pre></td></tr></table></figure>\n<p>hexo start发现问题<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  Blog hexo s</div><div class=\"line\">ERROR Plugin load failed: hexo-generator-searchdb</div></pre></td></tr></table></figure></p>\n<p>查看插件hexo-generator-searchdb 中的Redmine  发现node 需要降级到4.2.2以下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">npm install -g n</div><div class=\"line\">n 4.2.2</div></pre></td></tr></table></figure>\n<h2 id=\"menu-添加\"><a href=\"#menu-添加\" class=\"headerlink\" title=\"menu 添加\"></a>menu 添加</h2><blockquote>\n<p>默认的有：首页，归档，分类，标签，关于, 但是next主题默认只显示了首页 归档和标签。<br>以<strong> categories</strong> 添加为例(tags 也是如此)</p>\n</blockquote>\n<p>1.新建categories page<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">hexo new page &quot;categories&quot;</div></pre></td></tr></table></figure></p>\n<p>会在source下面生成一个categories目录。</p>\n<p>2.修改index.md</p>\n<p>打开categories文件夹中的index.md页面，在头部添加 – type: “categories” （为了点击的时候链接生效）<br>修改完之后<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: 分类</div><div class=\"line\">date: 2017-06-03 22:17:53</div><div class=\"line\">type: &quot;categories&quot;</div><div class=\"line\">---</div></pre></td></tr></table></figure></p>\n<p>3.在hexo &gt; theme &gt; next &gt; _config.yml 中修改menu下的categorues,去掉前面井号注释。</p>\n<h2 id=\"文章发表\"><a href=\"#文章发表\" class=\"headerlink\" title=\"文章发表\"></a>文章发表</h2><p>发表步骤如下</p>\n<ul>\n<li>新建文章<ul>\n<li>hexo new urlooker使用</li>\n</ul>\n</li>\n<li>编辑文章<ul>\n<li>直接vim 或者用自己的markdown编辑器编辑，这里需要提醒下添加<strong>tags</strong>和 <strong>categories</strong> 使用</li>\n<li>hexo中有Front-matter这个概念，是文件最上方以 — 分隔的区域，用于指定个别文件的变量。<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: urlooker使用</div><div class=\"line\">date: 2017-06-02 18:57:50</div><div class=\"line\">tags: open-falcon</div><div class=\"line\">categoris: 监控</div><div class=\"line\">---</div></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<p>举例如上</p>\n<h2 id=\"添加评论功能\"><a href=\"#添加评论功能\" class=\"headerlink\" title=\"添加评论功能\"></a>添加评论功能</h2><blockquote>\n<p>多说在2017.6.1停止服务了，比较尴尬，但是新的next 集成了友言的评论功能，设置非常方便</p>\n</blockquote>\n<ul>\n<li>注册<a href=\"http://www.uyan.cc/\" target=\"_blank\" rel=\"external\">友言官网</a>，在管理后台记下UID</li>\n<li>添加UID到_config.yml 格式为</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">youyan_uid: 2323232</div></pre></td></tr></table></figure>\n<h2 id=\"静态文件处理\"><a href=\"#静态文件处理\" class=\"headerlink\" title=\"静态文件处理\"></a>静态文件处理</h2><blockquote>\n<p>好像github-pages 最大存储为300M 所以不能尽情的存储，最好吧静态图片放到外面，我直接放到了七牛云存储上，每个图片生成一个外链，很方便。</p>\n</blockquote>\n<p>重新部署下hexo即可。</p>\n<p>好了，现在就可以随时markdown了。</p>\n<p>参考：</p>\n<ul>\n<li><a href=\"https://madongqiang2201.github.io/\" target=\"_blank\" rel=\"external\">https://madongqiang2201.github.io/</a></li>\n<li><a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"external\">http://theme-next.iissnan.com/getting-started.html</a></li>\n<li><a href=\"http://jeasonstudio.github.io/2016/05/26/Mac%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8EGitHub-Page%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2/\" target=\"_blank\" rel=\"external\">http://jeasonstudio.github.io/2016/05/26/Mac%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8EGitHub-Page%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Mac下使用github-hexo建博客\"><a href=\"#Mac下使用github-hexo建博客\" class=\"headerlink\" title=\"Mac下使用github+hexo建博客\"></a>Mac下使用github+hexo建博客</h1><blockquote>\n<p>很早之前就想建个博客，纠结于怎么建，有的同学使用LNMP，使用wordpress,Django，首先得有个服务器，还是不够方便。近期使用github托管一些平常使用的代码或者设置，而且平常习惯使用markdown写笔记，所以就想直接用github_pages+hexo建个博客。</p>\n</blockquote>\n<p><strong>下边是过程。</strong></p>\n<hr>\n<h2 id=\"安装过程\"><a href=\"#安装过程\" class=\"headerlink\" title=\"安装过程\"></a>安装过程</h2><p><strong>首先</strong>需要在Mac本地把git装好，公钥传到github，然后装好node，npm</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">- brew install nodejs</div><div class=\"line\">- brew install npm </div><div class=\"line\">- npm install -g hexo-cli</div><div class=\"line\">- (看下安装目录，可以做个软链到/usr/bin/)</div><div class=\"line\">- ln -s /usr/local/lib/node_modules/hexo-cli/bin/hexo /usr/bin/hexo</div></pre></td></tr></table></figure>\n<p><strong>然后</strong>再自己Mac上建一个工作取名<strong>Blog</strong>，在github上面新建个工程参考<a href=\"https://pages.github.com/\" target=\"_blank\" rel=\"external\">github-pages官网</a>必须以 <strong>git用户名.github.io</strong>这种格式命名工程名。之后再<strong>Blog</strong> 目录下clone该工程。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">- mkdir Blog</div><div class=\"line\">- cd Blog &amp;&amp; git clone https://github.com/fanquqi/fanquqi.github.io.git</div></pre></td></tr></table></figure>\n<h2 id=\"在本地建立站点\"><a href=\"#在本地建立站点\" class=\"headerlink\" title=\"在本地建立站点\"></a>在本地建立站点</h2><p>安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。<br><a href=\"https://hexo.io/zh-cn/docs\" target=\"_blank\" rel=\"external\">Hexo相关操作参考</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo init &lt;folder&gt;</div><div class=\"line\">$ cd &lt;folder&gt;</div><div class=\"line\">$ npm install</div></pre></td></tr></table></figure>\n<p>所以以上的<code>&lt;folder&gt;</code>我们 用Blog代替<br>操作可以改为这样,因为上文中我们已经手动建了一个<code>Blog</code>文件夹</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd Blog </div><div class=\"line\">hexo init </div><div class=\"line\">npm install</div></pre></td></tr></table></figure>\n<p>新建完成后我们的文件夹目录如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">.</div><div class=\"line\">├── _config.yml</div><div class=\"line\">├── package.json</div><div class=\"line\">├── scaffolds</div><div class=\"line\">├── scripts</div><div class=\"line\">├── source</div><div class=\"line\">|   ├── _drafts</div><div class=\"line\">|   └── _posts</div><div class=\"line\">└── themes</div></pre></td></tr></table></figure>\n<p>之后运行 hexo start 可以在<a href=\"http://localhost:4000\" target=\"_blank\" rel=\"external\">http://localhost:4000</a> 看到自己的页面</p>\n<p><strong>关联github</strong></p>\n<blockquote>\n<p>设置好本地之后,需要关联github，以后就可以在本地写作，传到github上了</p>\n</blockquote>\n<p>修改_config.yml,在最后加上(注意不能有tab，’:’后必须有个空格)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">deploy:</div><div class=\"line\">  type: git</div><div class=\"line\">  repository: https://github.com/fanquqi/fanquqi.github.io.git</div><div class=\"line\">  branch: master</div></pre></td></tr></table></figure>\n<p>在blog文件夹目录下执行生成静态页面命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate     或者：hexo g</div></pre></td></tr></table></figure>\n<p>如果出现如下报错</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ERROR Local hexo not found in ~/blog</div><div class=\"line\">ERROR Try runing: &apos;npm install hexo --save&apos;</div></pre></td></tr></table></figure>\n<p>执行<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">npm install hexo --save</div></pre></td></tr></table></figure></p>\n<p>如果没有出现略过此步</p>\n<p>然后deploy 一下 同步到远程github<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">hexo deploy</div></pre></td></tr></table></figure></p>\n<p>如果出现一下报错 没有找到git</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  Blog hexo deploy</div><div class=\"line\">ERROR Deployer not found: git</div></pre></td></tr></table></figure>\n<p>安装hexo-deploy-git</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  Blog npm install hexo-deployer-git --save</div><div class=\"line\">hexo-site@0.0.0 /Users/fanquanqing/workspace/Blog</div><div class=\"line\">└─┬ hexo-deployer-git@0.3.0</div><div class=\"line\">  └── moment@2.18.1</div></pre></td></tr></table></figure>\n<p>之后再次执行hexo generate和hexo deploy命令<br>如果没有报错，你就可以在<a href=\"https://fanquqi.github.io\" target=\"_blank\" rel=\"external\">https://fanquqi.github.io</a>  看到之前自己4000端口相同的内容了。好棒哦。。。</p>\n<hr>\n<p>##安装theme</p>\n<blockquote>\n<p>主题可以到hexo官网下载 <a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"external\">https://hexo.io/themes/ </a><br>这里以Next为例。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd Blog &amp;&amp; git clone https://github.com/iissnan/hexo-theme-next themes/next</div><div class=\"line\">#替换Blog/_config.yml themes: landscape 为 themes: next</div><div class=\"line\">hexo clean //清除缓存</div><div class=\"line\">hexo generata</div><div class=\"line\">hexo deploy</div><div class=\"line\">hexo start</div></pre></td></tr></table></figure>\n<p>配置查看<a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"external\">http://theme-next.iissnan.com/getting-started.html </a><br><strong>搜索功能添加</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 安装hexo-generator-searchdb(给博客添加搜索功能)</div><div class=\"line\">➜  Blog npm install hexo-generator-searchdb --save</div><div class=\"line\">hexo-site@0.0.0 /Users/fanquanqing/workspace/Blog</div><div class=\"line\">└─┬ hexo-generator-searchdb@1.0.7</div><div class=\"line\">  └── striptags@3.0.1</div><div class=\"line\">#修改_config.yml,添加</div><div class=\"line\">search:</div><div class=\"line\">  path: search.xml</div><div class=\"line\">  field: post</div><div class=\"line\">  format: html</div><div class=\"line\">  limit: 10000</div></pre></td></tr></table></figure>\n<p>hexo start发现问题<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  Blog hexo s</div><div class=\"line\">ERROR Plugin load failed: hexo-generator-searchdb</div></pre></td></tr></table></figure></p>\n<p>查看插件hexo-generator-searchdb 中的Redmine  发现node 需要降级到4.2.2以下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">npm install -g n</div><div class=\"line\">n 4.2.2</div></pre></td></tr></table></figure>\n<h2 id=\"menu-添加\"><a href=\"#menu-添加\" class=\"headerlink\" title=\"menu 添加\"></a>menu 添加</h2><blockquote>\n<p>默认的有：首页，归档，分类，标签，关于, 但是next主题默认只显示了首页 归档和标签。<br>以<strong> categories</strong> 添加为例(tags 也是如此)</p>\n</blockquote>\n<p>1.新建categories page<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">hexo new page &quot;categories&quot;</div></pre></td></tr></table></figure></p>\n<p>会在source下面生成一个categories目录。</p>\n<p>2.修改index.md</p>\n<p>打开categories文件夹中的index.md页面，在头部添加 – type: “categories” （为了点击的时候链接生效）<br>修改完之后<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: 分类</div><div class=\"line\">date: 2017-06-03 22:17:53</div><div class=\"line\">type: &quot;categories&quot;</div><div class=\"line\">---</div></pre></td></tr></table></figure></p>\n<p>3.在hexo &gt; theme &gt; next &gt; _config.yml 中修改menu下的categorues,去掉前面井号注释。</p>\n<h2 id=\"文章发表\"><a href=\"#文章发表\" class=\"headerlink\" title=\"文章发表\"></a>文章发表</h2><p>发表步骤如下</p>\n<ul>\n<li>新建文章<ul>\n<li>hexo new urlooker使用</li>\n</ul>\n</li>\n<li>编辑文章<ul>\n<li>直接vim 或者用自己的markdown编辑器编辑，这里需要提醒下添加<strong>tags</strong>和 <strong>categories</strong> 使用</li>\n<li>hexo中有Front-matter这个概念，是文件最上方以 — 分隔的区域，用于指定个别文件的变量。<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">title: urlooker使用</div><div class=\"line\">date: 2017-06-02 18:57:50</div><div class=\"line\">tags: open-falcon</div><div class=\"line\">categoris: 监控</div><div class=\"line\">---</div></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<p>举例如上</p>\n<h2 id=\"添加评论功能\"><a href=\"#添加评论功能\" class=\"headerlink\" title=\"添加评论功能\"></a>添加评论功能</h2><blockquote>\n<p>多说在2017.6.1停止服务了，比较尴尬，但是新的next 集成了友言的评论功能，设置非常方便</p>\n</blockquote>\n<ul>\n<li>注册<a href=\"http://www.uyan.cc/\" target=\"_blank\" rel=\"external\">友言官网</a>，在管理后台记下UID</li>\n<li>添加UID到_config.yml 格式为</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">youyan_uid: 2323232</div></pre></td></tr></table></figure>\n<h2 id=\"静态文件处理\"><a href=\"#静态文件处理\" class=\"headerlink\" title=\"静态文件处理\"></a>静态文件处理</h2><blockquote>\n<p>好像github-pages 最大存储为300M 所以不能尽情的存储，最好吧静态图片放到外面，我直接放到了七牛云存储上，每个图片生成一个外链，很方便。</p>\n</blockquote>\n<p>重新部署下hexo即可。</p>\n<p>好了，现在就可以随时markdown了。</p>\n<p>参考：</p>\n<ul>\n<li><a href=\"https://madongqiang2201.github.io/\" target=\"_blank\" rel=\"external\">https://madongqiang2201.github.io/</a></li>\n<li><a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"external\">http://theme-next.iissnan.com/getting-started.html</a></li>\n<li><a href=\"http://jeasonstudio.github.io/2016/05/26/Mac%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8EGitHub-Page%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2/\" target=\"_blank\" rel=\"external\">http://jeasonstudio.github.io/2016/05/26/Mac%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8EGitHub-Page%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2/</a></li>\n</ul>\n"},{"title":"Mac软件使用","date":"2017-06-06T09:48:15.000Z","_content":"[推荐下载链接-xclient](http://xclient.info/)\n[推荐下载链接-玩转苹果](http://www.ifunmac.com/)\n[少数派](https://sspai.com/)\n\n告别鼠标的效率神器: Alfred\n\n编辑器: sublime, Pycharm, Atom\n\n接口测试: charles, postman\n\njson格式化: Textlab\n\n脑图: Xmind \n\nMarkdown: 马克飞象, Mou \n\n远程工具: teamviewer\n\nVPN: Tunnalblik\n\n科学上网: shadowsocksx\n\n密码记录: 1password\n\n","source":"_posts/Mac软件使用.md","raw":"---\ntitle: Mac软件使用\ndate: 2017-06-06 17:48:15\ntags: Mac\n---\n[推荐下载链接-xclient](http://xclient.info/)\n[推荐下载链接-玩转苹果](http://www.ifunmac.com/)\n[少数派](https://sspai.com/)\n\n告别鼠标的效率神器: Alfred\n\n编辑器: sublime, Pycharm, Atom\n\n接口测试: charles, postman\n\njson格式化: Textlab\n\n脑图: Xmind \n\nMarkdown: 马克飞象, Mou \n\n远程工具: teamviewer\n\nVPN: Tunnalblik\n\n科学上网: shadowsocksx\n\n密码记录: 1password\n\n","slug":"Mac软件使用","published":1,"updated":"2017-06-22T10:48:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5d000j8tzzijorrmgk","content":"<p><a href=\"http://xclient.info/\" target=\"_blank\" rel=\"external\">推荐下载链接-xclient</a><br><a href=\"http://www.ifunmac.com/\" target=\"_blank\" rel=\"external\">推荐下载链接-玩转苹果</a><br><a href=\"https://sspai.com/\" target=\"_blank\" rel=\"external\">少数派</a></p>\n<p>告别鼠标的效率神器: Alfred</p>\n<p>编辑器: sublime, Pycharm, Atom</p>\n<p>接口测试: charles, postman</p>\n<p>json格式化: Textlab</p>\n<p>脑图: Xmind </p>\n<p>Markdown: 马克飞象, Mou </p>\n<p>远程工具: teamviewer</p>\n<p>VPN: Tunnalblik</p>\n<p>科学上网: shadowsocksx</p>\n<p>密码记录: 1password</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://xclient.info/\" target=\"_blank\" rel=\"external\">推荐下载链接-xclient</a><br><a href=\"http://www.ifunmac.com/\" target=\"_blank\" rel=\"external\">推荐下载链接-玩转苹果</a><br><a href=\"https://sspai.com/\" target=\"_blank\" rel=\"external\">少数派</a></p>\n<p>告别鼠标的效率神器: Alfred</p>\n<p>编辑器: sublime, Pycharm, Atom</p>\n<p>接口测试: charles, postman</p>\n<p>json格式化: Textlab</p>\n<p>脑图: Xmind </p>\n<p>Markdown: 马克飞象, Mou </p>\n<p>远程工具: teamviewer</p>\n<p>VPN: Tunnalblik</p>\n<p>科学上网: shadowsocksx</p>\n<p>密码记录: 1password</p>\n"},{"title":"Git使用总结","date":"2017-06-30T08:28:55.000Z","_content":"> 很长一段时间使用git都是只有 `add`,`commit`,`pull`,`push`等这几个简单的命令。想想自己也是使用github的人，怎么能只会这些皮毛。\n\n首先我们知道git主要是做版本控制工具，所以一些概念逻辑都是为了更好地实现这个功能。\n\n## 三个目录概念\n\n首先要对概念清楚 \n- Working Directory：工作目录，这个可以简单的理解为你在文件系统里真实看到的文件\n- Stage（Index）：暂存“目录”，用git add命令添加的文件就到了这里，即将被commit的文件\n- Repository：项目“目录”，用git commit提交的文件就到了这里\n\n## commit\n\n介绍几种比较6的commit的操作，记住使用git的一贯原则还是少量改动频繁提交，方便做版本控制。\n\n- 平常我们都是`git add ./`然后`git commit -m \"fix\"`提交代码\n- 这两条可以结合到一起直接`git commit -am \"fix\"`就做到了 \n或者指定文件`git commit test.txt -m \"fix2.0\"`.\n\n- 修改上一次提交 `git commit --amend -am \"fix2.0, 2.5` 这样之前2.0的commit_id直接被覆盖了。\n\n## checkout\n\n\n- 分支相关操作：git checkout 分支名/commit hash切换到相应的分支或commit，加上-b参数则会创建分支并切换过去\n    + git checkout -b branch3 1a222c3  注意这里commit_id为新分支起点\n\n- 恢复文件相关操作：git checkout [分支名/commit hash/HEAD快捷方式] -- 文件名恢复指定分支的最新commit或指定commit或快捷方式指向的commit的文件到工作目录，若省略中间的参数，则\n\n    - 暂存区有内容且暂存区内容与工作目录不同，则恢复暂存区的状态到工作目录(之前`git add`过恢复到当时的状态)\n\n    - 暂存区无内容，则恢复HEAD（最新的commit）的状态到工作目录\n\n## diff \n- 使用方式基本就是 `git diff [source] [target]` 也就是说 `target`相对于`source`有哪些变化 ,这里的target,source 可以是commit_id也可以是两个分支,同时`git diff master branch2`和`git diff HEAD branch2`显示结果是一样的\n- 只给一个参数 这个参数默认是 `source` 而`target` 默认是当前分支最新的commit\n- 不给参数 `source`为暂存区，`target`为工作目录\n- 如果想要使暂存目录作为target的话，需要使用--cached参数\n\n## reset \n- git reset [commit hash/分支名/快捷方式] [文件名]类似“git add的反操作”，直接将所在commit的文件状态恢复到暂存区域。省略commit则默认为HEAD，省略文件名默认为所有文件。只改变暂存目录，不改变工作目录，当前commit不变。\n- git reset --soft [commit hash/分支名/快捷方式]软恢复，将恢复前所在commit的文件状态恢复到暂存区，当前最新commit为参数中的commit。只改变暂存目录，不改变工作目录，当前commit改变。\n- git reset --hard [commit hash/分支名/快捷方式]硬恢复，强制将整个项目恢复为参数中的commit时的文件状态，清空暂存目录，工作目录clean。暂存目录和工作目录同时被改变，当前commit改变。\n\n关于reset命令的其他补充：当前HEAD已经位于“不是最新”，是不是前面的commit都找不回来了？当然不会，reset过的操作也是可以被reset的。有两种方法：\n\n1. 如果记得“最新”的hash（，则直接git reset --hard 1a222c3，则项目直接强制恢复到“最新”所在的状态。\n2. 如果不记得的话，运行git reflog，这个命令会输出一个列表，包含HEAD发生的所有变化。\n\n## cherry-pick\n> cherry-pick其实在工作中还挺常用的，就像copy一样，把一个分之上的某个或者某几个commit复制到另一个分之。一种常见的场景就是，比如我在A分支做了几次commit以后，发现其实我并不应该在A分支上工作，应该在B分支上工作，这时就需要将这些commit从A分支复制到B分支去了，这时候就需要cherry-pick命令了\n\n模拟下上面场景 在master分之上提交了两个commit  一个commit1 一个commit2，发现不应该在master上面操作，应该新建分之branch1\n```\n首先新建分之 从commit0开始，并切到branch1\ngit checkout -b branch1 commit0\n复制master分之 两个commit到当前分之\ngit cherry-pick commit1 commit2\n在master分支上将这两个commit删除。先切回master分支：\ngit checkout master，运行git reset --hard commit0\n\n```\n\n## merge\n\n\n## rebase\n\n\n","source":"_posts/Git使用总结.md","raw":"---\ntitle: Git使用总结\ndate: 2017-06-30 16:28:55\ntags: git\ncategories: git\n---\n> 很长一段时间使用git都是只有 `add`,`commit`,`pull`,`push`等这几个简单的命令。想想自己也是使用github的人，怎么能只会这些皮毛。\n\n首先我们知道git主要是做版本控制工具，所以一些概念逻辑都是为了更好地实现这个功能。\n\n## 三个目录概念\n\n首先要对概念清楚 \n- Working Directory：工作目录，这个可以简单的理解为你在文件系统里真实看到的文件\n- Stage（Index）：暂存“目录”，用git add命令添加的文件就到了这里，即将被commit的文件\n- Repository：项目“目录”，用git commit提交的文件就到了这里\n\n## commit\n\n介绍几种比较6的commit的操作，记住使用git的一贯原则还是少量改动频繁提交，方便做版本控制。\n\n- 平常我们都是`git add ./`然后`git commit -m \"fix\"`提交代码\n- 这两条可以结合到一起直接`git commit -am \"fix\"`就做到了 \n或者指定文件`git commit test.txt -m \"fix2.0\"`.\n\n- 修改上一次提交 `git commit --amend -am \"fix2.0, 2.5` 这样之前2.0的commit_id直接被覆盖了。\n\n## checkout\n\n\n- 分支相关操作：git checkout 分支名/commit hash切换到相应的分支或commit，加上-b参数则会创建分支并切换过去\n    + git checkout -b branch3 1a222c3  注意这里commit_id为新分支起点\n\n- 恢复文件相关操作：git checkout [分支名/commit hash/HEAD快捷方式] -- 文件名恢复指定分支的最新commit或指定commit或快捷方式指向的commit的文件到工作目录，若省略中间的参数，则\n\n    - 暂存区有内容且暂存区内容与工作目录不同，则恢复暂存区的状态到工作目录(之前`git add`过恢复到当时的状态)\n\n    - 暂存区无内容，则恢复HEAD（最新的commit）的状态到工作目录\n\n## diff \n- 使用方式基本就是 `git diff [source] [target]` 也就是说 `target`相对于`source`有哪些变化 ,这里的target,source 可以是commit_id也可以是两个分支,同时`git diff master branch2`和`git diff HEAD branch2`显示结果是一样的\n- 只给一个参数 这个参数默认是 `source` 而`target` 默认是当前分支最新的commit\n- 不给参数 `source`为暂存区，`target`为工作目录\n- 如果想要使暂存目录作为target的话，需要使用--cached参数\n\n## reset \n- git reset [commit hash/分支名/快捷方式] [文件名]类似“git add的反操作”，直接将所在commit的文件状态恢复到暂存区域。省略commit则默认为HEAD，省略文件名默认为所有文件。只改变暂存目录，不改变工作目录，当前commit不变。\n- git reset --soft [commit hash/分支名/快捷方式]软恢复，将恢复前所在commit的文件状态恢复到暂存区，当前最新commit为参数中的commit。只改变暂存目录，不改变工作目录，当前commit改变。\n- git reset --hard [commit hash/分支名/快捷方式]硬恢复，强制将整个项目恢复为参数中的commit时的文件状态，清空暂存目录，工作目录clean。暂存目录和工作目录同时被改变，当前commit改变。\n\n关于reset命令的其他补充：当前HEAD已经位于“不是最新”，是不是前面的commit都找不回来了？当然不会，reset过的操作也是可以被reset的。有两种方法：\n\n1. 如果记得“最新”的hash（，则直接git reset --hard 1a222c3，则项目直接强制恢复到“最新”所在的状态。\n2. 如果不记得的话，运行git reflog，这个命令会输出一个列表，包含HEAD发生的所有变化。\n\n## cherry-pick\n> cherry-pick其实在工作中还挺常用的，就像copy一样，把一个分之上的某个或者某几个commit复制到另一个分之。一种常见的场景就是，比如我在A分支做了几次commit以后，发现其实我并不应该在A分支上工作，应该在B分支上工作，这时就需要将这些commit从A分支复制到B分支去了，这时候就需要cherry-pick命令了\n\n模拟下上面场景 在master分之上提交了两个commit  一个commit1 一个commit2，发现不应该在master上面操作，应该新建分之branch1\n```\n首先新建分之 从commit0开始，并切到branch1\ngit checkout -b branch1 commit0\n复制master分之 两个commit到当前分之\ngit cherry-pick commit1 commit2\n在master分支上将这两个commit删除。先切回master分支：\ngit checkout master，运行git reset --hard commit0\n\n```\n\n## merge\n\n\n## rebase\n\n\n","slug":"Git使用总结","published":1,"updated":"2017-07-20T02:50:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5f000n8tzzdhq9mi0a","content":"<blockquote>\n<p>很长一段时间使用git都是只有 <code>add</code>,<code>commit</code>,<code>pull</code>,<code>push</code>等这几个简单的命令。想想自己也是使用github的人，怎么能只会这些皮毛。</p>\n</blockquote>\n<p>首先我们知道git主要是做版本控制工具，所以一些概念逻辑都是为了更好地实现这个功能。</p>\n<h2 id=\"三个目录概念\"><a href=\"#三个目录概念\" class=\"headerlink\" title=\"三个目录概念\"></a>三个目录概念</h2><p>首先要对概念清楚 </p>\n<ul>\n<li>Working Directory：工作目录，这个可以简单的理解为你在文件系统里真实看到的文件</li>\n<li>Stage（Index）：暂存“目录”，用git add命令添加的文件就到了这里，即将被commit的文件</li>\n<li>Repository：项目“目录”，用git commit提交的文件就到了这里</li>\n</ul>\n<h2 id=\"commit\"><a href=\"#commit\" class=\"headerlink\" title=\"commit\"></a>commit</h2><p>介绍几种比较6的commit的操作，记住使用git的一贯原则还是少量改动频繁提交，方便做版本控制。</p>\n<ul>\n<li>平常我们都是<code>git add ./</code>然后<code>git commit -m &quot;fix&quot;</code>提交代码</li>\n<li><p>这两条可以结合到一起直接<code>git commit -am &quot;fix&quot;</code>就做到了<br>或者指定文件<code>git commit test.txt -m &quot;fix2.0&quot;</code>.</p>\n</li>\n<li><p>修改上一次提交 <code>git commit --amend -am &quot;fix2.0, 2.5</code> 这样之前2.0的commit_id直接被覆盖了。</p>\n</li>\n</ul>\n<h2 id=\"checkout\"><a href=\"#checkout\" class=\"headerlink\" title=\"checkout\"></a>checkout</h2><ul>\n<li><p>分支相关操作：git checkout 分支名/commit hash切换到相应的分支或commit，加上-b参数则会创建分支并切换过去</p>\n<ul>\n<li>git checkout -b branch3 1a222c3  注意这里commit_id为新分支起点</li>\n</ul>\n</li>\n<li><p>恢复文件相关操作：git checkout [分支名/commit hash/HEAD快捷方式] – 文件名恢复指定分支的最新commit或指定commit或快捷方式指向的commit的文件到工作目录，若省略中间的参数，则</p>\n<ul>\n<li><p>暂存区有内容且暂存区内容与工作目录不同，则恢复暂存区的状态到工作目录(之前<code>git add</code>过恢复到当时的状态)</p>\n</li>\n<li><p>暂存区无内容，则恢复HEAD（最新的commit）的状态到工作目录</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"diff\"><a href=\"#diff\" class=\"headerlink\" title=\"diff\"></a>diff</h2><ul>\n<li>使用方式基本就是 <code>git diff [source] [target]</code> 也就是说 <code>target</code>相对于<code>source</code>有哪些变化 ,这里的target,source 可以是commit_id也可以是两个分支,同时<code>git diff master branch2</code>和<code>git diff HEAD branch2</code>显示结果是一样的</li>\n<li>只给一个参数 这个参数默认是 <code>source</code> 而<code>target</code> 默认是当前分支最新的commit</li>\n<li>不给参数 <code>source</code>为暂存区，<code>target</code>为工作目录</li>\n<li>如果想要使暂存目录作为target的话，需要使用–cached参数</li>\n</ul>\n<h2 id=\"reset\"><a href=\"#reset\" class=\"headerlink\" title=\"reset\"></a>reset</h2><ul>\n<li>git reset [commit hash/分支名/快捷方式] [文件名]类似“git add的反操作”，直接将所在commit的文件状态恢复到暂存区域。省略commit则默认为HEAD，省略文件名默认为所有文件。只改变暂存目录，不改变工作目录，当前commit不变。</li>\n<li>git reset –soft [commit hash/分支名/快捷方式]软恢复，将恢复前所在commit的文件状态恢复到暂存区，当前最新commit为参数中的commit。只改变暂存目录，不改变工作目录，当前commit改变。</li>\n<li>git reset –hard [commit hash/分支名/快捷方式]硬恢复，强制将整个项目恢复为参数中的commit时的文件状态，清空暂存目录，工作目录clean。暂存目录和工作目录同时被改变，当前commit改变。</li>\n</ul>\n<p>关于reset命令的其他补充：当前HEAD已经位于“不是最新”，是不是前面的commit都找不回来了？当然不会，reset过的操作也是可以被reset的。有两种方法：</p>\n<ol>\n<li>如果记得“最新”的hash（，则直接git reset –hard 1a222c3，则项目直接强制恢复到“最新”所在的状态。</li>\n<li>如果不记得的话，运行git reflog，这个命令会输出一个列表，包含HEAD发生的所有变化。</li>\n</ol>\n<h2 id=\"cherry-pick\"><a href=\"#cherry-pick\" class=\"headerlink\" title=\"cherry-pick\"></a>cherry-pick</h2><blockquote>\n<p>cherry-pick其实在工作中还挺常用的，就像copy一样，把一个分之上的某个或者某几个commit复制到另一个分之。一种常见的场景就是，比如我在A分支做了几次commit以后，发现其实我并不应该在A分支上工作，应该在B分支上工作，这时就需要将这些commit从A分支复制到B分支去了，这时候就需要cherry-pick命令了</p>\n</blockquote>\n<p>模拟下上面场景 在master分之上提交了两个commit  一个commit1 一个commit2，发现不应该在master上面操作，应该新建分之branch1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">首先新建分之 从commit0开始，并切到branch1</div><div class=\"line\">git checkout -b branch1 commit0</div><div class=\"line\">复制master分之 两个commit到当前分之</div><div class=\"line\">git cherry-pick commit1 commit2</div><div class=\"line\">在master分支上将这两个commit删除。先切回master分支：</div><div class=\"line\">git checkout master，运行git reset --hard commit0</div></pre></td></tr></table></figure></p>\n<h2 id=\"merge\"><a href=\"#merge\" class=\"headerlink\" title=\"merge\"></a>merge</h2><h2 id=\"rebase\"><a href=\"#rebase\" class=\"headerlink\" title=\"rebase\"></a>rebase</h2>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>很长一段时间使用git都是只有 <code>add</code>,<code>commit</code>,<code>pull</code>,<code>push</code>等这几个简单的命令。想想自己也是使用github的人，怎么能只会这些皮毛。</p>\n</blockquote>\n<p>首先我们知道git主要是做版本控制工具，所以一些概念逻辑都是为了更好地实现这个功能。</p>\n<h2 id=\"三个目录概念\"><a href=\"#三个目录概念\" class=\"headerlink\" title=\"三个目录概念\"></a>三个目录概念</h2><p>首先要对概念清楚 </p>\n<ul>\n<li>Working Directory：工作目录，这个可以简单的理解为你在文件系统里真实看到的文件</li>\n<li>Stage（Index）：暂存“目录”，用git add命令添加的文件就到了这里，即将被commit的文件</li>\n<li>Repository：项目“目录”，用git commit提交的文件就到了这里</li>\n</ul>\n<h2 id=\"commit\"><a href=\"#commit\" class=\"headerlink\" title=\"commit\"></a>commit</h2><p>介绍几种比较6的commit的操作，记住使用git的一贯原则还是少量改动频繁提交，方便做版本控制。</p>\n<ul>\n<li>平常我们都是<code>git add ./</code>然后<code>git commit -m &quot;fix&quot;</code>提交代码</li>\n<li><p>这两条可以结合到一起直接<code>git commit -am &quot;fix&quot;</code>就做到了<br>或者指定文件<code>git commit test.txt -m &quot;fix2.0&quot;</code>.</p>\n</li>\n<li><p>修改上一次提交 <code>git commit --amend -am &quot;fix2.0, 2.5</code> 这样之前2.0的commit_id直接被覆盖了。</p>\n</li>\n</ul>\n<h2 id=\"checkout\"><a href=\"#checkout\" class=\"headerlink\" title=\"checkout\"></a>checkout</h2><ul>\n<li><p>分支相关操作：git checkout 分支名/commit hash切换到相应的分支或commit，加上-b参数则会创建分支并切换过去</p>\n<ul>\n<li>git checkout -b branch3 1a222c3  注意这里commit_id为新分支起点</li>\n</ul>\n</li>\n<li><p>恢复文件相关操作：git checkout [分支名/commit hash/HEAD快捷方式] – 文件名恢复指定分支的最新commit或指定commit或快捷方式指向的commit的文件到工作目录，若省略中间的参数，则</p>\n<ul>\n<li><p>暂存区有内容且暂存区内容与工作目录不同，则恢复暂存区的状态到工作目录(之前<code>git add</code>过恢复到当时的状态)</p>\n</li>\n<li><p>暂存区无内容，则恢复HEAD（最新的commit）的状态到工作目录</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"diff\"><a href=\"#diff\" class=\"headerlink\" title=\"diff\"></a>diff</h2><ul>\n<li>使用方式基本就是 <code>git diff [source] [target]</code> 也就是说 <code>target</code>相对于<code>source</code>有哪些变化 ,这里的target,source 可以是commit_id也可以是两个分支,同时<code>git diff master branch2</code>和<code>git diff HEAD branch2</code>显示结果是一样的</li>\n<li>只给一个参数 这个参数默认是 <code>source</code> 而<code>target</code> 默认是当前分支最新的commit</li>\n<li>不给参数 <code>source</code>为暂存区，<code>target</code>为工作目录</li>\n<li>如果想要使暂存目录作为target的话，需要使用–cached参数</li>\n</ul>\n<h2 id=\"reset\"><a href=\"#reset\" class=\"headerlink\" title=\"reset\"></a>reset</h2><ul>\n<li>git reset [commit hash/分支名/快捷方式] [文件名]类似“git add的反操作”，直接将所在commit的文件状态恢复到暂存区域。省略commit则默认为HEAD，省略文件名默认为所有文件。只改变暂存目录，不改变工作目录，当前commit不变。</li>\n<li>git reset –soft [commit hash/分支名/快捷方式]软恢复，将恢复前所在commit的文件状态恢复到暂存区，当前最新commit为参数中的commit。只改变暂存目录，不改变工作目录，当前commit改变。</li>\n<li>git reset –hard [commit hash/分支名/快捷方式]硬恢复，强制将整个项目恢复为参数中的commit时的文件状态，清空暂存目录，工作目录clean。暂存目录和工作目录同时被改变，当前commit改变。</li>\n</ul>\n<p>关于reset命令的其他补充：当前HEAD已经位于“不是最新”，是不是前面的commit都找不回来了？当然不会，reset过的操作也是可以被reset的。有两种方法：</p>\n<ol>\n<li>如果记得“最新”的hash（，则直接git reset –hard 1a222c3，则项目直接强制恢复到“最新”所在的状态。</li>\n<li>如果不记得的话，运行git reflog，这个命令会输出一个列表，包含HEAD发生的所有变化。</li>\n</ol>\n<h2 id=\"cherry-pick\"><a href=\"#cherry-pick\" class=\"headerlink\" title=\"cherry-pick\"></a>cherry-pick</h2><blockquote>\n<p>cherry-pick其实在工作中还挺常用的，就像copy一样，把一个分之上的某个或者某几个commit复制到另一个分之。一种常见的场景就是，比如我在A分支做了几次commit以后，发现其实我并不应该在A分支上工作，应该在B分支上工作，这时就需要将这些commit从A分支复制到B分支去了，这时候就需要cherry-pick命令了</p>\n</blockquote>\n<p>模拟下上面场景 在master分之上提交了两个commit  一个commit1 一个commit2，发现不应该在master上面操作，应该新建分之branch1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">首先新建分之 从commit0开始，并切到branch1</div><div class=\"line\">git checkout -b branch1 commit0</div><div class=\"line\">复制master分之 两个commit到当前分之</div><div class=\"line\">git cherry-pick commit1 commit2</div><div class=\"line\">在master分支上将这两个commit删除。先切回master分支：</div><div class=\"line\">git checkout master，运行git reset --hard commit0</div></pre></td></tr></table></figure></p>\n<h2 id=\"merge\"><a href=\"#merge\" class=\"headerlink\" title=\"merge\"></a>merge</h2><h2 id=\"rebase\"><a href=\"#rebase\" class=\"headerlink\" title=\"rebase\"></a>rebase</h2>"},{"title":"MySQL问题查找,状态查看","date":"2017-08-02T08:35:18.000Z","_content":"\n导火索: 今天后端上线，上线脚本执行到数据库更改的时候卡住了(公司开发的devops,web操作)，登录机器查看ansible进程是在的，证明SQL 执行出错了。之前我很少接触mysql，全是部署增删改查，多表查询都少用，所以这次是一边Google一边查找原因。\n\n首先，这次数据库修改一共有四处，前三个都已经执行完成，就是最后一个加字段的没有成功。\n\n**排查过程**\n\n1. 查看表大小，确认不是因为表大导致执行时间过长。\n    其实这个再上线操作的时候又应该有个大概的认识，比如这个表功能大概是多少行，属于哪个工程等等，如果对业务熟悉，应该很快判断的出。\n    `相关命令`\n    ```\n    // 直接查找，可能较慢\n    select count(id) from table_name; \n    // 查找information_schema中的信息\n    select * from information_schema.TABLES \n        where information_schema.TABLES.TABLE_SCHEMA='databasename'\n        and information_schema.TABLES.TABLE_NAME='tablename'\\G\n    ```\n\n2. 如果不是表太大，可以看下正在进行的事务\n    了解事务的工作模式很重要，首先要知道自己的MySQL隔离级别，及每种隔离级别的特点。参考[美团点评团队的分享](https://tech.meituan.com/innodb-lock.html) 我们是使用的 已提交读（Read committed）\n    ```\n    // 查看当前隔离级别\n    SELECT @@session.tx_isolation;\n    // 查看当前执行的事务\n    SELECT * FROM information_schema.INNODB_TRX;\n    ```\n    当时主库加上字段之后，从库一直加不上字段就是因为有另一个事务一直没有提交，导致表一直是只读状态，阻塞了。\n\n\nselect * from information_schema.TABLES \n        where information_schema.TABLES.TABLE_SCHEMA='online_medical'\n        and information_schema.TABLES.TABLE_NAME='api_familydoctorservice'\\G\n","source":"_posts/MySQL问题查找-状态查看.md","raw":"---\ntitle: 'MySQL问题查找,状态查看'\ndate: 2017-08-02 16:35:18\ntags: MySQL\ncategories: 数据库\n---\n\n导火索: 今天后端上线，上线脚本执行到数据库更改的时候卡住了(公司开发的devops,web操作)，登录机器查看ansible进程是在的，证明SQL 执行出错了。之前我很少接触mysql，全是部署增删改查，多表查询都少用，所以这次是一边Google一边查找原因。\n\n首先，这次数据库修改一共有四处，前三个都已经执行完成，就是最后一个加字段的没有成功。\n\n**排查过程**\n\n1. 查看表大小，确认不是因为表大导致执行时间过长。\n    其实这个再上线操作的时候又应该有个大概的认识，比如这个表功能大概是多少行，属于哪个工程等等，如果对业务熟悉，应该很快判断的出。\n    `相关命令`\n    ```\n    // 直接查找，可能较慢\n    select count(id) from table_name; \n    // 查找information_schema中的信息\n    select * from information_schema.TABLES \n        where information_schema.TABLES.TABLE_SCHEMA='databasename'\n        and information_schema.TABLES.TABLE_NAME='tablename'\\G\n    ```\n\n2. 如果不是表太大，可以看下正在进行的事务\n    了解事务的工作模式很重要，首先要知道自己的MySQL隔离级别，及每种隔离级别的特点。参考[美团点评团队的分享](https://tech.meituan.com/innodb-lock.html) 我们是使用的 已提交读（Read committed）\n    ```\n    // 查看当前隔离级别\n    SELECT @@session.tx_isolation;\n    // 查看当前执行的事务\n    SELECT * FROM information_schema.INNODB_TRX;\n    ```\n    当时主库加上字段之后，从库一直加不上字段就是因为有另一个事务一直没有提交，导致表一直是只读状态，阻塞了。\n\n\nselect * from information_schema.TABLES \n        where information_schema.TABLES.TABLE_SCHEMA='online_medical'\n        and information_schema.TABLES.TABLE_NAME='api_familydoctorservice'\\G\n","slug":"MySQL问题查找-状态查看","published":1,"updated":"2017-08-08T03:43:23.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5h000p8tzzkrdlmq12","content":"<p>导火索: 今天后端上线，上线脚本执行到数据库更改的时候卡住了(公司开发的devops,web操作)，登录机器查看ansible进程是在的，证明SQL 执行出错了。之前我很少接触mysql，全是部署增删改查，多表查询都少用，所以这次是一边Google一边查找原因。</p>\n<p>首先，这次数据库修改一共有四处，前三个都已经执行完成，就是最后一个加字段的没有成功。</p>\n<p><strong>排查过程</strong></p>\n<ol>\n<li><p>查看表大小，确认不是因为表大导致执行时间过长。<br> 其实这个再上线操作的时候又应该有个大概的认识，比如这个表功能大概是多少行，属于哪个工程等等，如果对业务熟悉，应该很快判断的出。<br> <code>相关命令</code></p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 直接查找，可能较慢</div><div class=\"line\">select count(id) from table_name; </div><div class=\"line\">// 查找information_schema中的信息</div><div class=\"line\">select * from information_schema.TABLES </div><div class=\"line\">    where information_schema.TABLES.TABLE_SCHEMA=&apos;databasename&apos;</div><div class=\"line\">    and information_schema.TABLES.TABLE_NAME=&apos;tablename&apos;\\G</div></pre></td></tr></table></figure>\n</li>\n<li><p>如果不是表太大，可以看下正在进行的事务<br> 了解事务的工作模式很重要，首先要知道自己的MySQL隔离级别，及每种隔离级别的特点。参考<a href=\"https://tech.meituan.com/innodb-lock.html\" target=\"_blank\" rel=\"external\">美团点评团队的分享</a> 我们是使用的 已提交读（Read committed）</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 查看当前隔离级别</div><div class=\"line\">SELECT @@session.tx_isolation;</div><div class=\"line\">// 查看当前执行的事务</div><div class=\"line\">SELECT * FROM information_schema.INNODB_TRX;</div></pre></td></tr></table></figure>\n<p> 当时主库加上字段之后，从库一直加不上字段就是因为有另一个事务一直没有提交，导致表一直是只读状态，阻塞了。</p>\n</li>\n</ol>\n<p>select * from information_schema.TABLES<br>        where information_schema.TABLES.TABLE_SCHEMA=’online_medical’<br>        and information_schema.TABLES.TABLE_NAME=’api_familydoctorservice’\\G</p>\n","site":{"data":{}},"excerpt":"","more":"<p>导火索: 今天后端上线，上线脚本执行到数据库更改的时候卡住了(公司开发的devops,web操作)，登录机器查看ansible进程是在的，证明SQL 执行出错了。之前我很少接触mysql，全是部署增删改查，多表查询都少用，所以这次是一边Google一边查找原因。</p>\n<p>首先，这次数据库修改一共有四处，前三个都已经执行完成，就是最后一个加字段的没有成功。</p>\n<p><strong>排查过程</strong></p>\n<ol>\n<li><p>查看表大小，确认不是因为表大导致执行时间过长。<br> 其实这个再上线操作的时候又应该有个大概的认识，比如这个表功能大概是多少行，属于哪个工程等等，如果对业务熟悉，应该很快判断的出。<br> <code>相关命令</code></p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 直接查找，可能较慢</div><div class=\"line\">select count(id) from table_name; </div><div class=\"line\">// 查找information_schema中的信息</div><div class=\"line\">select * from information_schema.TABLES </div><div class=\"line\">    where information_schema.TABLES.TABLE_SCHEMA=&apos;databasename&apos;</div><div class=\"line\">    and information_schema.TABLES.TABLE_NAME=&apos;tablename&apos;\\G</div></pre></td></tr></table></figure>\n</li>\n<li><p>如果不是表太大，可以看下正在进行的事务<br> 了解事务的工作模式很重要，首先要知道自己的MySQL隔离级别，及每种隔离级别的特点。参考<a href=\"https://tech.meituan.com/innodb-lock.html\" target=\"_blank\" rel=\"external\">美团点评团队的分享</a> 我们是使用的 已提交读（Read committed）</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 查看当前隔离级别</div><div class=\"line\">SELECT @@session.tx_isolation;</div><div class=\"line\">// 查看当前执行的事务</div><div class=\"line\">SELECT * FROM information_schema.INNODB_TRX;</div></pre></td></tr></table></figure>\n<p> 当时主库加上字段之后，从库一直加不上字段就是因为有另一个事务一直没有提交，导致表一直是只读状态，阻塞了。</p>\n</li>\n</ol>\n<p>select * from information_schema.TABLES<br>        where information_schema.TABLES.TABLE_SCHEMA=’online_medical’<br>        and information_schema.TABLES.TABLE_NAME=’api_familydoctorservice’\\G</p>\n"},{"title":"MySQL使用记录","date":"2017-07-13T08:02:23.000Z","_content":"\n数据库现在为止我只接触过MySQL，MySQL自从被oracle收购后，就衍生出三大阵营，Drizzle、MariaDB和Percona Server（包括XtraDB引擎），第一个没接触过不太了解，MariaDB与percona又有很多相似点，比如都支持XtraDB（innodb加强版）\n看看两者优缺点：\n\n- Percona团队的最终声明是“Percona Server是由Oracle发布的最接近官方MySQL Enterprise发行版的版本”，因此与其他更改了大量基本核心MySQL代码的分支有所区别。\n- XtraDB 存储引擎是完全的向下兼容，在 MariaDB 中，XtraDB 存储引擎被标识为”ENGINE=InnoDB”，这个与 InnoDB 是一样的，所以你可以直接用XtraDB 替换掉 InnoDB 而不会产生任何问题。\n- MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，10.0.9版起使用XtraDB（名称代号为Aria）来代替MySQL的InnoDB。\n- Percona Server的一个缺点是他们自己管理代码，不接受外部开发人员的贡献，以这种方式确保他们对产品中所包含功能的控制。\n\n总之，二者目前为止没有拉开什么差距，所以可以自由选择。\n阿里使用的percona 但是Google使用的MariaDB。。。\n\n我也是用的percona。下边以它为例说明。\n\n数据库也是个比较大的技术栈，三言两语说不完，工具书都特别厚，我写这篇文章的目的无非就是想给自己一个查看SQL语句的地方，见识比较少，有错误我肯定不是故意的，全文参考这个[技能图谱](http://lib.csdn.net/maquealone/352262/chart/MySQL)\n\n# 安装部署\n\n直接yum就可以，国内有清华源，中科院源，比较快，官网下载简直是灾难。\n可以写ansible-playbook，没有难点不多说。\n\n\n## 配置文件详解\n\n```\n[mysqld3306]\n\n# 为PXC定制\nbinlog_format=ROW\ndefault-storage-engine         = InnoDB\ninnodb_autoinc_lock_mode=2\n\n\n# 绑定地址之后只能通过内部网络访问\n\nbind-address=10.******\n\nauto-increment-increment = 2\nauto-increment-offset = 1\n\n# 使用 xtrabackup-v2 必须制定datadir, 因为操作可能直接对 datadir进行\ndatadir=/home/mysql/3306/data\n\n# http://www.percona.com/doc/percona-xtrabackup/2.2/innobackupex/privileges.html#permissions-and-privileges-needed\n# 权限的配置\n# xtrapbackup在Donor上执行，因此只需localhost的权限\n\n\n\n# 约定:\nserver-id = 1\n\n\n# wsrep模式不依赖于GTID\n# 开启GTID\n# enforce_gtid_consistency=1\n# gtid_mode=on\n\n# 即便临时作为Slave，也记录自己的binlog\nlog-slave-updates=1\n\n# master_info_repository=TABLE\n# relay_log_info_repository=TABLE\n\n# GENERAL #\nuser                           = mysql\nport                           = 3306\nsocket                         = /home/mysql/3306/mysql.sock\npid-file                       = /home/mysql/3306/mysql.pid\n\n# MyISAM #\nkey-buffer-size                = 32M\nmyisam-recover                 = FORCE,BACKUP\n\n\nft-min-word-len = 4\nevent-scheduler = 0\n\n# SAFETY #\nmax-allowed-packet             = 16M\n\nskip-name-resolve\nmax_connections = 2000\nmax_connect_errors = 30\n\nback-log = 500\n\ncharacter-set-client-handshake = 1\ncharacter-set-server = utf8mb4\ncollation-server = utf8mb4_unicode_ci\n\n#character-set-client-handshake=1\n#character-set-client=utf8\n#character-set-server=utf8\n#collation-server=utf8_general_ci\n\n\n\n#key-buffer-size = 256M\ntable-open-cache = 2048\nmax-allowed-packet = 2048M\nslave-skip-errors = all                       #Skip duplicated key\nsort-buffer-size = 4M\njoin-buffer-size = 8M\nthread-cache-size = 50\nconcurrent-insert = 2\n\nthread-stack = 192K\nnet-buffer-length = 8K\nread-buffer-size = 256K\nread-rnd-buffer-size = 16M\nbulk-insert-buffer-size = 64M\n\n# 采用thread pool来处理连接\nthread_handling=pool-of-threads\n\n\nsql-mode                       = STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_AUTO_VALUE_ON_ZERO,NO_ENGINE_SUBSTITUTION,ONLY_FULL_GROUP_BY\nsysdate-is-now                 = 1\ninnodb                         = FORCE\ninnodb-strict-mode             = 1\n\n\n# BINARY LOGGING #\nlog-bin                        = /home/mysql/3306/data/mysql-bin\nexpire-logs-days               = 5\n# LOGGING #\n# log-output=file 默认就是FILE\nlog-error                      = /home/mysql/3306/data/mysql-error.log\nlong-query-time = 0.3\n# log-queries-not-using-indexes  = 1\nslow-query-log                 = 1\nslow-query-log-file            = /home/mysql/3306/data/mysql-slow.log\n\n# 默认为0(MySQL不控制binlog的输出)\n# sync-binlog                    = 1\n\n# CACHES AND LIMITS #\n\ntmp-table-size                 = 32M\nmax-heap-table-size            = 32M\n\n# 频繁修改的表不适合做query-cache, 否则反而影响效率\nquery-cache-type               = 0\nquery-cache-size               = 0\n# query-cache-limit = 2M\n# query-cache-min-res-unit = 512\n\nthread-cache-size              = 100\nopen-files-limit               = 65535\ntable-definition-cache         = 1024\ntable-open-cache               = 4096\n\n# INNODB #\ninnodb-flush-method            = O_DIRECT\ninnodb-log-files-in-group      = 2\n\n# innodb-file-per-table = 1设置之后， 下面的配置基本失效\ninnodb_data_file_path = ibdata1:10M:autoextend\ninnodb-thread-concurrency = 32\ninnodb-log-file-size           = 256M\ninnodb-flush-log-at-trx-commit = 2\ninnodb-file-per-table          = 1\n# 内存: 全部内存*0.7\ninnodb-buffer-pool-size = 25G\n\nperformance-schema = 0\nnet-read-timeout = 60\n\n# innodb-open-files 在MySQL5.6 auto-sized\n# 来自May2\ninnodb-rollback-on-timeout\ninnodb-status-file = 1\n\n\n# http://dev.mysql.com/doc/refman/5.6/en/innodb-performance-multiple_io_threads.html\n# http://zhan.renren.com/formysql?tagId=3942&checked=true\n# 从MySQL 5.5\n# innodb_file_io_threads = 4\ninnodb-read-io-threads = 16\ninnodb-write-io-threads = 8\n\ninnodb-io-capacity = 2000\n# innodb-stats-update-need-lock = 0 # MySQL 5.6中无效\n# innodb-stats-auto-update = 0\ninnodb-old-blocks-pct = 75\n# innodb-adaptive-flushing-method = \"estimate\"\n# innodb-adaptive-flushing = 1\n\n# https://www.facebook.com/notes/mysql-at-facebook/repeatable-read-versus-read-committed-for-innodb/244956410932\n# READ-COMMITTED 每次QUERY都要求调用: read_view_open_now, 而REPEATABLE-READ每次Transaction中只要求一次\n# REPEATABLE-READ 会导致读写不同步\ntransaction-isolation = READ-COMMITTED\n\ninnodb-sync-spin-loops = 100\ninnodb-spin-wait-delay = 30\n\ninnodb-file-format = \"Barracuda\"\ninnodb-file-format-max = \"Barracuda\"\n```\n\n# 基本操作\n> 日常操作无非就是增删改查。也可分为库层面操作，与表层面操作。\n\n## 库操作\n\n一般库操作很少，没有什么花样\n```\n# 创建数据库\ncreate database online_database;        \n# 查看数据库\nshow databases;  \n# 查看数据库信息    \nshow create database online_database;\n# 修改数据库的编码，可使用上一条语句查看是否修改成功\nalter database online_database default character set gbk collate gbk_bin;      \n# 删除数据库\ndrop database online_database;\n```\n\n","source":"_posts/MySQL使用记录.md","raw":"---\ntitle: MySQL使用记录\ndate: 2017-07-13 16:02:23\ntags: mysql \ncategories: 数据库\n---\n\n数据库现在为止我只接触过MySQL，MySQL自从被oracle收购后，就衍生出三大阵营，Drizzle、MariaDB和Percona Server（包括XtraDB引擎），第一个没接触过不太了解，MariaDB与percona又有很多相似点，比如都支持XtraDB（innodb加强版）\n看看两者优缺点：\n\n- Percona团队的最终声明是“Percona Server是由Oracle发布的最接近官方MySQL Enterprise发行版的版本”，因此与其他更改了大量基本核心MySQL代码的分支有所区别。\n- XtraDB 存储引擎是完全的向下兼容，在 MariaDB 中，XtraDB 存储引擎被标识为”ENGINE=InnoDB”，这个与 InnoDB 是一样的，所以你可以直接用XtraDB 替换掉 InnoDB 而不会产生任何问题。\n- MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，10.0.9版起使用XtraDB（名称代号为Aria）来代替MySQL的InnoDB。\n- Percona Server的一个缺点是他们自己管理代码，不接受外部开发人员的贡献，以这种方式确保他们对产品中所包含功能的控制。\n\n总之，二者目前为止没有拉开什么差距，所以可以自由选择。\n阿里使用的percona 但是Google使用的MariaDB。。。\n\n我也是用的percona。下边以它为例说明。\n\n数据库也是个比较大的技术栈，三言两语说不完，工具书都特别厚，我写这篇文章的目的无非就是想给自己一个查看SQL语句的地方，见识比较少，有错误我肯定不是故意的，全文参考这个[技能图谱](http://lib.csdn.net/maquealone/352262/chart/MySQL)\n\n# 安装部署\n\n直接yum就可以，国内有清华源，中科院源，比较快，官网下载简直是灾难。\n可以写ansible-playbook，没有难点不多说。\n\n\n## 配置文件详解\n\n```\n[mysqld3306]\n\n# 为PXC定制\nbinlog_format=ROW\ndefault-storage-engine         = InnoDB\ninnodb_autoinc_lock_mode=2\n\n\n# 绑定地址之后只能通过内部网络访问\n\nbind-address=10.******\n\nauto-increment-increment = 2\nauto-increment-offset = 1\n\n# 使用 xtrabackup-v2 必须制定datadir, 因为操作可能直接对 datadir进行\ndatadir=/home/mysql/3306/data\n\n# http://www.percona.com/doc/percona-xtrabackup/2.2/innobackupex/privileges.html#permissions-and-privileges-needed\n# 权限的配置\n# xtrapbackup在Donor上执行，因此只需localhost的权限\n\n\n\n# 约定:\nserver-id = 1\n\n\n# wsrep模式不依赖于GTID\n# 开启GTID\n# enforce_gtid_consistency=1\n# gtid_mode=on\n\n# 即便临时作为Slave，也记录自己的binlog\nlog-slave-updates=1\n\n# master_info_repository=TABLE\n# relay_log_info_repository=TABLE\n\n# GENERAL #\nuser                           = mysql\nport                           = 3306\nsocket                         = /home/mysql/3306/mysql.sock\npid-file                       = /home/mysql/3306/mysql.pid\n\n# MyISAM #\nkey-buffer-size                = 32M\nmyisam-recover                 = FORCE,BACKUP\n\n\nft-min-word-len = 4\nevent-scheduler = 0\n\n# SAFETY #\nmax-allowed-packet             = 16M\n\nskip-name-resolve\nmax_connections = 2000\nmax_connect_errors = 30\n\nback-log = 500\n\ncharacter-set-client-handshake = 1\ncharacter-set-server = utf8mb4\ncollation-server = utf8mb4_unicode_ci\n\n#character-set-client-handshake=1\n#character-set-client=utf8\n#character-set-server=utf8\n#collation-server=utf8_general_ci\n\n\n\n#key-buffer-size = 256M\ntable-open-cache = 2048\nmax-allowed-packet = 2048M\nslave-skip-errors = all                       #Skip duplicated key\nsort-buffer-size = 4M\njoin-buffer-size = 8M\nthread-cache-size = 50\nconcurrent-insert = 2\n\nthread-stack = 192K\nnet-buffer-length = 8K\nread-buffer-size = 256K\nread-rnd-buffer-size = 16M\nbulk-insert-buffer-size = 64M\n\n# 采用thread pool来处理连接\nthread_handling=pool-of-threads\n\n\nsql-mode                       = STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_AUTO_VALUE_ON_ZERO,NO_ENGINE_SUBSTITUTION,ONLY_FULL_GROUP_BY\nsysdate-is-now                 = 1\ninnodb                         = FORCE\ninnodb-strict-mode             = 1\n\n\n# BINARY LOGGING #\nlog-bin                        = /home/mysql/3306/data/mysql-bin\nexpire-logs-days               = 5\n# LOGGING #\n# log-output=file 默认就是FILE\nlog-error                      = /home/mysql/3306/data/mysql-error.log\nlong-query-time = 0.3\n# log-queries-not-using-indexes  = 1\nslow-query-log                 = 1\nslow-query-log-file            = /home/mysql/3306/data/mysql-slow.log\n\n# 默认为0(MySQL不控制binlog的输出)\n# sync-binlog                    = 1\n\n# CACHES AND LIMITS #\n\ntmp-table-size                 = 32M\nmax-heap-table-size            = 32M\n\n# 频繁修改的表不适合做query-cache, 否则反而影响效率\nquery-cache-type               = 0\nquery-cache-size               = 0\n# query-cache-limit = 2M\n# query-cache-min-res-unit = 512\n\nthread-cache-size              = 100\nopen-files-limit               = 65535\ntable-definition-cache         = 1024\ntable-open-cache               = 4096\n\n# INNODB #\ninnodb-flush-method            = O_DIRECT\ninnodb-log-files-in-group      = 2\n\n# innodb-file-per-table = 1设置之后， 下面的配置基本失效\ninnodb_data_file_path = ibdata1:10M:autoextend\ninnodb-thread-concurrency = 32\ninnodb-log-file-size           = 256M\ninnodb-flush-log-at-trx-commit = 2\ninnodb-file-per-table          = 1\n# 内存: 全部内存*0.7\ninnodb-buffer-pool-size = 25G\n\nperformance-schema = 0\nnet-read-timeout = 60\n\n# innodb-open-files 在MySQL5.6 auto-sized\n# 来自May2\ninnodb-rollback-on-timeout\ninnodb-status-file = 1\n\n\n# http://dev.mysql.com/doc/refman/5.6/en/innodb-performance-multiple_io_threads.html\n# http://zhan.renren.com/formysql?tagId=3942&checked=true\n# 从MySQL 5.5\n# innodb_file_io_threads = 4\ninnodb-read-io-threads = 16\ninnodb-write-io-threads = 8\n\ninnodb-io-capacity = 2000\n# innodb-stats-update-need-lock = 0 # MySQL 5.6中无效\n# innodb-stats-auto-update = 0\ninnodb-old-blocks-pct = 75\n# innodb-adaptive-flushing-method = \"estimate\"\n# innodb-adaptive-flushing = 1\n\n# https://www.facebook.com/notes/mysql-at-facebook/repeatable-read-versus-read-committed-for-innodb/244956410932\n# READ-COMMITTED 每次QUERY都要求调用: read_view_open_now, 而REPEATABLE-READ每次Transaction中只要求一次\n# REPEATABLE-READ 会导致读写不同步\ntransaction-isolation = READ-COMMITTED\n\ninnodb-sync-spin-loops = 100\ninnodb-spin-wait-delay = 30\n\ninnodb-file-format = \"Barracuda\"\ninnodb-file-format-max = \"Barracuda\"\n```\n\n# 基本操作\n> 日常操作无非就是增删改查。也可分为库层面操作，与表层面操作。\n\n## 库操作\n\n一般库操作很少，没有什么花样\n```\n# 创建数据库\ncreate database online_database;        \n# 查看数据库\nshow databases;  \n# 查看数据库信息    \nshow create database online_database;\n# 修改数据库的编码，可使用上一条语句查看是否修改成功\nalter database online_database default character set gbk collate gbk_bin;      \n# 删除数据库\ndrop database online_database;\n```\n\n","slug":"MySQL使用记录","published":1,"updated":"2017-08-03T07:37:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5j000t8tzzhrf1ut1r","content":"<p>数据库现在为止我只接触过MySQL，MySQL自从被oracle收购后，就衍生出三大阵营，Drizzle、MariaDB和Percona Server（包括XtraDB引擎），第一个没接触过不太了解，MariaDB与percona又有很多相似点，比如都支持XtraDB（innodb加强版）<br>看看两者优缺点：</p>\n<ul>\n<li>Percona团队的最终声明是“Percona Server是由Oracle发布的最接近官方MySQL Enterprise发行版的版本”，因此与其他更改了大量基本核心MySQL代码的分支有所区别。</li>\n<li>XtraDB 存储引擎是完全的向下兼容，在 MariaDB 中，XtraDB 存储引擎被标识为”ENGINE=InnoDB”，这个与 InnoDB 是一样的，所以你可以直接用XtraDB 替换掉 InnoDB 而不会产生任何问题。</li>\n<li>MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，10.0.9版起使用XtraDB（名称代号为Aria）来代替MySQL的InnoDB。</li>\n<li>Percona Server的一个缺点是他们自己管理代码，不接受外部开发人员的贡献，以这种方式确保他们对产品中所包含功能的控制。</li>\n</ul>\n<p>总之，二者目前为止没有拉开什么差距，所以可以自由选择。<br>阿里使用的percona 但是Google使用的MariaDB。。。</p>\n<p>我也是用的percona。下边以它为例说明。</p>\n<p>数据库也是个比较大的技术栈，三言两语说不完，工具书都特别厚，我写这篇文章的目的无非就是想给自己一个查看SQL语句的地方，见识比较少，有错误我肯定不是故意的，全文参考这个<a href=\"http://lib.csdn.net/maquealone/352262/chart/MySQL\" target=\"_blank\" rel=\"external\">技能图谱</a></p>\n<h1 id=\"安装部署\"><a href=\"#安装部署\" class=\"headerlink\" title=\"安装部署\"></a>安装部署</h1><p>直接yum就可以，国内有清华源，中科院源，比较快，官网下载简直是灾难。<br>可以写ansible-playbook，没有难点不多说。</p>\n<h2 id=\"配置文件详解\"><a href=\"#配置文件详解\" class=\"headerlink\" title=\"配置文件详解\"></a>配置文件详解</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div><div class=\"line\">173</div><div class=\"line\">174</div></pre></td><td class=\"code\"><pre><div class=\"line\">[mysqld3306]</div><div class=\"line\"></div><div class=\"line\"># 为PXC定制</div><div class=\"line\">binlog_format=ROW</div><div class=\"line\">default-storage-engine         = InnoDB</div><div class=\"line\">innodb_autoinc_lock_mode=2</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># 绑定地址之后只能通过内部网络访问</div><div class=\"line\"></div><div class=\"line\">bind-address=10.******</div><div class=\"line\"></div><div class=\"line\">auto-increment-increment = 2</div><div class=\"line\">auto-increment-offset = 1</div><div class=\"line\"></div><div class=\"line\"># 使用 xtrabackup-v2 必须制定datadir, 因为操作可能直接对 datadir进行</div><div class=\"line\">datadir=/home/mysql/3306/data</div><div class=\"line\"></div><div class=\"line\"># http://www.percona.com/doc/percona-xtrabackup/2.2/innobackupex/privileges.html#permissions-and-privileges-needed</div><div class=\"line\"># 权限的配置</div><div class=\"line\"># xtrapbackup在Donor上执行，因此只需localhost的权限</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># 约定:</div><div class=\"line\">server-id = 1</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># wsrep模式不依赖于GTID</div><div class=\"line\"># 开启GTID</div><div class=\"line\"># enforce_gtid_consistency=1</div><div class=\"line\"># gtid_mode=on</div><div class=\"line\"></div><div class=\"line\"># 即便临时作为Slave，也记录自己的binlog</div><div class=\"line\">log-slave-updates=1</div><div class=\"line\"></div><div class=\"line\"># master_info_repository=TABLE</div><div class=\"line\"># relay_log_info_repository=TABLE</div><div class=\"line\"></div><div class=\"line\"># GENERAL #</div><div class=\"line\">user                           = mysql</div><div class=\"line\">port                           = 3306</div><div class=\"line\">socket                         = /home/mysql/3306/mysql.sock</div><div class=\"line\">pid-file                       = /home/mysql/3306/mysql.pid</div><div class=\"line\"></div><div class=\"line\"># MyISAM #</div><div class=\"line\">key-buffer-size                = 32M</div><div class=\"line\">myisam-recover                 = FORCE,BACKUP</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">ft-min-word-len = 4</div><div class=\"line\">event-scheduler = 0</div><div class=\"line\"></div><div class=\"line\"># SAFETY #</div><div class=\"line\">max-allowed-packet             = 16M</div><div class=\"line\"></div><div class=\"line\">skip-name-resolve</div><div class=\"line\">max_connections = 2000</div><div class=\"line\">max_connect_errors = 30</div><div class=\"line\"></div><div class=\"line\">back-log = 500</div><div class=\"line\"></div><div class=\"line\">character-set-client-handshake = 1</div><div class=\"line\">character-set-server = utf8mb4</div><div class=\"line\">collation-server = utf8mb4_unicode_ci</div><div class=\"line\"></div><div class=\"line\">#character-set-client-handshake=1</div><div class=\"line\">#character-set-client=utf8</div><div class=\"line\">#character-set-server=utf8</div><div class=\"line\">#collation-server=utf8_general_ci</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">#key-buffer-size = 256M</div><div class=\"line\">table-open-cache = 2048</div><div class=\"line\">max-allowed-packet = 2048M</div><div class=\"line\">slave-skip-errors = all                       #Skip duplicated key</div><div class=\"line\">sort-buffer-size = 4M</div><div class=\"line\">join-buffer-size = 8M</div><div class=\"line\">thread-cache-size = 50</div><div class=\"line\">concurrent-insert = 2</div><div class=\"line\"></div><div class=\"line\">thread-stack = 192K</div><div class=\"line\">net-buffer-length = 8K</div><div class=\"line\">read-buffer-size = 256K</div><div class=\"line\">read-rnd-buffer-size = 16M</div><div class=\"line\">bulk-insert-buffer-size = 64M</div><div class=\"line\"></div><div class=\"line\"># 采用thread pool来处理连接</div><div class=\"line\">thread_handling=pool-of-threads</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">sql-mode                       = STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_AUTO_VALUE_ON_ZERO,NO_ENGINE_SUBSTITUTION,ONLY_FULL_GROUP_BY</div><div class=\"line\">sysdate-is-now                 = 1</div><div class=\"line\">innodb                         = FORCE</div><div class=\"line\">innodb-strict-mode             = 1</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># BINARY LOGGING #</div><div class=\"line\">log-bin                        = /home/mysql/3306/data/mysql-bin</div><div class=\"line\">expire-logs-days               = 5</div><div class=\"line\"># LOGGING #</div><div class=\"line\"># log-output=file 默认就是FILE</div><div class=\"line\">log-error                      = /home/mysql/3306/data/mysql-error.log</div><div class=\"line\">long-query-time = 0.3</div><div class=\"line\"># log-queries-not-using-indexes  = 1</div><div class=\"line\">slow-query-log                 = 1</div><div class=\"line\">slow-query-log-file            = /home/mysql/3306/data/mysql-slow.log</div><div class=\"line\"></div><div class=\"line\"># 默认为0(MySQL不控制binlog的输出)</div><div class=\"line\"># sync-binlog                    = 1</div><div class=\"line\"></div><div class=\"line\"># CACHES AND LIMITS #</div><div class=\"line\"></div><div class=\"line\">tmp-table-size                 = 32M</div><div class=\"line\">max-heap-table-size            = 32M</div><div class=\"line\"></div><div class=\"line\"># 频繁修改的表不适合做query-cache, 否则反而影响效率</div><div class=\"line\">query-cache-type               = 0</div><div class=\"line\">query-cache-size               = 0</div><div class=\"line\"># query-cache-limit = 2M</div><div class=\"line\"># query-cache-min-res-unit = 512</div><div class=\"line\"></div><div class=\"line\">thread-cache-size              = 100</div><div class=\"line\">open-files-limit               = 65535</div><div class=\"line\">table-definition-cache         = 1024</div><div class=\"line\">table-open-cache               = 4096</div><div class=\"line\"></div><div class=\"line\"># INNODB #</div><div class=\"line\">innodb-flush-method            = O_DIRECT</div><div class=\"line\">innodb-log-files-in-group      = 2</div><div class=\"line\"></div><div class=\"line\"># innodb-file-per-table = 1设置之后， 下面的配置基本失效</div><div class=\"line\">innodb_data_file_path = ibdata1:10M:autoextend</div><div class=\"line\">innodb-thread-concurrency = 32</div><div class=\"line\">innodb-log-file-size           = 256M</div><div class=\"line\">innodb-flush-log-at-trx-commit = 2</div><div class=\"line\">innodb-file-per-table          = 1</div><div class=\"line\"># 内存: 全部内存*0.7</div><div class=\"line\">innodb-buffer-pool-size = 25G</div><div class=\"line\"></div><div class=\"line\">performance-schema = 0</div><div class=\"line\">net-read-timeout = 60</div><div class=\"line\"></div><div class=\"line\"># innodb-open-files 在MySQL5.6 auto-sized</div><div class=\"line\"># 来自May2</div><div class=\"line\">innodb-rollback-on-timeout</div><div class=\"line\">innodb-status-file = 1</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># http://dev.mysql.com/doc/refman/5.6/en/innodb-performance-multiple_io_threads.html</div><div class=\"line\"># http://zhan.renren.com/formysql?tagId=3942&amp;checked=true</div><div class=\"line\"># 从MySQL 5.5</div><div class=\"line\"># innodb_file_io_threads = 4</div><div class=\"line\">innodb-read-io-threads = 16</div><div class=\"line\">innodb-write-io-threads = 8</div><div class=\"line\"></div><div class=\"line\">innodb-io-capacity = 2000</div><div class=\"line\"># innodb-stats-update-need-lock = 0 # MySQL 5.6中无效</div><div class=\"line\"># innodb-stats-auto-update = 0</div><div class=\"line\">innodb-old-blocks-pct = 75</div><div class=\"line\"># innodb-adaptive-flushing-method = &quot;estimate&quot;</div><div class=\"line\"># innodb-adaptive-flushing = 1</div><div class=\"line\"></div><div class=\"line\"># https://www.facebook.com/notes/mysql-at-facebook/repeatable-read-versus-read-committed-for-innodb/244956410932</div><div class=\"line\"># READ-COMMITTED 每次QUERY都要求调用: read_view_open_now, 而REPEATABLE-READ每次Transaction中只要求一次</div><div class=\"line\"># REPEATABLE-READ 会导致读写不同步</div><div class=\"line\">transaction-isolation = READ-COMMITTED</div><div class=\"line\"></div><div class=\"line\">innodb-sync-spin-loops = 100</div><div class=\"line\">innodb-spin-wait-delay = 30</div><div class=\"line\"></div><div class=\"line\">innodb-file-format = &quot;Barracuda&quot;</div><div class=\"line\">innodb-file-format-max = &quot;Barracuda&quot;</div></pre></td></tr></table></figure>\n<h1 id=\"基本操作\"><a href=\"#基本操作\" class=\"headerlink\" title=\"基本操作\"></a>基本操作</h1><blockquote>\n<p>日常操作无非就是增删改查。也可分为库层面操作，与表层面操作。</p>\n</blockquote>\n<h2 id=\"库操作\"><a href=\"#库操作\" class=\"headerlink\" title=\"库操作\"></a>库操作</h2><p>一般库操作很少，没有什么花样<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 创建数据库</div><div class=\"line\">create database online_database;        </div><div class=\"line\"># 查看数据库</div><div class=\"line\">show databases;  </div><div class=\"line\"># 查看数据库信息    </div><div class=\"line\">show create database online_database;</div><div class=\"line\"># 修改数据库的编码，可使用上一条语句查看是否修改成功</div><div class=\"line\">alter database online_database default character set gbk collate gbk_bin;      </div><div class=\"line\"># 删除数据库</div><div class=\"line\">drop database online_database;</div></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<p>数据库现在为止我只接触过MySQL，MySQL自从被oracle收购后，就衍生出三大阵营，Drizzle、MariaDB和Percona Server（包括XtraDB引擎），第一个没接触过不太了解，MariaDB与percona又有很多相似点，比如都支持XtraDB（innodb加强版）<br>看看两者优缺点：</p>\n<ul>\n<li>Percona团队的最终声明是“Percona Server是由Oracle发布的最接近官方MySQL Enterprise发行版的版本”，因此与其他更改了大量基本核心MySQL代码的分支有所区别。</li>\n<li>XtraDB 存储引擎是完全的向下兼容，在 MariaDB 中，XtraDB 存储引擎被标识为”ENGINE=InnoDB”，这个与 InnoDB 是一样的，所以你可以直接用XtraDB 替换掉 InnoDB 而不会产生任何问题。</li>\n<li>MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，10.0.9版起使用XtraDB（名称代号为Aria）来代替MySQL的InnoDB。</li>\n<li>Percona Server的一个缺点是他们自己管理代码，不接受外部开发人员的贡献，以这种方式确保他们对产品中所包含功能的控制。</li>\n</ul>\n<p>总之，二者目前为止没有拉开什么差距，所以可以自由选择。<br>阿里使用的percona 但是Google使用的MariaDB。。。</p>\n<p>我也是用的percona。下边以它为例说明。</p>\n<p>数据库也是个比较大的技术栈，三言两语说不完，工具书都特别厚，我写这篇文章的目的无非就是想给自己一个查看SQL语句的地方，见识比较少，有错误我肯定不是故意的，全文参考这个<a href=\"http://lib.csdn.net/maquealone/352262/chart/MySQL\" target=\"_blank\" rel=\"external\">技能图谱</a></p>\n<h1 id=\"安装部署\"><a href=\"#安装部署\" class=\"headerlink\" title=\"安装部署\"></a>安装部署</h1><p>直接yum就可以，国内有清华源，中科院源，比较快，官网下载简直是灾难。<br>可以写ansible-playbook，没有难点不多说。</p>\n<h2 id=\"配置文件详解\"><a href=\"#配置文件详解\" class=\"headerlink\" title=\"配置文件详解\"></a>配置文件详解</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div><div class=\"line\">173</div><div class=\"line\">174</div></pre></td><td class=\"code\"><pre><div class=\"line\">[mysqld3306]</div><div class=\"line\"></div><div class=\"line\"># 为PXC定制</div><div class=\"line\">binlog_format=ROW</div><div class=\"line\">default-storage-engine         = InnoDB</div><div class=\"line\">innodb_autoinc_lock_mode=2</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># 绑定地址之后只能通过内部网络访问</div><div class=\"line\"></div><div class=\"line\">bind-address=10.******</div><div class=\"line\"></div><div class=\"line\">auto-increment-increment = 2</div><div class=\"line\">auto-increment-offset = 1</div><div class=\"line\"></div><div class=\"line\"># 使用 xtrabackup-v2 必须制定datadir, 因为操作可能直接对 datadir进行</div><div class=\"line\">datadir=/home/mysql/3306/data</div><div class=\"line\"></div><div class=\"line\"># http://www.percona.com/doc/percona-xtrabackup/2.2/innobackupex/privileges.html#permissions-and-privileges-needed</div><div class=\"line\"># 权限的配置</div><div class=\"line\"># xtrapbackup在Donor上执行，因此只需localhost的权限</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># 约定:</div><div class=\"line\">server-id = 1</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># wsrep模式不依赖于GTID</div><div class=\"line\"># 开启GTID</div><div class=\"line\"># enforce_gtid_consistency=1</div><div class=\"line\"># gtid_mode=on</div><div class=\"line\"></div><div class=\"line\"># 即便临时作为Slave，也记录自己的binlog</div><div class=\"line\">log-slave-updates=1</div><div class=\"line\"></div><div class=\"line\"># master_info_repository=TABLE</div><div class=\"line\"># relay_log_info_repository=TABLE</div><div class=\"line\"></div><div class=\"line\"># GENERAL #</div><div class=\"line\">user                           = mysql</div><div class=\"line\">port                           = 3306</div><div class=\"line\">socket                         = /home/mysql/3306/mysql.sock</div><div class=\"line\">pid-file                       = /home/mysql/3306/mysql.pid</div><div class=\"line\"></div><div class=\"line\"># MyISAM #</div><div class=\"line\">key-buffer-size                = 32M</div><div class=\"line\">myisam-recover                 = FORCE,BACKUP</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">ft-min-word-len = 4</div><div class=\"line\">event-scheduler = 0</div><div class=\"line\"></div><div class=\"line\"># SAFETY #</div><div class=\"line\">max-allowed-packet             = 16M</div><div class=\"line\"></div><div class=\"line\">skip-name-resolve</div><div class=\"line\">max_connections = 2000</div><div class=\"line\">max_connect_errors = 30</div><div class=\"line\"></div><div class=\"line\">back-log = 500</div><div class=\"line\"></div><div class=\"line\">character-set-client-handshake = 1</div><div class=\"line\">character-set-server = utf8mb4</div><div class=\"line\">collation-server = utf8mb4_unicode_ci</div><div class=\"line\"></div><div class=\"line\">#character-set-client-handshake=1</div><div class=\"line\">#character-set-client=utf8</div><div class=\"line\">#character-set-server=utf8</div><div class=\"line\">#collation-server=utf8_general_ci</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">#key-buffer-size = 256M</div><div class=\"line\">table-open-cache = 2048</div><div class=\"line\">max-allowed-packet = 2048M</div><div class=\"line\">slave-skip-errors = all                       #Skip duplicated key</div><div class=\"line\">sort-buffer-size = 4M</div><div class=\"line\">join-buffer-size = 8M</div><div class=\"line\">thread-cache-size = 50</div><div class=\"line\">concurrent-insert = 2</div><div class=\"line\"></div><div class=\"line\">thread-stack = 192K</div><div class=\"line\">net-buffer-length = 8K</div><div class=\"line\">read-buffer-size = 256K</div><div class=\"line\">read-rnd-buffer-size = 16M</div><div class=\"line\">bulk-insert-buffer-size = 64M</div><div class=\"line\"></div><div class=\"line\"># 采用thread pool来处理连接</div><div class=\"line\">thread_handling=pool-of-threads</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">sql-mode                       = STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_AUTO_VALUE_ON_ZERO,NO_ENGINE_SUBSTITUTION,ONLY_FULL_GROUP_BY</div><div class=\"line\">sysdate-is-now                 = 1</div><div class=\"line\">innodb                         = FORCE</div><div class=\"line\">innodb-strict-mode             = 1</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># BINARY LOGGING #</div><div class=\"line\">log-bin                        = /home/mysql/3306/data/mysql-bin</div><div class=\"line\">expire-logs-days               = 5</div><div class=\"line\"># LOGGING #</div><div class=\"line\"># log-output=file 默认就是FILE</div><div class=\"line\">log-error                      = /home/mysql/3306/data/mysql-error.log</div><div class=\"line\">long-query-time = 0.3</div><div class=\"line\"># log-queries-not-using-indexes  = 1</div><div class=\"line\">slow-query-log                 = 1</div><div class=\"line\">slow-query-log-file            = /home/mysql/3306/data/mysql-slow.log</div><div class=\"line\"></div><div class=\"line\"># 默认为0(MySQL不控制binlog的输出)</div><div class=\"line\"># sync-binlog                    = 1</div><div class=\"line\"></div><div class=\"line\"># CACHES AND LIMITS #</div><div class=\"line\"></div><div class=\"line\">tmp-table-size                 = 32M</div><div class=\"line\">max-heap-table-size            = 32M</div><div class=\"line\"></div><div class=\"line\"># 频繁修改的表不适合做query-cache, 否则反而影响效率</div><div class=\"line\">query-cache-type               = 0</div><div class=\"line\">query-cache-size               = 0</div><div class=\"line\"># query-cache-limit = 2M</div><div class=\"line\"># query-cache-min-res-unit = 512</div><div class=\"line\"></div><div class=\"line\">thread-cache-size              = 100</div><div class=\"line\">open-files-limit               = 65535</div><div class=\"line\">table-definition-cache         = 1024</div><div class=\"line\">table-open-cache               = 4096</div><div class=\"line\"></div><div class=\"line\"># INNODB #</div><div class=\"line\">innodb-flush-method            = O_DIRECT</div><div class=\"line\">innodb-log-files-in-group      = 2</div><div class=\"line\"></div><div class=\"line\"># innodb-file-per-table = 1设置之后， 下面的配置基本失效</div><div class=\"line\">innodb_data_file_path = ibdata1:10M:autoextend</div><div class=\"line\">innodb-thread-concurrency = 32</div><div class=\"line\">innodb-log-file-size           = 256M</div><div class=\"line\">innodb-flush-log-at-trx-commit = 2</div><div class=\"line\">innodb-file-per-table          = 1</div><div class=\"line\"># 内存: 全部内存*0.7</div><div class=\"line\">innodb-buffer-pool-size = 25G</div><div class=\"line\"></div><div class=\"line\">performance-schema = 0</div><div class=\"line\">net-read-timeout = 60</div><div class=\"line\"></div><div class=\"line\"># innodb-open-files 在MySQL5.6 auto-sized</div><div class=\"line\"># 来自May2</div><div class=\"line\">innodb-rollback-on-timeout</div><div class=\"line\">innodb-status-file = 1</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># http://dev.mysql.com/doc/refman/5.6/en/innodb-performance-multiple_io_threads.html</div><div class=\"line\"># http://zhan.renren.com/formysql?tagId=3942&amp;checked=true</div><div class=\"line\"># 从MySQL 5.5</div><div class=\"line\"># innodb_file_io_threads = 4</div><div class=\"line\">innodb-read-io-threads = 16</div><div class=\"line\">innodb-write-io-threads = 8</div><div class=\"line\"></div><div class=\"line\">innodb-io-capacity = 2000</div><div class=\"line\"># innodb-stats-update-need-lock = 0 # MySQL 5.6中无效</div><div class=\"line\"># innodb-stats-auto-update = 0</div><div class=\"line\">innodb-old-blocks-pct = 75</div><div class=\"line\"># innodb-adaptive-flushing-method = &quot;estimate&quot;</div><div class=\"line\"># innodb-adaptive-flushing = 1</div><div class=\"line\"></div><div class=\"line\"># https://www.facebook.com/notes/mysql-at-facebook/repeatable-read-versus-read-committed-for-innodb/244956410932</div><div class=\"line\"># READ-COMMITTED 每次QUERY都要求调用: read_view_open_now, 而REPEATABLE-READ每次Transaction中只要求一次</div><div class=\"line\"># REPEATABLE-READ 会导致读写不同步</div><div class=\"line\">transaction-isolation = READ-COMMITTED</div><div class=\"line\"></div><div class=\"line\">innodb-sync-spin-loops = 100</div><div class=\"line\">innodb-spin-wait-delay = 30</div><div class=\"line\"></div><div class=\"line\">innodb-file-format = &quot;Barracuda&quot;</div><div class=\"line\">innodb-file-format-max = &quot;Barracuda&quot;</div></pre></td></tr></table></figure>\n<h1 id=\"基本操作\"><a href=\"#基本操作\" class=\"headerlink\" title=\"基本操作\"></a>基本操作</h1><blockquote>\n<p>日常操作无非就是增删改查。也可分为库层面操作，与表层面操作。</p>\n</blockquote>\n<h2 id=\"库操作\"><a href=\"#库操作\" class=\"headerlink\" title=\"库操作\"></a>库操作</h2><p>一般库操作很少，没有什么花样<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"># 创建数据库</div><div class=\"line\">create database online_database;        </div><div class=\"line\"># 查看数据库</div><div class=\"line\">show databases;  </div><div class=\"line\"># 查看数据库信息    </div><div class=\"line\">show create database online_database;</div><div class=\"line\"># 修改数据库的编码，可使用上一条语句查看是否修改成功</div><div class=\"line\">alter database online_database default character set gbk collate gbk_bin;      </div><div class=\"line\"># 删除数据库</div><div class=\"line\">drop database online_database;</div></pre></td></tr></table></figure></p>\n"},{"title":"PXE网络引导批量安装操作系统","date":"2016-08-03T07:49:00.000Z","_content":"\n## 前言：\n       一般系统安装方式基本上都是做一个安装盘，然后每个机器都是插上U盘花上20分钟左右时间操作，包括选择引导方式，语言，键盘布局，设定初始root密码等一系列操作。较为繁琐，但是辛苦不是最大的问题，效率才是。\n       这次我们机房迁移一共有三十台机器，每台不算初始化时间，只是安装系统就得很长时间，所以我们选择用PXE网络引导的方式，告别U盘。\n\n## PXE技术分析：\n### 工作过程\n![](http://or2jd66dq.bkt.clouddn.com/pxe%E5%BC%95%E5%AF%BC%E6%B5%81%E7%A8%8B.gif)\n其实就是DHCP+TFTP+FTP三个服务配合操作（FTP也可以用HTTP服务代替 因为我们本次操作的机器HTTP端口被占用所以直接选择FTP）\n\n\n\n## 原理：\n&emsp;&emsp;客户端PXE网卡启动\n从DHCP服务器获得IP\n从TFTP服务器上下载pxelinux.0、default\n根据配置文件default指定的vmlinuz、initrd.img启动系统内核,并下载指定的ks.cfg文件\n跟据ks.cfg去(HTTP/FTP/NFS)服务器下载RPM包并安装系统\n完成安装\n\n## 操作步骤：\n\nDHCP服务器安装配置 \n首先 确认DHCP服务没有安装，\n\n```\nrpm -qa | grep dhcp\n```\n    \n没有安装过就直接yum安装（也要注意同一内网之中有没有别的DHCP服务在运行，避免冲突）\n    \n```\nyum install dhcp*\n```\n    \n然后配置一下 \n    \n```\nvim /etc/dhcp/dhcpd.conf\n```\n\n<img src=\"http://or2jd66dq.bkt.clouddn.com/dhcp_conf.png\" width=\"500\" height=\"400\" alt=\"dhcp_conf\"/>\n\n配置完直接重启 dhcp服务。\n\n    service dhcp restart\n但是我们会看到\n![servie dhcpd start](http://or2jd66dq.bkt.clouddn.com/dhcp_start.png)\n\n这个时候直接运行\n    /usr/sbin/dhcpd \n就OK了(ps -ef 确认下进程是否在)\n![dhcpd状态](http://or2jd66dq.bkt.clouddn.com/ps_dhcp.png)\n\n## TFTP服务安装\n首先确定机器有没有安装TFTP服务\n    rpm -qa | grep tftp\n如果没有直接yum安装\n    yum install tftp*\n然后稍微修改些配置\n    disable 由yes改为no\n    server_args = 加上-u nobody (用户可以是所有人)\n\n/usr/lib/tftpboot 即为文件目录\n\n![tftpd.conf](http://or2jd66dq.bkt.clouddn.com/modify_tftp.png)\n\n服务启动\n    systemctl start tftp\n\n\n## FTP服务安装\n确定ftp服务之前没有安装 \n\n    yum -y install vsftpd \n\n修改一些配置   \n\n    vim /etc/vsftpd/vsftpd.conf   \n\n更改\n    anonymous_enable=YES\n\n这里需要保证anonymous_enable=YES （匿名用户登录开启）\n然后测试ftp服务正常与否    可以找一台内网机器或者本机实验\n![](http://or2jd66dq.bkt.clouddn.com/test_ftp.png)\n如果能用anonymous 免密码登录到ftp 证明服务正常\n\n## 文件拷贝         \n&emsp;&emsp;现在基本服务已经搭建完成了  我们需要准备一下镜像文件等挂载到TFTP 和 FTP服务器上供网络引导的机器读取下载。因为我们上边dhcp.conf中已经写到了 pxe client 要向 TFTP服务器请求的filename pxelinux.0 \n所以我们需要把这个文件拷贝到TFTP文件目录下。\nPXE启动映像文件由syslinux提供，我们只要安装syslinux，就会生成一个pxelinux.0文件，\n\n1. 只需要将 pxelinux.0 这个文件复制到TFTP根目录即可。\n\n        yum install -y syslinux\n        cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/\n\n2. 把我们之前下载好的镜像ISO文件挂载一下，目标路径为ftp服务器文件目录位置\n\n        mount -o loop /soft/CentOS-7-x86_64-Everything-1511.iso /var/ftp/pub/\n\n3. 复制iso 镜像中的/image/pxeboot/initrd.img 和vmlinux 至/var/lib/tftpboot/ 文件夹中\n\n        cp /var/ftp/pub/image/pxeboot/initrd.img /var/lib/tftpboot/\n        cp /var/ftp/pub/image/pxeboot/vmlinux /var/lib/tftpboot/\n\n4. 复制iso 镜像中的/isolinux/*.msg 至/var/lib/tftpboot/ 文件夹中\n    \n        cp /var/ftp/pub/isolinux/*.msg /var/lib/tftpboot/\n\n5. 在/var/lib/tftpboot/ 中新建一个pxelinux.cfg目录\n        \n        mkdir /var/lib/tftpboot/pxelinux.cfg\n\n6. 将iso 镜像中的/isolinux 目录中的isolinux.cfg复制到pxelinux.cfg目录中，同时更改文件名称为default\n        \n        cp /var/ftp/pub/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default\n\n7. 修改default文件\n        \n        vim /var/lib/tftpboot/pxelinux.cfg/default\n\n8. 服务启动\n        \n        systemctl start vsftpd\n\n\n![kickstart_modify](http://or2jd66dq.bkt.clouddn.com/kiclstart_modify.png)\n(如果有kickstart脚本也要在这里说明路径 例如: ks=ftp://10.215.33.12/pub/ks.cfg)\n\n至此文件拷贝完成（别忘了重启三个服务DHCP，TFTP，FTP）\n网络引导已经配置OK 重启客户端服务器的时候只需要进到boot manager中选择pxe网络引导即可。 \n\nkickstart脚本测试完成后会附上\n\n","source":"_posts/PXE网络引导批量安装操作系统.md","raw":"---\ntitle: PXE网络引导批量安装操作系统\ndate: 2016-08-03 15:49:00\ntags: PXE\ncategories: 基础运维\n---\n\n## 前言：\n       一般系统安装方式基本上都是做一个安装盘，然后每个机器都是插上U盘花上20分钟左右时间操作，包括选择引导方式，语言，键盘布局，设定初始root密码等一系列操作。较为繁琐，但是辛苦不是最大的问题，效率才是。\n       这次我们机房迁移一共有三十台机器，每台不算初始化时间，只是安装系统就得很长时间，所以我们选择用PXE网络引导的方式，告别U盘。\n\n## PXE技术分析：\n### 工作过程\n![](http://or2jd66dq.bkt.clouddn.com/pxe%E5%BC%95%E5%AF%BC%E6%B5%81%E7%A8%8B.gif)\n其实就是DHCP+TFTP+FTP三个服务配合操作（FTP也可以用HTTP服务代替 因为我们本次操作的机器HTTP端口被占用所以直接选择FTP）\n\n\n\n## 原理：\n&emsp;&emsp;客户端PXE网卡启动\n从DHCP服务器获得IP\n从TFTP服务器上下载pxelinux.0、default\n根据配置文件default指定的vmlinuz、initrd.img启动系统内核,并下载指定的ks.cfg文件\n跟据ks.cfg去(HTTP/FTP/NFS)服务器下载RPM包并安装系统\n完成安装\n\n## 操作步骤：\n\nDHCP服务器安装配置 \n首先 确认DHCP服务没有安装，\n\n```\nrpm -qa | grep dhcp\n```\n    \n没有安装过就直接yum安装（也要注意同一内网之中有没有别的DHCP服务在运行，避免冲突）\n    \n```\nyum install dhcp*\n```\n    \n然后配置一下 \n    \n```\nvim /etc/dhcp/dhcpd.conf\n```\n\n<img src=\"http://or2jd66dq.bkt.clouddn.com/dhcp_conf.png\" width=\"500\" height=\"400\" alt=\"dhcp_conf\"/>\n\n配置完直接重启 dhcp服务。\n\n    service dhcp restart\n但是我们会看到\n![servie dhcpd start](http://or2jd66dq.bkt.clouddn.com/dhcp_start.png)\n\n这个时候直接运行\n    /usr/sbin/dhcpd \n就OK了(ps -ef 确认下进程是否在)\n![dhcpd状态](http://or2jd66dq.bkt.clouddn.com/ps_dhcp.png)\n\n## TFTP服务安装\n首先确定机器有没有安装TFTP服务\n    rpm -qa | grep tftp\n如果没有直接yum安装\n    yum install tftp*\n然后稍微修改些配置\n    disable 由yes改为no\n    server_args = 加上-u nobody (用户可以是所有人)\n\n/usr/lib/tftpboot 即为文件目录\n\n![tftpd.conf](http://or2jd66dq.bkt.clouddn.com/modify_tftp.png)\n\n服务启动\n    systemctl start tftp\n\n\n## FTP服务安装\n确定ftp服务之前没有安装 \n\n    yum -y install vsftpd \n\n修改一些配置   \n\n    vim /etc/vsftpd/vsftpd.conf   \n\n更改\n    anonymous_enable=YES\n\n这里需要保证anonymous_enable=YES （匿名用户登录开启）\n然后测试ftp服务正常与否    可以找一台内网机器或者本机实验\n![](http://or2jd66dq.bkt.clouddn.com/test_ftp.png)\n如果能用anonymous 免密码登录到ftp 证明服务正常\n\n## 文件拷贝         \n&emsp;&emsp;现在基本服务已经搭建完成了  我们需要准备一下镜像文件等挂载到TFTP 和 FTP服务器上供网络引导的机器读取下载。因为我们上边dhcp.conf中已经写到了 pxe client 要向 TFTP服务器请求的filename pxelinux.0 \n所以我们需要把这个文件拷贝到TFTP文件目录下。\nPXE启动映像文件由syslinux提供，我们只要安装syslinux，就会生成一个pxelinux.0文件，\n\n1. 只需要将 pxelinux.0 这个文件复制到TFTP根目录即可。\n\n        yum install -y syslinux\n        cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/\n\n2. 把我们之前下载好的镜像ISO文件挂载一下，目标路径为ftp服务器文件目录位置\n\n        mount -o loop /soft/CentOS-7-x86_64-Everything-1511.iso /var/ftp/pub/\n\n3. 复制iso 镜像中的/image/pxeboot/initrd.img 和vmlinux 至/var/lib/tftpboot/ 文件夹中\n\n        cp /var/ftp/pub/image/pxeboot/initrd.img /var/lib/tftpboot/\n        cp /var/ftp/pub/image/pxeboot/vmlinux /var/lib/tftpboot/\n\n4. 复制iso 镜像中的/isolinux/*.msg 至/var/lib/tftpboot/ 文件夹中\n    \n        cp /var/ftp/pub/isolinux/*.msg /var/lib/tftpboot/\n\n5. 在/var/lib/tftpboot/ 中新建一个pxelinux.cfg目录\n        \n        mkdir /var/lib/tftpboot/pxelinux.cfg\n\n6. 将iso 镜像中的/isolinux 目录中的isolinux.cfg复制到pxelinux.cfg目录中，同时更改文件名称为default\n        \n        cp /var/ftp/pub/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default\n\n7. 修改default文件\n        \n        vim /var/lib/tftpboot/pxelinux.cfg/default\n\n8. 服务启动\n        \n        systemctl start vsftpd\n\n\n![kickstart_modify](http://or2jd66dq.bkt.clouddn.com/kiclstart_modify.png)\n(如果有kickstart脚本也要在这里说明路径 例如: ks=ftp://10.215.33.12/pub/ks.cfg)\n\n至此文件拷贝完成（别忘了重启三个服务DHCP，TFTP，FTP）\n网络引导已经配置OK 重启客户端服务器的时候只需要进到boot manager中选择pxe网络引导即可。 \n\nkickstart脚本测试完成后会附上\n\n","slug":"PXE网络引导批量安装操作系统","published":1,"updated":"2017-08-04T03:40:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5k000v8tzzht7mjw6n","content":"<h2 id=\"前言\"><a href=\"#前言：\" class=\"headerlink\" title=\"前言：\"></a>前言：</h2><pre><code>一般系统安装方式基本上都是做一个安装盘，然后每个机器都是插上U盘花上20分钟左右时间操作，包括选择引导方式，语言，键盘布局，设定初始root密码等一系列操作。较为繁琐，但是辛苦不是最大的问题，效率才是。\n这次我们机房迁移一共有三十台机器，每台不算初始化时间，只是安装系统就得很长时间，所以我们选择用PXE网络引导的方式，告别U盘。\n</code></pre><h2 id=\"pxe技术分析\"><a href=\"#PXE技术分析：\" class=\"headerlink\" title=\"PXE技术分析：\"></a>PXE技术分析：</h2><h3 id=\"工作过程\"><a href=\"#工作过程\" class=\"headerlink\" title=\"工作过程\"></a>工作过程</h3><p><img src=\"http://or2jd66dq.bkt.clouddn.com/pxe%E5%BC%95%E5%AF%BC%E6%B5%81%E7%A8%8B.gif\" alt=\"\"><br>其实就是DHCP+TFTP+FTP三个服务配合操作（FTP也可以用HTTP服务代替 因为我们本次操作的机器HTTP端口被占用所以直接选择FTP）</p>\n<h2 id=\"原理\"><a href=\"#原理：\" class=\"headerlink\" title=\"原理：\"></a>原理：</h2><p>&emsp;&emsp;客户端PXE网卡启动<br>从DHCP服务器获得IP<br>从TFTP服务器上下载pxelinux.0、default<br>根据配置文件default指定的vmlinuz、initrd.img启动系统内核,并下载指定的ks.cfg文件<br>跟据ks.cfg去(HTTP/FTP/NFS)服务器下载RPM包并安装系统<br>完成安装</p>\n<h2 id=\"操作步骤\"><a href=\"#操作步骤：\" class=\"headerlink\" title=\"操作步骤：\"></a>操作步骤：</h2><p>DHCP服务器安装配置<br>首先 确认DHCP服务没有安装，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rpm -qa | grep dhcp</div></pre></td></tr></table></figure>\n<p>没有安装过就直接yum安装（也要注意同一内网之中有没有别的DHCP服务在运行，避免冲突）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install dhcp*</div></pre></td></tr></table></figure>\n<p>然后配置一下 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim /etc/dhcp/dhcpd.conf</div></pre></td></tr></table></figure>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/dhcp_conf.png\" width=\"500\" height=\"400\" alt=\"dhcp_conf\"></p>\n<p>配置完直接重启 dhcp服务。</p>\n<pre><code>service dhcp restart\n</code></pre><p>但是我们会看到<br><img src=\"http://or2jd66dq.bkt.clouddn.com/dhcp_start.png\" alt=\"servie dhcpd start\"></p>\n<p>这个时候直接运行<br>    /usr/sbin/dhcpd<br>就OK了(ps -ef 确认下进程是否在)<br><img src=\"http://or2jd66dq.bkt.clouddn.com/ps_dhcp.png\" alt=\"dhcpd状态\"></p>\n<h2 id=\"tftp服务安装\"><a href=\"#TFTP服务安装\" class=\"headerlink\" title=\"TFTP服务安装\"></a>TFTP服务安装</h2><p>首先确定机器有没有安装TFTP服务<br>    rpm -qa | grep tftp<br>如果没有直接yum安装<br>    yum install tftp*<br>然后稍微修改些配置<br>    disable 由yes改为no<br>    server_args = 加上-u nobody (用户可以是所有人)</p>\n<p>/usr/lib/tftpboot 即为文件目录</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/modify_tftp.png\" alt=\"tftpd.conf\"></p>\n<p>服务启动<br>    systemctl start tftp</p>\n<h2 id=\"ftp服务安装\"><a href=\"#FTP服务安装\" class=\"headerlink\" title=\"FTP服务安装\"></a>FTP服务安装</h2><p>确定ftp服务之前没有安装 </p>\n<pre><code>yum -y install vsftpd \n</code></pre><p>修改一些配置   </p>\n<pre><code>vim /etc/vsftpd/vsftpd.conf   \n</code></pre><p>更改<br>    anonymous_enable=YES</p>\n<p>这里需要保证anonymous_enable=YES （匿名用户登录开启）<br>然后测试ftp服务正常与否    可以找一台内网机器或者本机实验<br><img src=\"http://or2jd66dq.bkt.clouddn.com/test_ftp.png\" alt=\"\"><br>如果能用anonymous 免密码登录到ftp 证明服务正常</p>\n<h2 id=\"文件拷贝\"><a href=\"#文件拷贝\" class=\"headerlink\" title=\"文件拷贝\"></a>文件拷贝</h2><p>&emsp;&emsp;现在基本服务已经搭建完成了  我们需要准备一下镜像文件等挂载到TFTP 和 FTP服务器上供网络引导的机器读取下载。因为我们上边dhcp.conf中已经写到了 pxe client 要向 TFTP服务器请求的filename pxelinux.0<br>所以我们需要把这个文件拷贝到TFTP文件目录下。<br>PXE启动映像文件由syslinux提供，我们只要安装syslinux，就会生成一个pxelinux.0文件，</p>\n<ol>\n<li><p>只需要将 pxelinux.0 这个文件复制到TFTP根目录即可。</p>\n<pre><code>yum install -y syslinux\ncp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/\n</code></pre></li>\n<li><p>把我们之前下载好的镜像ISO文件挂载一下，目标路径为ftp服务器文件目录位置</p>\n<pre><code>mount -o loop /soft/CentOS-7-x86_64-Everything-1511.iso /var/ftp/pub/\n</code></pre></li>\n<li><p>复制iso 镜像中的/image/pxeboot/initrd.img 和vmlinux 至/var/lib/tftpboot/ 文件夹中</p>\n<pre><code>cp /var/ftp/pub/image/pxeboot/initrd.img /var/lib/tftpboot/\ncp /var/ftp/pub/image/pxeboot/vmlinux /var/lib/tftpboot/\n</code></pre></li>\n<li><p>复制iso 镜像中的/isolinux/*.msg 至/var/lib/tftpboot/ 文件夹中</p>\n<pre><code>cp /var/ftp/pub/isolinux/*.msg /var/lib/tftpboot/\n</code></pre></li>\n<li><p>在/var/lib/tftpboot/ 中新建一个pxelinux.cfg目录</p>\n<pre><code>mkdir /var/lib/tftpboot/pxelinux.cfg\n</code></pre></li>\n<li><p>将iso 镜像中的/isolinux 目录中的isolinux.cfg复制到pxelinux.cfg目录中，同时更改文件名称为default</p>\n<pre><code>cp /var/ftp/pub/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default\n</code></pre></li>\n<li><p>修改default文件</p>\n<pre><code>vim /var/lib/tftpboot/pxelinux.cfg/default\n</code></pre></li>\n<li><p>服务启动</p>\n<pre><code>systemctl start vsftpd\n</code></pre></li>\n</ol>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/kiclstart_modify.png\" alt=\"kickstart_modify\"><br>(如果有kickstart脚本也要在这里说明路径 例如: ks=ftp://10.215.33.12/pub/ks.cfg)</p>\n<p>至此文件拷贝完成（别忘了重启三个服务DHCP，TFTP，FTP）<br>网络引导已经配置OK 重启客户端服务器的时候只需要进到boot manager中选择pxe网络引导即可。 </p>\n<p>kickstart脚本测试完成后会附上</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言：\"><a href=\"#前言：\" class=\"headerlink\" title=\"前言：\"></a>前言：</h2><pre><code>一般系统安装方式基本上都是做一个安装盘，然后每个机器都是插上U盘花上20分钟左右时间操作，包括选择引导方式，语言，键盘布局，设定初始root密码等一系列操作。较为繁琐，但是辛苦不是最大的问题，效率才是。\n这次我们机房迁移一共有三十台机器，每台不算初始化时间，只是安装系统就得很长时间，所以我们选择用PXE网络引导的方式，告别U盘。\n</code></pre><h2 id=\"PXE技术分析：\"><a href=\"#PXE技术分析：\" class=\"headerlink\" title=\"PXE技术分析：\"></a>PXE技术分析：</h2><h3 id=\"工作过程\"><a href=\"#工作过程\" class=\"headerlink\" title=\"工作过程\"></a>工作过程</h3><p><img src=\"http://or2jd66dq.bkt.clouddn.com/pxe%E5%BC%95%E5%AF%BC%E6%B5%81%E7%A8%8B.gif\" alt=\"\"><br>其实就是DHCP+TFTP+FTP三个服务配合操作（FTP也可以用HTTP服务代替 因为我们本次操作的机器HTTP端口被占用所以直接选择FTP）</p>\n<h2 id=\"原理：\"><a href=\"#原理：\" class=\"headerlink\" title=\"原理：\"></a>原理：</h2><p>&emsp;&emsp;客户端PXE网卡启动<br>从DHCP服务器获得IP<br>从TFTP服务器上下载pxelinux.0、default<br>根据配置文件default指定的vmlinuz、initrd.img启动系统内核,并下载指定的ks.cfg文件<br>跟据ks.cfg去(HTTP/FTP/NFS)服务器下载RPM包并安装系统<br>完成安装</p>\n<h2 id=\"操作步骤：\"><a href=\"#操作步骤：\" class=\"headerlink\" title=\"操作步骤：\"></a>操作步骤：</h2><p>DHCP服务器安装配置<br>首先 确认DHCP服务没有安装，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rpm -qa | grep dhcp</div></pre></td></tr></table></figure>\n<p>没有安装过就直接yum安装（也要注意同一内网之中有没有别的DHCP服务在运行，避免冲突）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install dhcp*</div></pre></td></tr></table></figure>\n<p>然后配置一下 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim /etc/dhcp/dhcpd.conf</div></pre></td></tr></table></figure>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/dhcp_conf.png\" width=\"500\" height=\"400\" alt=\"dhcp_conf\"></p>\n<p>配置完直接重启 dhcp服务。</p>\n<pre><code>service dhcp restart\n</code></pre><p>但是我们会看到<br><img src=\"http://or2jd66dq.bkt.clouddn.com/dhcp_start.png\" alt=\"servie dhcpd start\"></p>\n<p>这个时候直接运行<br>    /usr/sbin/dhcpd<br>就OK了(ps -ef 确认下进程是否在)<br><img src=\"http://or2jd66dq.bkt.clouddn.com/ps_dhcp.png\" alt=\"dhcpd状态\"></p>\n<h2 id=\"TFTP服务安装\"><a href=\"#TFTP服务安装\" class=\"headerlink\" title=\"TFTP服务安装\"></a>TFTP服务安装</h2><p>首先确定机器有没有安装TFTP服务<br>    rpm -qa | grep tftp<br>如果没有直接yum安装<br>    yum install tftp*<br>然后稍微修改些配置<br>    disable 由yes改为no<br>    server_args = 加上-u nobody (用户可以是所有人)</p>\n<p>/usr/lib/tftpboot 即为文件目录</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/modify_tftp.png\" alt=\"tftpd.conf\"></p>\n<p>服务启动<br>    systemctl start tftp</p>\n<h2 id=\"FTP服务安装\"><a href=\"#FTP服务安装\" class=\"headerlink\" title=\"FTP服务安装\"></a>FTP服务安装</h2><p>确定ftp服务之前没有安装 </p>\n<pre><code>yum -y install vsftpd \n</code></pre><p>修改一些配置   </p>\n<pre><code>vim /etc/vsftpd/vsftpd.conf   \n</code></pre><p>更改<br>    anonymous_enable=YES</p>\n<p>这里需要保证anonymous_enable=YES （匿名用户登录开启）<br>然后测试ftp服务正常与否    可以找一台内网机器或者本机实验<br><img src=\"http://or2jd66dq.bkt.clouddn.com/test_ftp.png\" alt=\"\"><br>如果能用anonymous 免密码登录到ftp 证明服务正常</p>\n<h2 id=\"文件拷贝\"><a href=\"#文件拷贝\" class=\"headerlink\" title=\"文件拷贝\"></a>文件拷贝</h2><p>&emsp;&emsp;现在基本服务已经搭建完成了  我们需要准备一下镜像文件等挂载到TFTP 和 FTP服务器上供网络引导的机器读取下载。因为我们上边dhcp.conf中已经写到了 pxe client 要向 TFTP服务器请求的filename pxelinux.0<br>所以我们需要把这个文件拷贝到TFTP文件目录下。<br>PXE启动映像文件由syslinux提供，我们只要安装syslinux，就会生成一个pxelinux.0文件，</p>\n<ol>\n<li><p>只需要将 pxelinux.0 这个文件复制到TFTP根目录即可。</p>\n<pre><code>yum install -y syslinux\ncp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/\n</code></pre></li>\n<li><p>把我们之前下载好的镜像ISO文件挂载一下，目标路径为ftp服务器文件目录位置</p>\n<pre><code>mount -o loop /soft/CentOS-7-x86_64-Everything-1511.iso /var/ftp/pub/\n</code></pre></li>\n<li><p>复制iso 镜像中的/image/pxeboot/initrd.img 和vmlinux 至/var/lib/tftpboot/ 文件夹中</p>\n<pre><code>cp /var/ftp/pub/image/pxeboot/initrd.img /var/lib/tftpboot/\ncp /var/ftp/pub/image/pxeboot/vmlinux /var/lib/tftpboot/\n</code></pre></li>\n<li><p>复制iso 镜像中的/isolinux/*.msg 至/var/lib/tftpboot/ 文件夹中</p>\n<pre><code>cp /var/ftp/pub/isolinux/*.msg /var/lib/tftpboot/\n</code></pre></li>\n<li><p>在/var/lib/tftpboot/ 中新建一个pxelinux.cfg目录</p>\n<pre><code>mkdir /var/lib/tftpboot/pxelinux.cfg\n</code></pre></li>\n<li><p>将iso 镜像中的/isolinux 目录中的isolinux.cfg复制到pxelinux.cfg目录中，同时更改文件名称为default</p>\n<pre><code>cp /var/ftp/pub/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default\n</code></pre></li>\n<li><p>修改default文件</p>\n<pre><code>vim /var/lib/tftpboot/pxelinux.cfg/default\n</code></pre></li>\n<li><p>服务启动</p>\n<pre><code>systemctl start vsftpd\n</code></pre></li>\n</ol>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/kiclstart_modify.png\" alt=\"kickstart_modify\"><br>(如果有kickstart脚本也要在这里说明路径 例如: ks=ftp://10.215.33.12/pub/ks.cfg)</p>\n<p>至此文件拷贝完成（别忘了重启三个服务DHCP，TFTP，FTP）<br>网络引导已经配置OK 重启客户端服务器的时候只需要进到boot manager中选择pxe网络引导即可。 </p>\n<p>kickstart脚本测试完成后会附上</p>\n"},{"title":"curl查看接口各阶段响应时间","date":"2017-06-16T04:02:57.000Z","_content":"### **使用场景**\n--------\n\n> 有接口查询比较慢，需要查找具体到底是哪块响应时间比较长，然后再定位具体的问题。\n\ncurl 有个 -w参数。可以格式化输出我们可以使用。\n它能够按照指定的格式打印某些信息，里面可以使用某些特定的变量，而且支持 \\n、\\t和 \\r 转义字符。提供的变量很多，比如 status_code、local_port、size_download 等等，这篇文章我们只关注和请求时间有关的变量（以 time_ 开头的变量）。\n\n**具体用法**\n\n``` \n➜  ~ curl 'https://api.mch.weixin.qq.com/pay/unifiedorder' -w '\\ntime_namelookup:  %{time_namelookup}\\ntime_connect:  %{time_connect}\\ntime_appconnect:  %{time_appconnect}\\ntime_pretransfer:  %{time_pretransfer}\\ntime_redirect:  %{time_redirect}\\ntime_starttransfer:  %{time_starttransfer}\\ntotal:  %{time_total}\\n'\n<xml><return_code><![CDATA[FAIL]]></return_code>\n<return_msg><![CDATA[请使用post方法]]></return_msg>\n</xml>\ntime_namelookup:  0.013\ntime_connect:  0.018\ntime_appconnect:  0.113\ntime_pretransfer:  0.113\ntime_redirect:  0.000\ntime_starttransfer:  0.180\ntotal:  0.180\n```\n\n具体变量解读：\n\n`time_namelookup`：DNS 域名解析的时候，就是把 URL 转换成 ip 地址的过程\n`time_connect`：TCP 连接建立的时间，就是三次握手的时间\n`time_appconnect`：SSL/SSH 等上层协议建立连接的时间，比如 `connect/handshake` 的时间\n`time_redirect`：从开始到最后一个请求事务的时间\n`time_pretransfer`：从请求开始到响应开始传输的时间\n`time_starttransfer`：从请求开始到第一个字节将要传输的时间\n`time_total`：这次请求花费的全部时间\n\n而我们这个接口使用的是openvpn访问的外网，openvpn使用的openssl认证。所以基本定位到问题就在openvpn的ssl认证过程中。\n\n\n","source":"_posts/curl查看接口各阶段响应时间.md","raw":"---\ntitle: curl查看接口各阶段响应时间\ndate: 2017-06-16 12:02:57\ntags: curl\ncategories: 基础运维\n---\n### **使用场景**\n--------\n\n> 有接口查询比较慢，需要查找具体到底是哪块响应时间比较长，然后再定位具体的问题。\n\ncurl 有个 -w参数。可以格式化输出我们可以使用。\n它能够按照指定的格式打印某些信息，里面可以使用某些特定的变量，而且支持 \\n、\\t和 \\r 转义字符。提供的变量很多，比如 status_code、local_port、size_download 等等，这篇文章我们只关注和请求时间有关的变量（以 time_ 开头的变量）。\n\n**具体用法**\n\n``` \n➜  ~ curl 'https://api.mch.weixin.qq.com/pay/unifiedorder' -w '\\ntime_namelookup:  %{time_namelookup}\\ntime_connect:  %{time_connect}\\ntime_appconnect:  %{time_appconnect}\\ntime_pretransfer:  %{time_pretransfer}\\ntime_redirect:  %{time_redirect}\\ntime_starttransfer:  %{time_starttransfer}\\ntotal:  %{time_total}\\n'\n<xml><return_code><![CDATA[FAIL]]></return_code>\n<return_msg><![CDATA[请使用post方法]]></return_msg>\n</xml>\ntime_namelookup:  0.013\ntime_connect:  0.018\ntime_appconnect:  0.113\ntime_pretransfer:  0.113\ntime_redirect:  0.000\ntime_starttransfer:  0.180\ntotal:  0.180\n```\n\n具体变量解读：\n\n`time_namelookup`：DNS 域名解析的时候，就是把 URL 转换成 ip 地址的过程\n`time_connect`：TCP 连接建立的时间，就是三次握手的时间\n`time_appconnect`：SSL/SSH 等上层协议建立连接的时间，比如 `connect/handshake` 的时间\n`time_redirect`：从开始到最后一个请求事务的时间\n`time_pretransfer`：从请求开始到响应开始传输的时间\n`time_starttransfer`：从请求开始到第一个字节将要传输的时间\n`time_total`：这次请求花费的全部时间\n\n而我们这个接口使用的是openvpn访问的外网，openvpn使用的openssl认证。所以基本定位到问题就在openvpn的ssl认证过程中。\n\n\n","slug":"curl查看接口各阶段响应时间","published":1,"updated":"2017-06-16T04:04:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5o000z8tzze5d0bhee","content":"<h3 id=\"使用场景\"><a href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"></a><strong>使用场景</strong></h3><hr>\n<blockquote>\n<p>有接口查询比较慢，需要查找具体到底是哪块响应时间比较长，然后再定位具体的问题。</p>\n</blockquote>\n<p>curl 有个 -w参数。可以格式化输出我们可以使用。<br>它能够按照指定的格式打印某些信息，里面可以使用某些特定的变量，而且支持 \\n、\\t和 \\r 转义字符。提供的变量很多，比如 status_code、local_port、size<em>download 等等，这篇文章我们只关注和请求时间有关的变量（以 time</em> 开头的变量）。</p>\n<p><strong>具体用法</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  ~ curl &apos;https://api.mch.weixin.qq.com/pay/unifiedorder&apos; -w &apos;\\ntime_namelookup:  %&#123;time_namelookup&#125;\\ntime_connect:  %&#123;time_connect&#125;\\ntime_appconnect:  %&#123;time_appconnect&#125;\\ntime_pretransfer:  %&#123;time_pretransfer&#125;\\ntime_redirect:  %&#123;time_redirect&#125;\\ntime_starttransfer:  %&#123;time_starttransfer&#125;\\ntotal:  %&#123;time_total&#125;\\n&apos;</div><div class=\"line\">&lt;xml&gt;&lt;return_code&gt;&lt;![CDATA[FAIL]]&gt;&lt;/return_code&gt;</div><div class=\"line\">&lt;return_msg&gt;&lt;![CDATA[请使用post方法]]&gt;&lt;/return_msg&gt;</div><div class=\"line\">&lt;/xml&gt;</div><div class=\"line\">time_namelookup:  0.013</div><div class=\"line\">time_connect:  0.018</div><div class=\"line\">time_appconnect:  0.113</div><div class=\"line\">time_pretransfer:  0.113</div><div class=\"line\">time_redirect:  0.000</div><div class=\"line\">time_starttransfer:  0.180</div><div class=\"line\">total:  0.180</div></pre></td></tr></table></figure>\n<p>具体变量解读：</p>\n<p><code>time_namelookup</code>：DNS 域名解析的时候，就是把 URL 转换成 ip 地址的过程<br><code>time_connect</code>：TCP 连接建立的时间，就是三次握手的时间<br><code>time_appconnect</code>：SSL/SSH 等上层协议建立连接的时间，比如 <code>connect/handshake</code> 的时间<br><code>time_redirect</code>：从开始到最后一个请求事务的时间<br><code>time_pretransfer</code>：从请求开始到响应开始传输的时间<br><code>time_starttransfer</code>：从请求开始到第一个字节将要传输的时间<br><code>time_total</code>：这次请求花费的全部时间</p>\n<p>而我们这个接口使用的是openvpn访问的外网，openvpn使用的openssl认证。所以基本定位到问题就在openvpn的ssl认证过程中。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"使用场景\"><a href=\"#使用场景\" class=\"headerlink\" title=\"使用场景\"></a><strong>使用场景</strong></h3><hr>\n<blockquote>\n<p>有接口查询比较慢，需要查找具体到底是哪块响应时间比较长，然后再定位具体的问题。</p>\n</blockquote>\n<p>curl 有个 -w参数。可以格式化输出我们可以使用。<br>它能够按照指定的格式打印某些信息，里面可以使用某些特定的变量，而且支持 \\n、\\t和 \\r 转义字符。提供的变量很多，比如 status_code、local_port、size<em>download 等等，这篇文章我们只关注和请求时间有关的变量（以 time</em> 开头的变量）。</p>\n<p><strong>具体用法</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  ~ curl &apos;https://api.mch.weixin.qq.com/pay/unifiedorder&apos; -w &apos;\\ntime_namelookup:  %&#123;time_namelookup&#125;\\ntime_connect:  %&#123;time_connect&#125;\\ntime_appconnect:  %&#123;time_appconnect&#125;\\ntime_pretransfer:  %&#123;time_pretransfer&#125;\\ntime_redirect:  %&#123;time_redirect&#125;\\ntime_starttransfer:  %&#123;time_starttransfer&#125;\\ntotal:  %&#123;time_total&#125;\\n&apos;</div><div class=\"line\">&lt;xml&gt;&lt;return_code&gt;&lt;![CDATA[FAIL]]&gt;&lt;/return_code&gt;</div><div class=\"line\">&lt;return_msg&gt;&lt;![CDATA[请使用post方法]]&gt;&lt;/return_msg&gt;</div><div class=\"line\">&lt;/xml&gt;</div><div class=\"line\">time_namelookup:  0.013</div><div class=\"line\">time_connect:  0.018</div><div class=\"line\">time_appconnect:  0.113</div><div class=\"line\">time_pretransfer:  0.113</div><div class=\"line\">time_redirect:  0.000</div><div class=\"line\">time_starttransfer:  0.180</div><div class=\"line\">total:  0.180</div></pre></td></tr></table></figure>\n<p>具体变量解读：</p>\n<p><code>time_namelookup</code>：DNS 域名解析的时候，就是把 URL 转换成 ip 地址的过程<br><code>time_connect</code>：TCP 连接建立的时间，就是三次握手的时间<br><code>time_appconnect</code>：SSL/SSH 等上层协议建立连接的时间，比如 <code>connect/handshake</code> 的时间<br><code>time_redirect</code>：从开始到最后一个请求事务的时间<br><code>time_pretransfer</code>：从请求开始到响应开始传输的时间<br><code>time_starttransfer</code>：从请求开始到第一个字节将要传输的时间<br><code>time_total</code>：这次请求花费的全部时间</p>\n<p>而我们这个接口使用的是openvpn访问的外网，openvpn使用的openssl认证。所以基本定位到问题就在openvpn的ssl认证过程中。</p>\n"},{"title":"docker命令","date":"2017-06-23T10:15:15.000Z","_content":"> 这些命令运行都是在本地Mac上运行的并非线上。\n> Mac安装docker参考[官网](https://store.docker.com/editions/community/docker-ce-desktop-mac)\n> 之后最好申请个加速器[阿里加速](https://account.aliyun.com/login/login.htm?oauth_callback=https%3A%2F%2Fcr.console.aliyun.com%2F&lang=zh#/imageList?onepasswdfill=3722C10CDB884416BE57D1C99C2C26A4&onepasswdvault=A2A7CEC8C02947EAAFD5227D16727010)，再配置一下 `Preferences`-->`Deamon`-->`Basic`-->`Registry mirrors` \n \n\n# 镜像相关\n## 获取镜像\n```\ndocker pull [选项] [Docker Registry地址]<仓库名>:<标签>\n```\n\n## 查看镜像\n`显示镜像`\n```\ndocker images\ndocker images ubuntu:16.04\n```\n`查看虚悬镜像`(有些镜像升级后旧版本就会变成虚悬镜像[dangling image] 仓库  标签 都是 <none>)\n```\ndocker images -f dangling=True\n```\n`删除虚悬镜像`\n```\ndocker rmi $(docker images -q -f dangling=true)\n```\n`安装自定义格式显示`\n```\n➜  workspace docker images --format \"{{.ID}}: {{.Repository}}\"\n958a7ae9e569: nginx\n```\n`--filter 过滤器`\n```\n docker images -f since=mongo:3.2\n```\n\n# 容器相关\n## 容器启动\n```\ndocker run -d -p 80:80 --name webserver nginx\n```\n这条命令 是用`nginx` 镜像 启动一个名为webserver的 容器， 并且映射到80 端口\n\n## 进到容器\n```\ndocker exec -it webserver bash\n```\n可以进到容器里面对容器webserver容器进行更改 `exit` 退出 \n\n## 保存镜像(docker commit)\n> 修改定制完容器，我们可以使用`docker commit`把它保存为新的镜像(但是因为修改历史不好查看，版本不好控制，一般很忌讳这样修改，要慎用)\n\n```\n➜ docker commit --author \"fanquqi\" --message \"change index.html\" webserver nginx:v2\nsha256:2ad516b8fb8a76714e58a865d8099cbf6c31c36aabf0e4733b7d2950706674c3\n```\n可以通过docker images 查看\n```\n➜ docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nnginx               v2                  2ad516b8fb8a        10 seconds ago      109 MB\nnginx               latest              958a7ae9e569        3 weeks ago         109 MB\n```\n可以通过docker history 查看更改历史\n```\n➜  workspace docker history nginx:v2\nIMAGE               CREATED              CREATED BY                                      SIZE                COMMENT\n2ad516b8fb8a        About a minute ago   nginx -g daemon off;                            306 B               change index.html\n958a7ae9e569        3 weeks ago          /bin/sh -c #(nop)  CMD [\"nginx\" \"-g\" \"daem...   0 B\n<missing>           3 weeks ago          /bin/sh -c #(nop)  STOPSIGNAL [SIGTERM]         0 B\n<missing>           3 weeks ago          /bin/sh -c #(nop)  EXPOSE 80/tcp                0 B\n<missing>           3 weeks ago          /bin/sh -c ln -sf /dev/stdout /var/log/ngi...   22 B\n<missing>           3 weeks ago          /bin/sh -c apt-get update  && apt-get inst...   52.2 MB\n<missing>           3 weeks ago          /bin/sh -c #(nop)  ENV NJS_VERSION=1.13.1....   0 B\n<missing>           3 weeks ago          /bin/sh -c #(nop)  ENV NGINX_VERSION=1.13....   0 B\n<missing>           6 weeks ago          /bin/sh -c #(nop)  MAINTAINER NGINX Docker...   0 B\n<missing>           6 weeks ago          /bin/sh -c #(nop)  CMD [\"/bin/bash\"]            0 B\n<missing>           6 weeks ago          /bin/sh -c #(nop) ADD file:a90ec883129f86b...   57.1 MB\n```\n紧接着我们可以运行这个镜像到一个新的容器\n```\ndocker run --name web2 -d -p 81:80 nginx:v2\n```\n\n## 使用Dockerfile\n\n\n\n","source":"_posts/docker命令.md","raw":"---\ntitle: docker命令\ndate: 2017-06-23 18:15:15\ntags: docker\ncategories: docker\n---\n> 这些命令运行都是在本地Mac上运行的并非线上。\n> Mac安装docker参考[官网](https://store.docker.com/editions/community/docker-ce-desktop-mac)\n> 之后最好申请个加速器[阿里加速](https://account.aliyun.com/login/login.htm?oauth_callback=https%3A%2F%2Fcr.console.aliyun.com%2F&lang=zh#/imageList?onepasswdfill=3722C10CDB884416BE57D1C99C2C26A4&onepasswdvault=A2A7CEC8C02947EAAFD5227D16727010)，再配置一下 `Preferences`-->`Deamon`-->`Basic`-->`Registry mirrors` \n \n\n# 镜像相关\n## 获取镜像\n```\ndocker pull [选项] [Docker Registry地址]<仓库名>:<标签>\n```\n\n## 查看镜像\n`显示镜像`\n```\ndocker images\ndocker images ubuntu:16.04\n```\n`查看虚悬镜像`(有些镜像升级后旧版本就会变成虚悬镜像[dangling image] 仓库  标签 都是 <none>)\n```\ndocker images -f dangling=True\n```\n`删除虚悬镜像`\n```\ndocker rmi $(docker images -q -f dangling=true)\n```\n`安装自定义格式显示`\n```\n➜  workspace docker images --format \"{{.ID}}: {{.Repository}}\"\n958a7ae9e569: nginx\n```\n`--filter 过滤器`\n```\n docker images -f since=mongo:3.2\n```\n\n# 容器相关\n## 容器启动\n```\ndocker run -d -p 80:80 --name webserver nginx\n```\n这条命令 是用`nginx` 镜像 启动一个名为webserver的 容器， 并且映射到80 端口\n\n## 进到容器\n```\ndocker exec -it webserver bash\n```\n可以进到容器里面对容器webserver容器进行更改 `exit` 退出 \n\n## 保存镜像(docker commit)\n> 修改定制完容器，我们可以使用`docker commit`把它保存为新的镜像(但是因为修改历史不好查看，版本不好控制，一般很忌讳这样修改，要慎用)\n\n```\n➜ docker commit --author \"fanquqi\" --message \"change index.html\" webserver nginx:v2\nsha256:2ad516b8fb8a76714e58a865d8099cbf6c31c36aabf0e4733b7d2950706674c3\n```\n可以通过docker images 查看\n```\n➜ docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nnginx               v2                  2ad516b8fb8a        10 seconds ago      109 MB\nnginx               latest              958a7ae9e569        3 weeks ago         109 MB\n```\n可以通过docker history 查看更改历史\n```\n➜  workspace docker history nginx:v2\nIMAGE               CREATED              CREATED BY                                      SIZE                COMMENT\n2ad516b8fb8a        About a minute ago   nginx -g daemon off;                            306 B               change index.html\n958a7ae9e569        3 weeks ago          /bin/sh -c #(nop)  CMD [\"nginx\" \"-g\" \"daem...   0 B\n<missing>           3 weeks ago          /bin/sh -c #(nop)  STOPSIGNAL [SIGTERM]         0 B\n<missing>           3 weeks ago          /bin/sh -c #(nop)  EXPOSE 80/tcp                0 B\n<missing>           3 weeks ago          /bin/sh -c ln -sf /dev/stdout /var/log/ngi...   22 B\n<missing>           3 weeks ago          /bin/sh -c apt-get update  && apt-get inst...   52.2 MB\n<missing>           3 weeks ago          /bin/sh -c #(nop)  ENV NJS_VERSION=1.13.1....   0 B\n<missing>           3 weeks ago          /bin/sh -c #(nop)  ENV NGINX_VERSION=1.13....   0 B\n<missing>           6 weeks ago          /bin/sh -c #(nop)  MAINTAINER NGINX Docker...   0 B\n<missing>           6 weeks ago          /bin/sh -c #(nop)  CMD [\"/bin/bash\"]            0 B\n<missing>           6 weeks ago          /bin/sh -c #(nop) ADD file:a90ec883129f86b...   57.1 MB\n```\n紧接着我们可以运行这个镜像到一个新的容器\n```\ndocker run --name web2 -d -p 81:80 nginx:v2\n```\n\n## 使用Dockerfile\n\n\n\n","slug":"docker命令","published":1,"updated":"2017-06-27T08:36:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5p00118tzzo3t50av5","content":"<blockquote>\n<p>这些命令运行都是在本地Mac上运行的并非线上。<br>Mac安装docker参考<a href=\"https://store.docker.com/editions/community/docker-ce-desktop-mac\" target=\"_blank\" rel=\"external\">官网</a><br>之后最好申请个加速器<a href=\"https://account.aliyun.com/login/login.htm?oauth_callback=https%3A%2F%2Fcr.console.aliyun.com%2F&amp;lang=zh#/imageList?onepasswdfill=3722C10CDB884416BE57D1C99C2C26A4&amp;onepasswdvault=A2A7CEC8C02947EAAFD5227D16727010\" target=\"_blank\" rel=\"external\">阿里加速</a>，再配置一下 <code>Preferences</code>–&gt;<code>Deamon</code>–&gt;<code>Basic</code>–&gt;<code>Registry mirrors</code> </p>\n</blockquote>\n<h1 id=\"镜像相关\"><a href=\"#镜像相关\" class=\"headerlink\" title=\"镜像相关\"></a>镜像相关</h1><h2 id=\"获取镜像\"><a href=\"#获取镜像\" class=\"headerlink\" title=\"获取镜像\"></a>获取镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt;</div></pre></td></tr></table></figure>\n<h2 id=\"查看镜像\"><a href=\"#查看镜像\" class=\"headerlink\" title=\"查看镜像\"></a>查看镜像</h2><p><code>显示镜像</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker images</div><div class=\"line\">docker images ubuntu:16.04</div></pre></td></tr></table></figure></p>\n<p><code>查看虚悬镜像</code>(有些镜像升级后旧版本就会变成虚悬镜像[dangling image] 仓库  标签 都是 <none>)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker images -f dangling=True</div></pre></td></tr></table></figure></none></p>\n<p><code>删除虚悬镜像</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker rmi $(docker images -q -f dangling=true)</div></pre></td></tr></table></figure></p>\n<p><code>安装自定义格式显示</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  workspace docker images --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot;</div><div class=\"line\">958a7ae9e569: nginx</div></pre></td></tr></table></figure></p>\n<p><code>--filter 过滤器</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker images -f since=mongo:3.2</div></pre></td></tr></table></figure></p>\n<h1 id=\"容器相关\"><a href=\"#容器相关\" class=\"headerlink\" title=\"容器相关\"></a>容器相关</h1><h2 id=\"容器启动\"><a href=\"#容器启动\" class=\"headerlink\" title=\"容器启动\"></a>容器启动</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d -p 80:80 --name webserver nginx</div></pre></td></tr></table></figure>\n<p>这条命令 是用<code>nginx</code> 镜像 启动一个名为webserver的 容器， 并且映射到80 端口</p>\n<h2 id=\"进到容器\"><a href=\"#进到容器\" class=\"headerlink\" title=\"进到容器\"></a>进到容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker exec -it webserver bash</div></pre></td></tr></table></figure>\n<p>可以进到容器里面对容器webserver容器进行更改 <code>exit</code> 退出 </p>\n<h2 id=\"保存镜像docker-commit\"><a href=\"#保存镜像-docker-commit\" class=\"headerlink\" title=\"保存镜像(docker commit)\"></a>保存镜像(docker commit)</h2><blockquote>\n<p>修改定制完容器，我们可以使用<code>docker commit</code>把它保存为新的镜像(但是因为修改历史不好查看，版本不好控制，一般很忌讳这样修改，要慎用)</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜ docker commit --author &quot;fanquqi&quot; --message &quot;change index.html&quot; webserver nginx:v2</div><div class=\"line\">sha256:2ad516b8fb8a76714e58a865d8099cbf6c31c36aabf0e4733b7d2950706674c3</div></pre></td></tr></table></figure>\n<p>可以通过docker images 查看<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜ docker images</div><div class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</div><div class=\"line\">nginx               v2                  2ad516b8fb8a        10 seconds ago      109 MB</div><div class=\"line\">nginx               latest              958a7ae9e569        3 weeks ago         109 MB</div></pre></td></tr></table></figure></p>\n<p>可以通过docker history 查看更改历史<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  workspace docker history nginx:v2</div><div class=\"line\">IMAGE               CREATED              CREATED BY                                      SIZE                COMMENT</div><div class=\"line\">2ad516b8fb8a        About a minute ago   nginx -g daemon off;                            306 B               change index.html</div><div class=\"line\">958a7ae9e569        3 weeks ago          /bin/sh -c #(nop)  CMD [&quot;nginx&quot; &quot;-g&quot; &quot;daem...   0 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c #(nop)  STOPSIGNAL [SIGTERM]         0 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c #(nop)  EXPOSE 80/tcp                0 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c ln -sf /dev/stdout /var/log/ngi...   22 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c apt-get update  &amp;&amp; apt-get inst...   52.2 MB</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c #(nop)  ENV NJS_VERSION=1.13.1....   0 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c #(nop)  ENV NGINX_VERSION=1.13....   0 B</div><div class=\"line\">&lt;missing&gt;           6 weeks ago          /bin/sh -c #(nop)  MAINTAINER NGINX Docker...   0 B</div><div class=\"line\">&lt;missing&gt;           6 weeks ago          /bin/sh -c #(nop)  CMD [&quot;/bin/bash&quot;]            0 B</div><div class=\"line\">&lt;missing&gt;           6 weeks ago          /bin/sh -c #(nop) ADD file:a90ec883129f86b...   57.1 MB</div></pre></td></tr></table></figure></p>\n<p>紧接着我们可以运行这个镜像到一个新的容器<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name web2 -d -p 81:80 nginx:v2</div></pre></td></tr></table></figure></p>\n<h2 id=\"使用dockerfile\"><a href=\"#使用Dockerfile\" class=\"headerlink\" title=\"使用Dockerfile\"></a>使用Dockerfile</h2>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>这些命令运行都是在本地Mac上运行的并非线上。<br>Mac安装docker参考<a href=\"https://store.docker.com/editions/community/docker-ce-desktop-mac\" target=\"_blank\" rel=\"external\">官网</a><br>之后最好申请个加速器<a href=\"https://account.aliyun.com/login/login.htm?oauth_callback=https%3A%2F%2Fcr.console.aliyun.com%2F&amp;lang=zh#/imageList?onepasswdfill=3722C10CDB884416BE57D1C99C2C26A4&amp;onepasswdvault=A2A7CEC8C02947EAAFD5227D16727010\" target=\"_blank\" rel=\"external\">阿里加速</a>，再配置一下 <code>Preferences</code>–&gt;<code>Deamon</code>–&gt;<code>Basic</code>–&gt;<code>Registry mirrors</code> </p>\n</blockquote>\n<h1 id=\"镜像相关\"><a href=\"#镜像相关\" class=\"headerlink\" title=\"镜像相关\"></a>镜像相关</h1><h2 id=\"获取镜像\"><a href=\"#获取镜像\" class=\"headerlink\" title=\"获取镜像\"></a>获取镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt;</div></pre></td></tr></table></figure>\n<h2 id=\"查看镜像\"><a href=\"#查看镜像\" class=\"headerlink\" title=\"查看镜像\"></a>查看镜像</h2><p><code>显示镜像</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker images</div><div class=\"line\">docker images ubuntu:16.04</div></pre></td></tr></table></figure></p>\n<p><code>查看虚悬镜像</code>(有些镜像升级后旧版本就会变成虚悬镜像[dangling image] 仓库  标签 都是 <none>)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker images -f dangling=True</div></pre></td></tr></table></figure></none></p>\n<p><code>删除虚悬镜像</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker rmi $(docker images -q -f dangling=true)</div></pre></td></tr></table></figure></p>\n<p><code>安装自定义格式显示</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  workspace docker images --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot;</div><div class=\"line\">958a7ae9e569: nginx</div></pre></td></tr></table></figure></p>\n<p><code>--filter 过滤器</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker images -f since=mongo:3.2</div></pre></td></tr></table></figure></p>\n<h1 id=\"容器相关\"><a href=\"#容器相关\" class=\"headerlink\" title=\"容器相关\"></a>容器相关</h1><h2 id=\"容器启动\"><a href=\"#容器启动\" class=\"headerlink\" title=\"容器启动\"></a>容器启动</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d -p 80:80 --name webserver nginx</div></pre></td></tr></table></figure>\n<p>这条命令 是用<code>nginx</code> 镜像 启动一个名为webserver的 容器， 并且映射到80 端口</p>\n<h2 id=\"进到容器\"><a href=\"#进到容器\" class=\"headerlink\" title=\"进到容器\"></a>进到容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker exec -it webserver bash</div></pre></td></tr></table></figure>\n<p>可以进到容器里面对容器webserver容器进行更改 <code>exit</code> 退出 </p>\n<h2 id=\"保存镜像-docker-commit\"><a href=\"#保存镜像-docker-commit\" class=\"headerlink\" title=\"保存镜像(docker commit)\"></a>保存镜像(docker commit)</h2><blockquote>\n<p>修改定制完容器，我们可以使用<code>docker commit</code>把它保存为新的镜像(但是因为修改历史不好查看，版本不好控制，一般很忌讳这样修改，要慎用)</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜ docker commit --author &quot;fanquqi&quot; --message &quot;change index.html&quot; webserver nginx:v2</div><div class=\"line\">sha256:2ad516b8fb8a76714e58a865d8099cbf6c31c36aabf0e4733b7d2950706674c3</div></pre></td></tr></table></figure>\n<p>可以通过docker images 查看<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜ docker images</div><div class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</div><div class=\"line\">nginx               v2                  2ad516b8fb8a        10 seconds ago      109 MB</div><div class=\"line\">nginx               latest              958a7ae9e569        3 weeks ago         109 MB</div></pre></td></tr></table></figure></p>\n<p>可以通过docker history 查看更改历史<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">➜  workspace docker history nginx:v2</div><div class=\"line\">IMAGE               CREATED              CREATED BY                                      SIZE                COMMENT</div><div class=\"line\">2ad516b8fb8a        About a minute ago   nginx -g daemon off;                            306 B               change index.html</div><div class=\"line\">958a7ae9e569        3 weeks ago          /bin/sh -c #(nop)  CMD [&quot;nginx&quot; &quot;-g&quot; &quot;daem...   0 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c #(nop)  STOPSIGNAL [SIGTERM]         0 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c #(nop)  EXPOSE 80/tcp                0 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c ln -sf /dev/stdout /var/log/ngi...   22 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c apt-get update  &amp;&amp; apt-get inst...   52.2 MB</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c #(nop)  ENV NJS_VERSION=1.13.1....   0 B</div><div class=\"line\">&lt;missing&gt;           3 weeks ago          /bin/sh -c #(nop)  ENV NGINX_VERSION=1.13....   0 B</div><div class=\"line\">&lt;missing&gt;           6 weeks ago          /bin/sh -c #(nop)  MAINTAINER NGINX Docker...   0 B</div><div class=\"line\">&lt;missing&gt;           6 weeks ago          /bin/sh -c #(nop)  CMD [&quot;/bin/bash&quot;]            0 B</div><div class=\"line\">&lt;missing&gt;           6 weeks ago          /bin/sh -c #(nop) ADD file:a90ec883129f86b...   57.1 MB</div></pre></td></tr></table></figure></p>\n<p>紧接着我们可以运行这个镜像到一个新的容器<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name web2 -d -p 81:80 nginx:v2</div></pre></td></tr></table></figure></p>\n<h2 id=\"使用Dockerfile\"><a href=\"#使用Dockerfile\" class=\"headerlink\" title=\"使用Dockerfile\"></a>使用Dockerfile</h2>"},{"title":"falcon问题处理","date":"2017-06-08T08:14:29.000Z","_content":"## grafana上面不支持open-falcon的大写metric(mymon metric更改小写)\n>(这是openfalcon的bug，falcon-plus中已经修复)\n\n但是我们现在使用的falcon没有升级，而且升级的得计划暂时没有安排。我们只能手动更改metric不用大写尽量用小写。\n以下记录mymon更改。\n**mymon**是使用go语言编写的，用来监控mysql的插件。[mymon代码链接](https://github.com/open-falcon/mymon)\n由于之前的mymon是通过ansible 脚本直接git pull下来的，所以有源码在，可以更改之后再build一下。\n找到`metric.go`修改大写的metric为小写。 修改完脚本如下。\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"os\"\n    \"time\"\n    \"strings\" #添加string\n)\n\nconst (\n    TIME_OUT = 30\n\n    ORIGIN   = \"GAUGE\"\n    DELTA_PS = \"COUNTER\"\n    DELTA    = \"\"\n)\n\n// COUNTER: Speed per second\n// GAUGE: Original, DEFAULT\nvar DataType = map[string]string{\n    \"Innodb_buffer_pool_reads\":         DELTA_PS,\n    \"Innodb_buffer_pool_read_requests\": DELTA_PS,\n    \"Innodb_compress_time\":             DELTA_PS,\n    \"Innodb_data_fsyncs\":               DELTA_PS,\n    \"Innodb_data_read\":                 DELTA_PS,\n    \"Innodb_data_reads\":                DELTA_PS,\n    \"Innodb_data_writes\":               DELTA_PS,\n    \"Innodb_data_written\":              DELTA_PS,\n    \"Innodb_last_checkpoint_at\":        DELTA_PS,\n    \"Innodb_log_flushed_up_to\":         DELTA_PS,\n    \"Innodb_log_sequence_number\":       DELTA_PS,\n    \"Innodb_mutex_os_waits\":            DELTA_PS,\n    \"Innodb_mutex_spin_rounds\":         DELTA_PS,\n    \"Innodb_mutex_spin_waits\":          DELTA_PS,\n    \"Innodb_pages_flushed_up_to\":       DELTA_PS,\n    \"Innodb_rows_deleted\":              DELTA_PS,\n    \"Innodb_rows_inserted\":             DELTA_PS,\n    \"Innodb_rows_locked\":               DELTA_PS,\n    \"Innodb_rows_modified\":             DELTA_PS,\n    \"Innodb_rows_read\":                 DELTA_PS,\n    \"Innodb_rows_updated\":              DELTA_PS,\n    \"Innodb_row_lock_time\":             DELTA_PS,\n    \"Innodb_row_lock_waits\":            DELTA_PS,\n    \"Innodb_uncompress_time\":           DELTA_PS,\n\n    \"Binlog_event_count\": DELTA_PS,\n    \"Binlog_number\":      DELTA_PS,\n    \"Slave_count\":        DELTA_PS,\n\n    \"Com_admin_commands\":        DELTA_PS,\n    \"Com_assign_to_keycache\":    DELTA_PS,\n    \"Com_alter_db\":              DELTA_PS,\n    \"Com_alter_db_upgrade\":      DELTA_PS,\n    \"Com_alter_event\":           DELTA_PS,\n    \"Com_alter_function\":        DELTA_PS,\n    \"Com_alter_procedure\":       DELTA_PS,\n    \"Com_alter_server\":          DELTA_PS,\n    \"Com_alter_table\":           DELTA_PS,\n    \"Com_alter_tablespace\":      DELTA_PS,\n    \"Com_analyze\":               DELTA_PS,\n    \"Com_begin\":                 DELTA_PS,\n    \"Com_binlog\":                DELTA_PS,\n    \"Com_call_procedure\":        DELTA_PS,\n    \"Com_change_db\":             DELTA_PS,\n    \"Com_change_master\":         DELTA_PS,\n    \"Com_check\":                 DELTA_PS,\n    \"Com_checksum\":              DELTA_PS,\n    \"Com_commit\":                DELTA_PS,\n    \"Com_create_db\":             DELTA_PS,\n    \"Com_create_event\":          DELTA_PS,\n    \"Com_create_function\":       DELTA_PS,\n    \"Com_create_index\":          DELTA_PS,\n    \"Com_create_procedure\":      DELTA_PS,\n    \"Com_create_server\":         DELTA_PS,\n    \"Com_create_table\":          DELTA_PS,\n    \"Com_create_trigger\":        DELTA_PS,\n    \"Com_create_udf\":            DELTA_PS,\n    \"Com_create_user\":           DELTA_PS,\n    \"Com_create_view\":           DELTA_PS,\n    \"Com_dealloc_sql\":           DELTA_PS,\n    \"Com_delete\":                DELTA_PS,\n    \"Com_delete_multi\":          DELTA_PS,\n    \"Com_do\":                    DELTA_PS,\n    \"Com_drop_db\":               DELTA_PS,\n    \"Com_drop_event\":            DELTA_PS,\n    \"Com_drop_function\":         DELTA_PS,\n    \"Com_drop_index\":            DELTA_PS,\n    \"Com_drop_procedure\":        DELTA_PS,\n    \"Com_drop_server\":           DELTA_PS,\n    \"Com_drop_table\":            DELTA_PS,\n    \"Com_drop_trigger\":          DELTA_PS,\n    \"Com_drop_user\":             DELTA_PS,\n    \"Com_drop_view\":             DELTA_PS,\n    \"Com_empty_query\":           DELTA_PS,\n    \"Com_execute_sql\":           DELTA_PS,\n    \"Com_flush\":                 DELTA_PS,\n    \"Com_grant\":                 DELTA_PS,\n    \"Com_ha_close\":              DELTA_PS,\n    \"Com_ha_open\":               DELTA_PS,\n    \"Com_ha_read\":               DELTA_PS,\n    \"Com_help\":                  DELTA_PS,\n    \"Com_insert\":                DELTA_PS,\n    \"Com_insert_select\":         DELTA_PS,\n    \"Com_install_plugin\":        DELTA_PS,\n    \"Com_kill\":                  DELTA_PS,\n    \"Com_load\":                  DELTA_PS,\n    \"Com_lock_tables\":           DELTA_PS,\n    \"Com_optimize\":              DELTA_PS,\n    \"Com_preload_keys\":          DELTA_PS,\n    \"Com_prepare_sql\":           DELTA_PS,\n    \"Com_purge\":                 DELTA_PS,\n    \"Com_purge_before_date\":     DELTA_PS,\n    \"Com_release_savepoint\":     DELTA_PS,\n    \"Com_rename_table\":          DELTA_PS,\n    \"Com_rename_user\":           DELTA_PS,\n    \"Com_repair\":                DELTA_PS,\n    \"Com_replace\":               DELTA_PS,\n    \"Com_replace_select\":        DELTA_PS,\n    \"Com_reset\":                 DELTA_PS,\n    \"Com_resignal\":              DELTA_PS,\n    \"Com_revoke\":                DELTA_PS,\n    \"Com_revoke_all\":            DELTA_PS,\n    \"Com_rollback\":              DELTA_PS,\n    \"Com_rollback_to_savepoint\": DELTA_PS,\n    \"Com_savepoint\":             DELTA_PS,\n    \"Com_select\":                DELTA_PS,\n    \"Com_set_option\":            DELTA_PS,\n    \"Com_signal\":                DELTA_PS,\n    \"Com_show_authors\":          DELTA_PS,\n    \"Com_show_binlog_events\":    DELTA_PS,\n    \"Com_show_binlogs\":          DELTA_PS,\n    \"Com_show_charsets\":         DELTA_PS,\n    \"Com_show_collations\":       DELTA_PS,\n    \"Com_show_contributors\":     DELTA_PS,\n    \"Com_show_create_db\":        DELTA_PS,\n    \"Com_show_create_event\":     DELTA_PS,\n    \"Com_show_create_func\":      DELTA_PS,\n    \"Com_show_create_proc\":      DELTA_PS,\n    \"Com_show_create_table\":     DELTA_PS,\n    \"Com_show_create_trigger\":   DELTA_PS,\n    \"Com_show_databases\":        DELTA_PS,\n    \"Com_show_engine_logs\":      DELTA_PS,\n    \"Com_show_engine_mutex\":     DELTA_PS,\n    \"Com_show_engine_status\":    DELTA_PS,\n    \"Com_show_events\":           DELTA_PS,\n    \"Com_show_errors\":           DELTA_PS,\n    \"Com_show_fields\":           DELTA_PS,\n    \"Com_show_function_status\":  DELTA_PS,\n    \"Com_show_grants\":           DELTA_PS,\n    \"Com_show_keys\":             DELTA_PS,\n    \"Com_show_master_status\":    DELTA_PS,\n    \"Com_show_open_tables\":      DELTA_PS,\n    \"Com_show_plugins\":          DELTA_PS,\n    \"Com_show_privileges\":       DELTA_PS,\n    \"Com_show_procedure_status\": DELTA_PS,\n    \"Com_show_processlist\":      DELTA_PS,\n    \"Com_show_profile\":          DELTA_PS,\n    \"Com_show_profiles\":         DELTA_PS,\n    \"Com_show_relaylog_events\":  DELTA_PS,\n    \"Com_show_slave_hosts\":      DELTA_PS,\n    \"Com_show_slave_status\":     DELTA_PS,\n    \"Com_show_status\":           DELTA_PS,\n    \"Com_show_storage_engines\":  DELTA_PS,\n    \"Com_show_table_status\":     DELTA_PS,\n    \"Com_show_tables\":           DELTA_PS,\n    \"Com_show_triggers\":         DELTA_PS,\n    \"Com_show_variables\":        DELTA_PS,\n    \"Com_show_warnings\":         DELTA_PS,\n    \"Com_slave_start\":           DELTA_PS,\n    \"Com_slave_stop\":            DELTA_PS,\n    \"Com_stmt_close\":            DELTA_PS,\n    \"Com_stmt_execute\":          DELTA_PS,\n    \"Com_stmt_fetch\":            DELTA_PS,\n    \"Com_stmt_prepare\":          DELTA_PS,\n    \"Com_stmt_reprepare\":        DELTA_PS,\n    \"Com_stmt_reset\":            DELTA_PS,\n    \"Com_stmt_send_long_data\":   DELTA_PS,\n    \"Com_truncate\":              DELTA_PS,\n    \"Com_uninstall_plugin\":      DELTA_PS,\n    \"Com_unlock_tables\":         DELTA_PS,\n    \"Com_update\":                DELTA_PS,\n    \"Com_update_multi\":          DELTA_PS,\n    \"Com_xa_commit\":             DELTA_PS,\n    \"Com_xa_end\":                DELTA_PS,\n    \"Com_xa_prepare\":            DELTA_PS,\n    \"Com_xa_recover\":            DELTA_PS,\n    \"Com_xa_rollback\":           DELTA_PS,\n    \"Com_xa_start\":              DELTA_PS,\n\n    \"Aborted_clients\":            DELTA_PS,\n    \"Aborted_connects\":           DELTA_PS,\n    \"Access_denied_errors\":       DELTA_PS,\n    \"Binlog_bytes_written\":       DELTA_PS,\n    \"Binlog_cache_disk_use\":      DELTA_PS,\n    \"Binlog_cache_use\":           DELTA_PS,\n    \"Binlog_stmt_cache_disk_use\": DELTA_PS,\n    \"Binlog_stmt_cache_use\":      DELTA_PS,\n    \"Bytes_received\":             DELTA_PS,\n    \"Bytes_sent\":                 DELTA_PS,\n    \"Connections\":                DELTA_PS,\n    \"Created_tmp_disk_tables\":    DELTA_PS,\n    \"Created_tmp_files\":          DELTA_PS,\n    \"Created_tmp_tables\":         DELTA_PS,\n    \"Handler_delete\":             DELTA_PS,\n    \"Handler_read_first\":         DELTA_PS,\n    \"Handler_read_key\":           DELTA_PS,\n    \"Handler_read_last\":          DELTA_PS,\n    \"Handler_read_next\":          DELTA_PS,\n    \"Handler_read_prev\":          DELTA_PS,\n    \"Handler_read_rnd\":           DELTA_PS,\n    \"Handler_read_rnd_next\":      DELTA_PS,\n    \"Handler_update\":             DELTA_PS,\n    \"Handler_write\":              DELTA_PS,\n    \"Opened_files\":               DELTA_PS,\n    \"Opened_tables\":              DELTA_PS,\n    \"Opened_table_definitions\":   DELTA_PS,\n    \"Qcache_hits\":                DELTA_PS,\n    \"Qcache_inserts\":             DELTA_PS,\n    \"Qcache_lowmem_prunes\":       DELTA_PS,\n    \"Qcache_not_cached\":          DELTA_PS,\n    \"Queries\":                    DELTA_PS,\n    \"Questions\":                  DELTA_PS,\n    \"Select_full_join\":           DELTA_PS,\n    \"Select_full_range_join\":     DELTA_PS,\n    \"Select_range_check\":         DELTA_PS,\n    \"Select_scan\":                DELTA_PS,\n    \"Slow_queries\":               DELTA_PS,\n    \"Sort_merge_passes\":          DELTA_PS,\n    \"Sort_range\":                 DELTA_PS,\n    \"Sort_rows\":                  DELTA_PS,\n    \"Sort_scan\":                  DELTA_PS,\n    \"Table_locks_immediate\":      DELTA_PS,\n    \"Table_locks_waited\":         DELTA_PS,\n    \"Threads_created\":            DELTA_PS,\n}\n\ntype MysqlIns struct {\n    Host string\n    Port int\n    Tag  string\n}\n\nfunc dataType(key_ string) string {\n    if v, ok := DataType[key_]; ok {\n        return v\n    }\n    return ORIGIN\n}\n\ntype MetaData struct {\n    Metric      string      `json:\"metric\"`      //key\n    Endpoint    string      `json:\"endpoint\"`    //hostname\n    Value       interface{} `json:\"value\"`       // number or string\n    CounterType string      `json:\"counterType\"` // GAUGE  原值   COUNTER 差值(ps)\n    Tags        string      `json:\"tags\"`        // port=3306,k=v\n    Timestamp   int64       `json:\"timestamp\"`\n    Step        int64       `json:\"step\"`\n}\n\nfunc (m *MetaData) String() string {\n    s := fmt.Sprintf(\"MetaData Metric:%s Endpoint:%s Value:%v CounterType:%s Tags:%s Timestamp:%d Step:%d\",\n        m.Metric, m.Endpoint, m.Value, m.CounterType, m.Tags, m.Timestamp, m.Step)\n    return s\n}\n\nfunc NewMetric(name string) *MetaData {\n    return &MetaData{\n        Metric:      strings.ToLower(name), #name 改为strings.ToLower(name)\n        Endpoint:    hostname(),\n        CounterType: dataType(name),\n        Tags:        fmt.Sprintf(\"port=%d\", cfg.Port),\n        Timestamp:   time.Now().Unix(),\n        Step:        60,\n    }\n}\n\nfunc hostname() string {\n    host := cfg.Endpoint\n    if host != \"\" {\n        return host\n    }\n    host, err := os.Hostname()\n    if err != nil {\n        host = cfg.Host\n    }\n    return host\n}\n\nfunc (m *MetaData) SetValue(v interface{}) {\n    m.Value = v\n}\n```\n\n之后在mymon目录 执行\n```\ngo get ./...\ngo build -o mymon\n```\n即可 \n\n之后可以去数据库手动删掉openfalcon 过期的metric(但是新的metric并没有更新，反而旧metric没了数据，可以试着修改endpoint，然后去数据区删除旧的endpoint)\n\n\n","source":"_posts/falcon问题处理.md","raw":"---\ntitle: falcon问题处理\ndate: 2017-06-08 16:14:29\ntags: falcon, 监控\ncategories: 监控\n---\n## grafana上面不支持open-falcon的大写metric(mymon metric更改小写)\n>(这是openfalcon的bug，falcon-plus中已经修复)\n\n但是我们现在使用的falcon没有升级，而且升级的得计划暂时没有安排。我们只能手动更改metric不用大写尽量用小写。\n以下记录mymon更改。\n**mymon**是使用go语言编写的，用来监控mysql的插件。[mymon代码链接](https://github.com/open-falcon/mymon)\n由于之前的mymon是通过ansible 脚本直接git pull下来的，所以有源码在，可以更改之后再build一下。\n找到`metric.go`修改大写的metric为小写。 修改完脚本如下。\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"os\"\n    \"time\"\n    \"strings\" #添加string\n)\n\nconst (\n    TIME_OUT = 30\n\n    ORIGIN   = \"GAUGE\"\n    DELTA_PS = \"COUNTER\"\n    DELTA    = \"\"\n)\n\n// COUNTER: Speed per second\n// GAUGE: Original, DEFAULT\nvar DataType = map[string]string{\n    \"Innodb_buffer_pool_reads\":         DELTA_PS,\n    \"Innodb_buffer_pool_read_requests\": DELTA_PS,\n    \"Innodb_compress_time\":             DELTA_PS,\n    \"Innodb_data_fsyncs\":               DELTA_PS,\n    \"Innodb_data_read\":                 DELTA_PS,\n    \"Innodb_data_reads\":                DELTA_PS,\n    \"Innodb_data_writes\":               DELTA_PS,\n    \"Innodb_data_written\":              DELTA_PS,\n    \"Innodb_last_checkpoint_at\":        DELTA_PS,\n    \"Innodb_log_flushed_up_to\":         DELTA_PS,\n    \"Innodb_log_sequence_number\":       DELTA_PS,\n    \"Innodb_mutex_os_waits\":            DELTA_PS,\n    \"Innodb_mutex_spin_rounds\":         DELTA_PS,\n    \"Innodb_mutex_spin_waits\":          DELTA_PS,\n    \"Innodb_pages_flushed_up_to\":       DELTA_PS,\n    \"Innodb_rows_deleted\":              DELTA_PS,\n    \"Innodb_rows_inserted\":             DELTA_PS,\n    \"Innodb_rows_locked\":               DELTA_PS,\n    \"Innodb_rows_modified\":             DELTA_PS,\n    \"Innodb_rows_read\":                 DELTA_PS,\n    \"Innodb_rows_updated\":              DELTA_PS,\n    \"Innodb_row_lock_time\":             DELTA_PS,\n    \"Innodb_row_lock_waits\":            DELTA_PS,\n    \"Innodb_uncompress_time\":           DELTA_PS,\n\n    \"Binlog_event_count\": DELTA_PS,\n    \"Binlog_number\":      DELTA_PS,\n    \"Slave_count\":        DELTA_PS,\n\n    \"Com_admin_commands\":        DELTA_PS,\n    \"Com_assign_to_keycache\":    DELTA_PS,\n    \"Com_alter_db\":              DELTA_PS,\n    \"Com_alter_db_upgrade\":      DELTA_PS,\n    \"Com_alter_event\":           DELTA_PS,\n    \"Com_alter_function\":        DELTA_PS,\n    \"Com_alter_procedure\":       DELTA_PS,\n    \"Com_alter_server\":          DELTA_PS,\n    \"Com_alter_table\":           DELTA_PS,\n    \"Com_alter_tablespace\":      DELTA_PS,\n    \"Com_analyze\":               DELTA_PS,\n    \"Com_begin\":                 DELTA_PS,\n    \"Com_binlog\":                DELTA_PS,\n    \"Com_call_procedure\":        DELTA_PS,\n    \"Com_change_db\":             DELTA_PS,\n    \"Com_change_master\":         DELTA_PS,\n    \"Com_check\":                 DELTA_PS,\n    \"Com_checksum\":              DELTA_PS,\n    \"Com_commit\":                DELTA_PS,\n    \"Com_create_db\":             DELTA_PS,\n    \"Com_create_event\":          DELTA_PS,\n    \"Com_create_function\":       DELTA_PS,\n    \"Com_create_index\":          DELTA_PS,\n    \"Com_create_procedure\":      DELTA_PS,\n    \"Com_create_server\":         DELTA_PS,\n    \"Com_create_table\":          DELTA_PS,\n    \"Com_create_trigger\":        DELTA_PS,\n    \"Com_create_udf\":            DELTA_PS,\n    \"Com_create_user\":           DELTA_PS,\n    \"Com_create_view\":           DELTA_PS,\n    \"Com_dealloc_sql\":           DELTA_PS,\n    \"Com_delete\":                DELTA_PS,\n    \"Com_delete_multi\":          DELTA_PS,\n    \"Com_do\":                    DELTA_PS,\n    \"Com_drop_db\":               DELTA_PS,\n    \"Com_drop_event\":            DELTA_PS,\n    \"Com_drop_function\":         DELTA_PS,\n    \"Com_drop_index\":            DELTA_PS,\n    \"Com_drop_procedure\":        DELTA_PS,\n    \"Com_drop_server\":           DELTA_PS,\n    \"Com_drop_table\":            DELTA_PS,\n    \"Com_drop_trigger\":          DELTA_PS,\n    \"Com_drop_user\":             DELTA_PS,\n    \"Com_drop_view\":             DELTA_PS,\n    \"Com_empty_query\":           DELTA_PS,\n    \"Com_execute_sql\":           DELTA_PS,\n    \"Com_flush\":                 DELTA_PS,\n    \"Com_grant\":                 DELTA_PS,\n    \"Com_ha_close\":              DELTA_PS,\n    \"Com_ha_open\":               DELTA_PS,\n    \"Com_ha_read\":               DELTA_PS,\n    \"Com_help\":                  DELTA_PS,\n    \"Com_insert\":                DELTA_PS,\n    \"Com_insert_select\":         DELTA_PS,\n    \"Com_install_plugin\":        DELTA_PS,\n    \"Com_kill\":                  DELTA_PS,\n    \"Com_load\":                  DELTA_PS,\n    \"Com_lock_tables\":           DELTA_PS,\n    \"Com_optimize\":              DELTA_PS,\n    \"Com_preload_keys\":          DELTA_PS,\n    \"Com_prepare_sql\":           DELTA_PS,\n    \"Com_purge\":                 DELTA_PS,\n    \"Com_purge_before_date\":     DELTA_PS,\n    \"Com_release_savepoint\":     DELTA_PS,\n    \"Com_rename_table\":          DELTA_PS,\n    \"Com_rename_user\":           DELTA_PS,\n    \"Com_repair\":                DELTA_PS,\n    \"Com_replace\":               DELTA_PS,\n    \"Com_replace_select\":        DELTA_PS,\n    \"Com_reset\":                 DELTA_PS,\n    \"Com_resignal\":              DELTA_PS,\n    \"Com_revoke\":                DELTA_PS,\n    \"Com_revoke_all\":            DELTA_PS,\n    \"Com_rollback\":              DELTA_PS,\n    \"Com_rollback_to_savepoint\": DELTA_PS,\n    \"Com_savepoint\":             DELTA_PS,\n    \"Com_select\":                DELTA_PS,\n    \"Com_set_option\":            DELTA_PS,\n    \"Com_signal\":                DELTA_PS,\n    \"Com_show_authors\":          DELTA_PS,\n    \"Com_show_binlog_events\":    DELTA_PS,\n    \"Com_show_binlogs\":          DELTA_PS,\n    \"Com_show_charsets\":         DELTA_PS,\n    \"Com_show_collations\":       DELTA_PS,\n    \"Com_show_contributors\":     DELTA_PS,\n    \"Com_show_create_db\":        DELTA_PS,\n    \"Com_show_create_event\":     DELTA_PS,\n    \"Com_show_create_func\":      DELTA_PS,\n    \"Com_show_create_proc\":      DELTA_PS,\n    \"Com_show_create_table\":     DELTA_PS,\n    \"Com_show_create_trigger\":   DELTA_PS,\n    \"Com_show_databases\":        DELTA_PS,\n    \"Com_show_engine_logs\":      DELTA_PS,\n    \"Com_show_engine_mutex\":     DELTA_PS,\n    \"Com_show_engine_status\":    DELTA_PS,\n    \"Com_show_events\":           DELTA_PS,\n    \"Com_show_errors\":           DELTA_PS,\n    \"Com_show_fields\":           DELTA_PS,\n    \"Com_show_function_status\":  DELTA_PS,\n    \"Com_show_grants\":           DELTA_PS,\n    \"Com_show_keys\":             DELTA_PS,\n    \"Com_show_master_status\":    DELTA_PS,\n    \"Com_show_open_tables\":      DELTA_PS,\n    \"Com_show_plugins\":          DELTA_PS,\n    \"Com_show_privileges\":       DELTA_PS,\n    \"Com_show_procedure_status\": DELTA_PS,\n    \"Com_show_processlist\":      DELTA_PS,\n    \"Com_show_profile\":          DELTA_PS,\n    \"Com_show_profiles\":         DELTA_PS,\n    \"Com_show_relaylog_events\":  DELTA_PS,\n    \"Com_show_slave_hosts\":      DELTA_PS,\n    \"Com_show_slave_status\":     DELTA_PS,\n    \"Com_show_status\":           DELTA_PS,\n    \"Com_show_storage_engines\":  DELTA_PS,\n    \"Com_show_table_status\":     DELTA_PS,\n    \"Com_show_tables\":           DELTA_PS,\n    \"Com_show_triggers\":         DELTA_PS,\n    \"Com_show_variables\":        DELTA_PS,\n    \"Com_show_warnings\":         DELTA_PS,\n    \"Com_slave_start\":           DELTA_PS,\n    \"Com_slave_stop\":            DELTA_PS,\n    \"Com_stmt_close\":            DELTA_PS,\n    \"Com_stmt_execute\":          DELTA_PS,\n    \"Com_stmt_fetch\":            DELTA_PS,\n    \"Com_stmt_prepare\":          DELTA_PS,\n    \"Com_stmt_reprepare\":        DELTA_PS,\n    \"Com_stmt_reset\":            DELTA_PS,\n    \"Com_stmt_send_long_data\":   DELTA_PS,\n    \"Com_truncate\":              DELTA_PS,\n    \"Com_uninstall_plugin\":      DELTA_PS,\n    \"Com_unlock_tables\":         DELTA_PS,\n    \"Com_update\":                DELTA_PS,\n    \"Com_update_multi\":          DELTA_PS,\n    \"Com_xa_commit\":             DELTA_PS,\n    \"Com_xa_end\":                DELTA_PS,\n    \"Com_xa_prepare\":            DELTA_PS,\n    \"Com_xa_recover\":            DELTA_PS,\n    \"Com_xa_rollback\":           DELTA_PS,\n    \"Com_xa_start\":              DELTA_PS,\n\n    \"Aborted_clients\":            DELTA_PS,\n    \"Aborted_connects\":           DELTA_PS,\n    \"Access_denied_errors\":       DELTA_PS,\n    \"Binlog_bytes_written\":       DELTA_PS,\n    \"Binlog_cache_disk_use\":      DELTA_PS,\n    \"Binlog_cache_use\":           DELTA_PS,\n    \"Binlog_stmt_cache_disk_use\": DELTA_PS,\n    \"Binlog_stmt_cache_use\":      DELTA_PS,\n    \"Bytes_received\":             DELTA_PS,\n    \"Bytes_sent\":                 DELTA_PS,\n    \"Connections\":                DELTA_PS,\n    \"Created_tmp_disk_tables\":    DELTA_PS,\n    \"Created_tmp_files\":          DELTA_PS,\n    \"Created_tmp_tables\":         DELTA_PS,\n    \"Handler_delete\":             DELTA_PS,\n    \"Handler_read_first\":         DELTA_PS,\n    \"Handler_read_key\":           DELTA_PS,\n    \"Handler_read_last\":          DELTA_PS,\n    \"Handler_read_next\":          DELTA_PS,\n    \"Handler_read_prev\":          DELTA_PS,\n    \"Handler_read_rnd\":           DELTA_PS,\n    \"Handler_read_rnd_next\":      DELTA_PS,\n    \"Handler_update\":             DELTA_PS,\n    \"Handler_write\":              DELTA_PS,\n    \"Opened_files\":               DELTA_PS,\n    \"Opened_tables\":              DELTA_PS,\n    \"Opened_table_definitions\":   DELTA_PS,\n    \"Qcache_hits\":                DELTA_PS,\n    \"Qcache_inserts\":             DELTA_PS,\n    \"Qcache_lowmem_prunes\":       DELTA_PS,\n    \"Qcache_not_cached\":          DELTA_PS,\n    \"Queries\":                    DELTA_PS,\n    \"Questions\":                  DELTA_PS,\n    \"Select_full_join\":           DELTA_PS,\n    \"Select_full_range_join\":     DELTA_PS,\n    \"Select_range_check\":         DELTA_PS,\n    \"Select_scan\":                DELTA_PS,\n    \"Slow_queries\":               DELTA_PS,\n    \"Sort_merge_passes\":          DELTA_PS,\n    \"Sort_range\":                 DELTA_PS,\n    \"Sort_rows\":                  DELTA_PS,\n    \"Sort_scan\":                  DELTA_PS,\n    \"Table_locks_immediate\":      DELTA_PS,\n    \"Table_locks_waited\":         DELTA_PS,\n    \"Threads_created\":            DELTA_PS,\n}\n\ntype MysqlIns struct {\n    Host string\n    Port int\n    Tag  string\n}\n\nfunc dataType(key_ string) string {\n    if v, ok := DataType[key_]; ok {\n        return v\n    }\n    return ORIGIN\n}\n\ntype MetaData struct {\n    Metric      string      `json:\"metric\"`      //key\n    Endpoint    string      `json:\"endpoint\"`    //hostname\n    Value       interface{} `json:\"value\"`       // number or string\n    CounterType string      `json:\"counterType\"` // GAUGE  原值   COUNTER 差值(ps)\n    Tags        string      `json:\"tags\"`        // port=3306,k=v\n    Timestamp   int64       `json:\"timestamp\"`\n    Step        int64       `json:\"step\"`\n}\n\nfunc (m *MetaData) String() string {\n    s := fmt.Sprintf(\"MetaData Metric:%s Endpoint:%s Value:%v CounterType:%s Tags:%s Timestamp:%d Step:%d\",\n        m.Metric, m.Endpoint, m.Value, m.CounterType, m.Tags, m.Timestamp, m.Step)\n    return s\n}\n\nfunc NewMetric(name string) *MetaData {\n    return &MetaData{\n        Metric:      strings.ToLower(name), #name 改为strings.ToLower(name)\n        Endpoint:    hostname(),\n        CounterType: dataType(name),\n        Tags:        fmt.Sprintf(\"port=%d\", cfg.Port),\n        Timestamp:   time.Now().Unix(),\n        Step:        60,\n    }\n}\n\nfunc hostname() string {\n    host := cfg.Endpoint\n    if host != \"\" {\n        return host\n    }\n    host, err := os.Hostname()\n    if err != nil {\n        host = cfg.Host\n    }\n    return host\n}\n\nfunc (m *MetaData) SetValue(v interface{}) {\n    m.Value = v\n}\n```\n\n之后在mymon目录 执行\n```\ngo get ./...\ngo build -o mymon\n```\n即可 \n\n之后可以去数据库手动删掉openfalcon 过期的metric(但是新的metric并没有更新，反而旧metric没了数据，可以试着修改endpoint，然后去数据区删除旧的endpoint)\n\n\n","slug":"falcon问题处理","published":1,"updated":"2017-06-23T05:46:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5s00148tzzskgm783w","content":"<h2 id=\"grafana上面不支持open-falcon的大写metricmymon-metric更改小写\"><a href=\"#grafana上面不支持open-falcon的大写metric-mymon-metric更改小写\" class=\"headerlink\" title=\"grafana上面不支持open-falcon的大写metric(mymon metric更改小写)\"></a>grafana上面不支持open-falcon的大写metric(mymon metric更改小写)</h2><blockquote>\n<p>(这是openfalcon的bug，falcon-plus中已经修复)</p>\n</blockquote>\n<p>但是我们现在使用的falcon没有升级，而且升级的得计划暂时没有安排。我们只能手动更改metric不用大写尽量用小写。<br>以下记录mymon更改。<br><strong>mymon</strong>是使用go语言编写的，用来监控mysql的插件。<a href=\"https://github.com/open-falcon/mymon\" target=\"_blank\" rel=\"external\">mymon代码链接</a><br>由于之前的mymon是通过ansible 脚本直接git pull下来的，所以有源码在，可以更改之后再build一下。<br>找到<code>metric.go</code>修改大写的metric为小写。 修改完脚本如下。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div><div class=\"line\">173</div><div class=\"line\">174</div><div class=\"line\">175</div><div class=\"line\">176</div><div class=\"line\">177</div><div class=\"line\">178</div><div class=\"line\">179</div><div class=\"line\">180</div><div class=\"line\">181</div><div class=\"line\">182</div><div class=\"line\">183</div><div class=\"line\">184</div><div class=\"line\">185</div><div class=\"line\">186</div><div class=\"line\">187</div><div class=\"line\">188</div><div class=\"line\">189</div><div class=\"line\">190</div><div class=\"line\">191</div><div class=\"line\">192</div><div class=\"line\">193</div><div class=\"line\">194</div><div class=\"line\">195</div><div class=\"line\">196</div><div class=\"line\">197</div><div class=\"line\">198</div><div class=\"line\">199</div><div class=\"line\">200</div><div class=\"line\">201</div><div class=\"line\">202</div><div class=\"line\">203</div><div class=\"line\">204</div><div class=\"line\">205</div><div class=\"line\">206</div><div class=\"line\">207</div><div class=\"line\">208</div><div class=\"line\">209</div><div class=\"line\">210</div><div class=\"line\">211</div><div class=\"line\">212</div><div class=\"line\">213</div><div class=\"line\">214</div><div class=\"line\">215</div><div class=\"line\">216</div><div class=\"line\">217</div><div class=\"line\">218</div><div class=\"line\">219</div><div class=\"line\">220</div><div class=\"line\">221</div><div class=\"line\">222</div><div class=\"line\">223</div><div class=\"line\">224</div><div class=\"line\">225</div><div class=\"line\">226</div><div class=\"line\">227</div><div class=\"line\">228</div><div class=\"line\">229</div><div class=\"line\">230</div><div class=\"line\">231</div><div class=\"line\">232</div><div class=\"line\">233</div><div class=\"line\">234</div><div class=\"line\">235</div><div class=\"line\">236</div><div class=\"line\">237</div><div class=\"line\">238</div><div class=\"line\">239</div><div class=\"line\">240</div><div class=\"line\">241</div><div class=\"line\">242</div><div class=\"line\">243</div><div class=\"line\">244</div><div class=\"line\">245</div><div class=\"line\">246</div><div class=\"line\">247</div><div class=\"line\">248</div><div class=\"line\">249</div><div class=\"line\">250</div><div class=\"line\">251</div><div class=\"line\">252</div><div class=\"line\">253</div><div class=\"line\">254</div><div class=\"line\">255</div><div class=\"line\">256</div><div class=\"line\">257</div><div class=\"line\">258</div><div class=\"line\">259</div><div class=\"line\">260</div><div class=\"line\">261</div><div class=\"line\">262</div><div class=\"line\">263</div><div class=\"line\">264</div><div class=\"line\">265</div><div class=\"line\">266</div><div class=\"line\">267</div><div class=\"line\">268</div><div class=\"line\">269</div><div class=\"line\">270</div><div class=\"line\">271</div><div class=\"line\">272</div><div class=\"line\">273</div><div class=\"line\">274</div><div class=\"line\">275</div><div class=\"line\">276</div><div class=\"line\">277</div><div class=\"line\">278</div><div class=\"line\">279</div><div class=\"line\">280</div><div class=\"line\">281</div><div class=\"line\">282</div><div class=\"line\">283</div><div class=\"line\">284</div><div class=\"line\">285</div><div class=\"line\">286</div><div class=\"line\">287</div><div class=\"line\">288</div><div class=\"line\">289</div><div class=\"line\">290</div><div class=\"line\">291</div></pre></td><td class=\"code\"><pre><div class=\"line\">package main</div><div class=\"line\"></div><div class=\"line\">import (</div><div class=\"line\">    &quot;fmt&quot;</div><div class=\"line\">    &quot;os&quot;</div><div class=\"line\">    &quot;time&quot;</div><div class=\"line\">    &quot;strings&quot; #添加string</div><div class=\"line\">)</div><div class=\"line\"></div><div class=\"line\">const (</div><div class=\"line\">    TIME_OUT = 30</div><div class=\"line\"></div><div class=\"line\">    ORIGIN   = &quot;GAUGE&quot;</div><div class=\"line\">    DELTA_PS = &quot;COUNTER&quot;</div><div class=\"line\">    DELTA    = &quot;&quot;</div><div class=\"line\">)</div><div class=\"line\"></div><div class=\"line\">// COUNTER: Speed per second</div><div class=\"line\">// GAUGE: Original, DEFAULT</div><div class=\"line\">var DataType = map[string]string&#123;</div><div class=\"line\">    &quot;Innodb_buffer_pool_reads&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Innodb_buffer_pool_read_requests&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Innodb_compress_time&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_fsyncs&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_read&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_reads&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_writes&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_written&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Innodb_last_checkpoint_at&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Innodb_log_flushed_up_to&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Innodb_log_sequence_number&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Innodb_mutex_os_waits&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Innodb_mutex_spin_rounds&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Innodb_mutex_spin_waits&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Innodb_pages_flushed_up_to&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_deleted&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_inserted&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_locked&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_modified&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_read&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_updated&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Innodb_row_lock_time&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Innodb_row_lock_waits&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Innodb_uncompress_time&quot;:           DELTA_PS,</div><div class=\"line\"></div><div class=\"line\">    &quot;Binlog_event_count&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Binlog_number&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Slave_count&quot;:        DELTA_PS,</div><div class=\"line\"></div><div class=\"line\">    &quot;Com_admin_commands&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_assign_to_keycache&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_db&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_db_upgrade&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_event&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_function&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_procedure&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_server&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_table&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_tablespace&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_analyze&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_begin&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_binlog&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_call_procedure&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_change_db&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_change_master&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_check&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_checksum&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_commit&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_create_db&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_create_event&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_create_function&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Com_create_index&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_create_procedure&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_create_server&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_create_table&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_create_trigger&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_create_udf&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_create_user&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_create_view&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_dealloc_sql&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_delete&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_delete_multi&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_do&quot;:                    DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_db&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_event&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_function&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_index&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_procedure&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_server&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_table&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_trigger&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_user&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_view&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_empty_query&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_execute_sql&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_flush&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_grant&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_ha_close&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_ha_open&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_ha_read&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_help&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Com_insert&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_insert_select&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_install_plugin&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_kill&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Com_load&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Com_lock_tables&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_optimize&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_preload_keys&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_prepare_sql&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_purge&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_purge_before_date&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_release_savepoint&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_rename_table&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_rename_user&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_repair&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_replace&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_replace_select&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_reset&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_resignal&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_revoke&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_revoke_all&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_rollback&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_rollback_to_savepoint&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Com_savepoint&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_select&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_set_option&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_signal&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_show_authors&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_show_binlog_events&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Com_show_binlogs&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_show_charsets&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_show_collations&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Com_show_contributors&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_db&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_event&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_func&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_proc&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_table&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_trigger&quot;:   DELTA_PS,</div><div class=\"line\">    &quot;Com_show_databases&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_show_engine_logs&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_engine_mutex&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_engine_status&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Com_show_events&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_errors&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_fields&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_function_status&quot;:  DELTA_PS,</div><div class=\"line\">    &quot;Com_show_grants&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_keys&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_show_master_status&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Com_show_open_tables&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_plugins&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_show_privileges&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Com_show_procedure_status&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Com_show_processlist&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_profile&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_show_profiles&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_show_relaylog_events&quot;:  DELTA_PS,</div><div class=\"line\">    &quot;Com_show_slave_hosts&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_slave_status&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_status&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_storage_engines&quot;:  DELTA_PS,</div><div class=\"line\">    &quot;Com_show_table_status&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_tables&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_triggers&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_show_variables&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_show_warnings&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_slave_start&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_slave_stop&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_close&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_execute&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_fetch&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_prepare&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_reprepare&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_reset&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_send_long_data&quot;:   DELTA_PS,</div><div class=\"line\">    &quot;Com_truncate&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_uninstall_plugin&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_unlock_tables&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_update&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_update_multi&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_commit&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_end&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_prepare&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_recover&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_rollback&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_start&quot;:              DELTA_PS,</div><div class=\"line\"></div><div class=\"line\">    &quot;Aborted_clients&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Aborted_connects&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Access_denied_errors&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Binlog_bytes_written&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Binlog_cache_disk_use&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Binlog_cache_use&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Binlog_stmt_cache_disk_use&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Binlog_stmt_cache_use&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Bytes_received&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Bytes_sent&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Connections&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Created_tmp_disk_tables&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Created_tmp_files&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Created_tmp_tables&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Handler_delete&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_first&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_key&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_last&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_next&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_prev&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_rnd&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_rnd_next&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Handler_update&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Handler_write&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Opened_files&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Opened_tables&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Opened_table_definitions&quot;:   DELTA_PS,</div><div class=\"line\">    &quot;Qcache_hits&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Qcache_inserts&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Qcache_lowmem_prunes&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Qcache_not_cached&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Queries&quot;:                    DELTA_PS,</div><div class=\"line\">    &quot;Questions&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Select_full_join&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Select_full_range_join&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Select_range_check&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Select_scan&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Slow_queries&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Sort_merge_passes&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Sort_range&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Sort_rows&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Sort_scan&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Table_locks_immediate&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Table_locks_waited&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Threads_created&quot;:            DELTA_PS,</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">type MysqlIns struct &#123;</div><div class=\"line\">    Host string</div><div class=\"line\">    Port int</div><div class=\"line\">    Tag  string</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func dataType(key_ string) string &#123;</div><div class=\"line\">    if v, ok := DataType[key_]; ok &#123;</div><div class=\"line\">        return v</div><div class=\"line\">    &#125;</div><div class=\"line\">    return ORIGIN</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">type MetaData struct &#123;</div><div class=\"line\">    Metric      string      `json:&quot;metric&quot;`      //key</div><div class=\"line\">    Endpoint    string      `json:&quot;endpoint&quot;`    //hostname</div><div class=\"line\">    Value       interface&#123;&#125; `json:&quot;value&quot;`       // number or string</div><div class=\"line\">    CounterType string      `json:&quot;counterType&quot;` // GAUGE  原值   COUNTER 差值(ps)</div><div class=\"line\">    Tags        string      `json:&quot;tags&quot;`        // port=3306,k=v</div><div class=\"line\">    Timestamp   int64       `json:&quot;timestamp&quot;`</div><div class=\"line\">    Step        int64       `json:&quot;step&quot;`</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func (m *MetaData) String() string &#123;</div><div class=\"line\">    s := fmt.Sprintf(&quot;MetaData Metric:%s Endpoint:%s Value:%v CounterType:%s Tags:%s Timestamp:%d Step:%d&quot;,</div><div class=\"line\">        m.Metric, m.Endpoint, m.Value, m.CounterType, m.Tags, m.Timestamp, m.Step)</div><div class=\"line\">    return s</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func NewMetric(name string) *MetaData &#123;</div><div class=\"line\">    return &amp;MetaData&#123;</div><div class=\"line\">        Metric:      strings.ToLower(name), #name 改为strings.ToLower(name)</div><div class=\"line\">        Endpoint:    hostname(),</div><div class=\"line\">        CounterType: dataType(name),</div><div class=\"line\">        Tags:        fmt.Sprintf(&quot;port=%d&quot;, cfg.Port),</div><div class=\"line\">        Timestamp:   time.Now().Unix(),</div><div class=\"line\">        Step:        60,</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func hostname() string &#123;</div><div class=\"line\">    host := cfg.Endpoint</div><div class=\"line\">    if host != &quot;&quot; &#123;</div><div class=\"line\">        return host</div><div class=\"line\">    &#125;</div><div class=\"line\">    host, err := os.Hostname()</div><div class=\"line\">    if err != nil &#123;</div><div class=\"line\">        host = cfg.Host</div><div class=\"line\">    &#125;</div><div class=\"line\">    return host</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func (m *MetaData) SetValue(v interface&#123;&#125;) &#123;</div><div class=\"line\">    m.Value = v</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>之后在mymon目录 执行<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">go get ./...</div><div class=\"line\">go build -o mymon</div></pre></td></tr></table></figure></p>\n<p>即可 </p>\n<p>之后可以去数据库手动删掉openfalcon 过期的metric(但是新的metric并没有更新，反而旧metric没了数据，可以试着修改endpoint，然后去数据区删除旧的endpoint)</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"grafana上面不支持open-falcon的大写metric-mymon-metric更改小写\"><a href=\"#grafana上面不支持open-falcon的大写metric-mymon-metric更改小写\" class=\"headerlink\" title=\"grafana上面不支持open-falcon的大写metric(mymon metric更改小写)\"></a>grafana上面不支持open-falcon的大写metric(mymon metric更改小写)</h2><blockquote>\n<p>(这是openfalcon的bug，falcon-plus中已经修复)</p>\n</blockquote>\n<p>但是我们现在使用的falcon没有升级，而且升级的得计划暂时没有安排。我们只能手动更改metric不用大写尽量用小写。<br>以下记录mymon更改。<br><strong>mymon</strong>是使用go语言编写的，用来监控mysql的插件。<a href=\"https://github.com/open-falcon/mymon\" target=\"_blank\" rel=\"external\">mymon代码链接</a><br>由于之前的mymon是通过ansible 脚本直接git pull下来的，所以有源码在，可以更改之后再build一下。<br>找到<code>metric.go</code>修改大写的metric为小写。 修改完脚本如下。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div><div class=\"line\">153</div><div class=\"line\">154</div><div class=\"line\">155</div><div class=\"line\">156</div><div class=\"line\">157</div><div class=\"line\">158</div><div class=\"line\">159</div><div class=\"line\">160</div><div class=\"line\">161</div><div class=\"line\">162</div><div class=\"line\">163</div><div class=\"line\">164</div><div class=\"line\">165</div><div class=\"line\">166</div><div class=\"line\">167</div><div class=\"line\">168</div><div class=\"line\">169</div><div class=\"line\">170</div><div class=\"line\">171</div><div class=\"line\">172</div><div class=\"line\">173</div><div class=\"line\">174</div><div class=\"line\">175</div><div class=\"line\">176</div><div class=\"line\">177</div><div class=\"line\">178</div><div class=\"line\">179</div><div class=\"line\">180</div><div class=\"line\">181</div><div class=\"line\">182</div><div class=\"line\">183</div><div class=\"line\">184</div><div class=\"line\">185</div><div class=\"line\">186</div><div class=\"line\">187</div><div class=\"line\">188</div><div class=\"line\">189</div><div class=\"line\">190</div><div class=\"line\">191</div><div class=\"line\">192</div><div class=\"line\">193</div><div class=\"line\">194</div><div class=\"line\">195</div><div class=\"line\">196</div><div class=\"line\">197</div><div class=\"line\">198</div><div class=\"line\">199</div><div class=\"line\">200</div><div class=\"line\">201</div><div class=\"line\">202</div><div class=\"line\">203</div><div class=\"line\">204</div><div class=\"line\">205</div><div class=\"line\">206</div><div class=\"line\">207</div><div class=\"line\">208</div><div class=\"line\">209</div><div class=\"line\">210</div><div class=\"line\">211</div><div class=\"line\">212</div><div class=\"line\">213</div><div class=\"line\">214</div><div class=\"line\">215</div><div class=\"line\">216</div><div class=\"line\">217</div><div class=\"line\">218</div><div class=\"line\">219</div><div class=\"line\">220</div><div class=\"line\">221</div><div class=\"line\">222</div><div class=\"line\">223</div><div class=\"line\">224</div><div class=\"line\">225</div><div class=\"line\">226</div><div class=\"line\">227</div><div class=\"line\">228</div><div class=\"line\">229</div><div class=\"line\">230</div><div class=\"line\">231</div><div class=\"line\">232</div><div class=\"line\">233</div><div class=\"line\">234</div><div class=\"line\">235</div><div class=\"line\">236</div><div class=\"line\">237</div><div class=\"line\">238</div><div class=\"line\">239</div><div class=\"line\">240</div><div class=\"line\">241</div><div class=\"line\">242</div><div class=\"line\">243</div><div class=\"line\">244</div><div class=\"line\">245</div><div class=\"line\">246</div><div class=\"line\">247</div><div class=\"line\">248</div><div class=\"line\">249</div><div class=\"line\">250</div><div class=\"line\">251</div><div class=\"line\">252</div><div class=\"line\">253</div><div class=\"line\">254</div><div class=\"line\">255</div><div class=\"line\">256</div><div class=\"line\">257</div><div class=\"line\">258</div><div class=\"line\">259</div><div class=\"line\">260</div><div class=\"line\">261</div><div class=\"line\">262</div><div class=\"line\">263</div><div class=\"line\">264</div><div class=\"line\">265</div><div class=\"line\">266</div><div class=\"line\">267</div><div class=\"line\">268</div><div class=\"line\">269</div><div class=\"line\">270</div><div class=\"line\">271</div><div class=\"line\">272</div><div class=\"line\">273</div><div class=\"line\">274</div><div class=\"line\">275</div><div class=\"line\">276</div><div class=\"line\">277</div><div class=\"line\">278</div><div class=\"line\">279</div><div class=\"line\">280</div><div class=\"line\">281</div><div class=\"line\">282</div><div class=\"line\">283</div><div class=\"line\">284</div><div class=\"line\">285</div><div class=\"line\">286</div><div class=\"line\">287</div><div class=\"line\">288</div><div class=\"line\">289</div><div class=\"line\">290</div><div class=\"line\">291</div></pre></td><td class=\"code\"><pre><div class=\"line\">package main</div><div class=\"line\"></div><div class=\"line\">import (</div><div class=\"line\">    &quot;fmt&quot;</div><div class=\"line\">    &quot;os&quot;</div><div class=\"line\">    &quot;time&quot;</div><div class=\"line\">    &quot;strings&quot; #添加string</div><div class=\"line\">)</div><div class=\"line\"></div><div class=\"line\">const (</div><div class=\"line\">    TIME_OUT = 30</div><div class=\"line\"></div><div class=\"line\">    ORIGIN   = &quot;GAUGE&quot;</div><div class=\"line\">    DELTA_PS = &quot;COUNTER&quot;</div><div class=\"line\">    DELTA    = &quot;&quot;</div><div class=\"line\">)</div><div class=\"line\"></div><div class=\"line\">// COUNTER: Speed per second</div><div class=\"line\">// GAUGE: Original, DEFAULT</div><div class=\"line\">var DataType = map[string]string&#123;</div><div class=\"line\">    &quot;Innodb_buffer_pool_reads&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Innodb_buffer_pool_read_requests&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Innodb_compress_time&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_fsyncs&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_read&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_reads&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_writes&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Innodb_data_written&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Innodb_last_checkpoint_at&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Innodb_log_flushed_up_to&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Innodb_log_sequence_number&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Innodb_mutex_os_waits&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Innodb_mutex_spin_rounds&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Innodb_mutex_spin_waits&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Innodb_pages_flushed_up_to&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_deleted&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_inserted&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_locked&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_modified&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_read&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Innodb_rows_updated&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Innodb_row_lock_time&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Innodb_row_lock_waits&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Innodb_uncompress_time&quot;:           DELTA_PS,</div><div class=\"line\"></div><div class=\"line\">    &quot;Binlog_event_count&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Binlog_number&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Slave_count&quot;:        DELTA_PS,</div><div class=\"line\"></div><div class=\"line\">    &quot;Com_admin_commands&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_assign_to_keycache&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_db&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_db_upgrade&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_event&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_function&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_procedure&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_server&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_table&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_alter_tablespace&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_analyze&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_begin&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_binlog&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_call_procedure&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_change_db&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_change_master&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_check&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_checksum&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_commit&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_create_db&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_create_event&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_create_function&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Com_create_index&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_create_procedure&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_create_server&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_create_table&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_create_trigger&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_create_udf&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_create_user&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_create_view&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_dealloc_sql&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_delete&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_delete_multi&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_do&quot;:                    DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_db&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_event&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_function&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_index&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_procedure&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_server&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_table&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_trigger&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_user&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_drop_view&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_empty_query&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_execute_sql&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_flush&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_grant&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_ha_close&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_ha_open&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_ha_read&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_help&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Com_insert&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_insert_select&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_install_plugin&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_kill&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Com_load&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Com_lock_tables&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_optimize&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_preload_keys&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_prepare_sql&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_purge&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_purge_before_date&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_release_savepoint&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_rename_table&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_rename_user&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_repair&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_replace&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Com_replace_select&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_reset&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Com_resignal&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_revoke&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_revoke_all&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_rollback&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_rollback_to_savepoint&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Com_savepoint&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_select&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_set_option&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_signal&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_show_authors&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_show_binlog_events&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Com_show_binlogs&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_show_charsets&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_show_collations&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Com_show_contributors&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_db&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_event&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_func&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_proc&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_table&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_create_trigger&quot;:   DELTA_PS,</div><div class=\"line\">    &quot;Com_show_databases&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_show_engine_logs&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_engine_mutex&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_engine_status&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Com_show_events&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_errors&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_fields&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_function_status&quot;:  DELTA_PS,</div><div class=\"line\">    &quot;Com_show_grants&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_keys&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_show_master_status&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Com_show_open_tables&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_plugins&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_show_privileges&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Com_show_procedure_status&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Com_show_processlist&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_profile&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_show_profiles&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_show_relaylog_events&quot;:  DELTA_PS,</div><div class=\"line\">    &quot;Com_show_slave_hosts&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_show_slave_status&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_status&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_storage_engines&quot;:  DELTA_PS,</div><div class=\"line\">    &quot;Com_show_table_status&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Com_show_tables&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_show_triggers&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_show_variables&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_show_warnings&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_slave_start&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_slave_stop&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_close&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_execute&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_fetch&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_prepare&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_reprepare&quot;:        DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_reset&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_stmt_send_long_data&quot;:   DELTA_PS,</div><div class=\"line\">    &quot;Com_truncate&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Com_uninstall_plugin&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Com_unlock_tables&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Com_update&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_update_multi&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_commit&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_end&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_prepare&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_recover&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_rollback&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Com_xa_start&quot;:              DELTA_PS,</div><div class=\"line\"></div><div class=\"line\">    &quot;Aborted_clients&quot;:            DELTA_PS,</div><div class=\"line\">    &quot;Aborted_connects&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Access_denied_errors&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Binlog_bytes_written&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Binlog_cache_disk_use&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Binlog_cache_use&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Binlog_stmt_cache_disk_use&quot;: DELTA_PS,</div><div class=\"line\">    &quot;Binlog_stmt_cache_use&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Bytes_received&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Bytes_sent&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Connections&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Created_tmp_disk_tables&quot;:    DELTA_PS,</div><div class=\"line\">    &quot;Created_tmp_files&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Created_tmp_tables&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Handler_delete&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_first&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_key&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_last&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_next&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_prev&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_rnd&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Handler_read_rnd_next&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Handler_update&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Handler_write&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Opened_files&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Opened_tables&quot;:              DELTA_PS,</div><div class=\"line\">    &quot;Opened_table_definitions&quot;:   DELTA_PS,</div><div class=\"line\">    &quot;Qcache_hits&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Qcache_inserts&quot;:             DELTA_PS,</div><div class=\"line\">    &quot;Qcache_lowmem_prunes&quot;:       DELTA_PS,</div><div class=\"line\">    &quot;Qcache_not_cached&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Queries&quot;:                    DELTA_PS,</div><div class=\"line\">    &quot;Questions&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Select_full_join&quot;:           DELTA_PS,</div><div class=\"line\">    &quot;Select_full_range_join&quot;:     DELTA_PS,</div><div class=\"line\">    &quot;Select_range_check&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Select_scan&quot;:                DELTA_PS,</div><div class=\"line\">    &quot;Slow_queries&quot;:               DELTA_PS,</div><div class=\"line\">    &quot;Sort_merge_passes&quot;:          DELTA_PS,</div><div class=\"line\">    &quot;Sort_range&quot;:                 DELTA_PS,</div><div class=\"line\">    &quot;Sort_rows&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Sort_scan&quot;:                  DELTA_PS,</div><div class=\"line\">    &quot;Table_locks_immediate&quot;:      DELTA_PS,</div><div class=\"line\">    &quot;Table_locks_waited&quot;:         DELTA_PS,</div><div class=\"line\">    &quot;Threads_created&quot;:            DELTA_PS,</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">type MysqlIns struct &#123;</div><div class=\"line\">    Host string</div><div class=\"line\">    Port int</div><div class=\"line\">    Tag  string</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func dataType(key_ string) string &#123;</div><div class=\"line\">    if v, ok := DataType[key_]; ok &#123;</div><div class=\"line\">        return v</div><div class=\"line\">    &#125;</div><div class=\"line\">    return ORIGIN</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">type MetaData struct &#123;</div><div class=\"line\">    Metric      string      `json:&quot;metric&quot;`      //key</div><div class=\"line\">    Endpoint    string      `json:&quot;endpoint&quot;`    //hostname</div><div class=\"line\">    Value       interface&#123;&#125; `json:&quot;value&quot;`       // number or string</div><div class=\"line\">    CounterType string      `json:&quot;counterType&quot;` // GAUGE  原值   COUNTER 差值(ps)</div><div class=\"line\">    Tags        string      `json:&quot;tags&quot;`        // port=3306,k=v</div><div class=\"line\">    Timestamp   int64       `json:&quot;timestamp&quot;`</div><div class=\"line\">    Step        int64       `json:&quot;step&quot;`</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func (m *MetaData) String() string &#123;</div><div class=\"line\">    s := fmt.Sprintf(&quot;MetaData Metric:%s Endpoint:%s Value:%v CounterType:%s Tags:%s Timestamp:%d Step:%d&quot;,</div><div class=\"line\">        m.Metric, m.Endpoint, m.Value, m.CounterType, m.Tags, m.Timestamp, m.Step)</div><div class=\"line\">    return s</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func NewMetric(name string) *MetaData &#123;</div><div class=\"line\">    return &amp;MetaData&#123;</div><div class=\"line\">        Metric:      strings.ToLower(name), #name 改为strings.ToLower(name)</div><div class=\"line\">        Endpoint:    hostname(),</div><div class=\"line\">        CounterType: dataType(name),</div><div class=\"line\">        Tags:        fmt.Sprintf(&quot;port=%d&quot;, cfg.Port),</div><div class=\"line\">        Timestamp:   time.Now().Unix(),</div><div class=\"line\">        Step:        60,</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func hostname() string &#123;</div><div class=\"line\">    host := cfg.Endpoint</div><div class=\"line\">    if host != &quot;&quot; &#123;</div><div class=\"line\">        return host</div><div class=\"line\">    &#125;</div><div class=\"line\">    host, err := os.Hostname()</div><div class=\"line\">    if err != nil &#123;</div><div class=\"line\">        host = cfg.Host</div><div class=\"line\">    &#125;</div><div class=\"line\">    return host</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func (m *MetaData) SetValue(v interface&#123;&#125;) &#123;</div><div class=\"line\">    m.Value = v</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>之后在mymon目录 执行<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">go get ./...</div><div class=\"line\">go build -o mymon</div></pre></td></tr></table></figure></p>\n<p>即可 </p>\n<p>之后可以去数据库手动删掉openfalcon 过期的metric(但是新的metric并没有更新，反而旧metric没了数据，可以试着修改endpoint，然后去数据区删除旧的endpoint)</p>\n"},{"title":"docker是什么","date":"2017-06-23T06:43:53.000Z","_content":"\n>之前公司在我来之前有个哥们儿是负责docker的，但是一直没有推广起来，测试环境都没有，这个项目就不了了之了。但是就在前几天跟ucloud架构交流，说起他之前在云上搞docker根据业务自动扩容，带宽自动调整。说的我真的眼睛放光。决心研究一下。\n\n我去年搞过虚拟化产品对虚拟化的产品做了调研。做了proxmox，类似kvm给测试服务用，开了几台虚拟机，这个产品支持机器热迁移等等。(这个博客刚开始写没多久，以后会把这些笔记也都放上来)\n其实虚拟化可以分为以下几种\n# 对比传统虚拟化\n## 传统虚拟化\n\n最流行的虚拟化方法，使用Hypervisor这种中间层软件，在虚拟服务器和底层硬件之间建立一个抽象层。\n\nHypervisor可以捕获CPU指令，为指令访问硬件控制器和外设充当中介。因而，完全虚拟化技术几乎能让任何一款操作系统不用改动就能安装到虚拟服务器上，而它们不知道自己运行在虚拟化环境下。主要缺点是，性能方面不如裸机，因为Hypervisor需要占用一些资源，给处理器带来开销。\n\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-23%20%E4%B8%8B%E5%8D%883.34.17.png)\n\n## 操作系统层虚拟化\n\n实现虚拟化还有一个方法，那就是在操作系统层面增添虚拟服务器功能。就操作系统层的虚拟化而言，没有独立的Hypervisor层。相反主机操作系统本身就负责在多个虚拟服务器之间分配硬件资源，并且让这些服务器彼此独立。一个明显的区别是，如果使用操作系统层虚拟化，所有虚拟服务器必须运行同一操作系统。\n\n虽然操作系统层虚拟化的灵活性比较差，但本机速度性能比较高。此外，由于架构在所有虚拟服务器上使用单一、标准的操作系统，管理起来比异构环境要容易。\n![](http://or2jd66dq.bkt.clouddn.com/docker%E8%99%9A%E6%8B%9F%E5%8C%96.png)\n`docker`属于操作系统层面的虚拟化。\n传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。它与传统hyper-V 的区别在于理念，之前的虚拟化都是以操作系统为中心的，而docker是以应用为中心，把应用的环境代码等打包成镜像直接发布。服务启动也是秒级的。\n\n\n# docker优势\n\n- 更高效的利用系统资源\n- 更快速的启动时间\n- 一致的运行环境\n- 持续交付和部署\n- 更轻松的迁移\n- 更轻松的维护和扩展\n\n这些优势都是运维喜欢的，所以运维要推行docker。 \n","source":"_posts/docker是什么.md","raw":"---\ntitle: docker是什么\ndate: 2017-06-23 14:43:53\ntags: docker\ncategories: docker\n---\n\n>之前公司在我来之前有个哥们儿是负责docker的，但是一直没有推广起来，测试环境都没有，这个项目就不了了之了。但是就在前几天跟ucloud架构交流，说起他之前在云上搞docker根据业务自动扩容，带宽自动调整。说的我真的眼睛放光。决心研究一下。\n\n我去年搞过虚拟化产品对虚拟化的产品做了调研。做了proxmox，类似kvm给测试服务用，开了几台虚拟机，这个产品支持机器热迁移等等。(这个博客刚开始写没多久，以后会把这些笔记也都放上来)\n其实虚拟化可以分为以下几种\n# 对比传统虚拟化\n## 传统虚拟化\n\n最流行的虚拟化方法，使用Hypervisor这种中间层软件，在虚拟服务器和底层硬件之间建立一个抽象层。\n\nHypervisor可以捕获CPU指令，为指令访问硬件控制器和外设充当中介。因而，完全虚拟化技术几乎能让任何一款操作系统不用改动就能安装到虚拟服务器上，而它们不知道自己运行在虚拟化环境下。主要缺点是，性能方面不如裸机，因为Hypervisor需要占用一些资源，给处理器带来开销。\n\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-23%20%E4%B8%8B%E5%8D%883.34.17.png)\n\n## 操作系统层虚拟化\n\n实现虚拟化还有一个方法，那就是在操作系统层面增添虚拟服务器功能。就操作系统层的虚拟化而言，没有独立的Hypervisor层。相反主机操作系统本身就负责在多个虚拟服务器之间分配硬件资源，并且让这些服务器彼此独立。一个明显的区别是，如果使用操作系统层虚拟化，所有虚拟服务器必须运行同一操作系统。\n\n虽然操作系统层虚拟化的灵活性比较差，但本机速度性能比较高。此外，由于架构在所有虚拟服务器上使用单一、标准的操作系统，管理起来比异构环境要容易。\n![](http://or2jd66dq.bkt.clouddn.com/docker%E8%99%9A%E6%8B%9F%E5%8C%96.png)\n`docker`属于操作系统层面的虚拟化。\n传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。它与传统hyper-V 的区别在于理念，之前的虚拟化都是以操作系统为中心的，而docker是以应用为中心，把应用的环境代码等打包成镜像直接发布。服务启动也是秒级的。\n\n\n# docker优势\n\n- 更高效的利用系统资源\n- 更快速的启动时间\n- 一致的运行环境\n- 持续交付和部署\n- 更轻松的迁移\n- 更轻松的维护和扩展\n\n这些优势都是运维喜欢的，所以运维要推行docker。 \n","slug":"docker是什么","published":1,"updated":"2017-06-23T07:45:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxv5u00188tzz2wv4t9dl","content":"<blockquote>\n<p>之前公司在我来之前有个哥们儿是负责docker的，但是一直没有推广起来，测试环境都没有，这个项目就不了了之了。但是就在前几天跟ucloud架构交流，说起他之前在云上搞docker根据业务自动扩容，带宽自动调整。说的我真的眼睛放光。决心研究一下。</p>\n</blockquote>\n<p>我去年搞过虚拟化产品对虚拟化的产品做了调研。做了proxmox，类似kvm给测试服务用，开了几台虚拟机，这个产品支持机器热迁移等等。(这个博客刚开始写没多久，以后会把这些笔记也都放上来)<br>其实虚拟化可以分为以下几种</p>\n<h1 id=\"对比传统虚拟化\"><a href=\"#对比传统虚拟化\" class=\"headerlink\" title=\"对比传统虚拟化\"></a>对比传统虚拟化</h1><h2 id=\"传统虚拟化\"><a href=\"#传统虚拟化\" class=\"headerlink\" title=\"传统虚拟化\"></a>传统虚拟化</h2><p>最流行的虚拟化方法，使用Hypervisor这种中间层软件，在虚拟服务器和底层硬件之间建立一个抽象层。</p>\n<p>Hypervisor可以捕获CPU指令，为指令访问硬件控制器和外设充当中介。因而，完全虚拟化技术几乎能让任何一款操作系统不用改动就能安装到虚拟服务器上，而它们不知道自己运行在虚拟化环境下。主要缺点是，性能方面不如裸机，因为Hypervisor需要占用一些资源，给处理器带来开销。</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-23%20%E4%B8%8B%E5%8D%883.34.17.png\" alt=\"\"></p>\n<h2 id=\"操作系统层虚拟化\"><a href=\"#操作系统层虚拟化\" class=\"headerlink\" title=\"操作系统层虚拟化\"></a>操作系统层虚拟化</h2><p>实现虚拟化还有一个方法，那就是在操作系统层面增添虚拟服务器功能。就操作系统层的虚拟化而言，没有独立的Hypervisor层。相反主机操作系统本身就负责在多个虚拟服务器之间分配硬件资源，并且让这些服务器彼此独立。一个明显的区别是，如果使用操作系统层虚拟化，所有虚拟服务器必须运行同一操作系统。</p>\n<p>虽然操作系统层虚拟化的灵活性比较差，但本机速度性能比较高。此外，由于架构在所有虚拟服务器上使用单一、标准的操作系统，管理起来比异构环境要容易。<br><img src=\"http://or2jd66dq.bkt.clouddn.com/docker%E8%99%9A%E6%8B%9F%E5%8C%96.png\" alt=\"\"><br><code>docker</code>属于操作系统层面的虚拟化。<br>传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。它与传统hyper-V 的区别在于理念，之前的虚拟化都是以操作系统为中心的，而docker是以应用为中心，把应用的环境代码等打包成镜像直接发布。服务启动也是秒级的。</p>\n<h1 id=\"docker优势\"><a href=\"#docker优势\" class=\"headerlink\" title=\"docker优势\"></a>docker优势</h1><ul>\n<li>更高效的利用系统资源</li>\n<li>更快速的启动时间</li>\n<li>一致的运行环境</li>\n<li>持续交付和部署</li>\n<li>更轻松的迁移</li>\n<li>更轻松的维护和扩展</li>\n</ul>\n<p>这些优势都是运维喜欢的，所以运维要推行docker。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>之前公司在我来之前有个哥们儿是负责docker的，但是一直没有推广起来，测试环境都没有，这个项目就不了了之了。但是就在前几天跟ucloud架构交流，说起他之前在云上搞docker根据业务自动扩容，带宽自动调整。说的我真的眼睛放光。决心研究一下。</p>\n</blockquote>\n<p>我去年搞过虚拟化产品对虚拟化的产品做了调研。做了proxmox，类似kvm给测试服务用，开了几台虚拟机，这个产品支持机器热迁移等等。(这个博客刚开始写没多久，以后会把这些笔记也都放上来)<br>其实虚拟化可以分为以下几种</p>\n<h1 id=\"对比传统虚拟化\"><a href=\"#对比传统虚拟化\" class=\"headerlink\" title=\"对比传统虚拟化\"></a>对比传统虚拟化</h1><h2 id=\"传统虚拟化\"><a href=\"#传统虚拟化\" class=\"headerlink\" title=\"传统虚拟化\"></a>传统虚拟化</h2><p>最流行的虚拟化方法，使用Hypervisor这种中间层软件，在虚拟服务器和底层硬件之间建立一个抽象层。</p>\n<p>Hypervisor可以捕获CPU指令，为指令访问硬件控制器和外设充当中介。因而，完全虚拟化技术几乎能让任何一款操作系统不用改动就能安装到虚拟服务器上，而它们不知道自己运行在虚拟化环境下。主要缺点是，性能方面不如裸机，因为Hypervisor需要占用一些资源，给处理器带来开销。</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-23%20%E4%B8%8B%E5%8D%883.34.17.png\" alt=\"\"></p>\n<h2 id=\"操作系统层虚拟化\"><a href=\"#操作系统层虚拟化\" class=\"headerlink\" title=\"操作系统层虚拟化\"></a>操作系统层虚拟化</h2><p>实现虚拟化还有一个方法，那就是在操作系统层面增添虚拟服务器功能。就操作系统层的虚拟化而言，没有独立的Hypervisor层。相反主机操作系统本身就负责在多个虚拟服务器之间分配硬件资源，并且让这些服务器彼此独立。一个明显的区别是，如果使用操作系统层虚拟化，所有虚拟服务器必须运行同一操作系统。</p>\n<p>虽然操作系统层虚拟化的灵活性比较差，但本机速度性能比较高。此外，由于架构在所有虚拟服务器上使用单一、标准的操作系统，管理起来比异构环境要容易。<br><img src=\"http://or2jd66dq.bkt.clouddn.com/docker%E8%99%9A%E6%8B%9F%E5%8C%96.png\" alt=\"\"><br><code>docker</code>属于操作系统层面的虚拟化。<br>传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。它与传统hyper-V 的区别在于理念，之前的虚拟化都是以操作系统为中心的，而docker是以应用为中心，把应用的环境代码等打包成镜像直接发布。服务启动也是秒级的。</p>\n<h1 id=\"docker优势\"><a href=\"#docker优势\" class=\"headerlink\" title=\"docker优势\"></a>docker优势</h1><ul>\n<li>更高效的利用系统资源</li>\n<li>更快速的启动时间</li>\n<li>一致的运行环境</li>\n<li>持续交付和部署</li>\n<li>更轻松的迁移</li>\n<li>更轻松的维护和扩展</li>\n</ul>\n<p>这些优势都是运维喜欢的，所以运维要推行docker。</p>\n"},{"title":"javascripts记录","date":"2017-06-27T09:38:57.000Z","_content":"> 这只是个愿望，有时间就看下，战线有可能会拖得很长，大家不要吐槽。\n## 基本语法\n\n- 赋值 \n```\nvar a = 1;\n```\n\n- if 格式(if (条件) {执行语句} 支持嵌套)\n```\nif (2>1) {\n    x = 1;\n    y = 2;\n    if (x>y) {\n        result = 0;\n    }\n    if (x<y) {\n        result = 1;\n    }\n}\n```\n\n- 注释\n```\n/* 这是注释 */\n```\n\n\n","source":"_posts/javascripts记录.md","raw":"---\ntitle: javascripts记录\ndate: 2017-06-27 17:38:57\ntags: javascripts\ncategories: 前端\n---\n> 这只是个愿望，有时间就看下，战线有可能会拖得很长，大家不要吐槽。\n## 基本语法\n\n- 赋值 \n```\nvar a = 1;\n```\n\n- if 格式(if (条件) {执行语句} 支持嵌套)\n```\nif (2>1) {\n    x = 1;\n    y = 2;\n    if (x>y) {\n        result = 0;\n    }\n    if (x<y) {\n        result = 1;\n    }\n}\n```\n\n- 注释\n```\n/* 这是注释 */\n```\n\n\n","slug":"javascripts记录","published":1,"updated":"2017-07-06T10:22:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvay00278tzzcdsboojl","content":"<blockquote>\n<p>这只是个愿望，有时间就看下，战线有可能会拖得很长，大家不要吐槽。</p>\n<h2 id=\"基本语法\"><a href=\"#基本语法\" class=\"headerlink\" title=\"基本语法\"></a>基本语法</h2></blockquote>\n<ul>\n<li><p>赋值 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">var a = 1;</div></pre></td></tr></table></figure>\n</li>\n<li><p>if 格式(if (条件) {执行语句} 支持嵌套)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">if (2&gt;1) &#123;</div><div class=\"line\">    x = 1;</div><div class=\"line\">    y = 2;</div><div class=\"line\">    if (x&gt;y) &#123;</div><div class=\"line\">        result = 0;</div><div class=\"line\">    &#125;</div><div class=\"line\">    if (x&lt;y) &#123;</div><div class=\"line\">        result = 1;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>注释</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">/* 这是注释 */</div></pre></td></tr></table></figure>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>这只是个愿望，有时间就看下，战线有可能会拖得很长，大家不要吐槽。</p>\n<h2 id=\"基本语法\"><a href=\"#基本语法\" class=\"headerlink\" title=\"基本语法\"></a>基本语法</h2></blockquote>\n<ul>\n<li><p>赋值 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">var a = 1;</div></pre></td></tr></table></figure>\n</li>\n<li><p>if 格式(if (条件) {执行语句} 支持嵌套)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">if (2&gt;1) &#123;</div><div class=\"line\">    x = 1;</div><div class=\"line\">    y = 2;</div><div class=\"line\">    if (x&gt;y) &#123;</div><div class=\"line\">        result = 0;</div><div class=\"line\">    &#125;</div><div class=\"line\">    if (x&lt;y) &#123;</div><div class=\"line\">        result = 1;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>注释</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">/* 这是注释 */</div></pre></td></tr></table></figure>\n</li>\n</ul>\n"},{"title":"file_beat接入ELK","date":"2017-06-06T07:56:13.000Z","_content":"\n> 公司之前的日志收集使用的kids(知乎开源的日志收集工具，不知道为啥用这个，难道是因为跟我们你是邻居？)。然后统一收留存到一台机器，做中转留几天的方便大家查看，后续直接存到Hadoop中。后来搭建ELK就是直接在这个机器上起的logstash，说白了只是把这几天的日志做了可视化。但是现在我们有了另一种需求，需要收集各个机器的系统日志，加上之前做了bash_history 也需要收集。但是我并不是很想用kids,它改配置重启都比较麻烦。也不太想用整个的logstash，太大了，正好filebeat可以满足我们的需求，很轻而且使用go开发。\n> 但是还是有一个想法，之前的ELK 有的时候会出现数据延时很大的情况，我分析是ES集群的压力过大，所以我想在ES之前加一个缓冲，加一个kafka队列\n> 这正好是一个实验的机会。\n\n\n之前架构：\n![](http://or2jd66dq.bkt.clouddn.com/ELK%E6%97%A9%E6%9C%9F%E6%9E%B6%E6%9E%84.png)\n\n架构调整如下：\n\n![](http://or2jd66dq.bkt.clouddn.com/ELK-kafka.png)\n\n参考:https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.html\n## 版本介绍\n- logstash 2.3.2\n- Elasticsearch 2.3.2\n- kafka 0.10.0.2\n- filebeat 5.0.0\n- kibana 4.3.1\n由于ELKstack 各个组件之前有很强的版本依赖，所以安装之前最好确认下。据说filebeat5.0 logstash也得使用5.0,ES 也得使用5.0 但是我们使filebeat 和logstash之间加了一个kafka队列，就给这两个组件直接解耦了。filebeat5.0之后才能直接output到kafka。logstash2.3可以直接使用kafka 作为input。正好。。。\n\n\n# kafka安装\n\n> 最新版本0.10.0.2\n> java 1.8\n\n部署参考: https://www.mtyun.com/library/32/how-to-install-kafka-on-centos7/\nkafka配置参考: http://www.cnblogs.com/davidwang456/p/4195873.html\n\n`Broker`\nKafka集群包含一个或多个服务器，这种服务器被称为broker\n\n`Topic`\n每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n\n`Partition`\nParition是物理上的概念，每个Topic包含一个或多个Partition.\n很像ES的分片概念，合理设置可以提高效率\n\n`Producer`\n负责发布消息到Kafka broker\n\n`Consumer`\n消息消费者，向Kafka broker读取消息的客户端。\n\n`Consumer Group`\n每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\n\n```\nwget http://mirror.bit.edu.cn/apache/kafka/0.10.2.1/kafka_2.10-0.10.2.1.tgz\ntar -zxvf kafka_2.10-0.10.2.1.tgz\n\n# 启动zookeeper \nbin/zookeeper-server-start.sh -daemon config/zookeeper.properties\n# 启动kafka\nbin/kafka-server-start.sh config/server.properties &\n# 功能验证\n## 新建一个topic \nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n## 查看topic \nbin/kafka-topics.sh --list --zookeeper localhost:2181\n## 手动产生消息\nbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test \nHello Kafka！\nnihao shijie\n## 消费消息\nbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning\nHello world!\nnihao shijie\n```\n\n## 单机多实例配置\n> 由于kafka 使用的是机器的文件系统存储，所以本机多实例的集群很好。尽量减少网络通讯。\n\n```\ncp config/server.properties config/server_1.properties\n# 修改配置文件 \nvim config/server_1.properties\n    broker.id=1\n    port=9093\n    log.dirs=/tmp/kafka_1-logs\n# 启动\nbin/kafka-server-start.sh config/server_1.properties &\n\n```\n\n## 机器调优\nFile descriptors\n\nkafka会使用大量文件和网络socket，所以，我们需要把file descriptors的默认配置改为100000。修改方法如下(之前机器初始化的时候做过响应更改，可以忽略)\n```\n#vi /etc/sysctl.conf\n\nfs.file-max = 32000\n\n#vi /etc/security/limits.conf\n\nyourusersoftnofile10000\n\nyouruserhardnofile30000\n```\n\n    \n# filebeat5 安装\n\n> 版本5.0.0\n\n```\ncurl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.0.0-x86_64.rpm\nrpm -ivh filebeat-5.0.0-x86_64.rpm\n```\n配置\n\n[官网配置参考](https://www.elastic.co/guide/en/beats/filebeat/5.0/configuration-filebeat-options.html)\n\n```\nfilebeat.prospectors:\n- input_type: log\n  paths:\n    - /var/log/bash_history.log*\n  fields:\n    log_source: bash_history\n  document_type: bash_history\n  scan_frequency: 1s\n  ignore_older: 30m\n\n- input_type: log\n  paths:\n    - /var/log/messages*\n  fields:\n    log_source: message\n  document_type: message\n  scan_frequency: 1s\n  ignore_older: 30m\n- input_type: log\n  paths:\n    - /var/log/cron\n  fields:\n    log_source: cron\n  document_type: cron\n  scan_frequency: 1s\n  ignore_older: 30m\n- input_type: log\n  paths:\n    - /var/log/secure\n  fields:\n    log_source: secure\n  document_type: secure\n  scan_frequency: 1s\n  ignore_older: 30m\noutput.kafka:\n  hosts: [\"localhost:9092\", \"localhost:9093\"]\n  topic: '%{[type]}'\n  partition.round_robin:\n    reachable_only: false\n  required_acks: 1\n  compression: gzip\n  max_message_bytes: 1000000\n```\n\n# logstash 配置\n\n> logstash 是把数据从kafka中拿过来，放到ES中配置如下\n\n```\ninput {\n  kafka {\n    zk_connect => \"localhost:2181\"\n    topic_id => \"sys_log\"\n  }\n}\n\noutput {\n\n    elasticsearch {\n        hosts => [\"10.215.33.36:9200\"]\n        manage_template => true\n        index => \"syslog-%{+YYYY.MM.dd}\"\n    }\n}\n```\n\n\n\n","source":"_posts/file-beat接入ELK.md","raw":"---\ntitle: file_beat接入ELK\ndate: 2017-06-06 15:56:13\ntags: ELK, filebeat, kafka\ncategories: 运维工具\n---\n\n> 公司之前的日志收集使用的kids(知乎开源的日志收集工具，不知道为啥用这个，难道是因为跟我们你是邻居？)。然后统一收留存到一台机器，做中转留几天的方便大家查看，后续直接存到Hadoop中。后来搭建ELK就是直接在这个机器上起的logstash，说白了只是把这几天的日志做了可视化。但是现在我们有了另一种需求，需要收集各个机器的系统日志，加上之前做了bash_history 也需要收集。但是我并不是很想用kids,它改配置重启都比较麻烦。也不太想用整个的logstash，太大了，正好filebeat可以满足我们的需求，很轻而且使用go开发。\n> 但是还是有一个想法，之前的ELK 有的时候会出现数据延时很大的情况，我分析是ES集群的压力过大，所以我想在ES之前加一个缓冲，加一个kafka队列\n> 这正好是一个实验的机会。\n\n\n之前架构：\n![](http://or2jd66dq.bkt.clouddn.com/ELK%E6%97%A9%E6%9C%9F%E6%9E%B6%E6%9E%84.png)\n\n架构调整如下：\n\n![](http://or2jd66dq.bkt.clouddn.com/ELK-kafka.png)\n\n参考:https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.html\n## 版本介绍\n- logstash 2.3.2\n- Elasticsearch 2.3.2\n- kafka 0.10.0.2\n- filebeat 5.0.0\n- kibana 4.3.1\n由于ELKstack 各个组件之前有很强的版本依赖，所以安装之前最好确认下。据说filebeat5.0 logstash也得使用5.0,ES 也得使用5.0 但是我们使filebeat 和logstash之间加了一个kafka队列，就给这两个组件直接解耦了。filebeat5.0之后才能直接output到kafka。logstash2.3可以直接使用kafka 作为input。正好。。。\n\n\n# kafka安装\n\n> 最新版本0.10.0.2\n> java 1.8\n\n部署参考: https://www.mtyun.com/library/32/how-to-install-kafka-on-centos7/\nkafka配置参考: http://www.cnblogs.com/davidwang456/p/4195873.html\n\n`Broker`\nKafka集群包含一个或多个服务器，这种服务器被称为broker\n\n`Topic`\n每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n\n`Partition`\nParition是物理上的概念，每个Topic包含一个或多个Partition.\n很像ES的分片概念，合理设置可以提高效率\n\n`Producer`\n负责发布消息到Kafka broker\n\n`Consumer`\n消息消费者，向Kafka broker读取消息的客户端。\n\n`Consumer Group`\n每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\n\n```\nwget http://mirror.bit.edu.cn/apache/kafka/0.10.2.1/kafka_2.10-0.10.2.1.tgz\ntar -zxvf kafka_2.10-0.10.2.1.tgz\n\n# 启动zookeeper \nbin/zookeeper-server-start.sh -daemon config/zookeeper.properties\n# 启动kafka\nbin/kafka-server-start.sh config/server.properties &\n# 功能验证\n## 新建一个topic \nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n## 查看topic \nbin/kafka-topics.sh --list --zookeeper localhost:2181\n## 手动产生消息\nbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test \nHello Kafka！\nnihao shijie\n## 消费消息\nbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning\nHello world!\nnihao shijie\n```\n\n## 单机多实例配置\n> 由于kafka 使用的是机器的文件系统存储，所以本机多实例的集群很好。尽量减少网络通讯。\n\n```\ncp config/server.properties config/server_1.properties\n# 修改配置文件 \nvim config/server_1.properties\n    broker.id=1\n    port=9093\n    log.dirs=/tmp/kafka_1-logs\n# 启动\nbin/kafka-server-start.sh config/server_1.properties &\n\n```\n\n## 机器调优\nFile descriptors\n\nkafka会使用大量文件和网络socket，所以，我们需要把file descriptors的默认配置改为100000。修改方法如下(之前机器初始化的时候做过响应更改，可以忽略)\n```\n#vi /etc/sysctl.conf\n\nfs.file-max = 32000\n\n#vi /etc/security/limits.conf\n\nyourusersoftnofile10000\n\nyouruserhardnofile30000\n```\n\n    \n# filebeat5 安装\n\n> 版本5.0.0\n\n```\ncurl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.0.0-x86_64.rpm\nrpm -ivh filebeat-5.0.0-x86_64.rpm\n```\n配置\n\n[官网配置参考](https://www.elastic.co/guide/en/beats/filebeat/5.0/configuration-filebeat-options.html)\n\n```\nfilebeat.prospectors:\n- input_type: log\n  paths:\n    - /var/log/bash_history.log*\n  fields:\n    log_source: bash_history\n  document_type: bash_history\n  scan_frequency: 1s\n  ignore_older: 30m\n\n- input_type: log\n  paths:\n    - /var/log/messages*\n  fields:\n    log_source: message\n  document_type: message\n  scan_frequency: 1s\n  ignore_older: 30m\n- input_type: log\n  paths:\n    - /var/log/cron\n  fields:\n    log_source: cron\n  document_type: cron\n  scan_frequency: 1s\n  ignore_older: 30m\n- input_type: log\n  paths:\n    - /var/log/secure\n  fields:\n    log_source: secure\n  document_type: secure\n  scan_frequency: 1s\n  ignore_older: 30m\noutput.kafka:\n  hosts: [\"localhost:9092\", \"localhost:9093\"]\n  topic: '%{[type]}'\n  partition.round_robin:\n    reachable_only: false\n  required_acks: 1\n  compression: gzip\n  max_message_bytes: 1000000\n```\n\n# logstash 配置\n\n> logstash 是把数据从kafka中拿过来，放到ES中配置如下\n\n```\ninput {\n  kafka {\n    zk_connect => \"localhost:2181\"\n    topic_id => \"sys_log\"\n  }\n}\n\noutput {\n\n    elasticsearch {\n        hosts => [\"10.215.33.36:9200\"]\n        manage_template => true\n        index => \"syslog-%{+YYYY.MM.dd}\"\n    }\n}\n```\n\n\n\n","slug":"file-beat接入ELK","published":1,"updated":"2017-08-02T08:37:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvb100298tzzrmchgwu0","content":"<blockquote>\n<p>公司之前的日志收集使用的kids(知乎开源的日志收集工具，不知道为啥用这个，难道是因为跟我们你是邻居？)。然后统一收留存到一台机器，做中转留几天的方便大家查看，后续直接存到Hadoop中。后来搭建ELK就是直接在这个机器上起的logstash，说白了只是把这几天的日志做了可视化。但是现在我们有了另一种需求，需要收集各个机器的系统日志，加上之前做了bash_history 也需要收集。但是我并不是很想用kids,它改配置重启都比较麻烦。也不太想用整个的logstash，太大了，正好filebeat可以满足我们的需求，很轻而且使用go开发。<br>但是还是有一个想法，之前的ELK 有的时候会出现数据延时很大的情况，我分析是ES集群的压力过大，所以我想在ES之前加一个缓冲，加一个kafka队列<br>这正好是一个实验的机会。</p>\n</blockquote>\n<p>之前架构：<br><img src=\"http://or2jd66dq.bkt.clouddn.com/ELK%E6%97%A9%E6%9C%9F%E6%9E%B6%E6%9E%84.png\" alt=\"\"></p>\n<p>架构调整如下：</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/ELK-kafka.png\" alt=\"\"></p>\n<p>参考:<a href=\"https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.html\" target=\"_blank\" rel=\"external\">https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.html</a></p>\n<h2 id=\"版本介绍\"><a href=\"#版本介绍\" class=\"headerlink\" title=\"版本介绍\"></a>版本介绍</h2><ul>\n<li>logstash 2.3.2</li>\n<li>Elasticsearch 2.3.2</li>\n<li>kafka 0.10.0.2</li>\n<li>filebeat 5.0.0</li>\n<li>kibana 4.3.1<br>由于ELKstack 各个组件之前有很强的版本依赖，所以安装之前最好确认下。据说filebeat5.0 logstash也得使用5.0,ES 也得使用5.0 但是我们使filebeat 和logstash之间加了一个kafka队列，就给这两个组件直接解耦了。filebeat5.0之后才能直接output到kafka。logstash2.3可以直接使用kafka 作为input。正好。。。</li>\n</ul>\n<h1 id=\"kafka安装\"><a href=\"#kafka安装\" class=\"headerlink\" title=\"kafka安装\"></a>kafka安装</h1><blockquote>\n<p>最新版本0.10.0.2<br>java 1.8</p>\n</blockquote>\n<p>部署参考: <a href=\"https://www.mtyun.com/library/32/how-to-install-kafka-on-centos7/\" target=\"_blank\" rel=\"external\">https://www.mtyun.com/library/32/how-to-install-kafka-on-centos7/</a><br>kafka配置参考: <a href=\"http://www.cnblogs.com/davidwang456/p/4195873.html\" target=\"_blank\" rel=\"external\">http://www.cnblogs.com/davidwang456/p/4195873.html</a></p>\n<p><code>Broker</code><br>Kafka集群包含一个或多个服务器，这种服务器被称为broker</p>\n<p><code>Topic</code><br>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>\n<p><code>Partition</code><br>Parition是物理上的概念，每个Topic包含一个或多个Partition.<br>很像ES的分片概念，合理设置可以提高效率</p>\n<p><code>Producer</code><br>负责发布消息到Kafka broker</p>\n<p><code>Consumer</code><br>消息消费者，向Kafka broker读取消息的客户端。</p>\n<p><code>Consumer Group</code><br>每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">wget http://mirror.bit.edu.cn/apache/kafka/0.10.2.1/kafka_2.10-0.10.2.1.tgz</div><div class=\"line\">tar -zxvf kafka_2.10-0.10.2.1.tgz</div><div class=\"line\"></div><div class=\"line\"># 启动zookeeper </div><div class=\"line\">bin/zookeeper-server-start.sh -daemon config/zookeeper.properties</div><div class=\"line\"># 启动kafka</div><div class=\"line\">bin/kafka-server-start.sh config/server.properties &amp;</div><div class=\"line\"># 功能验证</div><div class=\"line\">## 新建一个topic </div><div class=\"line\">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</div><div class=\"line\">## 查看topic </div><div class=\"line\">bin/kafka-topics.sh --list --zookeeper localhost:2181</div><div class=\"line\">## 手动产生消息</div><div class=\"line\">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test </div><div class=\"line\">Hello Kafka！</div><div class=\"line\">nihao shijie</div><div class=\"line\">## 消费消息</div><div class=\"line\">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning</div><div class=\"line\">Hello world!</div><div class=\"line\">nihao shijie</div></pre></td></tr></table></figure>\n<h2 id=\"单机多实例配置\"><a href=\"#单机多实例配置\" class=\"headerlink\" title=\"单机多实例配置\"></a>单机多实例配置</h2><blockquote>\n<p>由于kafka 使用的是机器的文件系统存储，所以本机多实例的集群很好。尽量减少网络通讯。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp config/server.properties config/server_1.properties</div><div class=\"line\"># 修改配置文件 </div><div class=\"line\">vim config/server_1.properties</div><div class=\"line\">    broker.id=1</div><div class=\"line\">    port=9093</div><div class=\"line\">    log.dirs=/tmp/kafka_1-logs</div><div class=\"line\"># 启动</div><div class=\"line\">bin/kafka-server-start.sh config/server_1.properties &amp;</div></pre></td></tr></table></figure>\n<h2 id=\"机器调优\"><a href=\"#机器调优\" class=\"headerlink\" title=\"机器调优\"></a>机器调优</h2><p>File descriptors</p>\n<p>kafka会使用大量文件和网络socket，所以，我们需要把file descriptors的默认配置改为100000。修改方法如下(之前机器初始化的时候做过响应更改，可以忽略)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">#vi /etc/sysctl.conf</div><div class=\"line\"></div><div class=\"line\">fs.file-max = 32000</div><div class=\"line\"></div><div class=\"line\">#vi /etc/security/limits.conf</div><div class=\"line\"></div><div class=\"line\">yourusersoftnofile10000</div><div class=\"line\"></div><div class=\"line\">youruserhardnofile30000</div></pre></td></tr></table></figure></p>\n<h1 id=\"filebeat5-安装\"><a href=\"#filebeat5-安装\" class=\"headerlink\" title=\"filebeat5 安装\"></a>filebeat5 安装</h1><blockquote>\n<p>版本5.0.0</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.0.0-x86_64.rpm</div><div class=\"line\">rpm -ivh filebeat-5.0.0-x86_64.rpm</div></pre></td></tr></table></figure>\n<p>配置</p>\n<p><a href=\"https://www.elastic.co/guide/en/beats/filebeat/5.0/configuration-filebeat-options.html\" target=\"_blank\" rel=\"external\">官网配置参考</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\">filebeat.prospectors:</div><div class=\"line\">- input_type: log</div><div class=\"line\">  paths:</div><div class=\"line\">    - /var/log/bash_history.log*</div><div class=\"line\">  fields:</div><div class=\"line\">    log_source: bash_history</div><div class=\"line\">  document_type: bash_history</div><div class=\"line\">  scan_frequency: 1s</div><div class=\"line\">  ignore_older: 30m</div><div class=\"line\"></div><div class=\"line\">- input_type: log</div><div class=\"line\">  paths:</div><div class=\"line\">    - /var/log/messages*</div><div class=\"line\">  fields:</div><div class=\"line\">    log_source: message</div><div class=\"line\">  document_type: message</div><div class=\"line\">  scan_frequency: 1s</div><div class=\"line\">  ignore_older: 30m</div><div class=\"line\">- input_type: log</div><div class=\"line\">  paths:</div><div class=\"line\">    - /var/log/cron</div><div class=\"line\">  fields:</div><div class=\"line\">    log_source: cron</div><div class=\"line\">  document_type: cron</div><div class=\"line\">  scan_frequency: 1s</div><div class=\"line\">  ignore_older: 30m</div><div class=\"line\">- input_type: log</div><div class=\"line\">  paths:</div><div class=\"line\">    - /var/log/secure</div><div class=\"line\">  fields:</div><div class=\"line\">    log_source: secure</div><div class=\"line\">  document_type: secure</div><div class=\"line\">  scan_frequency: 1s</div><div class=\"line\">  ignore_older: 30m</div><div class=\"line\">output.kafka:</div><div class=\"line\">  hosts: [&quot;localhost:9092&quot;, &quot;localhost:9093&quot;]</div><div class=\"line\">  topic: &apos;%&#123;[type]&#125;&apos;</div><div class=\"line\">  partition.round_robin:</div><div class=\"line\">    reachable_only: false</div><div class=\"line\">  required_acks: 1</div><div class=\"line\">  compression: gzip</div><div class=\"line\">  max_message_bytes: 1000000</div></pre></td></tr></table></figure>\n<h1 id=\"logstash-配置\"><a href=\"#logstash-配置\" class=\"headerlink\" title=\"logstash 配置\"></a>logstash 配置</h1><blockquote>\n<p>logstash 是把数据从kafka中拿过来，放到ES中配置如下</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">input &#123;</div><div class=\"line\">  kafka &#123;</div><div class=\"line\">    zk_connect =&gt; &quot;localhost:2181&quot;</div><div class=\"line\">    topic_id =&gt; &quot;sys_log&quot;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">output &#123;</div><div class=\"line\"></div><div class=\"line\">    elasticsearch &#123;</div><div class=\"line\">        hosts =&gt; [&quot;10.215.33.36:9200&quot;]</div><div class=\"line\">        manage_template =&gt; true</div><div class=\"line\">        index =&gt; &quot;syslog-%&#123;+YYYY.MM.dd&#125;&quot;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>公司之前的日志收集使用的kids(知乎开源的日志收集工具，不知道为啥用这个，难道是因为跟我们你是邻居？)。然后统一收留存到一台机器，做中转留几天的方便大家查看，后续直接存到Hadoop中。后来搭建ELK就是直接在这个机器上起的logstash，说白了只是把这几天的日志做了可视化。但是现在我们有了另一种需求，需要收集各个机器的系统日志，加上之前做了bash_history 也需要收集。但是我并不是很想用kids,它改配置重启都比较麻烦。也不太想用整个的logstash，太大了，正好filebeat可以满足我们的需求，很轻而且使用go开发。<br>但是还是有一个想法，之前的ELK 有的时候会出现数据延时很大的情况，我分析是ES集群的压力过大，所以我想在ES之前加一个缓冲，加一个kafka队列<br>这正好是一个实验的机会。</p>\n</blockquote>\n<p>之前架构：<br><img src=\"http://or2jd66dq.bkt.clouddn.com/ELK%E6%97%A9%E6%9C%9F%E6%9E%B6%E6%9E%84.png\" alt=\"\"></p>\n<p>架构调整如下：</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/ELK-kafka.png\" alt=\"\"></p>\n<p>参考:<a href=\"https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.html\" target=\"_blank\" rel=\"external\">https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.html</a></p>\n<h2 id=\"版本介绍\"><a href=\"#版本介绍\" class=\"headerlink\" title=\"版本介绍\"></a>版本介绍</h2><ul>\n<li>logstash 2.3.2</li>\n<li>Elasticsearch 2.3.2</li>\n<li>kafka 0.10.0.2</li>\n<li>filebeat 5.0.0</li>\n<li>kibana 4.3.1<br>由于ELKstack 各个组件之前有很强的版本依赖，所以安装之前最好确认下。据说filebeat5.0 logstash也得使用5.0,ES 也得使用5.0 但是我们使filebeat 和logstash之间加了一个kafka队列，就给这两个组件直接解耦了。filebeat5.0之后才能直接output到kafka。logstash2.3可以直接使用kafka 作为input。正好。。。</li>\n</ul>\n<h1 id=\"kafka安装\"><a href=\"#kafka安装\" class=\"headerlink\" title=\"kafka安装\"></a>kafka安装</h1><blockquote>\n<p>最新版本0.10.0.2<br>java 1.8</p>\n</blockquote>\n<p>部署参考: <a href=\"https://www.mtyun.com/library/32/how-to-install-kafka-on-centos7/\" target=\"_blank\" rel=\"external\">https://www.mtyun.com/library/32/how-to-install-kafka-on-centos7/</a><br>kafka配置参考: <a href=\"http://www.cnblogs.com/davidwang456/p/4195873.html\" target=\"_blank\" rel=\"external\">http://www.cnblogs.com/davidwang456/p/4195873.html</a></p>\n<p><code>Broker</code><br>Kafka集群包含一个或多个服务器，这种服务器被称为broker</p>\n<p><code>Topic</code><br>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>\n<p><code>Partition</code><br>Parition是物理上的概念，每个Topic包含一个或多个Partition.<br>很像ES的分片概念，合理设置可以提高效率</p>\n<p><code>Producer</code><br>负责发布消息到Kafka broker</p>\n<p><code>Consumer</code><br>消息消费者，向Kafka broker读取消息的客户端。</p>\n<p><code>Consumer Group</code><br>每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">wget http://mirror.bit.edu.cn/apache/kafka/0.10.2.1/kafka_2.10-0.10.2.1.tgz</div><div class=\"line\">tar -zxvf kafka_2.10-0.10.2.1.tgz</div><div class=\"line\"></div><div class=\"line\"># 启动zookeeper </div><div class=\"line\">bin/zookeeper-server-start.sh -daemon config/zookeeper.properties</div><div class=\"line\"># 启动kafka</div><div class=\"line\">bin/kafka-server-start.sh config/server.properties &amp;</div><div class=\"line\"># 功能验证</div><div class=\"line\">## 新建一个topic </div><div class=\"line\">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</div><div class=\"line\">## 查看topic </div><div class=\"line\">bin/kafka-topics.sh --list --zookeeper localhost:2181</div><div class=\"line\">## 手动产生消息</div><div class=\"line\">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test </div><div class=\"line\">Hello Kafka！</div><div class=\"line\">nihao shijie</div><div class=\"line\">## 消费消息</div><div class=\"line\">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning</div><div class=\"line\">Hello world!</div><div class=\"line\">nihao shijie</div></pre></td></tr></table></figure>\n<h2 id=\"单机多实例配置\"><a href=\"#单机多实例配置\" class=\"headerlink\" title=\"单机多实例配置\"></a>单机多实例配置</h2><blockquote>\n<p>由于kafka 使用的是机器的文件系统存储，所以本机多实例的集群很好。尽量减少网络通讯。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp config/server.properties config/server_1.properties</div><div class=\"line\"># 修改配置文件 </div><div class=\"line\">vim config/server_1.properties</div><div class=\"line\">    broker.id=1</div><div class=\"line\">    port=9093</div><div class=\"line\">    log.dirs=/tmp/kafka_1-logs</div><div class=\"line\"># 启动</div><div class=\"line\">bin/kafka-server-start.sh config/server_1.properties &amp;</div></pre></td></tr></table></figure>\n<h2 id=\"机器调优\"><a href=\"#机器调优\" class=\"headerlink\" title=\"机器调优\"></a>机器调优</h2><p>File descriptors</p>\n<p>kafka会使用大量文件和网络socket，所以，我们需要把file descriptors的默认配置改为100000。修改方法如下(之前机器初始化的时候做过响应更改，可以忽略)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">#vi /etc/sysctl.conf</div><div class=\"line\"></div><div class=\"line\">fs.file-max = 32000</div><div class=\"line\"></div><div class=\"line\">#vi /etc/security/limits.conf</div><div class=\"line\"></div><div class=\"line\">yourusersoftnofile10000</div><div class=\"line\"></div><div class=\"line\">youruserhardnofile30000</div></pre></td></tr></table></figure></p>\n<h1 id=\"filebeat5-安装\"><a href=\"#filebeat5-安装\" class=\"headerlink\" title=\"filebeat5 安装\"></a>filebeat5 安装</h1><blockquote>\n<p>版本5.0.0</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.0.0-x86_64.rpm</div><div class=\"line\">rpm -ivh filebeat-5.0.0-x86_64.rpm</div></pre></td></tr></table></figure>\n<p>配置</p>\n<p><a href=\"https://www.elastic.co/guide/en/beats/filebeat/5.0/configuration-filebeat-options.html\" target=\"_blank\" rel=\"external\">官网配置参考</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\">filebeat.prospectors:</div><div class=\"line\">- input_type: log</div><div class=\"line\">  paths:</div><div class=\"line\">    - /var/log/bash_history.log*</div><div class=\"line\">  fields:</div><div class=\"line\">    log_source: bash_history</div><div class=\"line\">  document_type: bash_history</div><div class=\"line\">  scan_frequency: 1s</div><div class=\"line\">  ignore_older: 30m</div><div class=\"line\"></div><div class=\"line\">- input_type: log</div><div class=\"line\">  paths:</div><div class=\"line\">    - /var/log/messages*</div><div class=\"line\">  fields:</div><div class=\"line\">    log_source: message</div><div class=\"line\">  document_type: message</div><div class=\"line\">  scan_frequency: 1s</div><div class=\"line\">  ignore_older: 30m</div><div class=\"line\">- input_type: log</div><div class=\"line\">  paths:</div><div class=\"line\">    - /var/log/cron</div><div class=\"line\">  fields:</div><div class=\"line\">    log_source: cron</div><div class=\"line\">  document_type: cron</div><div class=\"line\">  scan_frequency: 1s</div><div class=\"line\">  ignore_older: 30m</div><div class=\"line\">- input_type: log</div><div class=\"line\">  paths:</div><div class=\"line\">    - /var/log/secure</div><div class=\"line\">  fields:</div><div class=\"line\">    log_source: secure</div><div class=\"line\">  document_type: secure</div><div class=\"line\">  scan_frequency: 1s</div><div class=\"line\">  ignore_older: 30m</div><div class=\"line\">output.kafka:</div><div class=\"line\">  hosts: [&quot;localhost:9092&quot;, &quot;localhost:9093&quot;]</div><div class=\"line\">  topic: &apos;%&#123;[type]&#125;&apos;</div><div class=\"line\">  partition.round_robin:</div><div class=\"line\">    reachable_only: false</div><div class=\"line\">  required_acks: 1</div><div class=\"line\">  compression: gzip</div><div class=\"line\">  max_message_bytes: 1000000</div></pre></td></tr></table></figure>\n<h1 id=\"logstash-配置\"><a href=\"#logstash-配置\" class=\"headerlink\" title=\"logstash 配置\"></a>logstash 配置</h1><blockquote>\n<p>logstash 是把数据从kafka中拿过来，放到ES中配置如下</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">input &#123;</div><div class=\"line\">  kafka &#123;</div><div class=\"line\">    zk_connect =&gt; &quot;localhost:2181&quot;</div><div class=\"line\">    topic_id =&gt; &quot;sys_log&quot;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">output &#123;</div><div class=\"line\"></div><div class=\"line\">    elasticsearch &#123;</div><div class=\"line\">        hosts =&gt; [&quot;10.215.33.36:9200&quot;]</div><div class=\"line\">        manage_template =&gt; true</div><div class=\"line\">        index =&gt; &quot;syslog-%&#123;+YYYY.MM.dd&#125;&quot;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"title":"nginx之location,upstream,rewrite","date":"2017-07-08T06:19:45.000Z","_content":"\n> nginx配置第三篇，[nginx安装配置](https://fanquqi.github.io/2017/07/06/nginx%E4%B9%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/)中讲了很多基础配置，这次讲一下具体的操作配置。\n\n## location配置\n\n> location模块工作在虚拟主机server之下，对URL进行匹配，如果匹配成功就按照该location之中写的语句进行操作。\n\n**语法** \n\nlocation [=|~|~*|^~] /uri/ { … }\n\n**匹配规则**\n\n|         模式        |         含义                        |\n|:------------------|:---------------------------------: |\n|location = /uri     | = 表示精确匹配，只有完全匹配上才能生效。  |\n|location ^~ /uri|^~ 开头对URL路径进行前缀匹配，并且在正则之前。|\n|location ~ pattern |区分大小写的正则匹配|\n|location ~* pattern|不区分大小写的正则匹配|\n|location /uri|不带任何修饰符，也表示前缀匹配，但是在正则匹配之后|\n|location /|通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default|\n\n&emsp;&emsp;那么如果我们在一个虚拟主机下边写了很多location 规则，哪一个先匹配哪一个后匹配呢？\n是这样的。\nnginx会根据模糊程度排序的\n\n- 首先精确匹配 =\n- 其次前缀匹配 ^~\n- 其次是按文件中顺序的正则匹配\n- 然后匹配不带任何修饰的前缀匹配。\n- 最后是交给 / 通用匹配\n- 当有匹配成功时候，停止匹配，按当前匹配规则处理请求\n\n## upstream\n> 负载均衡模块,负责根据配置合理分流到各个代理节点，而且自带后端节点健康检查（需要自己通过proxy_read_timeout指令和proxy_next_upstream指令配置）\n\n[参考文章](http://nolinux.blog.51cto.com/4824967/1594029)\n**语法** `upstream name {server ip:port 状态}`\n\n```\nhttp {\n    upstream name {\n        \n        [ip_hash;]\n        server ip:port [weight=n];\n        server ip:port [weight=n];\n    }\n\n\n\nserver {\n    listen 80;\n    server_name   www.xxx.com; \n\n    proxy_pass http://name;\n    或者\n    uwsgi_pass \n    或者\n    fast_cgi_pass\n    }\n    \n}\n```\n上下文 http server location \n\n\n\n负载均衡策略: \n- 轮询(默认)\n- 设置权重(weight)\n- ip_hash(每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。)\n\n其次还可以定义状态\n\n- down 表示单前的server暂时不参与负载\n- weight 默认为1.weight越大，负载的权重就越大。\n- max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误\n- fail_timeout:max_fails次失败后，暂停的时间。\n- backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。\n\n### 负载均衡后端节点健康检查\n\n&emsp;&emsp;严格来说，nginx自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的ngx_http_proxy_module.\n  模块和ngx_http_upstream_module模块中的相关指令来完成当后端节点出现故障时，自动切换到健康节点来提供访问。\n\n\n这里学习下ngx_http_proxy_module 模块中的 `proxy_connect_timeout` 指令、`proxy_read_timeout`指令和`proxy_next_upstream`指令\n\n**设置与后端服务器建立连接的超时时间。** 应该注意这个超时一般不可能大于75秒。\n    \n    proxy_connect_timeout 60s;\n\n**设置从后端服务器读取响应的超时**\n\n    proxy_read_timeout 60s;\n\n**指定在何种情况下一个失败的请求应该被发送到下一台后端服务节点**\n\n    proxy_next_upstream error timeout;\n\n`error`      和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误\n\n`timeout`    和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时\n\n`invalid_header`  后端服务器返回空响应或者非法响应头\n\n`http_500`    后端服务器返回的响应状态码为500\n\n`http_502`    后端服务器返回的响应状态码为502\n\n`http_503`    后端服务器返回的响应状态码为503\n\n`http_504`    后端服务器返回的响应状态码为504\n\n`http_404`    后端服务器返回的响应状态码为404\n\n`off`         停止将请求发送给下一台后端服务器\n\n&emsp;&emsp;还可以通过tengine来实现，淘宝技术团队开发的`nginx_upstream_check_module`模块来实现。\n如果没有使用tengine需要打补丁。\n配置起来比上述方法简单一些。[参考地址](http://tengine.taobao.org/document_cn/http_upstream_check_cn.html)\n\n```\nhttp {\n    upstream cluster1 {\n        # simple round-robin\n        server 192.168.0.1:80;\n        server 192.168.0.2:80;\n        check interval=3000 rise=2 fall=5 timeout=1000 type=http;\n        check_http_send \"HEAD / HTTP/1.0\\r\\n\\r\\n\";\n        check_http_expect_alive http_2xx http_3xx;\n    }\n    upstream cluster2 {\n        # simple round-robin\n        server 192.168.0.3:80;\n        server 192.168.0.4:80;\n        check interval=3000 rise=2 fall=5 timeout=1000 type=http;\n        check_keepalive_requests 100;\n        check_http_send \"HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n\";\n        check_http_expect_alive http_2xx http_3xx;\n```\n\n&emsp;&emsp;上面配置的意思是，对name这个负载均衡条目中的所有节点，每个3秒检测一次，请求2次正常则标记 realserver状态为up，如果检测 5 次都失败，则标记 realserver的状态为down，超时时间为1秒。\n\n- interval：向后端发送的健康检查包的间隔。\n- fall(fall_count): 如果连续失败次数达到fall_count，服务器就被认为是down。\n- rise(rise_count): 如果连续成功次数达到rise_count，服务器就被认为是up。\n- timeout: 后端健康请求的超时时间。\n- type：健康检查包的类型，现在支持以下多种类型\n    - tcp：简单的tcp连接，如果连接成功，就说明后端正常。\n    - ssl_hello：发送一个初始的SSL hello包并接受服务器的SSL hello包。\n    - http：发送HTTP请求，通过后端的回复包的状态来判断后端是否存活。\n    - mysql: 向mysql服务器连接，通过接收服务器的greeting包来判断后端是否存活。\n    - ajp：向后端发送AJP协议的Cping包，通过接收Cpong包来判断后端是否存活。\n\n**check_keepalive_requests**\n\n&emsp;&emsp;该指令可以配置一个连接发送的请求数，其默认值为1，表示Tengine完成1次请求后即关闭连接。\n\n**check_http_send**\n\n&emsp;&emsp;该指令可以配置http健康检查包发送的请求内容。为了减少传输数据量，推荐采用\"HEAD\"方法。\n\n当采用长连接进行健康检查时，需在该指令中添加keep-alive请求头，如：\"HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n\"。\n同时，在采用\"GET\"方法的情况下，请求uri的size不宜过大，确保可以在1个interval内传输完成，否则会被健康检查模块视为后端服务器或网络异常。\n\n**check_http_expect_alive**\n\n\n&emsp;&emsp;该指令指定HTTP回复的成功状态，默认认为2XX和3XX的状态是健康的。如果爬虫多404多可以把4XX也写进去。\n\n## rewrite\n\n> rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用\n\n**语法**\n`rewrite regex replacement [flag];`\n\nflag标志位\n\n- last – 相当于Apache的[L]标记，表示完成rewrite，浏览器地址不变\n- break – 中止 Rewirte，不再继续匹配，浏览器地址不变\n- redirect – 返回临时重定向的 HTTP 状态 302 浏览器地址显示跳转后的地址\n- permanent – 返回永久重定向的 HTTP 状态 301 浏览器地址显示跳转后的地址\n\nlast一般写在server和if中，而break一般使用在location中\n\nlast不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配。\n\n**简单举例**\n\n```\n// 访问/example.html 的时候重写到/index.html\nrewrite /example.html /index.html last;\n// 访问/example.html 的时候重写到/index.html,并停止匹配\nrewrite /example.html /index.html break;\n// 把 /search/key => /search.html?keyword=key\nrewrite '^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\\.(png|jpg|gif)$' /data?file=$3.$4 last;\n \"^\" 表示开头匹配 \"$\" 表示结尾匹配 而且表示路径的\"/\"是需要转义的，\"$1\"表示表达式匹配到的第一个括号里面的内容，即([a-z]{2})\n```\n\n正则实例可以[参考](http://www.cnblogs.com/zxin/archive/2013/01/26/2877765.html)\n\n\n","source":"_posts/nginx之location-upstream-rewrite.md","raw":"---\ntitle: 'nginx之location,upstream,rewrite'\ndate: 2017-07-08 14:19:45\ntags: nginx\ncategories: 基础运维\n---\n\n> nginx配置第三篇，[nginx安装配置](https://fanquqi.github.io/2017/07/06/nginx%E4%B9%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/)中讲了很多基础配置，这次讲一下具体的操作配置。\n\n## location配置\n\n> location模块工作在虚拟主机server之下，对URL进行匹配，如果匹配成功就按照该location之中写的语句进行操作。\n\n**语法** \n\nlocation [=|~|~*|^~] /uri/ { … }\n\n**匹配规则**\n\n|         模式        |         含义                        |\n|:------------------|:---------------------------------: |\n|location = /uri     | = 表示精确匹配，只有完全匹配上才能生效。  |\n|location ^~ /uri|^~ 开头对URL路径进行前缀匹配，并且在正则之前。|\n|location ~ pattern |区分大小写的正则匹配|\n|location ~* pattern|不区分大小写的正则匹配|\n|location /uri|不带任何修饰符，也表示前缀匹配，但是在正则匹配之后|\n|location /|通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default|\n\n&emsp;&emsp;那么如果我们在一个虚拟主机下边写了很多location 规则，哪一个先匹配哪一个后匹配呢？\n是这样的。\nnginx会根据模糊程度排序的\n\n- 首先精确匹配 =\n- 其次前缀匹配 ^~\n- 其次是按文件中顺序的正则匹配\n- 然后匹配不带任何修饰的前缀匹配。\n- 最后是交给 / 通用匹配\n- 当有匹配成功时候，停止匹配，按当前匹配规则处理请求\n\n## upstream\n> 负载均衡模块,负责根据配置合理分流到各个代理节点，而且自带后端节点健康检查（需要自己通过proxy_read_timeout指令和proxy_next_upstream指令配置）\n\n[参考文章](http://nolinux.blog.51cto.com/4824967/1594029)\n**语法** `upstream name {server ip:port 状态}`\n\n```\nhttp {\n    upstream name {\n        \n        [ip_hash;]\n        server ip:port [weight=n];\n        server ip:port [weight=n];\n    }\n\n\n\nserver {\n    listen 80;\n    server_name   www.xxx.com; \n\n    proxy_pass http://name;\n    或者\n    uwsgi_pass \n    或者\n    fast_cgi_pass\n    }\n    \n}\n```\n上下文 http server location \n\n\n\n负载均衡策略: \n- 轮询(默认)\n- 设置权重(weight)\n- ip_hash(每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。)\n\n其次还可以定义状态\n\n- down 表示单前的server暂时不参与负载\n- weight 默认为1.weight越大，负载的权重就越大。\n- max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误\n- fail_timeout:max_fails次失败后，暂停的时间。\n- backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。\n\n### 负载均衡后端节点健康检查\n\n&emsp;&emsp;严格来说，nginx自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的ngx_http_proxy_module.\n  模块和ngx_http_upstream_module模块中的相关指令来完成当后端节点出现故障时，自动切换到健康节点来提供访问。\n\n\n这里学习下ngx_http_proxy_module 模块中的 `proxy_connect_timeout` 指令、`proxy_read_timeout`指令和`proxy_next_upstream`指令\n\n**设置与后端服务器建立连接的超时时间。** 应该注意这个超时一般不可能大于75秒。\n    \n    proxy_connect_timeout 60s;\n\n**设置从后端服务器读取响应的超时**\n\n    proxy_read_timeout 60s;\n\n**指定在何种情况下一个失败的请求应该被发送到下一台后端服务节点**\n\n    proxy_next_upstream error timeout;\n\n`error`      和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误\n\n`timeout`    和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时\n\n`invalid_header`  后端服务器返回空响应或者非法响应头\n\n`http_500`    后端服务器返回的响应状态码为500\n\n`http_502`    后端服务器返回的响应状态码为502\n\n`http_503`    后端服务器返回的响应状态码为503\n\n`http_504`    后端服务器返回的响应状态码为504\n\n`http_404`    后端服务器返回的响应状态码为404\n\n`off`         停止将请求发送给下一台后端服务器\n\n&emsp;&emsp;还可以通过tengine来实现，淘宝技术团队开发的`nginx_upstream_check_module`模块来实现。\n如果没有使用tengine需要打补丁。\n配置起来比上述方法简单一些。[参考地址](http://tengine.taobao.org/document_cn/http_upstream_check_cn.html)\n\n```\nhttp {\n    upstream cluster1 {\n        # simple round-robin\n        server 192.168.0.1:80;\n        server 192.168.0.2:80;\n        check interval=3000 rise=2 fall=5 timeout=1000 type=http;\n        check_http_send \"HEAD / HTTP/1.0\\r\\n\\r\\n\";\n        check_http_expect_alive http_2xx http_3xx;\n    }\n    upstream cluster2 {\n        # simple round-robin\n        server 192.168.0.3:80;\n        server 192.168.0.4:80;\n        check interval=3000 rise=2 fall=5 timeout=1000 type=http;\n        check_keepalive_requests 100;\n        check_http_send \"HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n\";\n        check_http_expect_alive http_2xx http_3xx;\n```\n\n&emsp;&emsp;上面配置的意思是，对name这个负载均衡条目中的所有节点，每个3秒检测一次，请求2次正常则标记 realserver状态为up，如果检测 5 次都失败，则标记 realserver的状态为down，超时时间为1秒。\n\n- interval：向后端发送的健康检查包的间隔。\n- fall(fall_count): 如果连续失败次数达到fall_count，服务器就被认为是down。\n- rise(rise_count): 如果连续成功次数达到rise_count，服务器就被认为是up。\n- timeout: 后端健康请求的超时时间。\n- type：健康检查包的类型，现在支持以下多种类型\n    - tcp：简单的tcp连接，如果连接成功，就说明后端正常。\n    - ssl_hello：发送一个初始的SSL hello包并接受服务器的SSL hello包。\n    - http：发送HTTP请求，通过后端的回复包的状态来判断后端是否存活。\n    - mysql: 向mysql服务器连接，通过接收服务器的greeting包来判断后端是否存活。\n    - ajp：向后端发送AJP协议的Cping包，通过接收Cpong包来判断后端是否存活。\n\n**check_keepalive_requests**\n\n&emsp;&emsp;该指令可以配置一个连接发送的请求数，其默认值为1，表示Tengine完成1次请求后即关闭连接。\n\n**check_http_send**\n\n&emsp;&emsp;该指令可以配置http健康检查包发送的请求内容。为了减少传输数据量，推荐采用\"HEAD\"方法。\n\n当采用长连接进行健康检查时，需在该指令中添加keep-alive请求头，如：\"HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n\"。\n同时，在采用\"GET\"方法的情况下，请求uri的size不宜过大，确保可以在1个interval内传输完成，否则会被健康检查模块视为后端服务器或网络异常。\n\n**check_http_expect_alive**\n\n\n&emsp;&emsp;该指令指定HTTP回复的成功状态，默认认为2XX和3XX的状态是健康的。如果爬虫多404多可以把4XX也写进去。\n\n## rewrite\n\n> rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用\n\n**语法**\n`rewrite regex replacement [flag];`\n\nflag标志位\n\n- last – 相当于Apache的[L]标记，表示完成rewrite，浏览器地址不变\n- break – 中止 Rewirte，不再继续匹配，浏览器地址不变\n- redirect – 返回临时重定向的 HTTP 状态 302 浏览器地址显示跳转后的地址\n- permanent – 返回永久重定向的 HTTP 状态 301 浏览器地址显示跳转后的地址\n\nlast一般写在server和if中，而break一般使用在location中\n\nlast不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配。\n\n**简单举例**\n\n```\n// 访问/example.html 的时候重写到/index.html\nrewrite /example.html /index.html last;\n// 访问/example.html 的时候重写到/index.html,并停止匹配\nrewrite /example.html /index.html break;\n// 把 /search/key => /search.html?keyword=key\nrewrite '^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\\.(png|jpg|gif)$' /data?file=$3.$4 last;\n \"^\" 表示开头匹配 \"$\" 表示结尾匹配 而且表示路径的\"/\"是需要转义的，\"$1\"表示表达式匹配到的第一个括号里面的内容，即([a-z]{2})\n```\n\n正则实例可以[参考](http://www.cnblogs.com/zxin/archive/2013/01/26/2877765.html)\n\n\n","slug":"nginx之location-upstream-rewrite","published":1,"updated":"2017-08-09T03:13:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvb8002c8tzz6pkimzi9","content":"<blockquote>\n<p>nginx配置第三篇，<a href=\"https://fanquqi.github.io/2017/07/06/nginx%E4%B9%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/\" target=\"_blank\" rel=\"external\">nginx安装配置</a>中讲了很多基础配置，这次讲一下具体的操作配置。</p>\n</blockquote>\n<h2 id=\"location配置\"><a href=\"#location配置\" class=\"headerlink\" title=\"location配置\"></a>location配置</h2><blockquote>\n<p>location模块工作在虚拟主机server之下，对URL进行匹配，如果匹配成功就按照该location之中写的语句进行操作。</p>\n</blockquote>\n<p><strong>语法</strong> </p>\n<p>location [=|~|~*|^~] /uri/ { … }</p>\n<p><strong>匹配规则</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">模式</th>\n<th style=\"text-align:center\">含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">location = /uri</td>\n<td style=\"text-align:center\">= 表示精确匹配，只有完全匹配上才能生效。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location ^~ /uri</td>\n<td style=\"text-align:center\">^~ 开头对URL路径进行前缀匹配，并且在正则之前。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location ~ pattern</td>\n<td style=\"text-align:center\">区分大小写的正则匹配</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location ~* pattern</td>\n<td style=\"text-align:center\">不区分大小写的正则匹配</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location /uri</td>\n<td style=\"text-align:center\">不带任何修饰符，也表示前缀匹配，但是在正则匹配之后</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location /</td>\n<td style=\"text-align:center\">通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default</td>\n</tr>\n</tbody>\n</table>\n<p>&emsp;&emsp;那么如果我们在一个虚拟主机下边写了很多location 规则，哪一个先匹配哪一个后匹配呢？<br>是这样的。<br>nginx会根据模糊程度排序的</p>\n<ul>\n<li>首先精确匹配 =</li>\n<li>其次前缀匹配 ^~</li>\n<li>其次是按文件中顺序的正则匹配</li>\n<li>然后匹配不带任何修饰的前缀匹配。</li>\n<li>最后是交给 / 通用匹配</li>\n<li>当有匹配成功时候，停止匹配，按当前匹配规则处理请求</li>\n</ul>\n<h2 id=\"upstream\"><a href=\"#upstream\" class=\"headerlink\" title=\"upstream\"></a>upstream</h2><blockquote>\n<p>负载均衡模块,负责根据配置合理分流到各个代理节点，而且自带后端节点健康检查（需要自己通过proxy_read_timeout指令和proxy_next_upstream指令配置）</p>\n</blockquote>\n<p><a href=\"http://nolinux.blog.51cto.com/4824967/1594029\" target=\"_blank\" rel=\"external\">参考文章</a><br><strong>语法</strong> <code>upstream name {server ip:port 状态}</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">http &#123;</div><div class=\"line\">    upstream name &#123;</div><div class=\"line\">        </div><div class=\"line\">        [ip_hash;]</div><div class=\"line\">        server ip:port [weight=n];</div><div class=\"line\">        server ip:port [weight=n];</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">server &#123;</div><div class=\"line\">    listen 80;</div><div class=\"line\">    server_name   www.xxx.com; </div><div class=\"line\"></div><div class=\"line\">    proxy_pass http://name;</div><div class=\"line\">    或者</div><div class=\"line\">    uwsgi_pass </div><div class=\"line\">    或者</div><div class=\"line\">    fast_cgi_pass</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>上下文 http server location </p>\n<p>负载均衡策略: </p>\n<ul>\n<li>轮询(默认)</li>\n<li>设置权重(weight)</li>\n<li>ip_hash(每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。)</li>\n</ul>\n<p>其次还可以定义状态</p>\n<ul>\n<li>down 表示单前的server暂时不参与负载</li>\n<li>weight 默认为1.weight越大，负载的权重就越大。</li>\n<li>max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误</li>\n<li>fail_timeout:max_fails次失败后，暂停的时间。</li>\n<li>backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</li>\n</ul>\n<h3 id=\"负载均衡后端节点健康检查\"><a href=\"#负载均衡后端节点健康检查\" class=\"headerlink\" title=\"负载均衡后端节点健康检查\"></a>负载均衡后端节点健康检查</h3><p>&emsp;&emsp;严格来说，nginx自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的ngx_http_proxy_module.<br>  模块和ngx_http_upstream_module模块中的相关指令来完成当后端节点出现故障时，自动切换到健康节点来提供访问。</p>\n<p>这里学习下ngx_http_proxy_module 模块中的 <code>proxy_connect_timeout</code> 指令、<code>proxy_read_timeout</code>指令和<code>proxy_next_upstream</code>指令</p>\n<p><strong>设置与后端服务器建立连接的超时时间。</strong> 应该注意这个超时一般不可能大于75秒。</p>\n<pre><code>proxy_connect_timeout 60s;\n</code></pre><p><strong>设置从后端服务器读取响应的超时</strong></p>\n<pre><code>proxy_read_timeout 60s;\n</code></pre><p><strong>指定在何种情况下一个失败的请求应该被发送到下一台后端服务节点</strong></p>\n<pre><code>proxy_next_upstream error timeout;\n</code></pre><p><code>error</code>      和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误</p>\n<p><code>timeout</code>    和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时</p>\n<p><code>invalid_header</code>  后端服务器返回空响应或者非法响应头</p>\n<p><code>http_500</code>    后端服务器返回的响应状态码为500</p>\n<p><code>http_502</code>    后端服务器返回的响应状态码为502</p>\n<p><code>http_503</code>    后端服务器返回的响应状态码为503</p>\n<p><code>http_504</code>    后端服务器返回的响应状态码为504</p>\n<p><code>http_404</code>    后端服务器返回的响应状态码为404</p>\n<p><code>off</code>         停止将请求发送给下一台后端服务器</p>\n<p>&emsp;&emsp;还可以通过tengine来实现，淘宝技术团队开发的<code>nginx_upstream_check_module</code>模块来实现。<br>如果没有使用tengine需要打补丁。<br>配置起来比上述方法简单一些。<a href=\"http://tengine.taobao.org/document_cn/http_upstream_check_cn.html\" target=\"_blank\" rel=\"external\">参考地址</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">http &#123;</div><div class=\"line\">    upstream cluster1 &#123;</div><div class=\"line\">        # simple round-robin</div><div class=\"line\">        server 192.168.0.1:80;</div><div class=\"line\">        server 192.168.0.2:80;</div><div class=\"line\">        check interval=3000 rise=2 fall=5 timeout=1000 type=http;</div><div class=\"line\">        check_http_send &quot;HEAD / HTTP/1.0\\r\\n\\r\\n&quot;;</div><div class=\"line\">        check_http_expect_alive http_2xx http_3xx;</div><div class=\"line\">    &#125;</div><div class=\"line\">    upstream cluster2 &#123;</div><div class=\"line\">        # simple round-robin</div><div class=\"line\">        server 192.168.0.3:80;</div><div class=\"line\">        server 192.168.0.4:80;</div><div class=\"line\">        check interval=3000 rise=2 fall=5 timeout=1000 type=http;</div><div class=\"line\">        check_keepalive_requests 100;</div><div class=\"line\">        check_http_send &quot;HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n&quot;;</div><div class=\"line\">        check_http_expect_alive http_2xx http_3xx;</div></pre></td></tr></table></figure>\n<p>&emsp;&emsp;上面配置的意思是，对name这个负载均衡条目中的所有节点，每个3秒检测一次，请求2次正常则标记 realserver状态为up，如果检测 5 次都失败，则标记 realserver的状态为down，超时时间为1秒。</p>\n<ul>\n<li>interval：向后端发送的健康检查包的间隔。</li>\n<li>fall(fall_count): 如果连续失败次数达到fall_count，服务器就被认为是down。</li>\n<li>rise(rise_count): 如果连续成功次数达到rise_count，服务器就被认为是up。</li>\n<li>timeout: 后端健康请求的超时时间。</li>\n<li>type：健康检查包的类型，现在支持以下多种类型<ul>\n<li>tcp：简单的tcp连接，如果连接成功，就说明后端正常。</li>\n<li>ssl_hello：发送一个初始的SSL hello包并接受服务器的SSL hello包。</li>\n<li>http：发送HTTP请求，通过后端的回复包的状态来判断后端是否存活。</li>\n<li>mysql: 向mysql服务器连接，通过接收服务器的greeting包来判断后端是否存活。</li>\n<li>ajp：向后端发送AJP协议的Cping包，通过接收Cpong包来判断后端是否存活。</li>\n</ul>\n</li>\n</ul>\n<p><strong>check_keepalive_requests</strong></p>\n<p>&emsp;&emsp;该指令可以配置一个连接发送的请求数，其默认值为1，表示Tengine完成1次请求后即关闭连接。</p>\n<p><strong>check_http_send</strong></p>\n<p>&emsp;&emsp;该指令可以配置http健康检查包发送的请求内容。为了减少传输数据量，推荐采用”HEAD”方法。</p>\n<p>当采用长连接进行健康检查时，需在该指令中添加keep-alive请求头，如：”HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n”。<br>同时，在采用”GET”方法的情况下，请求uri的size不宜过大，确保可以在1个interval内传输完成，否则会被健康检查模块视为后端服务器或网络异常。</p>\n<p><strong>check_http_expect_alive</strong></p>\n<p>&emsp;&emsp;该指令指定HTTP回复的成功状态，默认认为2XX和3XX的状态是健康的。如果爬虫多404多可以把4XX也写进去。</p>\n<h2 id=\"rewrite\"><a href=\"#rewrite\" class=\"headerlink\" title=\"rewrite\"></a>rewrite</h2><blockquote>\n<p>rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用</p>\n</blockquote>\n<p><strong>语法</strong><br><code>rewrite regex replacement [flag];</code></p>\n<p>flag标志位</p>\n<ul>\n<li>last – 相当于Apache的[L]标记，表示完成rewrite，浏览器地址不变</li>\n<li>break – 中止 Rewirte，不再继续匹配，浏览器地址不变</li>\n<li>redirect – 返回临时重定向的 HTTP 状态 302 浏览器地址显示跳转后的地址</li>\n<li>permanent – 返回永久重定向的 HTTP 状态 301 浏览器地址显示跳转后的地址</li>\n</ul>\n<p>last一般写在server和if中，而break一般使用在location中</p>\n<p>last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配。</p>\n<p><strong>简单举例</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 访问/example.html 的时候重写到/index.html</div><div class=\"line\">rewrite /example.html /index.html last;</div><div class=\"line\">// 访问/example.html 的时候重写到/index.html,并停止匹配</div><div class=\"line\">rewrite /example.html /index.html break;</div><div class=\"line\">// 把 /search/key =&gt; /search.html?keyword=key</div><div class=\"line\">rewrite &apos;^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\\.(png|jpg|gif)$&apos; /data?file=$3.$4 last;</div><div class=\"line\"> &quot;^&quot; 表示开头匹配 &quot;$&quot; 表示结尾匹配 而且表示路径的&quot;/&quot;是需要转义的，&quot;$1&quot;表示表达式匹配到的第一个括号里面的内容，即([a-z]&#123;2&#125;)</div></pre></td></tr></table></figure>\n<p>正则实例可以<a href=\"http://www.cnblogs.com/zxin/archive/2013/01/26/2877765.html\" target=\"_blank\" rel=\"external\">参考</a></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>nginx配置第三篇，<a href=\"https://fanquqi.github.io/2017/07/06/nginx%E4%B9%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/\" target=\"_blank\" rel=\"external\">nginx安装配置</a>中讲了很多基础配置，这次讲一下具体的操作配置。</p>\n</blockquote>\n<h2 id=\"location配置\"><a href=\"#location配置\" class=\"headerlink\" title=\"location配置\"></a>location配置</h2><blockquote>\n<p>location模块工作在虚拟主机server之下，对URL进行匹配，如果匹配成功就按照该location之中写的语句进行操作。</p>\n</blockquote>\n<p><strong>语法</strong> </p>\n<p>location [=|~|~*|^~] /uri/ { … }</p>\n<p><strong>匹配规则</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">模式</th>\n<th style=\"text-align:center\">含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">location = /uri</td>\n<td style=\"text-align:center\">= 表示精确匹配，只有完全匹配上才能生效。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location ^~ /uri</td>\n<td style=\"text-align:center\">^~ 开头对URL路径进行前缀匹配，并且在正则之前。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location ~ pattern</td>\n<td style=\"text-align:center\">区分大小写的正则匹配</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location ~* pattern</td>\n<td style=\"text-align:center\">不区分大小写的正则匹配</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location /uri</td>\n<td style=\"text-align:center\">不带任何修饰符，也表示前缀匹配，但是在正则匹配之后</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location /</td>\n<td style=\"text-align:center\">通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default</td>\n</tr>\n</tbody>\n</table>\n<p>&emsp;&emsp;那么如果我们在一个虚拟主机下边写了很多location 规则，哪一个先匹配哪一个后匹配呢？<br>是这样的。<br>nginx会根据模糊程度排序的</p>\n<ul>\n<li>首先精确匹配 =</li>\n<li>其次前缀匹配 ^~</li>\n<li>其次是按文件中顺序的正则匹配</li>\n<li>然后匹配不带任何修饰的前缀匹配。</li>\n<li>最后是交给 / 通用匹配</li>\n<li>当有匹配成功时候，停止匹配，按当前匹配规则处理请求</li>\n</ul>\n<h2 id=\"upstream\"><a href=\"#upstream\" class=\"headerlink\" title=\"upstream\"></a>upstream</h2><blockquote>\n<p>负载均衡模块,负责根据配置合理分流到各个代理节点，而且自带后端节点健康检查（需要自己通过proxy_read_timeout指令和proxy_next_upstream指令配置）</p>\n</blockquote>\n<p><a href=\"http://nolinux.blog.51cto.com/4824967/1594029\" target=\"_blank\" rel=\"external\">参考文章</a><br><strong>语法</strong> <code>upstream name {server ip:port 状态}</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">http &#123;</div><div class=\"line\">    upstream name &#123;</div><div class=\"line\">        </div><div class=\"line\">        [ip_hash;]</div><div class=\"line\">        server ip:port [weight=n];</div><div class=\"line\">        server ip:port [weight=n];</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">server &#123;</div><div class=\"line\">    listen 80;</div><div class=\"line\">    server_name   www.xxx.com; </div><div class=\"line\"></div><div class=\"line\">    proxy_pass http://name;</div><div class=\"line\">    或者</div><div class=\"line\">    uwsgi_pass </div><div class=\"line\">    或者</div><div class=\"line\">    fast_cgi_pass</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>上下文 http server location </p>\n<p>负载均衡策略: </p>\n<ul>\n<li>轮询(默认)</li>\n<li>设置权重(weight)</li>\n<li>ip_hash(每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。)</li>\n</ul>\n<p>其次还可以定义状态</p>\n<ul>\n<li>down 表示单前的server暂时不参与负载</li>\n<li>weight 默认为1.weight越大，负载的权重就越大。</li>\n<li>max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误</li>\n<li>fail_timeout:max_fails次失败后，暂停的时间。</li>\n<li>backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</li>\n</ul>\n<h3 id=\"负载均衡后端节点健康检查\"><a href=\"#负载均衡后端节点健康检查\" class=\"headerlink\" title=\"负载均衡后端节点健康检查\"></a>负载均衡后端节点健康检查</h3><p>&emsp;&emsp;严格来说，nginx自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的ngx_http_proxy_module.<br>  模块和ngx_http_upstream_module模块中的相关指令来完成当后端节点出现故障时，自动切换到健康节点来提供访问。</p>\n<p>这里学习下ngx_http_proxy_module 模块中的 <code>proxy_connect_timeout</code> 指令、<code>proxy_read_timeout</code>指令和<code>proxy_next_upstream</code>指令</p>\n<p><strong>设置与后端服务器建立连接的超时时间。</strong> 应该注意这个超时一般不可能大于75秒。</p>\n<pre><code>proxy_connect_timeout 60s;\n</code></pre><p><strong>设置从后端服务器读取响应的超时</strong></p>\n<pre><code>proxy_read_timeout 60s;\n</code></pre><p><strong>指定在何种情况下一个失败的请求应该被发送到下一台后端服务节点</strong></p>\n<pre><code>proxy_next_upstream error timeout;\n</code></pre><p><code>error</code>      和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误</p>\n<p><code>timeout</code>    和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时</p>\n<p><code>invalid_header</code>  后端服务器返回空响应或者非法响应头</p>\n<p><code>http_500</code>    后端服务器返回的响应状态码为500</p>\n<p><code>http_502</code>    后端服务器返回的响应状态码为502</p>\n<p><code>http_503</code>    后端服务器返回的响应状态码为503</p>\n<p><code>http_504</code>    后端服务器返回的响应状态码为504</p>\n<p><code>http_404</code>    后端服务器返回的响应状态码为404</p>\n<p><code>off</code>         停止将请求发送给下一台后端服务器</p>\n<p>&emsp;&emsp;还可以通过tengine来实现，淘宝技术团队开发的<code>nginx_upstream_check_module</code>模块来实现。<br>如果没有使用tengine需要打补丁。<br>配置起来比上述方法简单一些。<a href=\"http://tengine.taobao.org/document_cn/http_upstream_check_cn.html\" target=\"_blank\" rel=\"external\">参考地址</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">http &#123;</div><div class=\"line\">    upstream cluster1 &#123;</div><div class=\"line\">        # simple round-robin</div><div class=\"line\">        server 192.168.0.1:80;</div><div class=\"line\">        server 192.168.0.2:80;</div><div class=\"line\">        check interval=3000 rise=2 fall=5 timeout=1000 type=http;</div><div class=\"line\">        check_http_send &quot;HEAD / HTTP/1.0\\r\\n\\r\\n&quot;;</div><div class=\"line\">        check_http_expect_alive http_2xx http_3xx;</div><div class=\"line\">    &#125;</div><div class=\"line\">    upstream cluster2 &#123;</div><div class=\"line\">        # simple round-robin</div><div class=\"line\">        server 192.168.0.3:80;</div><div class=\"line\">        server 192.168.0.4:80;</div><div class=\"line\">        check interval=3000 rise=2 fall=5 timeout=1000 type=http;</div><div class=\"line\">        check_keepalive_requests 100;</div><div class=\"line\">        check_http_send &quot;HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n&quot;;</div><div class=\"line\">        check_http_expect_alive http_2xx http_3xx;</div></pre></td></tr></table></figure>\n<p>&emsp;&emsp;上面配置的意思是，对name这个负载均衡条目中的所有节点，每个3秒检测一次，请求2次正常则标记 realserver状态为up，如果检测 5 次都失败，则标记 realserver的状态为down，超时时间为1秒。</p>\n<ul>\n<li>interval：向后端发送的健康检查包的间隔。</li>\n<li>fall(fall_count): 如果连续失败次数达到fall_count，服务器就被认为是down。</li>\n<li>rise(rise_count): 如果连续成功次数达到rise_count，服务器就被认为是up。</li>\n<li>timeout: 后端健康请求的超时时间。</li>\n<li>type：健康检查包的类型，现在支持以下多种类型<ul>\n<li>tcp：简单的tcp连接，如果连接成功，就说明后端正常。</li>\n<li>ssl_hello：发送一个初始的SSL hello包并接受服务器的SSL hello包。</li>\n<li>http：发送HTTP请求，通过后端的回复包的状态来判断后端是否存活。</li>\n<li>mysql: 向mysql服务器连接，通过接收服务器的greeting包来判断后端是否存活。</li>\n<li>ajp：向后端发送AJP协议的Cping包，通过接收Cpong包来判断后端是否存活。</li>\n</ul>\n</li>\n</ul>\n<p><strong>check_keepalive_requests</strong></p>\n<p>&emsp;&emsp;该指令可以配置一个连接发送的请求数，其默认值为1，表示Tengine完成1次请求后即关闭连接。</p>\n<p><strong>check_http_send</strong></p>\n<p>&emsp;&emsp;该指令可以配置http健康检查包发送的请求内容。为了减少传输数据量，推荐采用”HEAD”方法。</p>\n<p>当采用长连接进行健康检查时，需在该指令中添加keep-alive请求头，如：”HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n”。<br>同时，在采用”GET”方法的情况下，请求uri的size不宜过大，确保可以在1个interval内传输完成，否则会被健康检查模块视为后端服务器或网络异常。</p>\n<p><strong>check_http_expect_alive</strong></p>\n<p>&emsp;&emsp;该指令指定HTTP回复的成功状态，默认认为2XX和3XX的状态是健康的。如果爬虫多404多可以把4XX也写进去。</p>\n<h2 id=\"rewrite\"><a href=\"#rewrite\" class=\"headerlink\" title=\"rewrite\"></a>rewrite</h2><blockquote>\n<p>rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用</p>\n</blockquote>\n<p><strong>语法</strong><br><code>rewrite regex replacement [flag];</code></p>\n<p>flag标志位</p>\n<ul>\n<li>last – 相当于Apache的[L]标记，表示完成rewrite，浏览器地址不变</li>\n<li>break – 中止 Rewirte，不再继续匹配，浏览器地址不变</li>\n<li>redirect – 返回临时重定向的 HTTP 状态 302 浏览器地址显示跳转后的地址</li>\n<li>permanent – 返回永久重定向的 HTTP 状态 301 浏览器地址显示跳转后的地址</li>\n</ul>\n<p>last一般写在server和if中，而break一般使用在location中</p>\n<p>last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配。</p>\n<p><strong>简单举例</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 访问/example.html 的时候重写到/index.html</div><div class=\"line\">rewrite /example.html /index.html last;</div><div class=\"line\">// 访问/example.html 的时候重写到/index.html,并停止匹配</div><div class=\"line\">rewrite /example.html /index.html break;</div><div class=\"line\">// 把 /search/key =&gt; /search.html?keyword=key</div><div class=\"line\">rewrite &apos;^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\\.(png|jpg|gif)$&apos; /data?file=$3.$4 last;</div><div class=\"line\"> &quot;^&quot; 表示开头匹配 &quot;$&quot; 表示结尾匹配 而且表示路径的&quot;/&quot;是需要转义的，&quot;$1&quot;表示表达式匹配到的第一个括号里面的内容，即([a-z]&#123;2&#125;)</div></pre></td></tr></table></figure>\n<p>正则实例可以<a href=\"http://www.cnblogs.com/zxin/archive/2013/01/26/2877765.html\" target=\"_blank\" rel=\"external\">参考</a></p>\n"},{"title":"influxdb使用笔记","date":"2017-07-06T12:00:36.000Z","_content":"> 之前从ucloudAPI上取下来的数据需要存到influxdb中，在grafana中进行展示。grafana是我自行部署推广使用的，influxdb是别的同事之前就开始用了。我这次正好用上，所以仔细看了下。虽然人家都把API封装好了，只是拿过来就用的事儿。但是我只是个爱学习的孩子。。。\n\n## 介绍\n> 关于时序数据库，除了常用的ElasticSearch之外，InfluxDB也是一个选择。\n\nInfluxDB 使用 go 语言编写。个人认为几个外在的优点在于：\n\n- 无特殊依赖，几乎开箱即用（如ES需要Java）；\n- 自带HTTP管理界面，免插件配置（如ES的kopf或者head）；\n- 自带数据过期功能；\n- 类SQL查询语句（再提ES，查询使用自己的DSL，虽然也可以通过sql插件来使用类SQL进行查询）；\n- 自带权限管理，精细到“表”级别；\n\n## 关键词解读\n参考[官方文档](https://docs.influxdata.com/influxdb/v1.0/concepts/glossary)\n\n- `time`  这个概念首先说明，influxdb本身就是一个时序数据库类似Elasticsearch，所以用来做流处理是很好的，一次插入，多次读写，少改动。 每次插入一条数据都必须要求一个时间戳，自己不定义他就自动生成。\n- `database`  就是数据库\n- `measurement` 相当于mysql中的table\n- `field` 类似于MySQL的字段，没有索引的列，是influxDB数据必须的组成部分。\n- `tags` 相当于MySQL带索引的字段，不必须\n- `retention policy (RP)` 描述数据存储多久，以及规定几个分片\n- `point` 同一时间戳产生的数据集合\n- `sereis`  measurement, tag set, and retention policy 都相同的数据集合\n\n\n## CLI命令\n> CLI[官方文档](https://docs.influxdata.com/influxdb/v1.2/introduction/getting_started/)\n> influx的CLI命令与mysql还是有很多相似之处的。不过用influxdb我们更多的是用他的API很少用到CLI，只是了解下，自己调试代码的时候可以验证一下自己的数据到底写没写进来。\n\n\n#### 建库\n\n```\nCREATE DATABASE mydb\n\n验证：\nSHOW DATABASES\n\n使用：\nUSE mydb\n```\n\n现在，建好库可以插入数据了。\n\n**数据类型**\n只支持以下几种\n`float`,`integer`,`string`,`Boolean`,`Timestamp`\n\n#### 建表并插入数据\n这条命令表示: 新建一个表名为`cpu`的表，设置`host`为`serverA`,`region`为`us_west`,`value`为0.64,其中 **host,region** 属性为`tags`, **value** 属性为`field`\n```\nINSERT cpu,host=serverA,region=us_west value=0.64\n```\n\n#### 查询数据\n```\nSELECT \"host\", \"region\", \"value\" FROM \"cpu\" WHERE \"value\">0.9\n```\n\n## HTTP API使用\n[官方文档查看](https://docs.influxdata.com/influxdb/v1.0/guides/writing_data/)\n\n建库\n```\ncurl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE mydb\"\n```\n\n单条数据写入\n\n```\ncurl -i -XPOST 'http://localhost:8086/write?db=mydb' --data-binary 'cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000'\n```\n\n多条数据写入\n```\ncurl -i -XPOST 'http://localhost:8086/write?db=mydb' --data-binary 'cpu_load_short,host=server02 value=0.67\ncpu_load_short,host=server02,region=us-west value=0.55 1422568543702900257\ncpu_load_short,direction=in,host=server01,region=us-west value=2.0 1422568543702900257'\n```\n\n\n","source":"_posts/influxdb使用笔记.md","raw":"---\ntitle: influxdb使用笔记\ndate: 2017-07-06 20:00:36\ntags: influxdb\ncategories: influxdb\n---\n> 之前从ucloudAPI上取下来的数据需要存到influxdb中，在grafana中进行展示。grafana是我自行部署推广使用的，influxdb是别的同事之前就开始用了。我这次正好用上，所以仔细看了下。虽然人家都把API封装好了，只是拿过来就用的事儿。但是我只是个爱学习的孩子。。。\n\n## 介绍\n> 关于时序数据库，除了常用的ElasticSearch之外，InfluxDB也是一个选择。\n\nInfluxDB 使用 go 语言编写。个人认为几个外在的优点在于：\n\n- 无特殊依赖，几乎开箱即用（如ES需要Java）；\n- 自带HTTP管理界面，免插件配置（如ES的kopf或者head）；\n- 自带数据过期功能；\n- 类SQL查询语句（再提ES，查询使用自己的DSL，虽然也可以通过sql插件来使用类SQL进行查询）；\n- 自带权限管理，精细到“表”级别；\n\n## 关键词解读\n参考[官方文档](https://docs.influxdata.com/influxdb/v1.0/concepts/glossary)\n\n- `time`  这个概念首先说明，influxdb本身就是一个时序数据库类似Elasticsearch，所以用来做流处理是很好的，一次插入，多次读写，少改动。 每次插入一条数据都必须要求一个时间戳，自己不定义他就自动生成。\n- `database`  就是数据库\n- `measurement` 相当于mysql中的table\n- `field` 类似于MySQL的字段，没有索引的列，是influxDB数据必须的组成部分。\n- `tags` 相当于MySQL带索引的字段，不必须\n- `retention policy (RP)` 描述数据存储多久，以及规定几个分片\n- `point` 同一时间戳产生的数据集合\n- `sereis`  measurement, tag set, and retention policy 都相同的数据集合\n\n\n## CLI命令\n> CLI[官方文档](https://docs.influxdata.com/influxdb/v1.2/introduction/getting_started/)\n> influx的CLI命令与mysql还是有很多相似之处的。不过用influxdb我们更多的是用他的API很少用到CLI，只是了解下，自己调试代码的时候可以验证一下自己的数据到底写没写进来。\n\n\n#### 建库\n\n```\nCREATE DATABASE mydb\n\n验证：\nSHOW DATABASES\n\n使用：\nUSE mydb\n```\n\n现在，建好库可以插入数据了。\n\n**数据类型**\n只支持以下几种\n`float`,`integer`,`string`,`Boolean`,`Timestamp`\n\n#### 建表并插入数据\n这条命令表示: 新建一个表名为`cpu`的表，设置`host`为`serverA`,`region`为`us_west`,`value`为0.64,其中 **host,region** 属性为`tags`, **value** 属性为`field`\n```\nINSERT cpu,host=serverA,region=us_west value=0.64\n```\n\n#### 查询数据\n```\nSELECT \"host\", \"region\", \"value\" FROM \"cpu\" WHERE \"value\">0.9\n```\n\n## HTTP API使用\n[官方文档查看](https://docs.influxdata.com/influxdb/v1.0/guides/writing_data/)\n\n建库\n```\ncurl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE mydb\"\n```\n\n单条数据写入\n\n```\ncurl -i -XPOST 'http://localhost:8086/write?db=mydb' --data-binary 'cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000'\n```\n\n多条数据写入\n```\ncurl -i -XPOST 'http://localhost:8086/write?db=mydb' --data-binary 'cpu_load_short,host=server02 value=0.67\ncpu_load_short,host=server02,region=us-west value=0.55 1422568543702900257\ncpu_load_short,direction=in,host=server01,region=us-west value=2.0 1422568543702900257'\n```\n\n\n","slug":"influxdb使用笔记","published":1,"updated":"2017-07-12T05:44:25.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbb002e8tzzu9y3hvof","content":"<blockquote>\n<p>之前从ucloudAPI上取下来的数据需要存到influxdb中，在grafana中进行展示。grafana是我自行部署推广使用的，influxdb是别的同事之前就开始用了。我这次正好用上，所以仔细看了下。虽然人家都把API封装好了，只是拿过来就用的事儿。但是我只是个爱学习的孩子。。。</p>\n</blockquote>\n<h2 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><blockquote>\n<p>关于时序数据库，除了常用的ElasticSearch之外，InfluxDB也是一个选择。</p>\n</blockquote>\n<p>InfluxDB 使用 go 语言编写。个人认为几个外在的优点在于：</p>\n<ul>\n<li>无特殊依赖，几乎开箱即用（如ES需要Java）；</li>\n<li>自带HTTP管理界面，免插件配置（如ES的kopf或者head）；</li>\n<li>自带数据过期功能；</li>\n<li>类SQL查询语句（再提ES，查询使用自己的DSL，虽然也可以通过sql插件来使用类SQL进行查询）；</li>\n<li>自带权限管理，精细到“表”级别；</li>\n</ul>\n<h2 id=\"关键词解读\"><a href=\"#关键词解读\" class=\"headerlink\" title=\"关键词解读\"></a>关键词解读</h2><p>参考<a href=\"https://docs.influxdata.com/influxdb/v1.0/concepts/glossary\" target=\"_blank\" rel=\"external\">官方文档</a></p>\n<ul>\n<li><code>time</code>  这个概念首先说明，influxdb本身就是一个时序数据库类似Elasticsearch，所以用来做流处理是很好的，一次插入，多次读写，少改动。 每次插入一条数据都必须要求一个时间戳，自己不定义他就自动生成。</li>\n<li><code>database</code>  就是数据库</li>\n<li><code>measurement</code> 相当于mysql中的table</li>\n<li><code>field</code> 类似于MySQL的字段，没有索引的列，是influxDB数据必须的组成部分。</li>\n<li><code>tags</code> 相当于MySQL带索引的字段，不必须</li>\n<li><code>retention policy (RP)</code> 描述数据存储多久，以及规定几个分片</li>\n<li><code>point</code> 同一时间戳产生的数据集合</li>\n<li><code>sereis</code>  measurement, tag set, and retention policy 都相同的数据集合</li>\n</ul>\n<h2 id=\"cli命令\"><a href=\"#CLI命令\" class=\"headerlink\" title=\"CLI命令\"></a>CLI命令</h2><blockquote>\n<p>CLI<a href=\"https://docs.influxdata.com/influxdb/v1.2/introduction/getting_started/\" target=\"_blank\" rel=\"external\">官方文档</a><br>influx的CLI命令与mysql还是有很多相似之处的。不过用influxdb我们更多的是用他的API很少用到CLI，只是了解下，自己调试代码的时候可以验证一下自己的数据到底写没写进来。</p>\n</blockquote>\n<h4 id=\"建库\"><a href=\"#建库\" class=\"headerlink\" title=\"建库\"></a>建库</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">CREATE DATABASE mydb</div><div class=\"line\"></div><div class=\"line\">验证：</div><div class=\"line\">SHOW DATABASES</div><div class=\"line\"></div><div class=\"line\">使用：</div><div class=\"line\">USE mydb</div></pre></td></tr></table></figure>\n<p>现在，建好库可以插入数据了。</p>\n<p><strong>数据类型</strong><br>只支持以下几种<br><code>float</code>,<code>integer</code>,<code>string</code>,<code>Boolean</code>,<code>Timestamp</code></p>\n<h4 id=\"建表并插入数据\"><a href=\"#建表并插入数据\" class=\"headerlink\" title=\"建表并插入数据\"></a>建表并插入数据</h4><p>这条命令表示: 新建一个表名为<code>cpu</code>的表，设置<code>host</code>为<code>serverA</code>,<code>region</code>为<code>us_west</code>,<code>value</code>为0.64,其中 <strong>host,region</strong> 属性为<code>tags</code>, <strong>value</strong> 属性为<code>field</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">INSERT cpu,host=serverA,region=us_west value=0.64</div></pre></td></tr></table></figure></p>\n<h4 id=\"查询数据\"><a href=\"#查询数据\" class=\"headerlink\" title=\"查询数据\"></a>查询数据</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">SELECT &quot;host&quot;, &quot;region&quot;, &quot;value&quot; FROM &quot;cpu&quot; WHERE &quot;value&quot;&gt;0.9</div></pre></td></tr></table></figure>\n<h2 id=\"http-api使用\"><a href=\"#HTTP-API使用\" class=\"headerlink\" title=\"HTTP API使用\"></a>HTTP API使用</h2><p><a href=\"https://docs.influxdata.com/influxdb/v1.0/guides/writing_data/\" target=\"_blank\" rel=\"external\">官方文档查看</a></p>\n<p>建库<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -i -XPOST http://localhost:8086/query --data-urlencode &quot;q=CREATE DATABASE mydb&quot;</div></pre></td></tr></table></figure></p>\n<p>单条数据写入</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -i -XPOST &apos;http://localhost:8086/write?db=mydb&apos; --data-binary &apos;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&apos;</div></pre></td></tr></table></figure>\n<p>多条数据写入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -i -XPOST &apos;http://localhost:8086/write?db=mydb&apos; --data-binary &apos;cpu_load_short,host=server02 value=0.67</div><div class=\"line\">cpu_load_short,host=server02,region=us-west value=0.55 1422568543702900257</div><div class=\"line\">cpu_load_short,direction=in,host=server01,region=us-west value=2.0 1422568543702900257&apos;</div></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>之前从ucloudAPI上取下来的数据需要存到influxdb中，在grafana中进行展示。grafana是我自行部署推广使用的，influxdb是别的同事之前就开始用了。我这次正好用上，所以仔细看了下。虽然人家都把API封装好了，只是拿过来就用的事儿。但是我只是个爱学习的孩子。。。</p>\n</blockquote>\n<h2 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><blockquote>\n<p>关于时序数据库，除了常用的ElasticSearch之外，InfluxDB也是一个选择。</p>\n</blockquote>\n<p>InfluxDB 使用 go 语言编写。个人认为几个外在的优点在于：</p>\n<ul>\n<li>无特殊依赖，几乎开箱即用（如ES需要Java）；</li>\n<li>自带HTTP管理界面，免插件配置（如ES的kopf或者head）；</li>\n<li>自带数据过期功能；</li>\n<li>类SQL查询语句（再提ES，查询使用自己的DSL，虽然也可以通过sql插件来使用类SQL进行查询）；</li>\n<li>自带权限管理，精细到“表”级别；</li>\n</ul>\n<h2 id=\"关键词解读\"><a href=\"#关键词解读\" class=\"headerlink\" title=\"关键词解读\"></a>关键词解读</h2><p>参考<a href=\"https://docs.influxdata.com/influxdb/v1.0/concepts/glossary\" target=\"_blank\" rel=\"external\">官方文档</a></p>\n<ul>\n<li><code>time</code>  这个概念首先说明，influxdb本身就是一个时序数据库类似Elasticsearch，所以用来做流处理是很好的，一次插入，多次读写，少改动。 每次插入一条数据都必须要求一个时间戳，自己不定义他就自动生成。</li>\n<li><code>database</code>  就是数据库</li>\n<li><code>measurement</code> 相当于mysql中的table</li>\n<li><code>field</code> 类似于MySQL的字段，没有索引的列，是influxDB数据必须的组成部分。</li>\n<li><code>tags</code> 相当于MySQL带索引的字段，不必须</li>\n<li><code>retention policy (RP)</code> 描述数据存储多久，以及规定几个分片</li>\n<li><code>point</code> 同一时间戳产生的数据集合</li>\n<li><code>sereis</code>  measurement, tag set, and retention policy 都相同的数据集合</li>\n</ul>\n<h2 id=\"CLI命令\"><a href=\"#CLI命令\" class=\"headerlink\" title=\"CLI命令\"></a>CLI命令</h2><blockquote>\n<p>CLI<a href=\"https://docs.influxdata.com/influxdb/v1.2/introduction/getting_started/\" target=\"_blank\" rel=\"external\">官方文档</a><br>influx的CLI命令与mysql还是有很多相似之处的。不过用influxdb我们更多的是用他的API很少用到CLI，只是了解下，自己调试代码的时候可以验证一下自己的数据到底写没写进来。</p>\n</blockquote>\n<h4 id=\"建库\"><a href=\"#建库\" class=\"headerlink\" title=\"建库\"></a>建库</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">CREATE DATABASE mydb</div><div class=\"line\"></div><div class=\"line\">验证：</div><div class=\"line\">SHOW DATABASES</div><div class=\"line\"></div><div class=\"line\">使用：</div><div class=\"line\">USE mydb</div></pre></td></tr></table></figure>\n<p>现在，建好库可以插入数据了。</p>\n<p><strong>数据类型</strong><br>只支持以下几种<br><code>float</code>,<code>integer</code>,<code>string</code>,<code>Boolean</code>,<code>Timestamp</code></p>\n<h4 id=\"建表并插入数据\"><a href=\"#建表并插入数据\" class=\"headerlink\" title=\"建表并插入数据\"></a>建表并插入数据</h4><p>这条命令表示: 新建一个表名为<code>cpu</code>的表，设置<code>host</code>为<code>serverA</code>,<code>region</code>为<code>us_west</code>,<code>value</code>为0.64,其中 <strong>host,region</strong> 属性为<code>tags</code>, <strong>value</strong> 属性为<code>field</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">INSERT cpu,host=serverA,region=us_west value=0.64</div></pre></td></tr></table></figure></p>\n<h4 id=\"查询数据\"><a href=\"#查询数据\" class=\"headerlink\" title=\"查询数据\"></a>查询数据</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">SELECT &quot;host&quot;, &quot;region&quot;, &quot;value&quot; FROM &quot;cpu&quot; WHERE &quot;value&quot;&gt;0.9</div></pre></td></tr></table></figure>\n<h2 id=\"HTTP-API使用\"><a href=\"#HTTP-API使用\" class=\"headerlink\" title=\"HTTP API使用\"></a>HTTP API使用</h2><p><a href=\"https://docs.influxdata.com/influxdb/v1.0/guides/writing_data/\" target=\"_blank\" rel=\"external\">官方文档查看</a></p>\n<p>建库<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -i -XPOST http://localhost:8086/query --data-urlencode &quot;q=CREATE DATABASE mydb&quot;</div></pre></td></tr></table></figure></p>\n<p>单条数据写入</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -i -XPOST &apos;http://localhost:8086/write?db=mydb&apos; --data-binary &apos;cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000&apos;</div></pre></td></tr></table></figure>\n<p>多条数据写入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -i -XPOST &apos;http://localhost:8086/write?db=mydb&apos; --data-binary &apos;cpu_load_short,host=server02 value=0.67</div><div class=\"line\">cpu_load_short,host=server02,region=us-west value=0.55 1422568543702900257</div><div class=\"line\">cpu_load_short,direction=in,host=server01,region=us-west value=2.0 1422568543702900257&apos;</div></pre></td></tr></table></figure></p>\n"},{"title":"mysql误删除表恢复","date":"2017-08-04T09:12:09.000Z","_content":"\n# 场景描述\n 今天有个开发哥哥来找我。说有个医生信息表被删除了（测试服）但是现在版本正在测试，账号已经登不上了，bug群里已经有人说话了，CTO已经看到了，情况已经很紧急了。但是我之前也没有遇到过这类事情，而且测试服mysql是不备份的，一时不知道要怎么办。\n\n# 解决\n\n**但是** 事情还是要解决也总是有解决办法。下边按照先后顺序记录了下我的操作方案。\n\n## 方案一\n\n> 使用bin-log，我们测试服mysql是有记录mysql-binlog的，（本来也是没有开的，在六月份的时候测试服总是内存不够用，我把数据库从本地迁移独立了出来开启了bin-log）\n\n**bin-log恢复方案介绍**\n\n先查看这次今天mysql操作记录，发现没有什么操作，毕竟周五， 所以计划直接恢复到删表之前（就是昨天，中间操作的一段时间有几个今天修改的记录不见得情况），然后再从删表后的时间节点到现在恢复，等于只跳过了那条删表操作，别的操作都重新来一遍。\n\n### 操作流程\n\n首先查看mysql-binlog 找到误操作drop table的时间节点 这里没有图文。。。\n    \n    // 查找对应的bin-log文件\n    mysqlbinlog mysql-bin.000002 | grep -A4 \"table_name\" \n\n然后恢复对应时间节点恢复（其实mysqlbinlog也可以对应postion节点恢复）\n    mysqlbinlog -d test_medical --stop-datetime='2017-08-03 17:57:05' /home/mysql/3306/data/mysql-bin.000002 | mysql -uroot -p -P 3306 -S /home/mysql/3306/mysql.sock\n    // -d 数据库名  --stop-datetime 结束时间点，--start-datetime 开始时间节点 二者可以一起写就是中间时间短的操作 \n\n    \n可想而知我这样操作的结果，肯定是一堆冲突，因为当前数据库已经是操作过一遍的结果了，再把执行过得命令拿过来执行下，肯定是有错误。\n所以我们方案一肯定是不可取的。\n\n![](http://or2jd66dq.bkt.clouddn.com/binlog-error.png)\n\n\n## 方案二\n\n> 我之前是有迁移过这个MySQL的，我赶紧看了下迁移的数据压缩包还在时间是2017-6-19,顿时感觉欣喜若狂\n\n我的设想是这样的，因为时间久远肯定不能再这个mysql上恢复到一个多月之前，我想把数据包下到本地电脑mysql，恢复数据，把这个表的dump下来，传到测试服mysql。然后数据包压缩完之后有3G多 下载限速1M大约一个小时。\n太久了。\n我索性在测试数据库服务器上 用ansible由装了一个mysql实例端口3309用时两分钟不到。\n\n恢复数据 [参考文档](https://fanquqi.github.io/2017/06/16/%E5%87%A0%E7%A7%8Dmysql%E8%BF%81%E7%A7%BB/)\n\n然后用mysqlbinlog恢复这一个多月来的数据。\n\n    mysqlbinlog -d test_medical --stop-datetime='2017-08-03 17:57:05' /home/mysql/3306/data/mysql-bin.000001 | mysql -uroot -p -P3309 -S /home/mysql/3309/mysql.sock\n    \n    mysqlbinlog -d test_medical --stop-datetime='2017-08-03 17:57:05' /home/mysql/3306/data/mysql-bin.000002 | mysql -uroot -p -P3309 -S /home/mysql/3309/mysql.sock\n\n备份表\n\n    mysqldump -uroot -p test_medical table_name > table_name.sql\n\n然后进到mysql source一下  结束。。\n\n\n# 总结\n\nbinlog是结合备份来用的，其实我们这次恢复也算是 `备份—恢复`流程\n\n所以\n\n数据库备份很重要，\n\n数据库备份很重要，\n\n数据库备份很重要。 \n\n\n","source":"_posts/mysql误删除表恢复.md","raw":"---\ntitle: mysql误删除表恢复\ndate: 2017-08-04 17:12:09\ntags: MySQL\ncategories: 数据库\n---\n\n# 场景描述\n 今天有个开发哥哥来找我。说有个医生信息表被删除了（测试服）但是现在版本正在测试，账号已经登不上了，bug群里已经有人说话了，CTO已经看到了，情况已经很紧急了。但是我之前也没有遇到过这类事情，而且测试服mysql是不备份的，一时不知道要怎么办。\n\n# 解决\n\n**但是** 事情还是要解决也总是有解决办法。下边按照先后顺序记录了下我的操作方案。\n\n## 方案一\n\n> 使用bin-log，我们测试服mysql是有记录mysql-binlog的，（本来也是没有开的，在六月份的时候测试服总是内存不够用，我把数据库从本地迁移独立了出来开启了bin-log）\n\n**bin-log恢复方案介绍**\n\n先查看这次今天mysql操作记录，发现没有什么操作，毕竟周五， 所以计划直接恢复到删表之前（就是昨天，中间操作的一段时间有几个今天修改的记录不见得情况），然后再从删表后的时间节点到现在恢复，等于只跳过了那条删表操作，别的操作都重新来一遍。\n\n### 操作流程\n\n首先查看mysql-binlog 找到误操作drop table的时间节点 这里没有图文。。。\n    \n    // 查找对应的bin-log文件\n    mysqlbinlog mysql-bin.000002 | grep -A4 \"table_name\" \n\n然后恢复对应时间节点恢复（其实mysqlbinlog也可以对应postion节点恢复）\n    mysqlbinlog -d test_medical --stop-datetime='2017-08-03 17:57:05' /home/mysql/3306/data/mysql-bin.000002 | mysql -uroot -p -P 3306 -S /home/mysql/3306/mysql.sock\n    // -d 数据库名  --stop-datetime 结束时间点，--start-datetime 开始时间节点 二者可以一起写就是中间时间短的操作 \n\n    \n可想而知我这样操作的结果，肯定是一堆冲突，因为当前数据库已经是操作过一遍的结果了，再把执行过得命令拿过来执行下，肯定是有错误。\n所以我们方案一肯定是不可取的。\n\n![](http://or2jd66dq.bkt.clouddn.com/binlog-error.png)\n\n\n## 方案二\n\n> 我之前是有迁移过这个MySQL的，我赶紧看了下迁移的数据压缩包还在时间是2017-6-19,顿时感觉欣喜若狂\n\n我的设想是这样的，因为时间久远肯定不能再这个mysql上恢复到一个多月之前，我想把数据包下到本地电脑mysql，恢复数据，把这个表的dump下来，传到测试服mysql。然后数据包压缩完之后有3G多 下载限速1M大约一个小时。\n太久了。\n我索性在测试数据库服务器上 用ansible由装了一个mysql实例端口3309用时两分钟不到。\n\n恢复数据 [参考文档](https://fanquqi.github.io/2017/06/16/%E5%87%A0%E7%A7%8Dmysql%E8%BF%81%E7%A7%BB/)\n\n然后用mysqlbinlog恢复这一个多月来的数据。\n\n    mysqlbinlog -d test_medical --stop-datetime='2017-08-03 17:57:05' /home/mysql/3306/data/mysql-bin.000001 | mysql -uroot -p -P3309 -S /home/mysql/3309/mysql.sock\n    \n    mysqlbinlog -d test_medical --stop-datetime='2017-08-03 17:57:05' /home/mysql/3306/data/mysql-bin.000002 | mysql -uroot -p -P3309 -S /home/mysql/3309/mysql.sock\n\n备份表\n\n    mysqldump -uroot -p test_medical table_name > table_name.sql\n\n然后进到mysql source一下  结束。。\n\n\n# 总结\n\nbinlog是结合备份来用的，其实我们这次恢复也算是 `备份—恢复`流程\n\n所以\n\n数据库备份很重要，\n\n数据库备份很重要，\n\n数据库备份很重要。 \n\n\n","slug":"mysql误删除表恢复","published":1,"updated":"2017-08-07T02:05:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbc002g8tzzkuo958gz","content":"<h1 id=\"场景描述\"><a href=\"#场景描述\" class=\"headerlink\" title=\"场景描述\"></a>场景描述</h1><p> 今天有个开发哥哥来找我。说有个医生信息表被删除了（测试服）但是现在版本正在测试，账号已经登不上了，bug群里已经有人说话了，CTO已经看到了，情况已经很紧急了。但是我之前也没有遇到过这类事情，而且测试服mysql是不备份的，一时不知道要怎么办。</p>\n<h1 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h1><p><strong>但是</strong> 事情还是要解决也总是有解决办法。下边按照先后顺序记录了下我的操作方案。</p>\n<h2 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h2><blockquote>\n<p>使用bin-log，我们测试服mysql是有记录mysql-binlog的，（本来也是没有开的，在六月份的时候测试服总是内存不够用，我把数据库从本地迁移独立了出来开启了bin-log）</p>\n</blockquote>\n<p><strong>bin-log恢复方案介绍</strong></p>\n<p>先查看这次今天mysql操作记录，发现没有什么操作，毕竟周五， 所以计划直接恢复到删表之前（就是昨天，中间操作的一段时间有几个今天修改的记录不见得情况），然后再从删表后的时间节点到现在恢复，等于只跳过了那条删表操作，别的操作都重新来一遍。</p>\n<h3 id=\"操作流程\"><a href=\"#操作流程\" class=\"headerlink\" title=\"操作流程\"></a>操作流程</h3><p>首先查看mysql-binlog 找到误操作drop table的时间节点 这里没有图文。。。</p>\n<pre><code>// 查找对应的bin-log文件\nmysqlbinlog mysql-bin.000002 | grep -A4 &quot;table_name&quot; \n</code></pre><p>然后恢复对应时间节点恢复（其实mysqlbinlog也可以对应postion节点恢复）<br>    mysqlbinlog -d test_medical –stop-datetime=’2017-08-03 17:57:05’ /home/mysql/3306/data/mysql-bin.000002 | mysql -uroot -p -P 3306 -S /home/mysql/3306/mysql.sock<br>    // -d 数据库名  –stop-datetime 结束时间点，–start-datetime 开始时间节点 二者可以一起写就是中间时间短的操作 </p>\n<p>可想而知我这样操作的结果，肯定是一堆冲突，因为当前数据库已经是操作过一遍的结果了，再把执行过得命令拿过来执行下，肯定是有错误。<br>所以我们方案一肯定是不可取的。</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/binlog-error.png\" alt=\"\"></p>\n<h2 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h2><blockquote>\n<p>我之前是有迁移过这个MySQL的，我赶紧看了下迁移的数据压缩包还在时间是2017-6-19,顿时感觉欣喜若狂</p>\n</blockquote>\n<p>我的设想是这样的，因为时间久远肯定不能再这个mysql上恢复到一个多月之前，我想把数据包下到本地电脑mysql，恢复数据，把这个表的dump下来，传到测试服mysql。然后数据包压缩完之后有3G多 下载限速1M大约一个小时。<br>太久了。<br>我索性在测试数据库服务器上 用ansible由装了一个mysql实例端口3309用时两分钟不到。</p>\n<p>恢复数据 <a href=\"https://fanquqi.github.io/2017/06/16/%E5%87%A0%E7%A7%8Dmysql%E8%BF%81%E7%A7%BB/\" target=\"_blank\" rel=\"external\">参考文档</a></p>\n<p>然后用mysqlbinlog恢复这一个多月来的数据。</p>\n<pre><code>mysqlbinlog -d test_medical --stop-datetime=&apos;2017-08-03 17:57:05&apos; /home/mysql/3306/data/mysql-bin.000001 | mysql -uroot -p -P3309 -S /home/mysql/3309/mysql.sock\n\nmysqlbinlog -d test_medical --stop-datetime=&apos;2017-08-03 17:57:05&apos; /home/mysql/3306/data/mysql-bin.000002 | mysql -uroot -p -P3309 -S /home/mysql/3309/mysql.sock\n</code></pre><p>备份表</p>\n<pre><code>mysqldump -uroot -p test_medical table_name &gt; table_name.sql\n</code></pre><p>然后进到mysql source一下  结束。。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>binlog是结合备份来用的，其实我们这次恢复也算是 <code>备份—恢复</code>流程</p>\n<p>所以</p>\n<p>数据库备份很重要，</p>\n<p>数据库备份很重要，</p>\n<p>数据库备份很重要。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"场景描述\"><a href=\"#场景描述\" class=\"headerlink\" title=\"场景描述\"></a>场景描述</h1><p> 今天有个开发哥哥来找我。说有个医生信息表被删除了（测试服）但是现在版本正在测试，账号已经登不上了，bug群里已经有人说话了，CTO已经看到了，情况已经很紧急了。但是我之前也没有遇到过这类事情，而且测试服mysql是不备份的，一时不知道要怎么办。</p>\n<h1 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h1><p><strong>但是</strong> 事情还是要解决也总是有解决办法。下边按照先后顺序记录了下我的操作方案。</p>\n<h2 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h2><blockquote>\n<p>使用bin-log，我们测试服mysql是有记录mysql-binlog的，（本来也是没有开的，在六月份的时候测试服总是内存不够用，我把数据库从本地迁移独立了出来开启了bin-log）</p>\n</blockquote>\n<p><strong>bin-log恢复方案介绍</strong></p>\n<p>先查看这次今天mysql操作记录，发现没有什么操作，毕竟周五， 所以计划直接恢复到删表之前（就是昨天，中间操作的一段时间有几个今天修改的记录不见得情况），然后再从删表后的时间节点到现在恢复，等于只跳过了那条删表操作，别的操作都重新来一遍。</p>\n<h3 id=\"操作流程\"><a href=\"#操作流程\" class=\"headerlink\" title=\"操作流程\"></a>操作流程</h3><p>首先查看mysql-binlog 找到误操作drop table的时间节点 这里没有图文。。。</p>\n<pre><code>// 查找对应的bin-log文件\nmysqlbinlog mysql-bin.000002 | grep -A4 &quot;table_name&quot; \n</code></pre><p>然后恢复对应时间节点恢复（其实mysqlbinlog也可以对应postion节点恢复）<br>    mysqlbinlog -d test_medical –stop-datetime=’2017-08-03 17:57:05’ /home/mysql/3306/data/mysql-bin.000002 | mysql -uroot -p -P 3306 -S /home/mysql/3306/mysql.sock<br>    // -d 数据库名  –stop-datetime 结束时间点，–start-datetime 开始时间节点 二者可以一起写就是中间时间短的操作 </p>\n<p>可想而知我这样操作的结果，肯定是一堆冲突，因为当前数据库已经是操作过一遍的结果了，再把执行过得命令拿过来执行下，肯定是有错误。<br>所以我们方案一肯定是不可取的。</p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/binlog-error.png\" alt=\"\"></p>\n<h2 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h2><blockquote>\n<p>我之前是有迁移过这个MySQL的，我赶紧看了下迁移的数据压缩包还在时间是2017-6-19,顿时感觉欣喜若狂</p>\n</blockquote>\n<p>我的设想是这样的，因为时间久远肯定不能再这个mysql上恢复到一个多月之前，我想把数据包下到本地电脑mysql，恢复数据，把这个表的dump下来，传到测试服mysql。然后数据包压缩完之后有3G多 下载限速1M大约一个小时。<br>太久了。<br>我索性在测试数据库服务器上 用ansible由装了一个mysql实例端口3309用时两分钟不到。</p>\n<p>恢复数据 <a href=\"https://fanquqi.github.io/2017/06/16/%E5%87%A0%E7%A7%8Dmysql%E8%BF%81%E7%A7%BB/\" target=\"_blank\" rel=\"external\">参考文档</a></p>\n<p>然后用mysqlbinlog恢复这一个多月来的数据。</p>\n<pre><code>mysqlbinlog -d test_medical --stop-datetime=&apos;2017-08-03 17:57:05&apos; /home/mysql/3306/data/mysql-bin.000001 | mysql -uroot -p -P3309 -S /home/mysql/3309/mysql.sock\n\nmysqlbinlog -d test_medical --stop-datetime=&apos;2017-08-03 17:57:05&apos; /home/mysql/3306/data/mysql-bin.000002 | mysql -uroot -p -P3309 -S /home/mysql/3309/mysql.sock\n</code></pre><p>备份表</p>\n<pre><code>mysqldump -uroot -p test_medical table_name &gt; table_name.sql\n</code></pre><p>然后进到mysql source一下  结束。。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>binlog是结合备份来用的，其实我们这次恢复也算是 <code>备份—恢复</code>流程</p>\n<p>所以</p>\n<p>数据库备份很重要，</p>\n<p>数据库备份很重要，</p>\n<p>数据库备份很重要。</p>\n"},{"title":"lsof十几个实例","date":"2017-06-06T08:36:41.000Z","_content":"# lsof十几个示例\n\n-------\n>lsof的意思是’列出打开的文件’，用于找出哪些文件被哪些进程打开或是占用。我们都知道Linux/UNIX的理念就是一切皆文件(包括pipes管道、sockets、directories目录、devices设备等等)。使用lsof命令的原因之一就是，当一个磁盘不能被卸载时，借助lsof这个命令我们可以轻易的识别哪些文件正在被占用.\n\n----------\n[toc]\n\n---------\n## 1.通过lsof命令列出所有打开的文件\n\n>在下面的例子中，它会以长列表的形式显示打开的文件，为了便于理解，它以Command、PID、USER、FD、TYPE分类\n``` powershell\n(July) [root@blog local]# lsof\nCOMMAND     PID   TID           USER   FD      TYPE             DEVICE  SIZE/OFF       NODE NAME\nsystemd       1                 root  cwd       DIR              253,0      4096        128 /\nsystemd       1                 root  rtd       DIR              253,0      4096        128 /\nsystemd       1                 root  txt       REG              253,0   1478168     198856 /usr/lib/systemd/systemd\nsystemd       1                 root  mem       REG              253,0     20032   50421307 /usr/lib64/libuuid.so.1.3.0\nsystemd       1                 root  mem       REG              253,0    252704   50886702 /usr/lib64/libblkid.so.1.1.0\nsystemd       1                 root  mem       REG              253,0     90664   50421293 /usr/lib64/libz.so.1.2.7\nsystemd       1                 root  mem       REG              253,0    157424   50421256 /usr/lib64/liblzma.so.5.2.2\nsystemd       1                 root  mem       REG              253,0     19888   50421655 /usr/lib64/libattr.so.1.1.0\nsystemd       1                 root  mem       REG              253,0     19776   51932115 /usr/lib64/libdl-2.17.so\nsystemd       1                 root  mem       REG              253,0    398264   51548149 /usr/lib64/libpcre.so.1.2.0\nsystemd       1                 root  mem       REG              253,0   2118128   50333965 /usr/lib64/libc-2.17.so\n```\n若不指定条件默认将显示所有进程打开的所有文件,lsof输出各列信息的意义如下:\n- COMMAND：进程的名称\n- PID：进程标识符\n- USER：进程所有者\n- FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等\n    - cwd 表示应用程序的当前工作目录\n    - RTD 根目录\n    - txt txt类型文件是程序代码，应用程序二进制文件本身或共享库\n    - MEM 内存映射文件\n    - u 表示该文件被打开并处于读取/写入模式，而不是只读 ® 或只写 (w) 模式。\n    - W 表示该应用程序具有对整个文件的写锁。该文件描述符用于确保每次只能打开一个应用程序实例。\n    - R 读访问\n    - 初始打开每个应用程序时，都具有三个文件描述符，从 0 到 2，分别表示标准输入、输出和错误流。所以大多数应用程序所打开的文件的FD都是从3开始。\n- TYPE：文件类型，如DIR、REG等\n    - DIR 目录\n    - REG 基本文件\n    - CHR 字符特殊文件\n    - FIFO 先进先出\n    - UNIX unix域套接字\n- DEVICE：指定磁盘的名称\n- SIZE：文件的大小\n- NODE：索引节点（文件在磁盘上的标识）\n- NAME：打开文件的确切名称\n\n----------------\n# 2.列出特定用户打开的文件\n\n使用**-u**选项后接用户指定某个用户打开文件\n``` powershell\n# lsof -u apache\nCOMMAND  PID   USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME\nhttpd   6032 apache  cwd    DIR    8,3     4096       2 /\nhttpd   6032 apache  rtd    DIR    8,3     4096       2 /\nhttpd   6032 apache  txt    REG    8,3   354688 1605148 /usr/sbin/httpd\nhttpd   6032 apache  mem    REG    8,3    65928  654110 /lib64/libnss_files-2.12.so\n```\n\n---------\n# 3.查找特定端口运行的进程\n使用**-i**选项来查找正在运行特定端口的进程\n``` powershell\n# lsof -i TCP:53\nCOMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nnamed   16885 named   20u  IPv4  61664      0t0  TCP localhost:domain (LISTEN)\n# lsof -i UDP:53\nCOMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nnamed   16885 named  512u  IPv4  61663      0t0  UDP localhost:domain\n# lsof -i:53\nnamed   16885 named   20u  IPv4  61664      0t0  TCP localhost:domain (LISTEN)\nnamed   16885 named  512u  IPv4  61663      0t0  UDP localhost:domain\n```\n\n--------\n\n# 4.列出ipv4 和ipv6的文件\n``` powershell\n #lsof -i 4\nCOMMAND    PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd      1239  root    3u  IPv4  10081      0t0  TCP *:ssh (LISTEN)\n# lsof -i 6\nCOMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd     1239   root    4u  IPv6  10083      0t0  TCP *:ssh (LISTEN)\n```\n-------\n#5.列出TCP端口范围1-1024端口\n``` powershell\n# lsof -i TCP:1-1024\nCOMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd     1239   root    3u  IPv4  10081      0t0  TCP *:ssh (LISTEN)\nsshd     1239   root    4u  IPv6  10083      0t0  TCP *:ssh (LISTEN)\nhttpd    2142   root    4u  IPv6  13337      0t0  TCP *:http (LISTEN)\n```\n\n-----\n# 6.通过脱字符排除某个用户\n``` powershell\n\n# lsof -u^root\nCOMMAND     PID   USER   FD   TYPE             DEVICE SIZE/OFF    NODE NAME\ndbus-daem  1212   dbus  cwd    DIR                8,3     4096       2 /\ndbus-daem  1212   dbus  rtd    DIR                8,3     4096       2 /\n```\n---------\n\n# 7.查找特定文件用户和命令\n``` powershell\n# lsof -i -u apache \nCOMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME\nhttpd     6032 apache  txt    REG    8,3   354688 1605148 /usr/sbin/httpd\nhttpd     6032 apache  mem    REG    8,3     9488  271645 /usr/lib64/apr-util-1/apr_ldap-1.so\n```\n-------\n\n# 8.查看所有的网络连接\n``` powershell\n# lsof -i\nCOMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd      1239   root    3u  IPv4  10081      0t0  TCP *:ssh (LISTEN)\nsshd      1239   root    4u  IPv6  10083      0t0  TCP *:ssh (LISTEN)\n```\n-------\n\n# 9.采用pid搜索\n``` powershell\n# lsof -p 1\nCOMMAND PID USER   FD   TYPE             DEVICE SIZE/OFF   NODE NAME\ninit      1 root  cwd    DIR                8,3     4096      2 /\ninit      1 root  rtd    DIR                8,3     4096      2 /\ninit      1 root  txt    REG                8,3   150352 527181 /sbin/init\n\n```\n-------\n\n# 10.杀死某个特定用户的所有活动\n``` powershell\n# kill -9 `lsof -t -u named`\n\n```\n-------\n\n# 11.查看谁在使用文件系统,在卸载文件系统时\n``` powershell\n# lsof /mnt/\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nbash    16672 root  cwd    DIR   11,0     8192 1856 /mnt\nlsof    17041 root  cwd    DIR   11,0     8192 1856 /mnt\nlsof    17042 root  cwd    DIR   11,0     8192 1856 /mnt\n\n```\n--------\n\n# 12.查看被删除的文件\n``` powershell\n# lsof | grep deleted --color\nconsole-k  1291   root  txt       REG                8,3   155008    1577669 /usr/sbin/console-kit-daemon.#prelink#.bXthE2 (deleted)\ntail      17553   root    3r      REG                8,3        6     523317 /tmp/test2 (deleted)\n\n```\n\n# 13.恢复误删除文件\n>当Linux计算机受到入侵时，常见的情况是日志文件被删除，以掩盖攻击者的踪迹。管理错误也可能导致意外删除重要的文件，比如在清理旧日志时，意外地删除了数据库的活动事务日志。有时可以通过lsof来恢复这些文件。\n\n>当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。\n>在/proc 目录下，其中包含了反映内核和进程树的各种文件。/proc目录挂载的是在内存中所映射的一块区域，所以这些文件和目录并不存在于磁盘中，因此当我们对这些文件进行读取和写入时，实际上是在从内存中获取相关信息。大多数与 lsof 相关的信息都存储于以进程的 PID 命名的目录中，即/proc/1234 中包含的是PID为1234 的进程的信息。\n\n当系统中的某个文件被意外地删除了，只要这个时候系统中还有进程正在访问该文件，那么我们就可以通过lsof从/proc目录下恢复该文件的内容。 假如由于误操作将/var/log/messages文件删除掉了，那么这时要将/var/log/messages文件恢复的方法如下：\n\n- 首先使用lsof来查看当前是否有进程打开/var/logmessages文件，如下:\n``` powershell\n# lsof |grep /var/log/messages\nsyslogd   1283      root    2w      REG        3,3  5381017    1773647 /var/log/messages (deleted)\n```\n- 从上面的信息可以看到 PID 1283（syslogd）打开文件的文件描述符为 2。同时还可以看到/var/log/messages已经标记被删除了。因此我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：\n``` powershell\n# head -n 10 /proc/1283/fd/2\nAug  4 13:50:15 holmes86 syslogd 1.4.1: restart.\nAug  4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started.\nAug  4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org) (gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007\nAug  4 13:50:15 holmes86 kernel: BIOS-provided physical RAM map:\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000000000 - 000000000009f000 (usable)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000000009f000 - 00000000000a0000 (reserved)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000100000 - 000000001f7d3800 (usable)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)\n```\n\n- 从上面的信息可以看出，查看 /proc/1283/fd/2 就可以得到所要恢复的数据。如果可以通过文件描述符查看相应的数据，那么就可以使用 I/O 重定向将其复制到文件中，如:\n``` powershell\ncat /proc/1283/fd/2 > /var/log/messages\n\n```\n","source":"_posts/lsof十几个实例.md","raw":"---\ntitle: lsof十几个实例\ndate: 2017-06-06 16:36:41\ntags: lsof\ncategories: 运维工具\n---\n# lsof十几个示例\n\n-------\n>lsof的意思是’列出打开的文件’，用于找出哪些文件被哪些进程打开或是占用。我们都知道Linux/UNIX的理念就是一切皆文件(包括pipes管道、sockets、directories目录、devices设备等等)。使用lsof命令的原因之一就是，当一个磁盘不能被卸载时，借助lsof这个命令我们可以轻易的识别哪些文件正在被占用.\n\n----------\n[toc]\n\n---------\n## 1.通过lsof命令列出所有打开的文件\n\n>在下面的例子中，它会以长列表的形式显示打开的文件，为了便于理解，它以Command、PID、USER、FD、TYPE分类\n``` powershell\n(July) [root@blog local]# lsof\nCOMMAND     PID   TID           USER   FD      TYPE             DEVICE  SIZE/OFF       NODE NAME\nsystemd       1                 root  cwd       DIR              253,0      4096        128 /\nsystemd       1                 root  rtd       DIR              253,0      4096        128 /\nsystemd       1                 root  txt       REG              253,0   1478168     198856 /usr/lib/systemd/systemd\nsystemd       1                 root  mem       REG              253,0     20032   50421307 /usr/lib64/libuuid.so.1.3.0\nsystemd       1                 root  mem       REG              253,0    252704   50886702 /usr/lib64/libblkid.so.1.1.0\nsystemd       1                 root  mem       REG              253,0     90664   50421293 /usr/lib64/libz.so.1.2.7\nsystemd       1                 root  mem       REG              253,0    157424   50421256 /usr/lib64/liblzma.so.5.2.2\nsystemd       1                 root  mem       REG              253,0     19888   50421655 /usr/lib64/libattr.so.1.1.0\nsystemd       1                 root  mem       REG              253,0     19776   51932115 /usr/lib64/libdl-2.17.so\nsystemd       1                 root  mem       REG              253,0    398264   51548149 /usr/lib64/libpcre.so.1.2.0\nsystemd       1                 root  mem       REG              253,0   2118128   50333965 /usr/lib64/libc-2.17.so\n```\n若不指定条件默认将显示所有进程打开的所有文件,lsof输出各列信息的意义如下:\n- COMMAND：进程的名称\n- PID：进程标识符\n- USER：进程所有者\n- FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等\n    - cwd 表示应用程序的当前工作目录\n    - RTD 根目录\n    - txt txt类型文件是程序代码，应用程序二进制文件本身或共享库\n    - MEM 内存映射文件\n    - u 表示该文件被打开并处于读取/写入模式，而不是只读 ® 或只写 (w) 模式。\n    - W 表示该应用程序具有对整个文件的写锁。该文件描述符用于确保每次只能打开一个应用程序实例。\n    - R 读访问\n    - 初始打开每个应用程序时，都具有三个文件描述符，从 0 到 2，分别表示标准输入、输出和错误流。所以大多数应用程序所打开的文件的FD都是从3开始。\n- TYPE：文件类型，如DIR、REG等\n    - DIR 目录\n    - REG 基本文件\n    - CHR 字符特殊文件\n    - FIFO 先进先出\n    - UNIX unix域套接字\n- DEVICE：指定磁盘的名称\n- SIZE：文件的大小\n- NODE：索引节点（文件在磁盘上的标识）\n- NAME：打开文件的确切名称\n\n----------------\n# 2.列出特定用户打开的文件\n\n使用**-u**选项后接用户指定某个用户打开文件\n``` powershell\n# lsof -u apache\nCOMMAND  PID   USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME\nhttpd   6032 apache  cwd    DIR    8,3     4096       2 /\nhttpd   6032 apache  rtd    DIR    8,3     4096       2 /\nhttpd   6032 apache  txt    REG    8,3   354688 1605148 /usr/sbin/httpd\nhttpd   6032 apache  mem    REG    8,3    65928  654110 /lib64/libnss_files-2.12.so\n```\n\n---------\n# 3.查找特定端口运行的进程\n使用**-i**选项来查找正在运行特定端口的进程\n``` powershell\n# lsof -i TCP:53\nCOMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nnamed   16885 named   20u  IPv4  61664      0t0  TCP localhost:domain (LISTEN)\n# lsof -i UDP:53\nCOMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nnamed   16885 named  512u  IPv4  61663      0t0  UDP localhost:domain\n# lsof -i:53\nnamed   16885 named   20u  IPv4  61664      0t0  TCP localhost:domain (LISTEN)\nnamed   16885 named  512u  IPv4  61663      0t0  UDP localhost:domain\n```\n\n--------\n\n# 4.列出ipv4 和ipv6的文件\n``` powershell\n #lsof -i 4\nCOMMAND    PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd      1239  root    3u  IPv4  10081      0t0  TCP *:ssh (LISTEN)\n# lsof -i 6\nCOMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd     1239   root    4u  IPv6  10083      0t0  TCP *:ssh (LISTEN)\n```\n-------\n#5.列出TCP端口范围1-1024端口\n``` powershell\n# lsof -i TCP:1-1024\nCOMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd     1239   root    3u  IPv4  10081      0t0  TCP *:ssh (LISTEN)\nsshd     1239   root    4u  IPv6  10083      0t0  TCP *:ssh (LISTEN)\nhttpd    2142   root    4u  IPv6  13337      0t0  TCP *:http (LISTEN)\n```\n\n-----\n# 6.通过脱字符排除某个用户\n``` powershell\n\n# lsof -u^root\nCOMMAND     PID   USER   FD   TYPE             DEVICE SIZE/OFF    NODE NAME\ndbus-daem  1212   dbus  cwd    DIR                8,3     4096       2 /\ndbus-daem  1212   dbus  rtd    DIR                8,3     4096       2 /\n```\n---------\n\n# 7.查找特定文件用户和命令\n``` powershell\n# lsof -i -u apache \nCOMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME\nhttpd     6032 apache  txt    REG    8,3   354688 1605148 /usr/sbin/httpd\nhttpd     6032 apache  mem    REG    8,3     9488  271645 /usr/lib64/apr-util-1/apr_ldap-1.so\n```\n-------\n\n# 8.查看所有的网络连接\n``` powershell\n# lsof -i\nCOMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsshd      1239   root    3u  IPv4  10081      0t0  TCP *:ssh (LISTEN)\nsshd      1239   root    4u  IPv6  10083      0t0  TCP *:ssh (LISTEN)\n```\n-------\n\n# 9.采用pid搜索\n``` powershell\n# lsof -p 1\nCOMMAND PID USER   FD   TYPE             DEVICE SIZE/OFF   NODE NAME\ninit      1 root  cwd    DIR                8,3     4096      2 /\ninit      1 root  rtd    DIR                8,3     4096      2 /\ninit      1 root  txt    REG                8,3   150352 527181 /sbin/init\n\n```\n-------\n\n# 10.杀死某个特定用户的所有活动\n``` powershell\n# kill -9 `lsof -t -u named`\n\n```\n-------\n\n# 11.查看谁在使用文件系统,在卸载文件系统时\n``` powershell\n# lsof /mnt/\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nbash    16672 root  cwd    DIR   11,0     8192 1856 /mnt\nlsof    17041 root  cwd    DIR   11,0     8192 1856 /mnt\nlsof    17042 root  cwd    DIR   11,0     8192 1856 /mnt\n\n```\n--------\n\n# 12.查看被删除的文件\n``` powershell\n# lsof | grep deleted --color\nconsole-k  1291   root  txt       REG                8,3   155008    1577669 /usr/sbin/console-kit-daemon.#prelink#.bXthE2 (deleted)\ntail      17553   root    3r      REG                8,3        6     523317 /tmp/test2 (deleted)\n\n```\n\n# 13.恢复误删除文件\n>当Linux计算机受到入侵时，常见的情况是日志文件被删除，以掩盖攻击者的踪迹。管理错误也可能导致意外删除重要的文件，比如在清理旧日志时，意外地删除了数据库的活动事务日志。有时可以通过lsof来恢复这些文件。\n\n>当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。\n>在/proc 目录下，其中包含了反映内核和进程树的各种文件。/proc目录挂载的是在内存中所映射的一块区域，所以这些文件和目录并不存在于磁盘中，因此当我们对这些文件进行读取和写入时，实际上是在从内存中获取相关信息。大多数与 lsof 相关的信息都存储于以进程的 PID 命名的目录中，即/proc/1234 中包含的是PID为1234 的进程的信息。\n\n当系统中的某个文件被意外地删除了，只要这个时候系统中还有进程正在访问该文件，那么我们就可以通过lsof从/proc目录下恢复该文件的内容。 假如由于误操作将/var/log/messages文件删除掉了，那么这时要将/var/log/messages文件恢复的方法如下：\n\n- 首先使用lsof来查看当前是否有进程打开/var/logmessages文件，如下:\n``` powershell\n# lsof |grep /var/log/messages\nsyslogd   1283      root    2w      REG        3,3  5381017    1773647 /var/log/messages (deleted)\n```\n- 从上面的信息可以看到 PID 1283（syslogd）打开文件的文件描述符为 2。同时还可以看到/var/log/messages已经标记被删除了。因此我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：\n``` powershell\n# head -n 10 /proc/1283/fd/2\nAug  4 13:50:15 holmes86 syslogd 1.4.1: restart.\nAug  4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started.\nAug  4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org) (gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007\nAug  4 13:50:15 holmes86 kernel: BIOS-provided physical RAM map:\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000000000 - 000000000009f000 (usable)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000000009f000 - 00000000000a0000 (reserved)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 0000000000100000 - 000000001f7d3800 (usable)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved)\nAug  4 13:50:15 holmes86 kernel:  BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)\n```\n\n- 从上面的信息可以看出，查看 /proc/1283/fd/2 就可以得到所要恢复的数据。如果可以通过文件描述符查看相应的数据，那么就可以使用 I/O 重定向将其复制到文件中，如:\n``` powershell\ncat /proc/1283/fd/2 > /var/log/messages\n\n```\n","slug":"lsof十几个实例","published":1,"updated":"2017-06-15T09:02:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbe002l8tzzujk62z2v","content":"<h1 id=\"lsof十几个示例\"><a href=\"#lsof十几个示例\" class=\"headerlink\" title=\"lsof十几个示例\"></a>lsof十几个示例</h1><hr>\n<blockquote>\n<p>lsof的意思是’列出打开的文件’，用于找出哪些文件被哪些进程打开或是占用。我们都知道Linux/UNIX的理念就是一切皆文件(包括pipes管道、sockets、directories目录、devices设备等等)。使用lsof命令的原因之一就是，当一个磁盘不能被卸载时，借助lsof这个命令我们可以轻易的识别哪些文件正在被占用.</p>\n</blockquote>\n<hr>\n<p>[toc]</p>\n<hr>\n<h2 id=\"1通过lsof命令列出所有打开的文件\"><a href=\"#1-通过lsof命令列出所有打开的文件\" class=\"headerlink\" title=\"1.通过lsof命令列出所有打开的文件\"></a>1.通过lsof命令列出所有打开的文件</h2><blockquote>\n<p>在下面的例子中，它会以长列表的形式显示打开的文件，为了便于理解，它以Command、PID、USER、FD、TYPE分类<br><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">(July) [root@blog local]<span class=\"comment\"># lsof</span></div><div class=\"line\">COMMAND     PID   TID           USER   FD      TYPE             DEVICE  SIZE/OFF       NODE NAME</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  cwd       DIR              <span class=\"number\">253</span>,<span class=\"number\">0</span>      <span class=\"number\">4096</span>        <span class=\"number\">128</span> /</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  rtd       DIR              <span class=\"number\">253</span>,<span class=\"number\">0</span>      <span class=\"number\">4096</span>        <span class=\"number\">128</span> /</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  txt       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>   <span class=\"number\">1478168</span>     <span class=\"number\">198856</span> /usr/lib/systemd/systemd</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>     <span class=\"number\">20032</span>   <span class=\"number\">50421307</span> /usr/lib64/libuuid.so.<span class=\"number\">1.3</span>.<span class=\"number\">0</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>    <span class=\"number\">252704</span>   <span class=\"number\">50886702</span> /usr/lib64/libblkid.so.<span class=\"number\">1.1</span>.<span class=\"number\">0</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>     <span class=\"number\">90664</span>   <span class=\"number\">50421293</span> /usr/lib64/libz.so.<span class=\"number\">1.2</span>.<span class=\"number\">7</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>    <span class=\"number\">157424</span>   <span class=\"number\">50421256</span> /usr/lib64/liblzma.so.<span class=\"number\">5.2</span>.<span class=\"number\">2</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>     <span class=\"number\">19888</span>   <span class=\"number\">50421655</span> /usr/lib64/libattr.so.<span class=\"number\">1.1</span>.<span class=\"number\">0</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>     <span class=\"number\">19776</span>   <span class=\"number\">51932115</span> /usr/lib64/libdl-<span class=\"number\">2.17</span>.so</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>    <span class=\"number\">398264</span>   <span class=\"number\">51548149</span> /usr/lib64/libpcre.so.<span class=\"number\">1.2</span>.<span class=\"number\">0</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>   <span class=\"number\">2118128</span>   <span class=\"number\">50333965</span> /usr/lib64/libc-<span class=\"number\">2.17</span>.so</div></pre></td></tr></table></figure></p>\n</blockquote>\n<p>若不指定条件默认将显示所有进程打开的所有文件,lsof输出各列信息的意义如下:</p>\n<ul>\n<li>COMMAND：进程的名称</li>\n<li>PID：进程标识符</li>\n<li>USER：进程所有者</li>\n<li>FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等<ul>\n<li>cwd 表示应用程序的当前工作目录</li>\n<li>RTD 根目录</li>\n<li>txt txt类型文件是程序代码，应用程序二进制文件本身或共享库</li>\n<li>MEM 内存映射文件</li>\n<li>u 表示该文件被打开并处于读取/写入模式，而不是只读 ® 或只写 (w) 模式。</li>\n<li>W 表示该应用程序具有对整个文件的写锁。该文件描述符用于确保每次只能打开一个应用程序实例。</li>\n<li>R 读访问</li>\n<li>初始打开每个应用程序时，都具有三个文件描述符，从 0 到 2，分别表示标准输入、输出和错误流。所以大多数应用程序所打开的文件的FD都是从3开始。</li>\n</ul>\n</li>\n<li>TYPE：文件类型，如DIR、REG等<ul>\n<li>DIR 目录</li>\n<li>REG 基本文件</li>\n<li>CHR 字符特殊文件</li>\n<li>FIFO 先进先出</li>\n<li>UNIX unix域套接字</li>\n</ul>\n</li>\n<li>DEVICE：指定磁盘的名称</li>\n<li>SIZE：文件的大小</li>\n<li>NODE：索引节点（文件在磁盘上的标识）</li>\n<li>NAME：打开文件的确切名称</li>\n</ul>\n<hr>\n<h1 id=\"2列出特定用户打开的文件\"><a href=\"#2-列出特定用户打开的文件\" class=\"headerlink\" title=\"2.列出特定用户打开的文件\"></a>2.列出特定用户打开的文件</h1><p>使用<strong>-u</strong>选项后接用户指定某个用户打开文件<br><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -u apache</span></div><div class=\"line\">COMMAND  PID   USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME</div><div class=\"line\">httpd   <span class=\"number\">6032</span> apache  cwd    DIR    <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>       <span class=\"number\">2</span> /</div><div class=\"line\">httpd   <span class=\"number\">6032</span> apache  rtd    DIR    <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>       <span class=\"number\">2</span> /</div><div class=\"line\">httpd   <span class=\"number\">6032</span> apache  txt    REG    <span class=\"number\">8</span>,<span class=\"number\">3</span>   <span class=\"number\">354688</span> <span class=\"number\">1605148</span> /usr/sbin/httpd</div><div class=\"line\">httpd   <span class=\"number\">6032</span> apache  mem    REG    <span class=\"number\">8</span>,<span class=\"number\">3</span>    <span class=\"number\">65928</span>  <span class=\"number\">654110</span> /lib64/libnss_files-<span class=\"number\">2.12</span>.so</div></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"3查找特定端口运行的进程\"><a href=\"#3-查找特定端口运行的进程\" class=\"headerlink\" title=\"3.查找特定端口运行的进程\"></a>3.查找特定端口运行的进程</h1><p>使用<strong>-i</strong>选项来查找正在运行特定端口的进程<br><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -i TCP:53</span></div><div class=\"line\">COMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">named   <span class=\"number\">16885</span> named   <span class=\"number\">20</span>u  IPv4  <span class=\"number\">61664</span>      <span class=\"number\">0</span>t0  TCP localhost:domain (LISTEN)</div><div class=\"line\"><span class=\"comment\"># lsof -i UDP:53</span></div><div class=\"line\">COMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">named   <span class=\"number\">16885</span> named  <span class=\"number\">512</span>u  IPv4  <span class=\"number\">61663</span>      <span class=\"number\">0</span>t0  UDP localhost:domain</div><div class=\"line\"><span class=\"comment\"># lsof -i:53</span></div><div class=\"line\">named   <span class=\"number\">16885</span> named   <span class=\"number\">20</span>u  IPv4  <span class=\"number\">61664</span>      <span class=\"number\">0</span>t0  TCP localhost:domain (LISTEN)</div><div class=\"line\">named   <span class=\"number\">16885</span> named  <span class=\"number\">512</span>u  IPv4  <span class=\"number\">61663</span>      <span class=\"number\">0</span>t0  UDP localhost:domain</div></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"4列出ipv4-和ipv6的文件\"><a href=\"#4-列出ipv4-和ipv6的文件\" class=\"headerlink\" title=\"4.列出ipv4 和ipv6的文件\"></a>4.列出ipv4 和ipv6的文件</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"> <span class=\"comment\">#lsof -i 4</span></div><div class=\"line\">COMMAND    PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">sshd      <span class=\"number\">1239</span>  root    <span class=\"number\">3</span>u  IPv4  <span class=\"number\">10081</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div><div class=\"line\"><span class=\"comment\"># lsof -i 6</span></div><div class=\"line\">COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">sshd     <span class=\"number\">1239</span>   root    <span class=\"number\">4</span>u  IPv6  <span class=\"number\">10083</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div></pre></td></tr></table></figure>\n<hr>\n<p>#5.列出TCP端口范围1-1024端口<br><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -i TCP:1-1024</span></div><div class=\"line\">COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">sshd     <span class=\"number\">1239</span>   root    <span class=\"number\">3</span>u  IPv4  <span class=\"number\">10081</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div><div class=\"line\">sshd     <span class=\"number\">1239</span>   root    <span class=\"number\">4</span>u  IPv6  <span class=\"number\">10083</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div><div class=\"line\">httpd    <span class=\"number\">2142</span>   root    <span class=\"number\">4</span>u  IPv6  <span class=\"number\">13337</span>      <span class=\"number\">0</span>t0  TCP *:http (LISTEN)</div></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"6通过脱字符排除某个用户\"><a href=\"#6-通过脱字符排除某个用户\" class=\"headerlink\" title=\"6.通过脱字符排除某个用户\"></a>6.通过脱字符排除某个用户</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># lsof -u^root</span></div><div class=\"line\">COMMAND     PID   USER   FD   TYPE             DEVICE SIZE/OFF    NODE NAME</div><div class=\"line\">dbus-daem  <span class=\"number\">1212</span>   dbus  cwd    DIR                <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>       <span class=\"number\">2</span> /</div><div class=\"line\">dbus-daem  <span class=\"number\">1212</span>   dbus  rtd    DIR                <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>       <span class=\"number\">2</span> /</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"7查找特定文件用户和命令\"><a href=\"#7-查找特定文件用户和命令\" class=\"headerlink\" title=\"7.查找特定文件用户和命令\"></a>7.查找特定文件用户和命令</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -i -u apache </span></div><div class=\"line\">COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME</div><div class=\"line\">httpd     <span class=\"number\">6032</span> apache  txt    REG    <span class=\"number\">8</span>,<span class=\"number\">3</span>   <span class=\"number\">354688</span> <span class=\"number\">1605148</span> /usr/sbin/httpd</div><div class=\"line\">httpd     <span class=\"number\">6032</span> apache  mem    REG    <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">9488</span>  <span class=\"number\">271645</span> /usr/lib64/apr-util-<span class=\"number\">1</span>/apr_ldap-<span class=\"number\">1</span>.so</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"8查看所有的网络连接\"><a href=\"#8-查看所有的网络连接\" class=\"headerlink\" title=\"8.查看所有的网络连接\"></a>8.查看所有的网络连接</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -i</span></div><div class=\"line\">COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">sshd      <span class=\"number\">1239</span>   root    <span class=\"number\">3</span>u  IPv4  <span class=\"number\">10081</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div><div class=\"line\">sshd      <span class=\"number\">1239</span>   root    <span class=\"number\">4</span>u  IPv6  <span class=\"number\">10083</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"9采用pid搜索\"><a href=\"#9-采用pid搜索\" class=\"headerlink\" title=\"9.采用pid搜索\"></a>9.采用pid搜索</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -p 1</span></div><div class=\"line\">COMMAND PID USER   FD   TYPE             DEVICE SIZE/OFF   NODE NAME</div><div class=\"line\">init      <span class=\"number\">1</span> root  cwd    DIR                <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>      <span class=\"number\">2</span> /</div><div class=\"line\">init      <span class=\"number\">1</span> root  rtd    DIR                <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>      <span class=\"number\">2</span> /</div><div class=\"line\">init      <span class=\"number\">1</span> root  txt    REG                <span class=\"number\">8</span>,<span class=\"number\">3</span>   <span class=\"number\">150352</span> <span class=\"number\">527181</span> /sbin/init</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"10杀死某个特定用户的所有活动\"><a href=\"#10-杀死某个特定用户的所有活动\" class=\"headerlink\" title=\"10.杀死某个特定用户的所有活动\"></a>10.杀死某个特定用户的所有活动</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># kill -9 `lsof -t -u named`</span></div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"11查看谁在使用文件系统在卸载文件系统时\"><a href=\"#11-查看谁在使用文件系统-在卸载文件系统时\" class=\"headerlink\" title=\"11.查看谁在使用文件系统,在卸载文件系统时\"></a>11.查看谁在使用文件系统,在卸载文件系统时</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof /mnt/</span></div><div class=\"line\">COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">bash    <span class=\"number\">16672</span> root  cwd    DIR   <span class=\"number\">11</span>,<span class=\"number\">0</span>     <span class=\"number\">8192</span> <span class=\"number\">1856</span> /mnt</div><div class=\"line\">lsof    <span class=\"number\">17041</span> root  cwd    DIR   <span class=\"number\">11</span>,<span class=\"number\">0</span>     <span class=\"number\">8192</span> <span class=\"number\">1856</span> /mnt</div><div class=\"line\">lsof    <span class=\"number\">17042</span> root  cwd    DIR   <span class=\"number\">11</span>,<span class=\"number\">0</span>     <span class=\"number\">8192</span> <span class=\"number\">1856</span> /mnt</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"12查看被删除的文件\"><a href=\"#12-查看被删除的文件\" class=\"headerlink\" title=\"12.查看被删除的文件\"></a>12.查看被删除的文件</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof | grep deleted --color</span></div><div class=\"line\">console-k  <span class=\"number\">1291</span>   root  txt       REG                <span class=\"number\">8</span>,<span class=\"number\">3</span>   <span class=\"number\">155008</span>    <span class=\"number\">1577669</span> /usr/sbin/console-kit-daemon.<span class=\"comment\">#prelink#.bXthE2 (deleted)</span></div><div class=\"line\">tail      <span class=\"number\">17553</span>   root    <span class=\"number\">3</span>r      REG                <span class=\"number\">8</span>,<span class=\"number\">3</span>        <span class=\"number\">6</span>     <span class=\"number\">523317</span> /tmp/test2 (deleted)</div></pre></td></tr></table></figure>\n<h1 id=\"13恢复误删除文件\"><a href=\"#13-恢复误删除文件\" class=\"headerlink\" title=\"13.恢复误删除文件\"></a>13.恢复误删除文件</h1><blockquote>\n<p>当Linux计算机受到入侵时，常见的情况是日志文件被删除，以掩盖攻击者的踪迹。管理错误也可能导致意外删除重要的文件，比如在清理旧日志时，意外地删除了数据库的活动事务日志。有时可以通过lsof来恢复这些文件。</p>\n<p>当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。<br>在/proc 目录下，其中包含了反映内核和进程树的各种文件。/proc目录挂载的是在内存中所映射的一块区域，所以这些文件和目录并不存在于磁盘中，因此当我们对这些文件进行读取和写入时，实际上是在从内存中获取相关信息。大多数与 lsof 相关的信息都存储于以进程的 PID 命名的目录中，即/proc/1234 中包含的是PID为1234 的进程的信息。</p>\n</blockquote>\n<p>当系统中的某个文件被意外地删除了，只要这个时候系统中还有进程正在访问该文件，那么我们就可以通过lsof从/proc目录下恢复该文件的内容。 假如由于误操作将/var/log/messages文件删除掉了，那么这时要将/var/log/messages文件恢复的方法如下：</p>\n<ul>\n<li><p>首先使用lsof来查看当前是否有进程打开/var/logmessages文件，如下:</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof |grep /var/log/messages</span></div><div class=\"line\">syslogd   <span class=\"number\">1283</span>      root    <span class=\"number\">2</span>w      REG        <span class=\"number\">3</span>,<span class=\"number\">3</span>  <span class=\"number\">5381017</span>    <span class=\"number\">1773647</span> /var/log/messages (deleted)</div></pre></td></tr></table></figure>\n</li>\n<li><p>从上面的信息可以看到 PID 1283（syslogd）打开文件的文件描述符为 2。同时还可以看到/var/log/messages已经标记被删除了。因此我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># head -n 10 /proc/1283/fd/2</span></div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 syslogd <span class=\"number\">1.4</span>.<span class=\"number\">1</span>: restart.</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel: klogd <span class=\"number\">1.4</span>.<span class=\"number\">1</span>, log source = /proc/kmsg started.</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel: Linux version <span class=\"number\">2.6</span>.<span class=\"number\">22.1</span>-<span class=\"number\">8</span> (root@everestbuilder.linux-ren.org) (gcc version <span class=\"number\">4.2</span>.<span class=\"number\">0</span>) <span class=\"comment\">#1 SMP Wed Jul 18 11:18:32 EDT 2007</span></div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel: BIOS-provided physical RAM map:</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">0000000000000000</span> - <span class=\"number\">000000000009</span>f000 (usable)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">000000000009</span>f000 - <span class=\"number\">00000000000</span>a0000 (reserved)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">0000000000100000</span> - <span class=\"number\">000000001</span>f7d3800 (usable)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">000000001</span>f7d3800 - <span class=\"number\">0000000020000000</span> (reserved)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">00000000</span>e0000000 - <span class=\"number\">00000000</span>f0007000 (reserved)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">00000000</span>f0008000 - <span class=\"number\">00000000</span>f000c000 (reserved)</div></pre></td></tr></table></figure>\n</li>\n<li><p>从上面的信息可以看出，查看 /proc/1283/fd/2 就可以得到所要恢复的数据。如果可以通过文件描述符查看相应的数据，那么就可以使用 I/O 重定向将其复制到文件中，如:</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat /proc/<span class=\"number\">1283</span>/fd/<span class=\"number\">2</span> &gt; /var/log/messages</div></pre></td></tr></table></figure>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"lsof十几个示例\"><a href=\"#lsof十几个示例\" class=\"headerlink\" title=\"lsof十几个示例\"></a>lsof十几个示例</h1><hr>\n<blockquote>\n<p>lsof的意思是’列出打开的文件’，用于找出哪些文件被哪些进程打开或是占用。我们都知道Linux/UNIX的理念就是一切皆文件(包括pipes管道、sockets、directories目录、devices设备等等)。使用lsof命令的原因之一就是，当一个磁盘不能被卸载时，借助lsof这个命令我们可以轻易的识别哪些文件正在被占用.</p>\n</blockquote>\n<hr>\n<p>[toc]</p>\n<hr>\n<h2 id=\"1-通过lsof命令列出所有打开的文件\"><a href=\"#1-通过lsof命令列出所有打开的文件\" class=\"headerlink\" title=\"1.通过lsof命令列出所有打开的文件\"></a>1.通过lsof命令列出所有打开的文件</h2><blockquote>\n<p>在下面的例子中，它会以长列表的形式显示打开的文件，为了便于理解，它以Command、PID、USER、FD、TYPE分类<br><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">(July) [root@blog local]<span class=\"comment\"># lsof</span></div><div class=\"line\">COMMAND     PID   TID           USER   FD      TYPE             DEVICE  SIZE/OFF       NODE NAME</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  cwd       DIR              <span class=\"number\">253</span>,<span class=\"number\">0</span>      <span class=\"number\">4096</span>        <span class=\"number\">128</span> /</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  rtd       DIR              <span class=\"number\">253</span>,<span class=\"number\">0</span>      <span class=\"number\">4096</span>        <span class=\"number\">128</span> /</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  txt       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>   <span class=\"number\">1478168</span>     <span class=\"number\">198856</span> /usr/lib/systemd/systemd</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>     <span class=\"number\">20032</span>   <span class=\"number\">50421307</span> /usr/lib64/libuuid.so.<span class=\"number\">1.3</span>.<span class=\"number\">0</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>    <span class=\"number\">252704</span>   <span class=\"number\">50886702</span> /usr/lib64/libblkid.so.<span class=\"number\">1.1</span>.<span class=\"number\">0</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>     <span class=\"number\">90664</span>   <span class=\"number\">50421293</span> /usr/lib64/libz.so.<span class=\"number\">1.2</span>.<span class=\"number\">7</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>    <span class=\"number\">157424</span>   <span class=\"number\">50421256</span> /usr/lib64/liblzma.so.<span class=\"number\">5.2</span>.<span class=\"number\">2</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>     <span class=\"number\">19888</span>   <span class=\"number\">50421655</span> /usr/lib64/libattr.so.<span class=\"number\">1.1</span>.<span class=\"number\">0</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>     <span class=\"number\">19776</span>   <span class=\"number\">51932115</span> /usr/lib64/libdl-<span class=\"number\">2.17</span>.so</div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>    <span class=\"number\">398264</span>   <span class=\"number\">51548149</span> /usr/lib64/libpcre.so.<span class=\"number\">1.2</span>.<span class=\"number\">0</span></div><div class=\"line\">systemd       <span class=\"number\">1</span>                 root  mem       REG              <span class=\"number\">253</span>,<span class=\"number\">0</span>   <span class=\"number\">2118128</span>   <span class=\"number\">50333965</span> /usr/lib64/libc-<span class=\"number\">2.17</span>.so</div></pre></td></tr></table></figure></p>\n</blockquote>\n<p>若不指定条件默认将显示所有进程打开的所有文件,lsof输出各列信息的意义如下:</p>\n<ul>\n<li>COMMAND：进程的名称</li>\n<li>PID：进程标识符</li>\n<li>USER：进程所有者</li>\n<li>FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等<ul>\n<li>cwd 表示应用程序的当前工作目录</li>\n<li>RTD 根目录</li>\n<li>txt txt类型文件是程序代码，应用程序二进制文件本身或共享库</li>\n<li>MEM 内存映射文件</li>\n<li>u 表示该文件被打开并处于读取/写入模式，而不是只读 ® 或只写 (w) 模式。</li>\n<li>W 表示该应用程序具有对整个文件的写锁。该文件描述符用于确保每次只能打开一个应用程序实例。</li>\n<li>R 读访问</li>\n<li>初始打开每个应用程序时，都具有三个文件描述符，从 0 到 2，分别表示标准输入、输出和错误流。所以大多数应用程序所打开的文件的FD都是从3开始。</li>\n</ul>\n</li>\n<li>TYPE：文件类型，如DIR、REG等<ul>\n<li>DIR 目录</li>\n<li>REG 基本文件</li>\n<li>CHR 字符特殊文件</li>\n<li>FIFO 先进先出</li>\n<li>UNIX unix域套接字</li>\n</ul>\n</li>\n<li>DEVICE：指定磁盘的名称</li>\n<li>SIZE：文件的大小</li>\n<li>NODE：索引节点（文件在磁盘上的标识）</li>\n<li>NAME：打开文件的确切名称</li>\n</ul>\n<hr>\n<h1 id=\"2-列出特定用户打开的文件\"><a href=\"#2-列出特定用户打开的文件\" class=\"headerlink\" title=\"2.列出特定用户打开的文件\"></a>2.列出特定用户打开的文件</h1><p>使用<strong>-u</strong>选项后接用户指定某个用户打开文件<br><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -u apache</span></div><div class=\"line\">COMMAND  PID   USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME</div><div class=\"line\">httpd   <span class=\"number\">6032</span> apache  cwd    DIR    <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>       <span class=\"number\">2</span> /</div><div class=\"line\">httpd   <span class=\"number\">6032</span> apache  rtd    DIR    <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>       <span class=\"number\">2</span> /</div><div class=\"line\">httpd   <span class=\"number\">6032</span> apache  txt    REG    <span class=\"number\">8</span>,<span class=\"number\">3</span>   <span class=\"number\">354688</span> <span class=\"number\">1605148</span> /usr/sbin/httpd</div><div class=\"line\">httpd   <span class=\"number\">6032</span> apache  mem    REG    <span class=\"number\">8</span>,<span class=\"number\">3</span>    <span class=\"number\">65928</span>  <span class=\"number\">654110</span> /lib64/libnss_files-<span class=\"number\">2.12</span>.so</div></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"3-查找特定端口运行的进程\"><a href=\"#3-查找特定端口运行的进程\" class=\"headerlink\" title=\"3.查找特定端口运行的进程\"></a>3.查找特定端口运行的进程</h1><p>使用<strong>-i</strong>选项来查找正在运行特定端口的进程<br><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -i TCP:53</span></div><div class=\"line\">COMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">named   <span class=\"number\">16885</span> named   <span class=\"number\">20</span>u  IPv4  <span class=\"number\">61664</span>      <span class=\"number\">0</span>t0  TCP localhost:domain (LISTEN)</div><div class=\"line\"><span class=\"comment\"># lsof -i UDP:53</span></div><div class=\"line\">COMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">named   <span class=\"number\">16885</span> named  <span class=\"number\">512</span>u  IPv4  <span class=\"number\">61663</span>      <span class=\"number\">0</span>t0  UDP localhost:domain</div><div class=\"line\"><span class=\"comment\"># lsof -i:53</span></div><div class=\"line\">named   <span class=\"number\">16885</span> named   <span class=\"number\">20</span>u  IPv4  <span class=\"number\">61664</span>      <span class=\"number\">0</span>t0  TCP localhost:domain (LISTEN)</div><div class=\"line\">named   <span class=\"number\">16885</span> named  <span class=\"number\">512</span>u  IPv4  <span class=\"number\">61663</span>      <span class=\"number\">0</span>t0  UDP localhost:domain</div></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"4-列出ipv4-和ipv6的文件\"><a href=\"#4-列出ipv4-和ipv6的文件\" class=\"headerlink\" title=\"4.列出ipv4 和ipv6的文件\"></a>4.列出ipv4 和ipv6的文件</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"> <span class=\"comment\">#lsof -i 4</span></div><div class=\"line\">COMMAND    PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">sshd      <span class=\"number\">1239</span>  root    <span class=\"number\">3</span>u  IPv4  <span class=\"number\">10081</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div><div class=\"line\"><span class=\"comment\"># lsof -i 6</span></div><div class=\"line\">COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">sshd     <span class=\"number\">1239</span>   root    <span class=\"number\">4</span>u  IPv6  <span class=\"number\">10083</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div></pre></td></tr></table></figure>\n<hr>\n<p>#5.列出TCP端口范围1-1024端口<br><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -i TCP:1-1024</span></div><div class=\"line\">COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">sshd     <span class=\"number\">1239</span>   root    <span class=\"number\">3</span>u  IPv4  <span class=\"number\">10081</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div><div class=\"line\">sshd     <span class=\"number\">1239</span>   root    <span class=\"number\">4</span>u  IPv6  <span class=\"number\">10083</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div><div class=\"line\">httpd    <span class=\"number\">2142</span>   root    <span class=\"number\">4</span>u  IPv6  <span class=\"number\">13337</span>      <span class=\"number\">0</span>t0  TCP *:http (LISTEN)</div></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"6-通过脱字符排除某个用户\"><a href=\"#6-通过脱字符排除某个用户\" class=\"headerlink\" title=\"6.通过脱字符排除某个用户\"></a>6.通过脱字符排除某个用户</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># lsof -u^root</span></div><div class=\"line\">COMMAND     PID   USER   FD   TYPE             DEVICE SIZE/OFF    NODE NAME</div><div class=\"line\">dbus-daem  <span class=\"number\">1212</span>   dbus  cwd    DIR                <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>       <span class=\"number\">2</span> /</div><div class=\"line\">dbus-daem  <span class=\"number\">1212</span>   dbus  rtd    DIR                <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>       <span class=\"number\">2</span> /</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"7-查找特定文件用户和命令\"><a href=\"#7-查找特定文件用户和命令\" class=\"headerlink\" title=\"7.查找特定文件用户和命令\"></a>7.查找特定文件用户和命令</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -i -u apache </span></div><div class=\"line\">COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME</div><div class=\"line\">httpd     <span class=\"number\">6032</span> apache  txt    REG    <span class=\"number\">8</span>,<span class=\"number\">3</span>   <span class=\"number\">354688</span> <span class=\"number\">1605148</span> /usr/sbin/httpd</div><div class=\"line\">httpd     <span class=\"number\">6032</span> apache  mem    REG    <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">9488</span>  <span class=\"number\">271645</span> /usr/lib64/apr-util-<span class=\"number\">1</span>/apr_ldap-<span class=\"number\">1</span>.so</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"8-查看所有的网络连接\"><a href=\"#8-查看所有的网络连接\" class=\"headerlink\" title=\"8.查看所有的网络连接\"></a>8.查看所有的网络连接</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -i</span></div><div class=\"line\">COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">sshd      <span class=\"number\">1239</span>   root    <span class=\"number\">3</span>u  IPv4  <span class=\"number\">10081</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div><div class=\"line\">sshd      <span class=\"number\">1239</span>   root    <span class=\"number\">4</span>u  IPv6  <span class=\"number\">10083</span>      <span class=\"number\">0</span>t0  TCP *:ssh (LISTEN)</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"9-采用pid搜索\"><a href=\"#9-采用pid搜索\" class=\"headerlink\" title=\"9.采用pid搜索\"></a>9.采用pid搜索</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof -p 1</span></div><div class=\"line\">COMMAND PID USER   FD   TYPE             DEVICE SIZE/OFF   NODE NAME</div><div class=\"line\">init      <span class=\"number\">1</span> root  cwd    DIR                <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>      <span class=\"number\">2</span> /</div><div class=\"line\">init      <span class=\"number\">1</span> root  rtd    DIR                <span class=\"number\">8</span>,<span class=\"number\">3</span>     <span class=\"number\">4096</span>      <span class=\"number\">2</span> /</div><div class=\"line\">init      <span class=\"number\">1</span> root  txt    REG                <span class=\"number\">8</span>,<span class=\"number\">3</span>   <span class=\"number\">150352</span> <span class=\"number\">527181</span> /sbin/init</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"10-杀死某个特定用户的所有活动\"><a href=\"#10-杀死某个特定用户的所有活动\" class=\"headerlink\" title=\"10.杀死某个特定用户的所有活动\"></a>10.杀死某个特定用户的所有活动</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># kill -9 `lsof -t -u named`</span></div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"11-查看谁在使用文件系统-在卸载文件系统时\"><a href=\"#11-查看谁在使用文件系统-在卸载文件系统时\" class=\"headerlink\" title=\"11.查看谁在使用文件系统,在卸载文件系统时\"></a>11.查看谁在使用文件系统,在卸载文件系统时</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof /mnt/</span></div><div class=\"line\">COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class=\"line\">bash    <span class=\"number\">16672</span> root  cwd    DIR   <span class=\"number\">11</span>,<span class=\"number\">0</span>     <span class=\"number\">8192</span> <span class=\"number\">1856</span> /mnt</div><div class=\"line\">lsof    <span class=\"number\">17041</span> root  cwd    DIR   <span class=\"number\">11</span>,<span class=\"number\">0</span>     <span class=\"number\">8192</span> <span class=\"number\">1856</span> /mnt</div><div class=\"line\">lsof    <span class=\"number\">17042</span> root  cwd    DIR   <span class=\"number\">11</span>,<span class=\"number\">0</span>     <span class=\"number\">8192</span> <span class=\"number\">1856</span> /mnt</div></pre></td></tr></table></figure>\n<hr>\n<h1 id=\"12-查看被删除的文件\"><a href=\"#12-查看被删除的文件\" class=\"headerlink\" title=\"12.查看被删除的文件\"></a>12.查看被删除的文件</h1><figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof | grep deleted --color</span></div><div class=\"line\">console-k  <span class=\"number\">1291</span>   root  txt       REG                <span class=\"number\">8</span>,<span class=\"number\">3</span>   <span class=\"number\">155008</span>    <span class=\"number\">1577669</span> /usr/sbin/console-kit-daemon.<span class=\"comment\">#prelink#.bXthE2 (deleted)</span></div><div class=\"line\">tail      <span class=\"number\">17553</span>   root    <span class=\"number\">3</span>r      REG                <span class=\"number\">8</span>,<span class=\"number\">3</span>        <span class=\"number\">6</span>     <span class=\"number\">523317</span> /tmp/test2 (deleted)</div></pre></td></tr></table></figure>\n<h1 id=\"13-恢复误删除文件\"><a href=\"#13-恢复误删除文件\" class=\"headerlink\" title=\"13.恢复误删除文件\"></a>13.恢复误删除文件</h1><blockquote>\n<p>当Linux计算机受到入侵时，常见的情况是日志文件被删除，以掩盖攻击者的踪迹。管理错误也可能导致意外删除重要的文件，比如在清理旧日志时，意外地删除了数据库的活动事务日志。有时可以通过lsof来恢复这些文件。</p>\n<p>当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。<br>在/proc 目录下，其中包含了反映内核和进程树的各种文件。/proc目录挂载的是在内存中所映射的一块区域，所以这些文件和目录并不存在于磁盘中，因此当我们对这些文件进行读取和写入时，实际上是在从内存中获取相关信息。大多数与 lsof 相关的信息都存储于以进程的 PID 命名的目录中，即/proc/1234 中包含的是PID为1234 的进程的信息。</p>\n</blockquote>\n<p>当系统中的某个文件被意外地删除了，只要这个时候系统中还有进程正在访问该文件，那么我们就可以通过lsof从/proc目录下恢复该文件的内容。 假如由于误操作将/var/log/messages文件删除掉了，那么这时要将/var/log/messages文件恢复的方法如下：</p>\n<ul>\n<li><p>首先使用lsof来查看当前是否有进程打开/var/logmessages文件，如下:</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># lsof |grep /var/log/messages</span></div><div class=\"line\">syslogd   <span class=\"number\">1283</span>      root    <span class=\"number\">2</span>w      REG        <span class=\"number\">3</span>,<span class=\"number\">3</span>  <span class=\"number\">5381017</span>    <span class=\"number\">1773647</span> /var/log/messages (deleted)</div></pre></td></tr></table></figure>\n</li>\n<li><p>从上面的信息可以看到 PID 1283（syslogd）打开文件的文件描述符为 2。同时还可以看到/var/log/messages已经标记被删除了。因此我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># head -n 10 /proc/1283/fd/2</span></div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 syslogd <span class=\"number\">1.4</span>.<span class=\"number\">1</span>: restart.</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel: klogd <span class=\"number\">1.4</span>.<span class=\"number\">1</span>, log source = /proc/kmsg started.</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel: Linux version <span class=\"number\">2.6</span>.<span class=\"number\">22.1</span>-<span class=\"number\">8</span> (root@everestbuilder.linux-ren.org) (gcc version <span class=\"number\">4.2</span>.<span class=\"number\">0</span>) <span class=\"comment\">#1 SMP Wed Jul 18 11:18:32 EDT 2007</span></div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel: BIOS-provided physical RAM map:</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">0000000000000000</span> - <span class=\"number\">000000000009</span>f000 (usable)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">000000000009</span>f000 - <span class=\"number\">00000000000</span>a0000 (reserved)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">0000000000100000</span> - <span class=\"number\">000000001</span>f7d3800 (usable)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">000000001</span>f7d3800 - <span class=\"number\">0000000020000000</span> (reserved)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">00000000</span>e0000000 - <span class=\"number\">00000000</span>f0007000 (reserved)</div><div class=\"line\">Aug  <span class=\"number\">4</span> <span class=\"number\">13</span>:<span class=\"number\">50</span>:<span class=\"number\">15</span> holmes86 kernel:  BIOS-e820: <span class=\"number\">00000000</span>f0008000 - <span class=\"number\">00000000</span>f000c000 (reserved)</div></pre></td></tr></table></figure>\n</li>\n<li><p>从上面的信息可以看出，查看 /proc/1283/fd/2 就可以得到所要恢复的数据。如果可以通过文件描述符查看相应的数据，那么就可以使用 I/O 重定向将其复制到文件中，如:</p>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat /proc/<span class=\"number\">1283</span>/fd/<span class=\"number\">2</span> &gt; /var/log/messages</div></pre></td></tr></table></figure>\n</li>\n</ul>\n"},{"title":"nginx之HTTPS配置","date":"2017-07-07T07:15:38.000Z","_content":"\n> https现在是标配了，HTTPS 可以给用户带来更安全、比如减少了被劫持的概率，更好隐私保护的网络体验，这些好处大家都耳熟能详，本文不再赘述。现在很多浏览器都在推行HTTPS的普及。尽快升级吧。\n\n其实大体就是分为`ssl证书申请`和`配置HTTPS`两个步骤\n\n## 证书申请\n这次介绍并没有从申请证书开始，因为之前已经申请过了，申请步骤请[参考](https://aotu.io/notes/2016/08/16/nginx-https/index.html)\nSSL 证书主要有两个功能：加密和身份证明，通常需要购买，也有免费的，通过第三方 SSL 证书机构颁发。分为企业级别和个人级别。\nSSL 具体加密实现[参考](http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html)\n查看证书相关配置，包括哪个机构颁发的，过期时间等等信息可以到https://www.chinassl.net 自助查看\n\n## nginx HTTPS配置\n\n首先我们把得到的domain.key domain.crt 放到 nginx的conf下，\n可以在nginx.conf 的`server`中配置\n\n**基础配置**\n```\n server {\n     listen              443 ssl http2;\n     #证书文件(注意路径及权限)\n     ssl on;\n     ssl_certificate     example.com.crt;\n     #私钥文件\n     ssl_certificate_key example.com.key;\n     ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;\n     ssl_ciphers         HIGH:!aNULL:!MD5;\n\n#....\n}\n```\n必须使用监听命令 listen 的 ssl 参数和定义服务器证书文件和私钥文件\n\n`ssl_protocols` 可以用来限制连接只包含 SSL/TLS 的加強版本，默认值如上。\n`ssl_ciphers` 选择加密套件，不同的浏览器所支持的套件（和顺序）可能会不同。这里指定的是OpenSSL库能够识别的写法，你可以通过 openssl -v cipher 'RC4:HIGH:!aNULL:!MD5'（后面是你所指定的套件加密算法） 来看所支持算法。\n\n\n\n**加强 HTTPS 安全性**\n\n```\nssl_prefer_server_ciphers ON;\nadd_header X-Frame-Options DENY;\nadd_header X-Content-Type-Options nosniff;\nadd_header X-Xss-Protection 1;\n\n```\n\n`ssl_prefer_server_ciphers ON`设置协商加密算法时，优先使用我们服务端的加密套件，而不是客户端浏览器的加密套件。\n`add_header X-Frame-Options DENY`减少点击劫持\n\n\n\n**HTTPS优化参数**\n```\nssl_session_cache shared:SSL:10m;\n\nssl_session_timeout 10m;\nssl_buffer_size 1400;\n\n```\n\n`ssl_session_cache shared:SSL:10m;` 设置ssl/tls会话缓存的类型和大小。如果设置了这个参数一般是shared，buildin可能会参数内存碎片，默认是none，和off差不多，停用缓存。如shared:SSL:10m表示我所有的nginx工作进程共享ssl会话缓存，官网介绍说1M可以存放约4000个sessions。 \n`ssl_session_timeout 10m;`  客户端可以重用会话缓存中ssl参数的过期时间。\n`ssl_buffer_size 1400;` 缓冲区调优，从1.5.9版本开始,Nginx允许使用ssl_buffer_size指令自定义TLS缓冲区的大小，默认值是 16 KB,但是这个值不一定是最优化的,尤其是你希望首字节数据被尽早发送时,有报告显示使 用1400字节的配置可以显著减少延迟。[参考](http://fangpeishi.com/optimizing-tls-record-size.html)\n\n\n**配置参考**\n```\nssl                  on;\nssl_session_timeout  30m;\nssl_protocols  TLSv1 TLSv1.1 TLSv1.2;\n\nssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA:!CAMELLIA;\n\nssl_prefer_server_ciphers   on;\nssl_buffer_size 1400;\n\nssl_session_cache    shared:SSL:10m;\nssl_certificate      domain.crt;\nssl_certificate_key  domain.key;\n\n```\n","source":"_posts/nginx之HTTPS配置.md","raw":"---\ntitle: nginx之HTTPS配置\ndate: 2017-07-07 15:15:38\ntags: nginx\ncategories: 基础运维\n---\n\n> https现在是标配了，HTTPS 可以给用户带来更安全、比如减少了被劫持的概率，更好隐私保护的网络体验，这些好处大家都耳熟能详，本文不再赘述。现在很多浏览器都在推行HTTPS的普及。尽快升级吧。\n\n其实大体就是分为`ssl证书申请`和`配置HTTPS`两个步骤\n\n## 证书申请\n这次介绍并没有从申请证书开始，因为之前已经申请过了，申请步骤请[参考](https://aotu.io/notes/2016/08/16/nginx-https/index.html)\nSSL 证书主要有两个功能：加密和身份证明，通常需要购买，也有免费的，通过第三方 SSL 证书机构颁发。分为企业级别和个人级别。\nSSL 具体加密实现[参考](http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html)\n查看证书相关配置，包括哪个机构颁发的，过期时间等等信息可以到https://www.chinassl.net 自助查看\n\n## nginx HTTPS配置\n\n首先我们把得到的domain.key domain.crt 放到 nginx的conf下，\n可以在nginx.conf 的`server`中配置\n\n**基础配置**\n```\n server {\n     listen              443 ssl http2;\n     #证书文件(注意路径及权限)\n     ssl on;\n     ssl_certificate     example.com.crt;\n     #私钥文件\n     ssl_certificate_key example.com.key;\n     ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;\n     ssl_ciphers         HIGH:!aNULL:!MD5;\n\n#....\n}\n```\n必须使用监听命令 listen 的 ssl 参数和定义服务器证书文件和私钥文件\n\n`ssl_protocols` 可以用来限制连接只包含 SSL/TLS 的加強版本，默认值如上。\n`ssl_ciphers` 选择加密套件，不同的浏览器所支持的套件（和顺序）可能会不同。这里指定的是OpenSSL库能够识别的写法，你可以通过 openssl -v cipher 'RC4:HIGH:!aNULL:!MD5'（后面是你所指定的套件加密算法） 来看所支持算法。\n\n\n\n**加强 HTTPS 安全性**\n\n```\nssl_prefer_server_ciphers ON;\nadd_header X-Frame-Options DENY;\nadd_header X-Content-Type-Options nosniff;\nadd_header X-Xss-Protection 1;\n\n```\n\n`ssl_prefer_server_ciphers ON`设置协商加密算法时，优先使用我们服务端的加密套件，而不是客户端浏览器的加密套件。\n`add_header X-Frame-Options DENY`减少点击劫持\n\n\n\n**HTTPS优化参数**\n```\nssl_session_cache shared:SSL:10m;\n\nssl_session_timeout 10m;\nssl_buffer_size 1400;\n\n```\n\n`ssl_session_cache shared:SSL:10m;` 设置ssl/tls会话缓存的类型和大小。如果设置了这个参数一般是shared，buildin可能会参数内存碎片，默认是none，和off差不多，停用缓存。如shared:SSL:10m表示我所有的nginx工作进程共享ssl会话缓存，官网介绍说1M可以存放约4000个sessions。 \n`ssl_session_timeout 10m;`  客户端可以重用会话缓存中ssl参数的过期时间。\n`ssl_buffer_size 1400;` 缓冲区调优，从1.5.9版本开始,Nginx允许使用ssl_buffer_size指令自定义TLS缓冲区的大小，默认值是 16 KB,但是这个值不一定是最优化的,尤其是你希望首字节数据被尽早发送时,有报告显示使 用1400字节的配置可以显著减少延迟。[参考](http://fangpeishi.com/optimizing-tls-record-size.html)\n\n\n**配置参考**\n```\nssl                  on;\nssl_session_timeout  30m;\nssl_protocols  TLSv1 TLSv1.1 TLSv1.2;\n\nssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA:!CAMELLIA;\n\nssl_prefer_server_ciphers   on;\nssl_buffer_size 1400;\n\nssl_session_cache    shared:SSL:10m;\nssl_certificate      domain.crt;\nssl_certificate_key  domain.key;\n\n```\n","slug":"nginx之HTTPS配置","published":1,"updated":"2017-07-20T06:20:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbg002n8tzzcfxedlbh","content":"<blockquote>\n<p>https现在是标配了，HTTPS 可以给用户带来更安全、比如减少了被劫持的概率，更好隐私保护的网络体验，这些好处大家都耳熟能详，本文不再赘述。现在很多浏览器都在推行HTTPS的普及。尽快升级吧。</p>\n</blockquote>\n<p>其实大体就是分为<code>ssl证书申请</code>和<code>配置HTTPS</code>两个步骤</p>\n<h2 id=\"证书申请\"><a href=\"#证书申请\" class=\"headerlink\" title=\"证书申请\"></a>证书申请</h2><p>这次介绍并没有从申请证书开始，因为之前已经申请过了，申请步骤请<a href=\"https://aotu.io/notes/2016/08/16/nginx-https/index.html\" target=\"_blank\" rel=\"external\">参考</a><br>SSL 证书主要有两个功能：加密和身份证明，通常需要购买，也有免费的，通过第三方 SSL 证书机构颁发。分为企业级别和个人级别。<br>SSL 具体加密实现<a href=\"http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html\" target=\"_blank\" rel=\"external\">参考</a><br>查看证书相关配置，包括哪个机构颁发的，过期时间等等信息可以到<a href=\"https://www.chinassl.net\" target=\"_blank\" rel=\"external\">https://www.chinassl.net</a> 自助查看</p>\n<h2 id=\"nginx-https配置\"><a href=\"#nginx-HTTPS配置\" class=\"headerlink\" title=\"nginx HTTPS配置\"></a>nginx HTTPS配置</h2><p>首先我们把得到的domain.key domain.crt 放到 nginx的conf下，<br>可以在nginx.conf 的<code>server</code>中配置</p>\n<p><strong>基础配置</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"> server &#123;</div><div class=\"line\">     listen              443 ssl http2;</div><div class=\"line\">     #证书文件(注意路径及权限)</div><div class=\"line\">     ssl on;</div><div class=\"line\">     ssl_certificate     example.com.crt;</div><div class=\"line\">     #私钥文件</div><div class=\"line\">     ssl_certificate_key example.com.key;</div><div class=\"line\">     ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;</div><div class=\"line\">     ssl_ciphers         HIGH:!aNULL:!MD5;</div><div class=\"line\"></div><div class=\"line\">#....</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>必须使用监听命令 listen 的 ssl 参数和定义服务器证书文件和私钥文件</p>\n<p><code>ssl_protocols</code> 可以用来限制连接只包含 SSL/TLS 的加強版本，默认值如上。<br><code>ssl_ciphers</code> 选择加密套件，不同的浏览器所支持的套件（和顺序）可能会不同。这里指定的是OpenSSL库能够识别的写法，你可以通过 openssl -v cipher ‘RC4:HIGH:!aNULL:!MD5’（后面是你所指定的套件加密算法） 来看所支持算法。</p>\n<p><strong>加强 HTTPS 安全性</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssl_prefer_server_ciphers ON;</div><div class=\"line\">add_header X-Frame-Options DENY;</div><div class=\"line\">add_header X-Content-Type-Options nosniff;</div><div class=\"line\">add_header X-Xss-Protection 1;</div></pre></td></tr></table></figure>\n<p><code>ssl_prefer_server_ciphers ON</code>设置协商加密算法时，优先使用我们服务端的加密套件，而不是客户端浏览器的加密套件。<br><code>add_header X-Frame-Options DENY</code>减少点击劫持</p>\n<p><strong>HTTPS优化参数</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssl_session_cache shared:SSL:10m;</div><div class=\"line\"></div><div class=\"line\">ssl_session_timeout 10m;</div><div class=\"line\">ssl_buffer_size 1400;</div></pre></td></tr></table></figure></p>\n<p><code>ssl_session_cache shared:SSL:10m;</code> 设置ssl/tls会话缓存的类型和大小。如果设置了这个参数一般是shared，buildin可能会参数内存碎片，默认是none，和off差不多，停用缓存。如shared:SSL:10m表示我所有的nginx工作进程共享ssl会话缓存，官网介绍说1M可以存放约4000个sessions。<br><code>ssl_session_timeout 10m;</code>  客户端可以重用会话缓存中ssl参数的过期时间。<br><code>ssl_buffer_size 1400;</code> 缓冲区调优，从1.5.9版本开始,Nginx允许使用ssl_buffer_size指令自定义TLS缓冲区的大小，默认值是 16 KB,但是这个值不一定是最优化的,尤其是你希望首字节数据被尽早发送时,有报告显示使 用1400字节的配置可以显著减少延迟。<a href=\"http://fangpeishi.com/optimizing-tls-record-size.html\" target=\"_blank\" rel=\"external\">参考</a></p>\n<p><strong>配置参考</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssl                  on;</div><div class=\"line\">ssl_session_timeout  30m;</div><div class=\"line\">ssl_protocols  TLSv1 TLSv1.1 TLSv1.2;</div><div class=\"line\"></div><div class=\"line\">ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA:!CAMELLIA;</div><div class=\"line\"></div><div class=\"line\">ssl_prefer_server_ciphers   on;</div><div class=\"line\">ssl_buffer_size 1400;</div><div class=\"line\"></div><div class=\"line\">ssl_session_cache    shared:SSL:10m;</div><div class=\"line\">ssl_certificate      domain.crt;</div><div class=\"line\">ssl_certificate_key  domain.key;</div></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>https现在是标配了，HTTPS 可以给用户带来更安全、比如减少了被劫持的概率，更好隐私保护的网络体验，这些好处大家都耳熟能详，本文不再赘述。现在很多浏览器都在推行HTTPS的普及。尽快升级吧。</p>\n</blockquote>\n<p>其实大体就是分为<code>ssl证书申请</code>和<code>配置HTTPS</code>两个步骤</p>\n<h2 id=\"证书申请\"><a href=\"#证书申请\" class=\"headerlink\" title=\"证书申请\"></a>证书申请</h2><p>这次介绍并没有从申请证书开始，因为之前已经申请过了，申请步骤请<a href=\"https://aotu.io/notes/2016/08/16/nginx-https/index.html\" target=\"_blank\" rel=\"external\">参考</a><br>SSL 证书主要有两个功能：加密和身份证明，通常需要购买，也有免费的，通过第三方 SSL 证书机构颁发。分为企业级别和个人级别。<br>SSL 具体加密实现<a href=\"http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html\" target=\"_blank\" rel=\"external\">参考</a><br>查看证书相关配置，包括哪个机构颁发的，过期时间等等信息可以到<a href=\"https://www.chinassl.net\" target=\"_blank\" rel=\"external\">https://www.chinassl.net</a> 自助查看</p>\n<h2 id=\"nginx-HTTPS配置\"><a href=\"#nginx-HTTPS配置\" class=\"headerlink\" title=\"nginx HTTPS配置\"></a>nginx HTTPS配置</h2><p>首先我们把得到的domain.key domain.crt 放到 nginx的conf下，<br>可以在nginx.conf 的<code>server</code>中配置</p>\n<p><strong>基础配置</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"> server &#123;</div><div class=\"line\">     listen              443 ssl http2;</div><div class=\"line\">     #证书文件(注意路径及权限)</div><div class=\"line\">     ssl on;</div><div class=\"line\">     ssl_certificate     example.com.crt;</div><div class=\"line\">     #私钥文件</div><div class=\"line\">     ssl_certificate_key example.com.key;</div><div class=\"line\">     ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;</div><div class=\"line\">     ssl_ciphers         HIGH:!aNULL:!MD5;</div><div class=\"line\"></div><div class=\"line\">#....</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>必须使用监听命令 listen 的 ssl 参数和定义服务器证书文件和私钥文件</p>\n<p><code>ssl_protocols</code> 可以用来限制连接只包含 SSL/TLS 的加強版本，默认值如上。<br><code>ssl_ciphers</code> 选择加密套件，不同的浏览器所支持的套件（和顺序）可能会不同。这里指定的是OpenSSL库能够识别的写法，你可以通过 openssl -v cipher ‘RC4:HIGH:!aNULL:!MD5’（后面是你所指定的套件加密算法） 来看所支持算法。</p>\n<p><strong>加强 HTTPS 安全性</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssl_prefer_server_ciphers ON;</div><div class=\"line\">add_header X-Frame-Options DENY;</div><div class=\"line\">add_header X-Content-Type-Options nosniff;</div><div class=\"line\">add_header X-Xss-Protection 1;</div></pre></td></tr></table></figure>\n<p><code>ssl_prefer_server_ciphers ON</code>设置协商加密算法时，优先使用我们服务端的加密套件，而不是客户端浏览器的加密套件。<br><code>add_header X-Frame-Options DENY</code>减少点击劫持</p>\n<p><strong>HTTPS优化参数</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssl_session_cache shared:SSL:10m;</div><div class=\"line\"></div><div class=\"line\">ssl_session_timeout 10m;</div><div class=\"line\">ssl_buffer_size 1400;</div></pre></td></tr></table></figure></p>\n<p><code>ssl_session_cache shared:SSL:10m;</code> 设置ssl/tls会话缓存的类型和大小。如果设置了这个参数一般是shared，buildin可能会参数内存碎片，默认是none，和off差不多，停用缓存。如shared:SSL:10m表示我所有的nginx工作进程共享ssl会话缓存，官网介绍说1M可以存放约4000个sessions。<br><code>ssl_session_timeout 10m;</code>  客户端可以重用会话缓存中ssl参数的过期时间。<br><code>ssl_buffer_size 1400;</code> 缓冲区调优，从1.5.9版本开始,Nginx允许使用ssl_buffer_size指令自定义TLS缓冲区的大小，默认值是 16 KB,但是这个值不一定是最优化的,尤其是你希望首字节数据被尽早发送时,有报告显示使 用1400字节的配置可以显著减少延迟。<a href=\"http://fangpeishi.com/optimizing-tls-record-size.html\" target=\"_blank\" rel=\"external\">参考</a></p>\n<p><strong>配置参考</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssl                  on;</div><div class=\"line\">ssl_session_timeout  30m;</div><div class=\"line\">ssl_protocols  TLSv1 TLSv1.1 TLSv1.2;</div><div class=\"line\"></div><div class=\"line\">ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA:!CAMELLIA;</div><div class=\"line\"></div><div class=\"line\">ssl_prefer_server_ciphers   on;</div><div class=\"line\">ssl_buffer_size 1400;</div><div class=\"line\"></div><div class=\"line\">ssl_session_cache    shared:SSL:10m;</div><div class=\"line\">ssl_certificate      domain.crt;</div><div class=\"line\">ssl_certificate_key  domain.key;</div></pre></td></tr></table></figure></p>\n"},{"title":"nginx之安装配置","date":"2017-07-06T11:52:30.000Z","_content":"\nnginx 相关知识参考网站\n[Tengine](http://tengine.taobao.org/)\n\n> nginx 首先从安装配置说起问题说起\n\n# 安装\n> 一般都是源码编译安装，直接解压编译安装就好没有啥可说的 一般需要安装PCRE zlib openssl 库 以及所需要模块例如openLDAP等\n\n**特别说明** \n安装完成之后再添加模块,需要重启服务，reload不会生效。 \n[参考链接](http://taokey.blog.51cto.com/4633273/1318719)\n\n# 配置\n> nginx的配置是一门很深的功课，首先我们要对基本的http协议特别了解，配置过程可能要各种rewrite，各种location。不要慌，一点一点来。\n\n## 配置文件参数详解\n> 首先对`nginx.conf`里面的各个配置项进行一下解释。 \n\n首先说下少数几个高级配置，一般写在开头，模块配置之上\n**进程运行的用户组** \n``` \nuser  nginx nginx;\n```\n\n**进程数** 一般跟CPU核数相匹配。nginx启动后有多少个worker处理请求，不包括master，(master不处理请求，二十主要接受客户端的请求并分配给worker处理)这里还涉及到下边要说的`worker_connections`, 正常被大家接受的nginx最大连接数就是靠这两个计算出来的.\n\n- nginx作为http服务器的时候：\n    - max_clients = worker_processes * worker_connections\n- nginx作为反向代理服务器的时候：\n    - max_clients = worker_processes * worker_connections/4\n\n具体为什么去[参考](http://liuqunying.blog.51cto.com/3984207/1420556)\n```\nworker_processes  8;\n```\n\n**最大打开文件数量** 这个如果没有设置会使用linux系统默认的文件最大打开数 `ulimit -a`可以查看到。\n```\nworker_rlimit_nofile 65535;\n```\n\n### Events模块\n\n这里包含nginx所有处理连接的设置\n```\nevents {\n    worker_connections 2048;\n\n    use epoll;\n}\n```\n`worker_connections`表示一个worker同时打开最大连接数。\n`use epoll`定义轮询方法 如果你的内核为linux 2.6+ 应该使用epoll异步非阻塞模型\n\n### http模块\n\n> HTTP模块控制着nginx http处理的所有核心特性\n\n```\n\nhttp {\n \n    server_tokens off;\n \n    sendfile on;\n\n    tcp_nopush on;\n    tcp_nodelay on;\n\n    ...\n\n}\n```\n\n`server_tokens` 这个只是在错误页面不显示nginx版本，为了安全。\n`sendfile` ,`tcp_nopush`,`tcp_nodelay`这三条一般同时出现 提高读写速度 提升性能 ，tcp_nopush 依赖sendfile, tcp_nodelay 不缓存数据，(禁用nagle算法，发送小数据不缓存直接发)\n\n\n```\nlog_format main '$remote_addr - - [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" '\n                '\"$http_user_agent\" [$request_time, $upstream_response_time] $host ($remote_port) \"sid=$cookie_sessionid\"';\naccess_log  logs/access.log  main;\n```\n定义日志格式 `main` 下边引用该格式。其实可以设置成json格式的，以后收集解析也方便。\n\n```\nlingering_close off;\nkeepalive_timeout 5;\nsend_timeout 20;\nproxy_connect_timeout 30;\nproxy_read_timeout 20;\nproxy_send_timeout 20;\n\n```\n\n`lingering_close` 定义关闭连接的方式，有三个选项 **off|on|always** `off`：请求完成之后，关闭连接，不管此时有没有收到客户端数据；`on`是中间值，一般情况下在关闭连接前都会处理连接上的用户发送的数据，除了有些情况下在业务上认定这之后的数据是不必要的；`always`无条件处理完所有用户请求。Tengine 默认off效率高些，但是存在误杀状况，nginx默认on 算个小坑。\n\n`keepalive_timeout` 给客户端分配keep-alive链接超时时间\n\n`send_timeout` 发送响应的超时时间，两个客户端请求之间的时间\n\n这几个一般用在nginx做反向代理的时候\n`proxy_connect_timeout` 后端服务器连接的超时时间_发起握手等候响应超时时间\n`proxy_read_timeout` 后端服务器处理请求的时间\n`proxy_send_timeout` 后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据\n\n```\n\ninclude /etc/nginx/mime.types;\ndefault_type application/octet-stream;\n```\ninclude只是一个在当前文件中包含另一个文件内容的指令。这里我们使用它来加载稍后会用到的一系列的MIME类型。其实就是content-type与扩展名的映射。在客户端发来一个请求之后，nginx通过扩展名找到对应的content-type,下载返回的头信息中，浏览器收到之后会按照这个类型做解析展示。这样就不至于发生css文件本当做html一样当文本展示了。如果在mime.types中没有找到，会使用default_type\n\n\n```\n## GZIP Setting\ngzip  on;\ngzip_min_length  1000;\ngzip_buffers     4 8k;\ngzip_http_version  1.0;\ngzip_comp_level  5;\ngzip_types       text/plain text/css application/x-javascript application/json application/xml;\n```\ngzip是GNU zip的缩写，它是一个GNU自由软件的文件压缩程序，可以极大的加速网站.有时压缩比率高到80%,近来测试了一下,最少都有40%以上,还是相当不错的。\n`gzip`\n决定是否开启gzip模块\n\n`gzip_min_length`\n当返回内容大于此值时才会使用gzip进行压缩,以K为单位,当值为0时，所有页面都进行压缩\n`gzip_buffers`\n设置gzip申请内存的大小,其作用是按块大小的倍数申请内存空间\n`gzip_http_version`\n用于识别http协议的版本，早期的浏览器不支持gzip压缩，用户会看到乱码，所以为了支持前期版本加了此选项,目前此项基本可以忽略\n`gzip_comp_level`\n设置gzip压缩等级，等级越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大\n`gzip_types`\n设置需要压缩的MIME类型,非设置值不进行压缩\n## server模块\n\n> server模块是http的子模块，定义虚拟主机\n格式\n```\nserver {\n    listen      80;\n    server_name map.baidu.com www.baidu.com; \n    client_max_body_size 10m;\n    root   /Users/yangyi/www;\n    index  index.php index.html index.htm; \n    charset utf-8;\n\n    }\n}\n```\n\n`server {}` server标志虚拟主机开始，在 {} 中配置\n`listen `监听 80端口\n`server_name`用来指定IP地址或者域名，多个域名之间用空格分开。这里指定域名为map.baidu.com 或者www.baidu.com。\n`client_max_body_size`  文件上传大小\n`charset` 声明网站默认编码格式\n\n直接转发到到10.0.0.1:9000，这几个proxy_set_header的意思是改变请求头的Host为客户端的Host，ip 否则在下层的服务端会认为客户端是这台代理的nginx。\nX-Forwarded-For 是一个 HTTP 扩展头部。HTTP/1.1（RFC 2616）协议并没有对它的定义，它最开始是由 Squid 这个缓存代理软件引入，用来表示 HTTP 请求端真实 IP。如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用，并被写入 RFC 7239（Forwarded HTTP Extension）标准之中。\n格式如下\n> X-Forwarded-For: client, proxy1, proxy2\n\n可以看到，XFF 的内容由「英文逗号 + 空格」隔开的多个部分组成，最开始的是离服务端最远的设备 IP，然后是每一级代理设备的 IP。\n如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP 分别为 IP1、IP2、IP3，用户真实 IP 为 IP0，那么按照 XFF 标准，服务端最终会收到以下信息：\n\n> X-Forwarded-For: IP0, IP1, IP2\n\n这个在多级代理的时候可以设置下，逻辑关系更清晰。\n\n## location 模块\n\n> 在server内部\n\n```\nlocation / {\n            root   /Users/yangyi/www;\n            index  index.php index.html index.htm;\n        }\n```\n\n```\nlocation / {\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $remote_addr;\n    proxy_pass http://10.0.0.1:9000;\n    proxy_redirect default;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n```\n\n\n**一个配置样例**\n```\nuser www-data;\n\npid /var/run/nginx.pid;\n\nworker_processes auto;\n\nworker_rlimit_nofile 100000;\n\n \nevents {\n\n    worker_connections 2048;\n    multi_accept on;\n    use epoll;\n\n}\n\nhttp {\n    server_tokens off;\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    log_format main '$remote_addr - - [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" '\n                '\"$http_user_agent\" [$request_time, $upstream_response_time] $host ($remote_port) \"sid=$cookie_sessionid\"';\n    access_log  logs/access.log  main;\n\n    error_log /var/log/nginx/error.log crit;\n \n\n    keepalive_timeout 10;\n\n    client_header_timeout 10;\n\n    client_body_timeout 10;\n    reset_timedout_connection on;\n\n    send_timeout 10;\n    limit_conn_zone $binary_remote_addr zone=addr:5m;\n    limit_conn addr 100;\n    include /etc/nginx/mime.types;\n    default_type text/html;\n    charset UTF-8;\n    gzip on;\n    gzip_disable \"msie6\";\n    gzip_proxied any;\n    gzip_min_length 1000;\n    gzip_comp_level 6;\n    gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;\n    open_file_cache max=100000 inactive=20s;\n    open_file_cache_valid 30s;\n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n\n}\n\n\n最后 关于nginx和http https等的设置可以参考[博客](https://imququ.com/)\n","source":"_posts/nginx之安装配置.md","raw":"---\ntitle: nginx之安装配置\ndate: 2017-07-06 19:52:30\ntags: nginx\ncategories: 基础运维    \n---\n\nnginx 相关知识参考网站\n[Tengine](http://tengine.taobao.org/)\n\n> nginx 首先从安装配置说起问题说起\n\n# 安装\n> 一般都是源码编译安装，直接解压编译安装就好没有啥可说的 一般需要安装PCRE zlib openssl 库 以及所需要模块例如openLDAP等\n\n**特别说明** \n安装完成之后再添加模块,需要重启服务，reload不会生效。 \n[参考链接](http://taokey.blog.51cto.com/4633273/1318719)\n\n# 配置\n> nginx的配置是一门很深的功课，首先我们要对基本的http协议特别了解，配置过程可能要各种rewrite，各种location。不要慌，一点一点来。\n\n## 配置文件参数详解\n> 首先对`nginx.conf`里面的各个配置项进行一下解释。 \n\n首先说下少数几个高级配置，一般写在开头，模块配置之上\n**进程运行的用户组** \n``` \nuser  nginx nginx;\n```\n\n**进程数** 一般跟CPU核数相匹配。nginx启动后有多少个worker处理请求，不包括master，(master不处理请求，二十主要接受客户端的请求并分配给worker处理)这里还涉及到下边要说的`worker_connections`, 正常被大家接受的nginx最大连接数就是靠这两个计算出来的.\n\n- nginx作为http服务器的时候：\n    - max_clients = worker_processes * worker_connections\n- nginx作为反向代理服务器的时候：\n    - max_clients = worker_processes * worker_connections/4\n\n具体为什么去[参考](http://liuqunying.blog.51cto.com/3984207/1420556)\n```\nworker_processes  8;\n```\n\n**最大打开文件数量** 这个如果没有设置会使用linux系统默认的文件最大打开数 `ulimit -a`可以查看到。\n```\nworker_rlimit_nofile 65535;\n```\n\n### Events模块\n\n这里包含nginx所有处理连接的设置\n```\nevents {\n    worker_connections 2048;\n\n    use epoll;\n}\n```\n`worker_connections`表示一个worker同时打开最大连接数。\n`use epoll`定义轮询方法 如果你的内核为linux 2.6+ 应该使用epoll异步非阻塞模型\n\n### http模块\n\n> HTTP模块控制着nginx http处理的所有核心特性\n\n```\n\nhttp {\n \n    server_tokens off;\n \n    sendfile on;\n\n    tcp_nopush on;\n    tcp_nodelay on;\n\n    ...\n\n}\n```\n\n`server_tokens` 这个只是在错误页面不显示nginx版本，为了安全。\n`sendfile` ,`tcp_nopush`,`tcp_nodelay`这三条一般同时出现 提高读写速度 提升性能 ，tcp_nopush 依赖sendfile, tcp_nodelay 不缓存数据，(禁用nagle算法，发送小数据不缓存直接发)\n\n\n```\nlog_format main '$remote_addr - - [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" '\n                '\"$http_user_agent\" [$request_time, $upstream_response_time] $host ($remote_port) \"sid=$cookie_sessionid\"';\naccess_log  logs/access.log  main;\n```\n定义日志格式 `main` 下边引用该格式。其实可以设置成json格式的，以后收集解析也方便。\n\n```\nlingering_close off;\nkeepalive_timeout 5;\nsend_timeout 20;\nproxy_connect_timeout 30;\nproxy_read_timeout 20;\nproxy_send_timeout 20;\n\n```\n\n`lingering_close` 定义关闭连接的方式，有三个选项 **off|on|always** `off`：请求完成之后，关闭连接，不管此时有没有收到客户端数据；`on`是中间值，一般情况下在关闭连接前都会处理连接上的用户发送的数据，除了有些情况下在业务上认定这之后的数据是不必要的；`always`无条件处理完所有用户请求。Tengine 默认off效率高些，但是存在误杀状况，nginx默认on 算个小坑。\n\n`keepalive_timeout` 给客户端分配keep-alive链接超时时间\n\n`send_timeout` 发送响应的超时时间，两个客户端请求之间的时间\n\n这几个一般用在nginx做反向代理的时候\n`proxy_connect_timeout` 后端服务器连接的超时时间_发起握手等候响应超时时间\n`proxy_read_timeout` 后端服务器处理请求的时间\n`proxy_send_timeout` 后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据\n\n```\n\ninclude /etc/nginx/mime.types;\ndefault_type application/octet-stream;\n```\ninclude只是一个在当前文件中包含另一个文件内容的指令。这里我们使用它来加载稍后会用到的一系列的MIME类型。其实就是content-type与扩展名的映射。在客户端发来一个请求之后，nginx通过扩展名找到对应的content-type,下载返回的头信息中，浏览器收到之后会按照这个类型做解析展示。这样就不至于发生css文件本当做html一样当文本展示了。如果在mime.types中没有找到，会使用default_type\n\n\n```\n## GZIP Setting\ngzip  on;\ngzip_min_length  1000;\ngzip_buffers     4 8k;\ngzip_http_version  1.0;\ngzip_comp_level  5;\ngzip_types       text/plain text/css application/x-javascript application/json application/xml;\n```\ngzip是GNU zip的缩写，它是一个GNU自由软件的文件压缩程序，可以极大的加速网站.有时压缩比率高到80%,近来测试了一下,最少都有40%以上,还是相当不错的。\n`gzip`\n决定是否开启gzip模块\n\n`gzip_min_length`\n当返回内容大于此值时才会使用gzip进行压缩,以K为单位,当值为0时，所有页面都进行压缩\n`gzip_buffers`\n设置gzip申请内存的大小,其作用是按块大小的倍数申请内存空间\n`gzip_http_version`\n用于识别http协议的版本，早期的浏览器不支持gzip压缩，用户会看到乱码，所以为了支持前期版本加了此选项,目前此项基本可以忽略\n`gzip_comp_level`\n设置gzip压缩等级，等级越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大\n`gzip_types`\n设置需要压缩的MIME类型,非设置值不进行压缩\n## server模块\n\n> server模块是http的子模块，定义虚拟主机\n格式\n```\nserver {\n    listen      80;\n    server_name map.baidu.com www.baidu.com; \n    client_max_body_size 10m;\n    root   /Users/yangyi/www;\n    index  index.php index.html index.htm; \n    charset utf-8;\n\n    }\n}\n```\n\n`server {}` server标志虚拟主机开始，在 {} 中配置\n`listen `监听 80端口\n`server_name`用来指定IP地址或者域名，多个域名之间用空格分开。这里指定域名为map.baidu.com 或者www.baidu.com。\n`client_max_body_size`  文件上传大小\n`charset` 声明网站默认编码格式\n\n直接转发到到10.0.0.1:9000，这几个proxy_set_header的意思是改变请求头的Host为客户端的Host，ip 否则在下层的服务端会认为客户端是这台代理的nginx。\nX-Forwarded-For 是一个 HTTP 扩展头部。HTTP/1.1（RFC 2616）协议并没有对它的定义，它最开始是由 Squid 这个缓存代理软件引入，用来表示 HTTP 请求端真实 IP。如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用，并被写入 RFC 7239（Forwarded HTTP Extension）标准之中。\n格式如下\n> X-Forwarded-For: client, proxy1, proxy2\n\n可以看到，XFF 的内容由「英文逗号 + 空格」隔开的多个部分组成，最开始的是离服务端最远的设备 IP，然后是每一级代理设备的 IP。\n如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP 分别为 IP1、IP2、IP3，用户真实 IP 为 IP0，那么按照 XFF 标准，服务端最终会收到以下信息：\n\n> X-Forwarded-For: IP0, IP1, IP2\n\n这个在多级代理的时候可以设置下，逻辑关系更清晰。\n\n## location 模块\n\n> 在server内部\n\n```\nlocation / {\n            root   /Users/yangyi/www;\n            index  index.php index.html index.htm;\n        }\n```\n\n```\nlocation / {\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $remote_addr;\n    proxy_pass http://10.0.0.1:9000;\n    proxy_redirect default;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n```\n\n\n**一个配置样例**\n```\nuser www-data;\n\npid /var/run/nginx.pid;\n\nworker_processes auto;\n\nworker_rlimit_nofile 100000;\n\n \nevents {\n\n    worker_connections 2048;\n    multi_accept on;\n    use epoll;\n\n}\n\nhttp {\n    server_tokens off;\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    log_format main '$remote_addr - - [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" '\n                '\"$http_user_agent\" [$request_time, $upstream_response_time] $host ($remote_port) \"sid=$cookie_sessionid\"';\n    access_log  logs/access.log  main;\n\n    error_log /var/log/nginx/error.log crit;\n \n\n    keepalive_timeout 10;\n\n    client_header_timeout 10;\n\n    client_body_timeout 10;\n    reset_timedout_connection on;\n\n    send_timeout 10;\n    limit_conn_zone $binary_remote_addr zone=addr:5m;\n    limit_conn addr 100;\n    include /etc/nginx/mime.types;\n    default_type text/html;\n    charset UTF-8;\n    gzip on;\n    gzip_disable \"msie6\";\n    gzip_proxied any;\n    gzip_min_length 1000;\n    gzip_comp_level 6;\n    gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;\n    open_file_cache max=100000 inactive=20s;\n    open_file_cache_valid 30s;\n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n\n}\n\n\n最后 关于nginx和http https等的设置可以参考[博客](https://imququ.com/)\n","slug":"nginx之安装配置","published":1,"updated":"2017-08-01T11:13:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbi002q8tzzaz5yj76f","content":"<p>nginx 相关知识参考网站<br><a href=\"http://tengine.taobao.org/\" target=\"_blank\" rel=\"external\">Tengine</a></p>\n<blockquote>\n<p>nginx 首先从安装配置说起问题说起</p>\n</blockquote>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><blockquote>\n<p>一般都是源码编译安装，直接解压编译安装就好没有啥可说的 一般需要安装PCRE zlib openssl 库 以及所需要模块例如openLDAP等</p>\n</blockquote>\n<p><strong>特别说明</strong><br>安装完成之后再添加模块,需要重启服务，reload不会生效。<br><a href=\"http://taokey.blog.51cto.com/4633273/1318719\" target=\"_blank\" rel=\"external\">参考链接</a></p>\n<h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><blockquote>\n<p>nginx的配置是一门很深的功课，首先我们要对基本的http协议特别了解，配置过程可能要各种rewrite，各种location。不要慌，一点一点来。</p>\n</blockquote>\n<h2 id=\"配置文件参数详解\"><a href=\"#配置文件参数详解\" class=\"headerlink\" title=\"配置文件参数详解\"></a>配置文件参数详解</h2><blockquote>\n<p>首先对<code>nginx.conf</code>里面的各个配置项进行一下解释。 </p>\n</blockquote>\n<p>首先说下少数几个高级配置，一般写在开头，模块配置之上<br><strong>进程运行的用户组</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">user  nginx nginx;</div></pre></td></tr></table></figure></p>\n<p><strong>进程数</strong> 一般跟CPU核数相匹配。nginx启动后有多少个worker处理请求，不包括master，(master不处理请求，二十主要接受客户端的请求并分配给worker处理)这里还涉及到下边要说的<code>worker_connections</code>, 正常被大家接受的nginx最大连接数就是靠这两个计算出来的.</p>\n<ul>\n<li>nginx作为http服务器的时候：<ul>\n<li>max_clients = worker_processes * worker_connections</li>\n</ul>\n</li>\n<li>nginx作为反向代理服务器的时候：<ul>\n<li>max_clients = worker_processes * worker_connections/4</li>\n</ul>\n</li>\n</ul>\n<p>具体为什么去<a href=\"http://liuqunying.blog.51cto.com/3984207/1420556\" target=\"_blank\" rel=\"external\">参考</a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">worker_processes  8;</div></pre></td></tr></table></figure></p>\n<p><strong>最大打开文件数量</strong> 这个如果没有设置会使用linux系统默认的文件最大打开数 <code>ulimit -a</code>可以查看到。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">worker_rlimit_nofile 65535;</div></pre></td></tr></table></figure></p>\n<h3 id=\"events模块\"><a href=\"#Events模块\" class=\"headerlink\" title=\"Events模块\"></a>Events模块</h3><p>这里包含nginx所有处理连接的设置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">events &#123;</div><div class=\"line\">    worker_connections 2048;</div><div class=\"line\"></div><div class=\"line\">    use epoll;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>worker_connections</code>表示一个worker同时打开最大连接数。<br><code>use epoll</code>定义轮询方法 如果你的内核为linux 2.6+ 应该使用epoll异步非阻塞模型</p>\n<h3 id=\"http模块\"><a href=\"#http模块\" class=\"headerlink\" title=\"http模块\"></a>http模块</h3><blockquote>\n<p>HTTP模块控制着nginx http处理的所有核心特性</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">http &#123;</div><div class=\"line\"> </div><div class=\"line\">    server_tokens off;</div><div class=\"line\"> </div><div class=\"line\">    sendfile on;</div><div class=\"line\"></div><div class=\"line\">    tcp_nopush on;</div><div class=\"line\">    tcp_nodelay on;</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>server_tokens</code> 这个只是在错误页面不显示nginx版本，为了安全。<br><code>sendfile</code> ,<code>tcp_nopush</code>,<code>tcp_nodelay</code>这三条一般同时出现 提高读写速度 提升性能 ，tcp_nopush 依赖sendfile, tcp_nodelay 不缓存数据，(禁用nagle算法，发送小数据不缓存直接发)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">log_format main &apos;$remote_addr - - [$time_local] &quot;$request&quot; $status $body_bytes_sent &quot;$http_referer&quot; &apos;</div><div class=\"line\">                &apos;&quot;$http_user_agent&quot; [$request_time, $upstream_response_time] $host ($remote_port) &quot;sid=$cookie_sessionid&quot;&apos;;</div><div class=\"line\">access_log  logs/access.log  main;</div></pre></td></tr></table></figure>\n<p>定义日志格式 <code>main</code> 下边引用该格式。其实可以设置成json格式的，以后收集解析也方便。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">lingering_close off;</div><div class=\"line\">keepalive_timeout 5;</div><div class=\"line\">send_timeout 20;</div><div class=\"line\">proxy_connect_timeout 30;</div><div class=\"line\">proxy_read_timeout 20;</div><div class=\"line\">proxy_send_timeout 20;</div></pre></td></tr></table></figure>\n<p><code>lingering_close</code> 定义关闭连接的方式，有三个选项 <strong>off|on|always</strong> <code>off</code>：请求完成之后，关闭连接，不管此时有没有收到客户端数据；<code>on</code>是中间值，一般情况下在关闭连接前都会处理连接上的用户发送的数据，除了有些情况下在业务上认定这之后的数据是不必要的；<code>always</code>无条件处理完所有用户请求。Tengine 默认off效率高些，但是存在误杀状况，nginx默认on 算个小坑。</p>\n<p><code>keepalive_timeout</code> 给客户端分配keep-alive链接超时时间</p>\n<p><code>send_timeout</code> 发送响应的超时时间，两个客户端请求之间的时间</p>\n<p>这几个一般用在nginx做反向代理的时候<br><code>proxy_connect_timeout</code> 后端服务器连接的超时时间_发起握手等候响应超时时间<br><code>proxy_read_timeout</code> 后端服务器处理请求的时间<br><code>proxy_send_timeout</code> 后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">include /etc/nginx/mime.types;</div><div class=\"line\">default_type application/octet-stream;</div></pre></td></tr></table></figure>\n<p>include只是一个在当前文件中包含另一个文件内容的指令。这里我们使用它来加载稍后会用到的一系列的MIME类型。其实就是content-type与扩展名的映射。在客户端发来一个请求之后，nginx通过扩展名找到对应的content-type,下载返回的头信息中，浏览器收到之后会按照这个类型做解析展示。这样就不至于发生css文件本当做html一样当文本展示了。如果在mime.types中没有找到，会使用default_type</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">## GZIP Setting</div><div class=\"line\">gzip  on;</div><div class=\"line\">gzip_min_length  1000;</div><div class=\"line\">gzip_buffers     4 8k;</div><div class=\"line\">gzip_http_version  1.0;</div><div class=\"line\">gzip_comp_level  5;</div><div class=\"line\">gzip_types       text/plain text/css application/x-javascript application/json application/xml;</div></pre></td></tr></table></figure>\n<p>gzip是GNU zip的缩写，它是一个GNU自由软件的文件压缩程序，可以极大的加速网站.有时压缩比率高到80%,近来测试了一下,最少都有40%以上,还是相当不错的。<br><code>gzip</code><br>决定是否开启gzip模块</p>\n<p><code>gzip_min_length</code><br>当返回内容大于此值时才会使用gzip进行压缩,以K为单位,当值为0时，所有页面都进行压缩<br><code>gzip_buffers</code><br>设置gzip申请内存的大小,其作用是按块大小的倍数申请内存空间<br><code>gzip_http_version</code><br>用于识别http协议的版本，早期的浏览器不支持gzip压缩，用户会看到乱码，所以为了支持前期版本加了此选项,目前此项基本可以忽略<br><code>gzip_comp_level</code><br>设置gzip压缩等级，等级越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大<br><code>gzip_types</code><br>设置需要压缩的MIME类型,非设置值不进行压缩</p>\n<h2 id=\"server模块\"><a href=\"#server模块\" class=\"headerlink\" title=\"server模块\"></a>server模块</h2><blockquote>\n<p>server模块是http的子模块，定义虚拟主机<br>格式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">server &#123;</div><div class=\"line\">    listen      80;</div><div class=\"line\">    server_name map.baidu.com www.baidu.com; </div><div class=\"line\">    client_max_body_size 10m;</div><div class=\"line\">    root   /Users/yangyi/www;</div><div class=\"line\">    index  index.php index.html index.htm; </div><div class=\"line\">    charset utf-8;</div><div class=\"line\"></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n</blockquote>\n<p><code>server {}</code> server标志虚拟主机开始，在 {} 中配置<br><code>listen</code>监听 80端口<br><code>server_name</code>用来指定IP地址或者域名，多个域名之间用空格分开。这里指定域名为map.baidu.com 或者www.baidu.com。<br><code>client_max_body_size</code>  文件上传大小<br><code>charset</code> 声明网站默认编码格式</p>\n<p>直接转发到到10.0.0.1:9000，这几个proxy_set_header的意思是改变请求头的Host为客户端的Host，ip 否则在下层的服务端会认为客户端是这台代理的nginx。<br>X-Forwarded-For 是一个 HTTP 扩展头部。HTTP/1.1（RFC 2616）协议并没有对它的定义，它最开始是由 Squid 这个缓存代理软件引入，用来表示 HTTP 请求端真实 IP。如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用，并被写入 RFC 7239（Forwarded HTTP Extension）标准之中。<br>格式如下</p>\n<blockquote>\n<p>X-Forwarded-For: client, proxy1, proxy2</p>\n</blockquote>\n<p>可以看到，XFF 的内容由「英文逗号 + 空格」隔开的多个部分组成，最开始的是离服务端最远的设备 IP，然后是每一级代理设备的 IP。<br>如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP 分别为 IP1、IP2、IP3，用户真实 IP 为 IP0，那么按照 XFF 标准，服务端最终会收到以下信息：</p>\n<blockquote>\n<p>X-Forwarded-For: IP0, IP1, IP2</p>\n</blockquote>\n<p>这个在多级代理的时候可以设置下，逻辑关系更清晰。</p>\n<h2 id=\"location-模块\"><a href=\"#location-模块\" class=\"headerlink\" title=\"location 模块\"></a>location 模块</h2><blockquote>\n<p>在server内部</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">location / &#123;</div><div class=\"line\">            root   /Users/yangyi/www;</div><div class=\"line\">            index  index.php index.html index.htm;</div><div class=\"line\">        &#125;</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">location / &#123;</div><div class=\"line\">    proxy_set_header Host $host;</div><div class=\"line\">    proxy_set_header X-Real-IP $remote_addr;</div><div class=\"line\">    proxy_set_header X-Forwarded-For $remote_addr;</div><div class=\"line\">    proxy_pass http://10.0.0.1:9000;</div><div class=\"line\">    proxy_redirect default;</div><div class=\"line\">    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div></pre></td></tr></table></figure>\n<p><strong>一个配置样例</strong><br>```<br>user www-data;</p>\n<p>pid /var/run/nginx.pid;</p>\n<p>worker_processes auto;</p>\n<p>worker_rlimit_nofile 100000;</p>\n<p>events {</p>\n<pre><code>worker_connections 2048;\nmulti_accept on;\nuse epoll;\n</code></pre><p>}</p>\n<p>http {<br>    server_tokens off;<br>    sendfile on;<br>    tcp_nopush on;<br>    tcp_nodelay on;<br>    log_format main ‘$remote_addr - - [$time_local] “$request” $status $body_bytes_sent “$http_referer” ‘<br>                ‘“$http_user_agent” [$request_time, $upstream_response_time] $host ($remote_port) “sid=$cookie_sessionid”‘;<br>    access_log  logs/access.log  main;</p>\n<pre><code>error_log /var/log/nginx/error.log crit;\n\n\nkeepalive_timeout 10;\n\nclient_header_timeout 10;\n\nclient_body_timeout 10;\nreset_timedout_connection on;\n\nsend_timeout 10;\nlimit_conn_zone $binary_remote_addr zone=addr:5m;\nlimit_conn addr 100;\ninclude /etc/nginx/mime.types;\ndefault_type text/html;\ncharset UTF-8;\ngzip on;\ngzip_disable &quot;msie6&quot;;\ngzip_proxied any;\ngzip_min_length 1000;\ngzip_comp_level 6;\ngzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;\nopen_file_cache max=100000 inactive=20s;\nopen_file_cache_valid 30s;\nopen_file_cache_min_uses 2;\nopen_file_cache_errors on;\ninclude /etc/nginx/conf.d/*.conf;\ninclude /etc/nginx/sites-enabled/*;\n</code></pre><p>}</p>\n<p>最后 关于nginx和http https等的设置可以参考<a href=\"https://imququ.com/\" target=\"_blank\" rel=\"external\">博客</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>nginx 相关知识参考网站<br><a href=\"http://tengine.taobao.org/\" target=\"_blank\" rel=\"external\">Tengine</a></p>\n<blockquote>\n<p>nginx 首先从安装配置说起问题说起</p>\n</blockquote>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><blockquote>\n<p>一般都是源码编译安装，直接解压编译安装就好没有啥可说的 一般需要安装PCRE zlib openssl 库 以及所需要模块例如openLDAP等</p>\n</blockquote>\n<p><strong>特别说明</strong><br>安装完成之后再添加模块,需要重启服务，reload不会生效。<br><a href=\"http://taokey.blog.51cto.com/4633273/1318719\" target=\"_blank\" rel=\"external\">参考链接</a></p>\n<h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><blockquote>\n<p>nginx的配置是一门很深的功课，首先我们要对基本的http协议特别了解，配置过程可能要各种rewrite，各种location。不要慌，一点一点来。</p>\n</blockquote>\n<h2 id=\"配置文件参数详解\"><a href=\"#配置文件参数详解\" class=\"headerlink\" title=\"配置文件参数详解\"></a>配置文件参数详解</h2><blockquote>\n<p>首先对<code>nginx.conf</code>里面的各个配置项进行一下解释。 </p>\n</blockquote>\n<p>首先说下少数几个高级配置，一般写在开头，模块配置之上<br><strong>进程运行的用户组</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">user  nginx nginx;</div></pre></td></tr></table></figure></p>\n<p><strong>进程数</strong> 一般跟CPU核数相匹配。nginx启动后有多少个worker处理请求，不包括master，(master不处理请求，二十主要接受客户端的请求并分配给worker处理)这里还涉及到下边要说的<code>worker_connections</code>, 正常被大家接受的nginx最大连接数就是靠这两个计算出来的.</p>\n<ul>\n<li>nginx作为http服务器的时候：<ul>\n<li>max_clients = worker_processes * worker_connections</li>\n</ul>\n</li>\n<li>nginx作为反向代理服务器的时候：<ul>\n<li>max_clients = worker_processes * worker_connections/4</li>\n</ul>\n</li>\n</ul>\n<p>具体为什么去<a href=\"http://liuqunying.blog.51cto.com/3984207/1420556\" target=\"_blank\" rel=\"external\">参考</a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">worker_processes  8;</div></pre></td></tr></table></figure></p>\n<p><strong>最大打开文件数量</strong> 这个如果没有设置会使用linux系统默认的文件最大打开数 <code>ulimit -a</code>可以查看到。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">worker_rlimit_nofile 65535;</div></pre></td></tr></table></figure></p>\n<h3 id=\"Events模块\"><a href=\"#Events模块\" class=\"headerlink\" title=\"Events模块\"></a>Events模块</h3><p>这里包含nginx所有处理连接的设置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">events &#123;</div><div class=\"line\">    worker_connections 2048;</div><div class=\"line\"></div><div class=\"line\">    use epoll;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>worker_connections</code>表示一个worker同时打开最大连接数。<br><code>use epoll</code>定义轮询方法 如果你的内核为linux 2.6+ 应该使用epoll异步非阻塞模型</p>\n<h3 id=\"http模块\"><a href=\"#http模块\" class=\"headerlink\" title=\"http模块\"></a>http模块</h3><blockquote>\n<p>HTTP模块控制着nginx http处理的所有核心特性</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">http &#123;</div><div class=\"line\"> </div><div class=\"line\">    server_tokens off;</div><div class=\"line\"> </div><div class=\"line\">    sendfile on;</div><div class=\"line\"></div><div class=\"line\">    tcp_nopush on;</div><div class=\"line\">    tcp_nodelay on;</div><div class=\"line\"></div><div class=\"line\">    ...</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>server_tokens</code> 这个只是在错误页面不显示nginx版本，为了安全。<br><code>sendfile</code> ,<code>tcp_nopush</code>,<code>tcp_nodelay</code>这三条一般同时出现 提高读写速度 提升性能 ，tcp_nopush 依赖sendfile, tcp_nodelay 不缓存数据，(禁用nagle算法，发送小数据不缓存直接发)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">log_format main &apos;$remote_addr - - [$time_local] &quot;$request&quot; $status $body_bytes_sent &quot;$http_referer&quot; &apos;</div><div class=\"line\">                &apos;&quot;$http_user_agent&quot; [$request_time, $upstream_response_time] $host ($remote_port) &quot;sid=$cookie_sessionid&quot;&apos;;</div><div class=\"line\">access_log  logs/access.log  main;</div></pre></td></tr></table></figure>\n<p>定义日志格式 <code>main</code> 下边引用该格式。其实可以设置成json格式的，以后收集解析也方便。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">lingering_close off;</div><div class=\"line\">keepalive_timeout 5;</div><div class=\"line\">send_timeout 20;</div><div class=\"line\">proxy_connect_timeout 30;</div><div class=\"line\">proxy_read_timeout 20;</div><div class=\"line\">proxy_send_timeout 20;</div></pre></td></tr></table></figure>\n<p><code>lingering_close</code> 定义关闭连接的方式，有三个选项 <strong>off|on|always</strong> <code>off</code>：请求完成之后，关闭连接，不管此时有没有收到客户端数据；<code>on</code>是中间值，一般情况下在关闭连接前都会处理连接上的用户发送的数据，除了有些情况下在业务上认定这之后的数据是不必要的；<code>always</code>无条件处理完所有用户请求。Tengine 默认off效率高些，但是存在误杀状况，nginx默认on 算个小坑。</p>\n<p><code>keepalive_timeout</code> 给客户端分配keep-alive链接超时时间</p>\n<p><code>send_timeout</code> 发送响应的超时时间，两个客户端请求之间的时间</p>\n<p>这几个一般用在nginx做反向代理的时候<br><code>proxy_connect_timeout</code> 后端服务器连接的超时时间_发起握手等候响应超时时间<br><code>proxy_read_timeout</code> 后端服务器处理请求的时间<br><code>proxy_send_timeout</code> 后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">include /etc/nginx/mime.types;</div><div class=\"line\">default_type application/octet-stream;</div></pre></td></tr></table></figure>\n<p>include只是一个在当前文件中包含另一个文件内容的指令。这里我们使用它来加载稍后会用到的一系列的MIME类型。其实就是content-type与扩展名的映射。在客户端发来一个请求之后，nginx通过扩展名找到对应的content-type,下载返回的头信息中，浏览器收到之后会按照这个类型做解析展示。这样就不至于发生css文件本当做html一样当文本展示了。如果在mime.types中没有找到，会使用default_type</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">## GZIP Setting</div><div class=\"line\">gzip  on;</div><div class=\"line\">gzip_min_length  1000;</div><div class=\"line\">gzip_buffers     4 8k;</div><div class=\"line\">gzip_http_version  1.0;</div><div class=\"line\">gzip_comp_level  5;</div><div class=\"line\">gzip_types       text/plain text/css application/x-javascript application/json application/xml;</div></pre></td></tr></table></figure>\n<p>gzip是GNU zip的缩写，它是一个GNU自由软件的文件压缩程序，可以极大的加速网站.有时压缩比率高到80%,近来测试了一下,最少都有40%以上,还是相当不错的。<br><code>gzip</code><br>决定是否开启gzip模块</p>\n<p><code>gzip_min_length</code><br>当返回内容大于此值时才会使用gzip进行压缩,以K为单位,当值为0时，所有页面都进行压缩<br><code>gzip_buffers</code><br>设置gzip申请内存的大小,其作用是按块大小的倍数申请内存空间<br><code>gzip_http_version</code><br>用于识别http协议的版本，早期的浏览器不支持gzip压缩，用户会看到乱码，所以为了支持前期版本加了此选项,目前此项基本可以忽略<br><code>gzip_comp_level</code><br>设置gzip压缩等级，等级越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大<br><code>gzip_types</code><br>设置需要压缩的MIME类型,非设置值不进行压缩</p>\n<h2 id=\"server模块\"><a href=\"#server模块\" class=\"headerlink\" title=\"server模块\"></a>server模块</h2><blockquote>\n<p>server模块是http的子模块，定义虚拟主机<br>格式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">server &#123;</div><div class=\"line\">    listen      80;</div><div class=\"line\">    server_name map.baidu.com www.baidu.com; </div><div class=\"line\">    client_max_body_size 10m;</div><div class=\"line\">    root   /Users/yangyi/www;</div><div class=\"line\">    index  index.php index.html index.htm; </div><div class=\"line\">    charset utf-8;</div><div class=\"line\"></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n</blockquote>\n<p><code>server {}</code> server标志虚拟主机开始，在 {} 中配置<br><code>listen</code>监听 80端口<br><code>server_name</code>用来指定IP地址或者域名，多个域名之间用空格分开。这里指定域名为map.baidu.com 或者www.baidu.com。<br><code>client_max_body_size</code>  文件上传大小<br><code>charset</code> 声明网站默认编码格式</p>\n<p>直接转发到到10.0.0.1:9000，这几个proxy_set_header的意思是改变请求头的Host为客户端的Host，ip 否则在下层的服务端会认为客户端是这台代理的nginx。<br>X-Forwarded-For 是一个 HTTP 扩展头部。HTTP/1.1（RFC 2616）协议并没有对它的定义，它最开始是由 Squid 这个缓存代理软件引入，用来表示 HTTP 请求端真实 IP。如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用，并被写入 RFC 7239（Forwarded HTTP Extension）标准之中。<br>格式如下</p>\n<blockquote>\n<p>X-Forwarded-For: client, proxy1, proxy2</p>\n</blockquote>\n<p>可以看到，XFF 的内容由「英文逗号 + 空格」隔开的多个部分组成，最开始的是离服务端最远的设备 IP，然后是每一级代理设备的 IP。<br>如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP 分别为 IP1、IP2、IP3，用户真实 IP 为 IP0，那么按照 XFF 标准，服务端最终会收到以下信息：</p>\n<blockquote>\n<p>X-Forwarded-For: IP0, IP1, IP2</p>\n</blockquote>\n<p>这个在多级代理的时候可以设置下，逻辑关系更清晰。</p>\n<h2 id=\"location-模块\"><a href=\"#location-模块\" class=\"headerlink\" title=\"location 模块\"></a>location 模块</h2><blockquote>\n<p>在server内部</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">location / &#123;</div><div class=\"line\">            root   /Users/yangyi/www;</div><div class=\"line\">            index  index.php index.html index.htm;</div><div class=\"line\">        &#125;</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">location / &#123;</div><div class=\"line\">    proxy_set_header Host $host;</div><div class=\"line\">    proxy_set_header X-Real-IP $remote_addr;</div><div class=\"line\">    proxy_set_header X-Forwarded-For $remote_addr;</div><div class=\"line\">    proxy_pass http://10.0.0.1:9000;</div><div class=\"line\">    proxy_redirect default;</div><div class=\"line\">    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div></pre></td></tr></table></figure>\n<p><strong>一个配置样例</strong><br>```<br>user www-data;</p>\n<p>pid /var/run/nginx.pid;</p>\n<p>worker_processes auto;</p>\n<p>worker_rlimit_nofile 100000;</p>\n<p>events {</p>\n<pre><code>worker_connections 2048;\nmulti_accept on;\nuse epoll;\n</code></pre><p>}</p>\n<p>http {<br>    server_tokens off;<br>    sendfile on;<br>    tcp_nopush on;<br>    tcp_nodelay on;<br>    log_format main ‘$remote_addr - - [$time_local] “$request” $status $body_bytes_sent “$http_referer” ‘<br>                ‘“$http_user_agent” [$request_time, $upstream_response_time] $host ($remote_port) “sid=$cookie_sessionid”‘;<br>    access_log  logs/access.log  main;</p>\n<pre><code>error_log /var/log/nginx/error.log crit;\n\n\nkeepalive_timeout 10;\n\nclient_header_timeout 10;\n\nclient_body_timeout 10;\nreset_timedout_connection on;\n\nsend_timeout 10;\nlimit_conn_zone $binary_remote_addr zone=addr:5m;\nlimit_conn addr 100;\ninclude /etc/nginx/mime.types;\ndefault_type text/html;\ncharset UTF-8;\ngzip on;\ngzip_disable &quot;msie6&quot;;\ngzip_proxied any;\ngzip_min_length 1000;\ngzip_comp_level 6;\ngzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;\nopen_file_cache max=100000 inactive=20s;\nopen_file_cache_valid 30s;\nopen_file_cache_min_uses 2;\nopen_file_cache_errors on;\ninclude /etc/nginx/conf.d/*.conf;\ninclude /etc/nginx/sites-enabled/*;\n</code></pre><p>}</p>\n<p>最后 关于nginx和http https等的设置可以参考<a href=\"https://imququ.com/\" target=\"_blank\" rel=\"external\">博客</a></p>\n"},{"title":"nginx之请求限流限速问题","date":"2017-07-20T07:04:07.000Z","_content":"\n# 单位时间按照IP地址限速 \n\n工作当中经常需要按照IP地址限速，加白名单或者黑名单，这里面就会用到map来设置。看下边例子展示\n\n```\nhttp {  \n    geo $white_ip {\n        ranges;\n        default 0;\n        127.0.0.1-127.0.0.1 1;\n\n        36.110.16.242-36.110.16.242 1\n         \n    }\n\n\n    map $white_ip $white_ip_address {\n        0 $binary_remote_addr;\n        1 \"\";\n    }\n\n    limit_req_zone $white_ip_address zone=:10m rate=20r/s;\n    \n    ....\n\n}\n```\n\n**解释下**\n\n上述通过`geo模块` 设定了白名单 \n\n**ngx_http_geo_module** 模块可以用来创建变量，其值依赖于客户端IP地址。\n语法: geo [$address] $variable { ... }    设置在http 模块中  \n`[$address]` 可以为空，使用默认变量也就是$remote_addr 其实例子中 `geo $white_ip {}`  就相当于`geo $remote_addr $white_ip {}`\n`$white_ip` 命名为`white_ip` \n`ranges` 使用以地址段的形式定义地址，这个参数必须放在首位。为了加速装载地址库，地址应按升序定义。\n`default` 设置默认值，如果客户端地址不能匹配任意一个定义的地址，nginx将使用此值。\n\n注：如果36.110.16.242 这个IP地址访问本站, `white_ip` 这个变量值就是 1,否则就是0 \n\n\n通过`map模块` 对$white_ip进行映射\n\n**ngx_http_map_module** 模块可以创建变量，这些变量的值与另外的变量值相关联（上文的$white_ip）。允许分类或者同时映射多个值到多个不同值并储存到一个变量中，map指令用来创建变量，但是仅在变量被接受的时候执行视图映射操作，对于处理没有引用变量的请求时，这个模块并没有性能上的缺失。 \n\n语法: map $var1 $var2 { ... }\n\n上文map指令是将$white_ip值为0的，也就是受限制的IP，映射为客户端IP。将$white_ip值为1的，映射为空的字符串。\n`limit_conn_zone`和`limit_req_zone`指令对于键为空值的将会被忽略，从而实现对于列出来的IP不做限制。\n\n`limit_req_zone ` 真正操作限速 \n**ngx_http_limit_req_module** 模块\n\n# 下载限速\n\n```\nlocation /file { \n    limit_rate 128k;\n# 限制下载速度128K/s \n  } \n\n# 如果想设置用户下载文件的前10m大小时不限速，大于10m后再以128kb/s限速可以增加以下配内容，修改nginx.conf文件\n\nlocation /download { \n       limit_rate_after 10m; \n       limit_rate 128k; \n }  \n```\n\n","source":"_posts/nginx之请求限流限速问题.md","raw":"---\ntitle: nginx之请求限流限速问题\ndate: 2017-07-20 15:04:07\ntags: nginx\n---\n\n# 单位时间按照IP地址限速 \n\n工作当中经常需要按照IP地址限速，加白名单或者黑名单，这里面就会用到map来设置。看下边例子展示\n\n```\nhttp {  \n    geo $white_ip {\n        ranges;\n        default 0;\n        127.0.0.1-127.0.0.1 1;\n\n        36.110.16.242-36.110.16.242 1\n         \n    }\n\n\n    map $white_ip $white_ip_address {\n        0 $binary_remote_addr;\n        1 \"\";\n    }\n\n    limit_req_zone $white_ip_address zone=:10m rate=20r/s;\n    \n    ....\n\n}\n```\n\n**解释下**\n\n上述通过`geo模块` 设定了白名单 \n\n**ngx_http_geo_module** 模块可以用来创建变量，其值依赖于客户端IP地址。\n语法: geo [$address] $variable { ... }    设置在http 模块中  \n`[$address]` 可以为空，使用默认变量也就是$remote_addr 其实例子中 `geo $white_ip {}`  就相当于`geo $remote_addr $white_ip {}`\n`$white_ip` 命名为`white_ip` \n`ranges` 使用以地址段的形式定义地址，这个参数必须放在首位。为了加速装载地址库，地址应按升序定义。\n`default` 设置默认值，如果客户端地址不能匹配任意一个定义的地址，nginx将使用此值。\n\n注：如果36.110.16.242 这个IP地址访问本站, `white_ip` 这个变量值就是 1,否则就是0 \n\n\n通过`map模块` 对$white_ip进行映射\n\n**ngx_http_map_module** 模块可以创建变量，这些变量的值与另外的变量值相关联（上文的$white_ip）。允许分类或者同时映射多个值到多个不同值并储存到一个变量中，map指令用来创建变量，但是仅在变量被接受的时候执行视图映射操作，对于处理没有引用变量的请求时，这个模块并没有性能上的缺失。 \n\n语法: map $var1 $var2 { ... }\n\n上文map指令是将$white_ip值为0的，也就是受限制的IP，映射为客户端IP。将$white_ip值为1的，映射为空的字符串。\n`limit_conn_zone`和`limit_req_zone`指令对于键为空值的将会被忽略，从而实现对于列出来的IP不做限制。\n\n`limit_req_zone ` 真正操作限速 \n**ngx_http_limit_req_module** 模块\n\n# 下载限速\n\n```\nlocation /file { \n    limit_rate 128k;\n# 限制下载速度128K/s \n  } \n\n# 如果想设置用户下载文件的前10m大小时不限速，大于10m后再以128kb/s限速可以增加以下配内容，修改nginx.conf文件\n\nlocation /download { \n       limit_rate_after 10m; \n       limit_rate 128k; \n }  \n```\n\n","slug":"nginx之请求限流限速问题","published":1,"updated":"2017-08-03T07:45:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbj002t8tzzx8ar1ksj","content":"<h1 id=\"单位时间按照ip地址限速\"><a href=\"#单位时间按照IP地址限速\" class=\"headerlink\" title=\"单位时间按照IP地址限速\"></a>单位时间按照IP地址限速</h1><p>工作当中经常需要按照IP地址限速，加白名单或者黑名单，这里面就会用到map来设置。看下边例子展示</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">http &#123;  </div><div class=\"line\">    geo $white_ip &#123;</div><div class=\"line\">        ranges;</div><div class=\"line\">        default 0;</div><div class=\"line\">        127.0.0.1-127.0.0.1 1;</div><div class=\"line\"></div><div class=\"line\">        36.110.16.242-36.110.16.242 1</div><div class=\"line\">         </div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">    map $white_ip $white_ip_address &#123;</div><div class=\"line\">        0 $binary_remote_addr;</div><div class=\"line\">        1 &quot;&quot;;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    limit_req_zone $white_ip_address zone=:10m rate=20r/s;</div><div class=\"line\">    </div><div class=\"line\">    ....</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><strong>解释下</strong></p>\n<p>上述通过<code>geo模块</code> 设定了白名单 </p>\n<p><strong>ngx_http_geo_module</strong> 模块可以用来创建变量，其值依赖于客户端IP地址。<br>语法: geo [$address] $variable { … }    设置在http 模块中<br><code>[$address]</code> 可以为空，使用默认变量也就是$remote_addr 其实例子中 <code>geo $white_ip {}</code>  就相当于<code>geo $remote_addr $white_ip {}</code><br><code>$white_ip</code> 命名为<code>white_ip</code><br><code>ranges</code> 使用以地址段的形式定义地址，这个参数必须放在首位。为了加速装载地址库，地址应按升序定义。<br><code>default</code> 设置默认值，如果客户端地址不能匹配任意一个定义的地址，nginx将使用此值。</p>\n<p>注：如果36.110.16.242 这个IP地址访问本站, <code>white_ip</code> 这个变量值就是 1,否则就是0 </p>\n<p>通过<code>map模块</code> 对$white_ip进行映射</p>\n<p><strong>ngx_http_map_module</strong> 模块可以创建变量，这些变量的值与另外的变量值相关联（上文的$white_ip）。允许分类或者同时映射多个值到多个不同值并储存到一个变量中，map指令用来创建变量，但是仅在变量被接受的时候执行视图映射操作，对于处理没有引用变量的请求时，这个模块并没有性能上的缺失。 </p>\n<p>语法: map $var1 $var2 { … }</p>\n<p>上文map指令是将$white_ip值为0的，也就是受限制的IP，映射为客户端IP。将$white_ip值为1的，映射为空的字符串。<br><code>limit_conn_zone</code>和<code>limit_req_zone</code>指令对于键为空值的将会被忽略，从而实现对于列出来的IP不做限制。</p>\n<p><code>limit_req_zone</code> 真正操作限速<br><strong>ngx_http_limit_req_module</strong> 模块</p>\n<h1 id=\"下载限速\"><a href=\"#下载限速\" class=\"headerlink\" title=\"下载限速\"></a>下载限速</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">location /file &#123; </div><div class=\"line\">    limit_rate 128k;</div><div class=\"line\"># 限制下载速度128K/s </div><div class=\"line\">  &#125; </div><div class=\"line\"></div><div class=\"line\"># 如果想设置用户下载文件的前10m大小时不限速，大于10m后再以128kb/s限速可以增加以下配内容，修改nginx.conf文件</div><div class=\"line\"></div><div class=\"line\">location /download &#123; </div><div class=\"line\">       limit_rate_after 10m; </div><div class=\"line\">       limit_rate 128k; </div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"单位时间按照IP地址限速\"><a href=\"#单位时间按照IP地址限速\" class=\"headerlink\" title=\"单位时间按照IP地址限速\"></a>单位时间按照IP地址限速</h1><p>工作当中经常需要按照IP地址限速，加白名单或者黑名单，这里面就会用到map来设置。看下边例子展示</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">http &#123;  </div><div class=\"line\">    geo $white_ip &#123;</div><div class=\"line\">        ranges;</div><div class=\"line\">        default 0;</div><div class=\"line\">        127.0.0.1-127.0.0.1 1;</div><div class=\"line\"></div><div class=\"line\">        36.110.16.242-36.110.16.242 1</div><div class=\"line\">         </div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">    map $white_ip $white_ip_address &#123;</div><div class=\"line\">        0 $binary_remote_addr;</div><div class=\"line\">        1 &quot;&quot;;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    limit_req_zone $white_ip_address zone=:10m rate=20r/s;</div><div class=\"line\">    </div><div class=\"line\">    ....</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><strong>解释下</strong></p>\n<p>上述通过<code>geo模块</code> 设定了白名单 </p>\n<p><strong>ngx_http_geo_module</strong> 模块可以用来创建变量，其值依赖于客户端IP地址。<br>语法: geo [$address] $variable { … }    设置在http 模块中<br><code>[$address]</code> 可以为空，使用默认变量也就是$remote_addr 其实例子中 <code>geo $white_ip {}</code>  就相当于<code>geo $remote_addr $white_ip {}</code><br><code>$white_ip</code> 命名为<code>white_ip</code><br><code>ranges</code> 使用以地址段的形式定义地址，这个参数必须放在首位。为了加速装载地址库，地址应按升序定义。<br><code>default</code> 设置默认值，如果客户端地址不能匹配任意一个定义的地址，nginx将使用此值。</p>\n<p>注：如果36.110.16.242 这个IP地址访问本站, <code>white_ip</code> 这个变量值就是 1,否则就是0 </p>\n<p>通过<code>map模块</code> 对$white_ip进行映射</p>\n<p><strong>ngx_http_map_module</strong> 模块可以创建变量，这些变量的值与另外的变量值相关联（上文的$white_ip）。允许分类或者同时映射多个值到多个不同值并储存到一个变量中，map指令用来创建变量，但是仅在变量被接受的时候执行视图映射操作，对于处理没有引用变量的请求时，这个模块并没有性能上的缺失。 </p>\n<p>语法: map $var1 $var2 { … }</p>\n<p>上文map指令是将$white_ip值为0的，也就是受限制的IP，映射为客户端IP。将$white_ip值为1的，映射为空的字符串。<br><code>limit_conn_zone</code>和<code>limit_req_zone</code>指令对于键为空值的将会被忽略，从而实现对于列出来的IP不做限制。</p>\n<p><code>limit_req_zone</code> 真正操作限速<br><strong>ngx_http_limit_req_module</strong> 模块</p>\n<h1 id=\"下载限速\"><a href=\"#下载限速\" class=\"headerlink\" title=\"下载限速\"></a>下载限速</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">location /file &#123; </div><div class=\"line\">    limit_rate 128k;</div><div class=\"line\"># 限制下载速度128K/s </div><div class=\"line\">  &#125; </div><div class=\"line\"></div><div class=\"line\"># 如果想设置用户下载文件的前10m大小时不限速，大于10m后再以128kb/s限速可以增加以下配内容，修改nginx.conf文件</div><div class=\"line\"></div><div class=\"line\">location /download &#123; </div><div class=\"line\">       limit_rate_after 10m; </div><div class=\"line\">       limit_rate 128k; </div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n"},{"title":"rpm包制作","date":"2017-06-16T04:07:02.000Z","_content":"\n---------\n>今天突然收到老大发的这篇文章[分分钟拯救监控知识体系][1]，看到硬件监控的时候。突然想到我们是用的我们的硬件监控只是用了Dell的megacli工具监控了raid和磁盘的状态，连CPU温度主板温度这些基本指标好像都没有。因为我们用的open-falcon于是google下看到这篇[open-falconHWcheck][2] \n\n\n  [1]: http://mp.weixin.qq.com/s/TnhE_4afl0valv41V5ZFDA\n  [2]: https://github.com/51web/hwcheck\n  \n  [toc]\n  \n  ----------------\n  \n## 制作过程\n```\n git clone https://github.com/51web/hwcheck hwcheck-0.2\ntar czf hwcheck-0.2.tar.gz hwcheck-0.2\nrpmbuild -tb hwcheck-0.2.tar.gz\n  ```\n  具体可以使用 rpm --help 查看帮助\n\n## rpm包相关操作\n  \n### RPM包安装：\n```\nrpm -ivh example.rpm\n```\n  \n### 查看已经安装的RPM包\n```\nrpm -qa \nrpm -qa | grep tomcat4 查看 tomcat4 是否被安装；\n```\n\n### 验证RPM包\n> 这个可用作系统有问题的时候或者是有人恶意更改系统文件的时候\n\n```\n[root@md5 lib]# rpm -Vf /etc/*\nS.5....T.  c /etc/sysctl.conf\n.......T.  c /etc/bashrc\nS.5....T.  c /etc/hosts.allow\nS.5....T.  c /etc/hosts.deny\n```\n解释下上边的命令  \n其中，**S** 表示文件大小修改过，**T** 表示文件日期修改过。具体看man page\n","source":"_posts/rpm包制作.md","raw":"---\ntitle: rpm包制作\ndate: 2017-06-16 12:07:02\ntags: rpm \ncategories: 基础运维\n---\n\n---------\n>今天突然收到老大发的这篇文章[分分钟拯救监控知识体系][1]，看到硬件监控的时候。突然想到我们是用的我们的硬件监控只是用了Dell的megacli工具监控了raid和磁盘的状态，连CPU温度主板温度这些基本指标好像都没有。因为我们用的open-falcon于是google下看到这篇[open-falconHWcheck][2] \n\n\n  [1]: http://mp.weixin.qq.com/s/TnhE_4afl0valv41V5ZFDA\n  [2]: https://github.com/51web/hwcheck\n  \n  [toc]\n  \n  ----------------\n  \n## 制作过程\n```\n git clone https://github.com/51web/hwcheck hwcheck-0.2\ntar czf hwcheck-0.2.tar.gz hwcheck-0.2\nrpmbuild -tb hwcheck-0.2.tar.gz\n  ```\n  具体可以使用 rpm --help 查看帮助\n\n## rpm包相关操作\n  \n### RPM包安装：\n```\nrpm -ivh example.rpm\n```\n  \n### 查看已经安装的RPM包\n```\nrpm -qa \nrpm -qa | grep tomcat4 查看 tomcat4 是否被安装；\n```\n\n### 验证RPM包\n> 这个可用作系统有问题的时候或者是有人恶意更改系统文件的时候\n\n```\n[root@md5 lib]# rpm -Vf /etc/*\nS.5....T.  c /etc/sysctl.conf\n.......T.  c /etc/bashrc\nS.5....T.  c /etc/hosts.allow\nS.5....T.  c /etc/hosts.deny\n```\n解释下上边的命令  \n其中，**S** 表示文件大小修改过，**T** 表示文件日期修改过。具体看man page\n","slug":"rpm包制作","published":1,"updated":"2017-06-16T04:08:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbo002x8tzz2sq3d2eb","content":"<hr>\n<blockquote>\n<p>今天突然收到老大发的这篇文章<a href=\"http://mp.weixin.qq.com/s/TnhE_4afl0valv41V5ZFDA\" target=\"_blank\" rel=\"external\">分分钟拯救监控知识体系</a>，看到硬件监控的时候。突然想到我们是用的我们的硬件监控只是用了Dell的megacli工具监控了raid和磁盘的状态，连CPU温度主板温度这些基本指标好像都没有。因为我们用的open-falcon于是google下看到这篇<a href=\"https://github.com/51web/hwcheck\" target=\"_blank\" rel=\"external\">open-falconHWcheck</a> </p>\n</blockquote>\n<p>  [toc]</p>\n<hr>\n<h2 id=\"制作过程\"><a href=\"#制作过程\" class=\"headerlink\" title=\"制作过程\"></a>制作过程</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"> git clone https://github.com/51web/hwcheck hwcheck-0.2</div><div class=\"line\">tar czf hwcheck-0.2.tar.gz hwcheck-0.2</div><div class=\"line\">rpmbuild -tb hwcheck-0.2.tar.gz</div></pre></td></tr></table></figure>\n<p>  具体可以使用 rpm –help 查看帮助</p>\n<h2 id=\"rpm包相关操作\"><a href=\"#rpm包相关操作\" class=\"headerlink\" title=\"rpm包相关操作\"></a>rpm包相关操作</h2><h3 id=\"rpm包安装\"><a href=\"#RPM包安装：\" class=\"headerlink\" title=\"RPM包安装：\"></a>RPM包安装：</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rpm -ivh example.rpm</div></pre></td></tr></table></figure>\n<h3 id=\"查看已经安装的rpm包\"><a href=\"#查看已经安装的RPM包\" class=\"headerlink\" title=\"查看已经安装的RPM包\"></a>查看已经安装的RPM包</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">rpm -qa </div><div class=\"line\">rpm -qa | grep tomcat4 查看 tomcat4 是否被安装；</div></pre></td></tr></table></figure>\n<h3 id=\"验证rpm包\"><a href=\"#验证RPM包\" class=\"headerlink\" title=\"验证RPM包\"></a>验证RPM包</h3><blockquote>\n<p>这个可用作系统有问题的时候或者是有人恶意更改系统文件的时候</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@md5 lib]# rpm -Vf /etc/*</div><div class=\"line\">S.5....T.  c /etc/sysctl.conf</div><div class=\"line\">.......T.  c /etc/bashrc</div><div class=\"line\">S.5....T.  c /etc/hosts.allow</div><div class=\"line\">S.5....T.  c /etc/hosts.deny</div></pre></td></tr></table></figure>\n<p>解释下上边的命令<br>其中，<strong>S</strong> 表示文件大小修改过，<strong>T</strong> 表示文件日期修改过。具体看man page</p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<blockquote>\n<p>今天突然收到老大发的这篇文章<a href=\"http://mp.weixin.qq.com/s/TnhE_4afl0valv41V5ZFDA\" target=\"_blank\" rel=\"external\">分分钟拯救监控知识体系</a>，看到硬件监控的时候。突然想到我们是用的我们的硬件监控只是用了Dell的megacli工具监控了raid和磁盘的状态，连CPU温度主板温度这些基本指标好像都没有。因为我们用的open-falcon于是google下看到这篇<a href=\"https://github.com/51web/hwcheck\" target=\"_blank\" rel=\"external\">open-falconHWcheck</a> </p>\n</blockquote>\n<p>  [toc]</p>\n<hr>\n<h2 id=\"制作过程\"><a href=\"#制作过程\" class=\"headerlink\" title=\"制作过程\"></a>制作过程</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"> git clone https://github.com/51web/hwcheck hwcheck-0.2</div><div class=\"line\">tar czf hwcheck-0.2.tar.gz hwcheck-0.2</div><div class=\"line\">rpmbuild -tb hwcheck-0.2.tar.gz</div></pre></td></tr></table></figure>\n<p>  具体可以使用 rpm –help 查看帮助</p>\n<h2 id=\"rpm包相关操作\"><a href=\"#rpm包相关操作\" class=\"headerlink\" title=\"rpm包相关操作\"></a>rpm包相关操作</h2><h3 id=\"RPM包安装：\"><a href=\"#RPM包安装：\" class=\"headerlink\" title=\"RPM包安装：\"></a>RPM包安装：</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">rpm -ivh example.rpm</div></pre></td></tr></table></figure>\n<h3 id=\"查看已经安装的RPM包\"><a href=\"#查看已经安装的RPM包\" class=\"headerlink\" title=\"查看已经安装的RPM包\"></a>查看已经安装的RPM包</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">rpm -qa </div><div class=\"line\">rpm -qa | grep tomcat4 查看 tomcat4 是否被安装；</div></pre></td></tr></table></figure>\n<h3 id=\"验证RPM包\"><a href=\"#验证RPM包\" class=\"headerlink\" title=\"验证RPM包\"></a>验证RPM包</h3><blockquote>\n<p>这个可用作系统有问题的时候或者是有人恶意更改系统文件的时候</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@md5 lib]# rpm -Vf /etc/*</div><div class=\"line\">S.5....T.  c /etc/sysctl.conf</div><div class=\"line\">.......T.  c /etc/bashrc</div><div class=\"line\">S.5....T.  c /etc/hosts.allow</div><div class=\"line\">S.5....T.  c /etc/hosts.deny</div></pre></td></tr></table></figure>\n<p>解释下上边的命令<br>其中，<strong>S</strong> 表示文件大小修改过，<strong>T</strong> 表示文件日期修改过。具体看man page</p>\n"},{"title":"openvpn安装","date":"2017-06-25T01:58:40.000Z","_content":"\n> openvpn不多作介绍，直接上部署过程\n\n# 服务器环境\n* 机器名：host01\n* 操作系统：CentOS Linux release 7.0.1406 (Core)\n* 内网IP：10.******\n* 外网IP：12.******\n* 安装方式：yum\n* openvpn版本：OpenVPN 2.3.12 x86_64-redhat-linux-gnu\n\n# 安装步骤\n\n## 安装前操作\n \n`关闭selinux 配置防火墙`\n\n```    \n setenforce 0\n sed -i '/^SELINUX=/c\\SELINUX=disabled' /etc/selinux/config\n iptables -I INPUT -p udp --dport 1194 -m comment --comment \"openvpn\" -j ACCEPT\n iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE \n service iptables save\n                       \n```\n\n`开启路由转发功能`\n```\n sed -i '/net.ipv4.ip_forward/s/0/1/' /etc/sysctl.conf\n echo \"1\">/proc/sys/net/ipv4/ip_forward\n sysctl -p\n```\n`安装openssl，lzo`（用于压缩通讯数据，加快传输速度）\n``` \nyum install openssl openssl-delvel\nyum install lzo\n```\n\n## 安装步骤\n\n`安装配置openvpn和easy-rsa`\n\n```\nyum install openvpn easy-rsa\n```\n\n`修改vars文件`\n\n```\ncat /usr/share/easy-rsa/2.0/vars | grep -Ev \"^$|#\"\nexport EASY_RSA=\"`pwd`\"\nexport OPENSSL=\"openssl\"\nexport PKCS11TOOL=\"pkcs11-tool\"\nexport GREP=\"grep\"\nexport KEY_CONFIG=`$EASY_RSA/whichopensslcnf $EASY_RSA`\nexport KEY_DIR=\"$EASY_RSA/keys\"\necho NOTE: If you run ./clean-all, I will be doing a rm -rf on $KEY_DIR\nexport PKCS11_MODULE_PATH=\"dummy\"\nexport PKCS11_PIN=\"dummy\"\nexport KEY_SIZE=2048\nexport CA_EXPIRE=3650\nexport KEY_EXPIRE=3650\nexport KEY_COUNTRY=\"CN\"\nexport KEY_PROVINCE=\"CA\"\nexport KEY_CITY=\"Bei Jing\"\nexport KEY_ORG=\"Fort-Funston\"\nexport KEY_EMAIL=\"me@myhost.mydomain\"\nexport KEY_OU=\"MyOrganizationalUnit\"\nexport KEY_NAME=\"EasyRSA\"       \n\n**copy easy_rsa目录**\n\ncp -r /usr/share/easy-rsa/2.0/* /etc/openvpn/\n```\n\n\n初始化环境变量\n```\nsource vars\n```\n\n清除keys目录下所有与证书相关的文件\n\n```\n./clean-all\n```\n\n生成根证书ca.crt 根秘钥ca.key（一路回车）\n\n```\n./build-ca\n```\n\n为服务端生成证书秘钥（一路回车）\n\n```\n./build-key-server server\n```\n\n创建迪菲·赫尔曼密钥，会生成dh2048.pem文件（过程比较慢）\n\n```\n./build-dh\n```\n\n生成ta.key（防DOS攻击，等）\n\n```\nopenvpn --genkey --secret keys/ta.key\n```\n\n创建服务端配置文件\n\n```\n在openvpn目录下创建一个keys目录\nmkdir /etc/openvpn/keys\n```\n\n复制一份刚创建好的证书秘钥到新创建的keys\n\n```\ncp /usr/share/easy-rsa/2.0/keys/{ca.crt,server.{crt,key},dh2048.pem,ta.key} /etc/openvpn/keys/\n```\n\n复制一份配置文件模板到/etc/openvpn/\n\n```\ncp /usr/share/doc/openvpn-2.3.12/sample/sample-config-files/server.conf /etc/openvpn/\n```\n\n修改一下配置文件(这里使用的udp,会比tcp更快一下)\n```\n[root@vpn ~]# cat /etc/openvpn/server.conf | grep -Ev \"^#|;|^$\"\nport 1194\nproto udp\ndev tun\nca keys/ca.crt\ncert keys/server.crt\nkey keys/server.key  # This file should be kept secret\ndh keys/dh2048.pem\nserver 10.8.3.0 255.255.255.0\nifconfig-pool-persist ipp.txt\npush \"route 10.0.0.0 255.0.0.0\"\nkeepalive 10 120\ntls-auth keys/ta.key 0 # This file is secret\ncomp-lzo\npersist-key\npersist-tun\nstatus openvpn-status.log\nlog         openvpn.log\nverb 5\n```\n\n## openvpn启动 \nsystemctl -f enable openvpn@server.service\nsystemctl start openvpn@server.service\n\n## 添加|删除用户\n**添加用户脚本**(可以使用它自动添加用户)\n```\n#!/bin/bash\nvpnServer1=10.9.104.39\n#vpnServer2=10.12.1.28\n# a. 在vpnserver01中创建新vpn用户\nif [ -z $1 ]\nthen\n  echo \"Error:请在脚本后添加用户名作为参数，例如：'./01_addUser.sh zhangsan'\"\nelse\n  cp /etc/openvpn/keys/$1.crt ./ > /dev/null 2>&1\n  if [ -f $1.crt ]\n  then\n    echo \"$1 用户已存在，请检查！\"\n    rm -f *.crt\n  else\n\n    cd /etc/openvpn/ && pwd && source /etc/openvpn/vars && ./build-key --batch $1\n#    cd /etc/openvpn/ && pwd && source /usr/share/easy-rsa/2.0/vars && ./build-key --batch $1\n    # b. 新用户配置文件修改以及打包发送mail到用户\n    cd -\n    mkdir -p $1\ncat << EOF >> ./$1/$1.ovpn\nclient\ndev tun\nproto udp\nremote ****** 1194\nremote-random\nresolv-retry 10\nnobind\npersist-key\npersist-tun\nca ca.crt\ncert $1.crt\nkey $1.key\nremote-cert-tls server\ntls-auth ta.key 1\ncomp-lzo\nverb 3\nEOF\n\n    cp /etc/openvpn/keys/{ca.crt,$1.{crt,key},ta.key} ./$1/\n\n#    cp /etc/openvpn/keys/$1.{crt,key} /home/chunyu_sys/workspace/cy_ansible/roles/vpn_agent/files/\n    cp README.txt ./$1/;cp openVPN-clinet-config-for-Mac.pdf ./$1/\n    cp /etc/hosts ./$1/chunyu_hosts\n    tar czf $1.tar.gz $1/\n    rm -fr $1/\n#    python ./send_mail.py $1@chunyu.me \"[运维][vpn申请]openVPN configuration files\" $1.tar.gz\n#    mutt -s \"openVPN configuration files\" -a $1.tar.gz -- xiepengcheng@chunyu.me < $1.tar.gz\n    #rm -f $1.tar.gz\n    echo \"用户 $1 创建完毕\"\n  fi\nfi\n```\n\n**删除用户脚本**\n\n```\n#!/bin/bash\nvpnServer1=host01\n\nif [ -z $1 ]\nthen\n  echo \"Error:请在脚本后添加用户名作为参数，例如：'./02_delUser.sh zhangsan'\"\nelse\n  cp /etc/openvpn/keys/$1.crt ./\n  if [ -f $1.crt ]\n  then\n  cd /etc/openvpn && source vars && ./revoke-full $1\n  rm -rf /etc/openvpn/keys/$1.*\n  echo \"用户 $1 删除完毕\"\n  cd -\n  rm -f $1.crt\n  else\n    echo \"$1 此VPN用户不存在，请检查!\"\n  fi\nfi\n```\n\n\n## 使用TC进行限速 \n因为大家都不遵守规则，总是把vpn带宽占满，影响别的用户使用，所以必须加以限制\n\n```\ntc qdisc add dev tun0 root handle 1:0 htb default 10\n\ntc class add dev tun0 parent 1:0 classid 1:1 htb rate 10Mbit burst 15k\n\ntc class add dev tun0 parent 1:1 classid 1:10 htb rate 640kbit ceil 640kbit burst 15k\n\ntc qdisc add dev tun0 parent 1:10 handle 10: sfq perturb 10\n\ntc filter add dev tun0 protocol ip parent 1:0 prio 3 u32 match ip dst 10.0.0.6 flowid 1:10\n\n```\n\n上面规则可以控制10.0.0.6这个用户的下载带宽为:80KB/s,以此类推限制其它用户.如果会写shell,可以作一个程序,加到openvpn的拨入脚本中.\n\n\n\n上传是在eth0(假如外网卡是eth0)上做.\n\n总结：\n如果iptables关了，openvpn服务起了，客户端还是连不上，telnet 1194端口也不通，记得把云主机外网防火墙改一下。\n","source":"_posts/openvpn安装.md","raw":"---\ntitle: openvpn安装\ndate: 2017-06-25 09:58:40\ntags: openvpn\ncategories: 基础运维\n---\n\n> openvpn不多作介绍，直接上部署过程\n\n# 服务器环境\n* 机器名：host01\n* 操作系统：CentOS Linux release 7.0.1406 (Core)\n* 内网IP：10.******\n* 外网IP：12.******\n* 安装方式：yum\n* openvpn版本：OpenVPN 2.3.12 x86_64-redhat-linux-gnu\n\n# 安装步骤\n\n## 安装前操作\n \n`关闭selinux 配置防火墙`\n\n```    \n setenforce 0\n sed -i '/^SELINUX=/c\\SELINUX=disabled' /etc/selinux/config\n iptables -I INPUT -p udp --dport 1194 -m comment --comment \"openvpn\" -j ACCEPT\n iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE \n service iptables save\n                       \n```\n\n`开启路由转发功能`\n```\n sed -i '/net.ipv4.ip_forward/s/0/1/' /etc/sysctl.conf\n echo \"1\">/proc/sys/net/ipv4/ip_forward\n sysctl -p\n```\n`安装openssl，lzo`（用于压缩通讯数据，加快传输速度）\n``` \nyum install openssl openssl-delvel\nyum install lzo\n```\n\n## 安装步骤\n\n`安装配置openvpn和easy-rsa`\n\n```\nyum install openvpn easy-rsa\n```\n\n`修改vars文件`\n\n```\ncat /usr/share/easy-rsa/2.0/vars | grep -Ev \"^$|#\"\nexport EASY_RSA=\"`pwd`\"\nexport OPENSSL=\"openssl\"\nexport PKCS11TOOL=\"pkcs11-tool\"\nexport GREP=\"grep\"\nexport KEY_CONFIG=`$EASY_RSA/whichopensslcnf $EASY_RSA`\nexport KEY_DIR=\"$EASY_RSA/keys\"\necho NOTE: If you run ./clean-all, I will be doing a rm -rf on $KEY_DIR\nexport PKCS11_MODULE_PATH=\"dummy\"\nexport PKCS11_PIN=\"dummy\"\nexport KEY_SIZE=2048\nexport CA_EXPIRE=3650\nexport KEY_EXPIRE=3650\nexport KEY_COUNTRY=\"CN\"\nexport KEY_PROVINCE=\"CA\"\nexport KEY_CITY=\"Bei Jing\"\nexport KEY_ORG=\"Fort-Funston\"\nexport KEY_EMAIL=\"me@myhost.mydomain\"\nexport KEY_OU=\"MyOrganizationalUnit\"\nexport KEY_NAME=\"EasyRSA\"       \n\n**copy easy_rsa目录**\n\ncp -r /usr/share/easy-rsa/2.0/* /etc/openvpn/\n```\n\n\n初始化环境变量\n```\nsource vars\n```\n\n清除keys目录下所有与证书相关的文件\n\n```\n./clean-all\n```\n\n生成根证书ca.crt 根秘钥ca.key（一路回车）\n\n```\n./build-ca\n```\n\n为服务端生成证书秘钥（一路回车）\n\n```\n./build-key-server server\n```\n\n创建迪菲·赫尔曼密钥，会生成dh2048.pem文件（过程比较慢）\n\n```\n./build-dh\n```\n\n生成ta.key（防DOS攻击，等）\n\n```\nopenvpn --genkey --secret keys/ta.key\n```\n\n创建服务端配置文件\n\n```\n在openvpn目录下创建一个keys目录\nmkdir /etc/openvpn/keys\n```\n\n复制一份刚创建好的证书秘钥到新创建的keys\n\n```\ncp /usr/share/easy-rsa/2.0/keys/{ca.crt,server.{crt,key},dh2048.pem,ta.key} /etc/openvpn/keys/\n```\n\n复制一份配置文件模板到/etc/openvpn/\n\n```\ncp /usr/share/doc/openvpn-2.3.12/sample/sample-config-files/server.conf /etc/openvpn/\n```\n\n修改一下配置文件(这里使用的udp,会比tcp更快一下)\n```\n[root@vpn ~]# cat /etc/openvpn/server.conf | grep -Ev \"^#|;|^$\"\nport 1194\nproto udp\ndev tun\nca keys/ca.crt\ncert keys/server.crt\nkey keys/server.key  # This file should be kept secret\ndh keys/dh2048.pem\nserver 10.8.3.0 255.255.255.0\nifconfig-pool-persist ipp.txt\npush \"route 10.0.0.0 255.0.0.0\"\nkeepalive 10 120\ntls-auth keys/ta.key 0 # This file is secret\ncomp-lzo\npersist-key\npersist-tun\nstatus openvpn-status.log\nlog         openvpn.log\nverb 5\n```\n\n## openvpn启动 \nsystemctl -f enable openvpn@server.service\nsystemctl start openvpn@server.service\n\n## 添加|删除用户\n**添加用户脚本**(可以使用它自动添加用户)\n```\n#!/bin/bash\nvpnServer1=10.9.104.39\n#vpnServer2=10.12.1.28\n# a. 在vpnserver01中创建新vpn用户\nif [ -z $1 ]\nthen\n  echo \"Error:请在脚本后添加用户名作为参数，例如：'./01_addUser.sh zhangsan'\"\nelse\n  cp /etc/openvpn/keys/$1.crt ./ > /dev/null 2>&1\n  if [ -f $1.crt ]\n  then\n    echo \"$1 用户已存在，请检查！\"\n    rm -f *.crt\n  else\n\n    cd /etc/openvpn/ && pwd && source /etc/openvpn/vars && ./build-key --batch $1\n#    cd /etc/openvpn/ && pwd && source /usr/share/easy-rsa/2.0/vars && ./build-key --batch $1\n    # b. 新用户配置文件修改以及打包发送mail到用户\n    cd -\n    mkdir -p $1\ncat << EOF >> ./$1/$1.ovpn\nclient\ndev tun\nproto udp\nremote ****** 1194\nremote-random\nresolv-retry 10\nnobind\npersist-key\npersist-tun\nca ca.crt\ncert $1.crt\nkey $1.key\nremote-cert-tls server\ntls-auth ta.key 1\ncomp-lzo\nverb 3\nEOF\n\n    cp /etc/openvpn/keys/{ca.crt,$1.{crt,key},ta.key} ./$1/\n\n#    cp /etc/openvpn/keys/$1.{crt,key} /home/chunyu_sys/workspace/cy_ansible/roles/vpn_agent/files/\n    cp README.txt ./$1/;cp openVPN-clinet-config-for-Mac.pdf ./$1/\n    cp /etc/hosts ./$1/chunyu_hosts\n    tar czf $1.tar.gz $1/\n    rm -fr $1/\n#    python ./send_mail.py $1@chunyu.me \"[运维][vpn申请]openVPN configuration files\" $1.tar.gz\n#    mutt -s \"openVPN configuration files\" -a $1.tar.gz -- xiepengcheng@chunyu.me < $1.tar.gz\n    #rm -f $1.tar.gz\n    echo \"用户 $1 创建完毕\"\n  fi\nfi\n```\n\n**删除用户脚本**\n\n```\n#!/bin/bash\nvpnServer1=host01\n\nif [ -z $1 ]\nthen\n  echo \"Error:请在脚本后添加用户名作为参数，例如：'./02_delUser.sh zhangsan'\"\nelse\n  cp /etc/openvpn/keys/$1.crt ./\n  if [ -f $1.crt ]\n  then\n  cd /etc/openvpn && source vars && ./revoke-full $1\n  rm -rf /etc/openvpn/keys/$1.*\n  echo \"用户 $1 删除完毕\"\n  cd -\n  rm -f $1.crt\n  else\n    echo \"$1 此VPN用户不存在，请检查!\"\n  fi\nfi\n```\n\n\n## 使用TC进行限速 \n因为大家都不遵守规则，总是把vpn带宽占满，影响别的用户使用，所以必须加以限制\n\n```\ntc qdisc add dev tun0 root handle 1:0 htb default 10\n\ntc class add dev tun0 parent 1:0 classid 1:1 htb rate 10Mbit burst 15k\n\ntc class add dev tun0 parent 1:1 classid 1:10 htb rate 640kbit ceil 640kbit burst 15k\n\ntc qdisc add dev tun0 parent 1:10 handle 10: sfq perturb 10\n\ntc filter add dev tun0 protocol ip parent 1:0 prio 3 u32 match ip dst 10.0.0.6 flowid 1:10\n\n```\n\n上面规则可以控制10.0.0.6这个用户的下载带宽为:80KB/s,以此类推限制其它用户.如果会写shell,可以作一个程序,加到openvpn的拨入脚本中.\n\n\n\n上传是在eth0(假如外网卡是eth0)上做.\n\n总结：\n如果iptables关了，openvpn服务起了，客户端还是连不上，telnet 1194端口也不通，记得把云主机外网防火墙改一下。\n","slug":"openvpn安装","published":1,"updated":"2017-06-25T02:39:27.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbq00308tzzq9k1mgz6","content":"<blockquote>\n<p>openvpn不多作介绍，直接上部署过程</p>\n</blockquote>\n<h1 id=\"服务器环境\"><a href=\"#服务器环境\" class=\"headerlink\" title=\"服务器环境\"></a>服务器环境</h1><ul>\n<li>机器名：host01</li>\n<li>操作系统：CentOS Linux release 7.0.1406 (Core)</li>\n<li>内网IP：10.<strong>**</strong></li>\n<li>外网IP：12.<strong>**</strong></li>\n<li>安装方式：yum</li>\n<li>openvpn版本：OpenVPN 2.3.12 x86_64-redhat-linux-gnu</li>\n</ul>\n<h1 id=\"安装步骤\"><a href=\"#安装步骤\" class=\"headerlink\" title=\"安装步骤\"></a>安装步骤</h1><h2 id=\"安装前操作\"><a href=\"#安装前操作\" class=\"headerlink\" title=\"安装前操作\"></a>安装前操作</h2><p><code>关闭selinux 配置防火墙</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">setenforce 0</div><div class=\"line\">sed -i &apos;/^SELINUX=/c\\SELINUX=disabled&apos; /etc/selinux/config</div><div class=\"line\">iptables -I INPUT -p udp --dport 1194 -m comment --comment &quot;openvpn&quot; -j ACCEPT</div><div class=\"line\">iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE </div><div class=\"line\">service iptables save</div></pre></td></tr></table></figure>\n<p><code>开启路由转发功能</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sed -i &apos;/net.ipv4.ip_forward/s/0/1/&apos; /etc/sysctl.conf</div><div class=\"line\">echo &quot;1&quot;&gt;/proc/sys/net/ipv4/ip_forward</div><div class=\"line\">sysctl -p</div></pre></td></tr></table></figure></p>\n<p><code>安装openssl，lzo</code>（用于压缩通讯数据，加快传输速度）<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install openssl openssl-delvel</div><div class=\"line\">yum install lzo</div></pre></td></tr></table></figure></p>\n<h2 id=\"安装步骤\"><a href=\"#安装步骤-1\" class=\"headerlink\" title=\"安装步骤\"></a>安装步骤</h2><p><code>安装配置openvpn和easy-rsa</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install openvpn easy-rsa</div></pre></td></tr></table></figure>\n<p><code>修改vars文件</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat /usr/share/easy-rsa/2.0/vars | grep -Ev &quot;^$|#&quot;</div><div class=\"line\">export EASY_RSA=&quot;`pwd`&quot;</div><div class=\"line\">export OPENSSL=&quot;openssl&quot;</div><div class=\"line\">export PKCS11TOOL=&quot;pkcs11-tool&quot;</div><div class=\"line\">export GREP=&quot;grep&quot;</div><div class=\"line\">export KEY_CONFIG=`$EASY_RSA/whichopensslcnf $EASY_RSA`</div><div class=\"line\">export KEY_DIR=&quot;$EASY_RSA/keys&quot;</div><div class=\"line\">echo NOTE: If you run ./clean-all, I will be doing a rm -rf on $KEY_DIR</div><div class=\"line\">export PKCS11_MODULE_PATH=&quot;dummy&quot;</div><div class=\"line\">export PKCS11_PIN=&quot;dummy&quot;</div><div class=\"line\">export KEY_SIZE=2048</div><div class=\"line\">export CA_EXPIRE=3650</div><div class=\"line\">export KEY_EXPIRE=3650</div><div class=\"line\">export KEY_COUNTRY=&quot;CN&quot;</div><div class=\"line\">export KEY_PROVINCE=&quot;CA&quot;</div><div class=\"line\">export KEY_CITY=&quot;Bei Jing&quot;</div><div class=\"line\">export KEY_ORG=&quot;Fort-Funston&quot;</div><div class=\"line\">export KEY_EMAIL=&quot;me@myhost.mydomain&quot;</div><div class=\"line\">export KEY_OU=&quot;MyOrganizationalUnit&quot;</div><div class=\"line\">export KEY_NAME=&quot;EasyRSA&quot;       </div><div class=\"line\"></div><div class=\"line\">**copy easy_rsa目录**</div><div class=\"line\"></div><div class=\"line\">cp -r /usr/share/easy-rsa/2.0/* /etc/openvpn/</div></pre></td></tr></table></figure>\n<p>初始化环境变量<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">source vars</div></pre></td></tr></table></figure></p>\n<p>清除keys目录下所有与证书相关的文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./clean-all</div></pre></td></tr></table></figure>\n<p>生成根证书ca.crt 根秘钥ca.key（一路回车）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./build-ca</div></pre></td></tr></table></figure>\n<p>为服务端生成证书秘钥（一路回车）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./build-key-server server</div></pre></td></tr></table></figure>\n<p>创建迪菲·赫尔曼密钥，会生成dh2048.pem文件（过程比较慢）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./build-dh</div></pre></td></tr></table></figure>\n<p>生成ta.key（防DOS攻击，等）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">openvpn --genkey --secret keys/ta.key</div></pre></td></tr></table></figure>\n<p>创建服务端配置文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">在openvpn目录下创建一个keys目录</div><div class=\"line\">mkdir /etc/openvpn/keys</div></pre></td></tr></table></figure>\n<p>复制一份刚创建好的证书秘钥到新创建的keys</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp /usr/share/easy-rsa/2.0/keys/&#123;ca.crt,server.&#123;crt,key&#125;,dh2048.pem,ta.key&#125; /etc/openvpn/keys/</div></pre></td></tr></table></figure>\n<p>复制一份配置文件模板到/etc/openvpn/</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp /usr/share/doc/openvpn-2.3.12/sample/sample-config-files/server.conf /etc/openvpn/</div></pre></td></tr></table></figure>\n<p>修改一下配置文件(这里使用的udp,会比tcp更快一下)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@vpn ~]# cat /etc/openvpn/server.conf | grep -Ev &quot;^#|;|^$&quot;</div><div class=\"line\">port 1194</div><div class=\"line\">proto udp</div><div class=\"line\">dev tun</div><div class=\"line\">ca keys/ca.crt</div><div class=\"line\">cert keys/server.crt</div><div class=\"line\">key keys/server.key  # This file should be kept secret</div><div class=\"line\">dh keys/dh2048.pem</div><div class=\"line\">server 10.8.3.0 255.255.255.0</div><div class=\"line\">ifconfig-pool-persist ipp.txt</div><div class=\"line\">push &quot;route 10.0.0.0 255.0.0.0&quot;</div><div class=\"line\">keepalive 10 120</div><div class=\"line\">tls-auth keys/ta.key 0 # This file is secret</div><div class=\"line\">comp-lzo</div><div class=\"line\">persist-key</div><div class=\"line\">persist-tun</div><div class=\"line\">status openvpn-status.log</div><div class=\"line\">log         openvpn.log</div><div class=\"line\">verb 5</div></pre></td></tr></table></figure></p>\n<h2 id=\"openvpn启动\"><a href=\"#openvpn启动\" class=\"headerlink\" title=\"openvpn启动\"></a>openvpn启动</h2><p>systemctl -f enable openvpn@server.service<br>systemctl start openvpn@server.service</p>\n<h2 id=\"添加删除用户\"><a href=\"#添加-删除用户\" class=\"headerlink\" title=\"添加|删除用户\"></a>添加|删除用户</h2><p><strong>添加用户脚本</strong>(可以使用它自动添加用户)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/bash</div><div class=\"line\">vpnServer1=10.9.104.39</div><div class=\"line\">#vpnServer2=10.12.1.28</div><div class=\"line\"># a. 在vpnserver01中创建新vpn用户</div><div class=\"line\">if [ -z $1 ]</div><div class=\"line\">then</div><div class=\"line\">  echo &quot;Error:请在脚本后添加用户名作为参数，例如：&apos;./01_addUser.sh zhangsan&apos;&quot;</div><div class=\"line\">else</div><div class=\"line\">  cp /etc/openvpn/keys/$1.crt ./ &gt; /dev/null 2&gt;&amp;1</div><div class=\"line\">  if [ -f $1.crt ]</div><div class=\"line\">  then</div><div class=\"line\">    echo &quot;$1 用户已存在，请检查！&quot;</div><div class=\"line\">    rm -f *.crt</div><div class=\"line\">  else</div><div class=\"line\"></div><div class=\"line\">    cd /etc/openvpn/ &amp;&amp; pwd &amp;&amp; source /etc/openvpn/vars &amp;&amp; ./build-key --batch $1</div><div class=\"line\">#    cd /etc/openvpn/ &amp;&amp; pwd &amp;&amp; source /usr/share/easy-rsa/2.0/vars &amp;&amp; ./build-key --batch $1</div><div class=\"line\">    # b. 新用户配置文件修改以及打包发送mail到用户</div><div class=\"line\">    cd -</div><div class=\"line\">    mkdir -p $1</div><div class=\"line\">cat &lt;&lt; EOF &gt;&gt; ./$1/$1.ovpn</div><div class=\"line\">client</div><div class=\"line\">dev tun</div><div class=\"line\">proto udp</div><div class=\"line\">remote ****** 1194</div><div class=\"line\">remote-random</div><div class=\"line\">resolv-retry 10</div><div class=\"line\">nobind</div><div class=\"line\">persist-key</div><div class=\"line\">persist-tun</div><div class=\"line\">ca ca.crt</div><div class=\"line\">cert $1.crt</div><div class=\"line\">key $1.key</div><div class=\"line\">remote-cert-tls server</div><div class=\"line\">tls-auth ta.key 1</div><div class=\"line\">comp-lzo</div><div class=\"line\">verb 3</div><div class=\"line\">EOF</div><div class=\"line\"></div><div class=\"line\">    cp /etc/openvpn/keys/&#123;ca.crt,$1.&#123;crt,key&#125;,ta.key&#125; ./$1/</div><div class=\"line\"></div><div class=\"line\">#    cp /etc/openvpn/keys/$1.&#123;crt,key&#125; /home/chunyu_sys/workspace/cy_ansible/roles/vpn_agent/files/</div><div class=\"line\">    cp README.txt ./$1/;cp openVPN-clinet-config-for-Mac.pdf ./$1/</div><div class=\"line\">    cp /etc/hosts ./$1/chunyu_hosts</div><div class=\"line\">    tar czf $1.tar.gz $1/</div><div class=\"line\">    rm -fr $1/</div><div class=\"line\">#    python ./send_mail.py $1@chunyu.me &quot;[运维][vpn申请]openVPN configuration files&quot; $1.tar.gz</div><div class=\"line\">#    mutt -s &quot;openVPN configuration files&quot; -a $1.tar.gz -- xiepengcheng@chunyu.me &lt; $1.tar.gz</div><div class=\"line\">    #rm -f $1.tar.gz</div><div class=\"line\">    echo &quot;用户 $1 创建完毕&quot;</div><div class=\"line\">  fi</div><div class=\"line\">fi</div></pre></td></tr></table></figure></p>\n<p><strong>删除用户脚本</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/bash</div><div class=\"line\">vpnServer1=host01</div><div class=\"line\"></div><div class=\"line\">if [ -z $1 ]</div><div class=\"line\">then</div><div class=\"line\">  echo &quot;Error:请在脚本后添加用户名作为参数，例如：&apos;./02_delUser.sh zhangsan&apos;&quot;</div><div class=\"line\">else</div><div class=\"line\">  cp /etc/openvpn/keys/$1.crt ./</div><div class=\"line\">  if [ -f $1.crt ]</div><div class=\"line\">  then</div><div class=\"line\">  cd /etc/openvpn &amp;&amp; source vars &amp;&amp; ./revoke-full $1</div><div class=\"line\">  rm -rf /etc/openvpn/keys/$1.*</div><div class=\"line\">  echo &quot;用户 $1 删除完毕&quot;</div><div class=\"line\">  cd -</div><div class=\"line\">  rm -f $1.crt</div><div class=\"line\">  else</div><div class=\"line\">    echo &quot;$1 此VPN用户不存在，请检查!&quot;</div><div class=\"line\">  fi</div><div class=\"line\">fi</div></pre></td></tr></table></figure>\n<h2 id=\"使用tc进行限速\"><a href=\"#使用TC进行限速\" class=\"headerlink\" title=\"使用TC进行限速\"></a>使用TC进行限速</h2><p>因为大家都不遵守规则，总是把vpn带宽占满，影响别的用户使用，所以必须加以限制</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc qdisc add dev tun0 root handle 1:0 htb default 10</div><div class=\"line\"></div><div class=\"line\">tc class add dev tun0 parent 1:0 classid 1:1 htb rate 10Mbit burst 15k</div><div class=\"line\"></div><div class=\"line\">tc class add dev tun0 parent 1:1 classid 1:10 htb rate 640kbit ceil 640kbit burst 15k</div><div class=\"line\"></div><div class=\"line\">tc qdisc add dev tun0 parent 1:10 handle 10: sfq perturb 10</div><div class=\"line\"></div><div class=\"line\">tc filter add dev tun0 protocol ip parent 1:0 prio 3 u32 match ip dst 10.0.0.6 flowid 1:10</div></pre></td></tr></table></figure>\n<p>上面规则可以控制10.0.0.6这个用户的下载带宽为:80KB/s,以此类推限制其它用户.如果会写shell,可以作一个程序,加到openvpn的拨入脚本中.</p>\n<p>上传是在eth0(假如外网卡是eth0)上做.</p>\n<p>总结：<br>如果iptables关了，openvpn服务起了，客户端还是连不上，telnet 1194端口也不通，记得把云主机外网防火墙改一下。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>openvpn不多作介绍，直接上部署过程</p>\n</blockquote>\n<h1 id=\"服务器环境\"><a href=\"#服务器环境\" class=\"headerlink\" title=\"服务器环境\"></a>服务器环境</h1><ul>\n<li>机器名：host01</li>\n<li>操作系统：CentOS Linux release 7.0.1406 (Core)</li>\n<li>内网IP：10.<strong>**</strong></li>\n<li>外网IP：12.<strong>**</strong></li>\n<li>安装方式：yum</li>\n<li>openvpn版本：OpenVPN 2.3.12 x86_64-redhat-linux-gnu</li>\n</ul>\n<h1 id=\"安装步骤\"><a href=\"#安装步骤\" class=\"headerlink\" title=\"安装步骤\"></a>安装步骤</h1><h2 id=\"安装前操作\"><a href=\"#安装前操作\" class=\"headerlink\" title=\"安装前操作\"></a>安装前操作</h2><p><code>关闭selinux 配置防火墙</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">setenforce 0</div><div class=\"line\">sed -i &apos;/^SELINUX=/c\\SELINUX=disabled&apos; /etc/selinux/config</div><div class=\"line\">iptables -I INPUT -p udp --dport 1194 -m comment --comment &quot;openvpn&quot; -j ACCEPT</div><div class=\"line\">iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE </div><div class=\"line\">service iptables save</div></pre></td></tr></table></figure>\n<p><code>开启路由转发功能</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sed -i &apos;/net.ipv4.ip_forward/s/0/1/&apos; /etc/sysctl.conf</div><div class=\"line\">echo &quot;1&quot;&gt;/proc/sys/net/ipv4/ip_forward</div><div class=\"line\">sysctl -p</div></pre></td></tr></table></figure></p>\n<p><code>安装openssl，lzo</code>（用于压缩通讯数据，加快传输速度）<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install openssl openssl-delvel</div><div class=\"line\">yum install lzo</div></pre></td></tr></table></figure></p>\n<h2 id=\"安装步骤-1\"><a href=\"#安装步骤-1\" class=\"headerlink\" title=\"安装步骤\"></a>安装步骤</h2><p><code>安装配置openvpn和easy-rsa</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install openvpn easy-rsa</div></pre></td></tr></table></figure>\n<p><code>修改vars文件</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat /usr/share/easy-rsa/2.0/vars | grep -Ev &quot;^$|#&quot;</div><div class=\"line\">export EASY_RSA=&quot;`pwd`&quot;</div><div class=\"line\">export OPENSSL=&quot;openssl&quot;</div><div class=\"line\">export PKCS11TOOL=&quot;pkcs11-tool&quot;</div><div class=\"line\">export GREP=&quot;grep&quot;</div><div class=\"line\">export KEY_CONFIG=`$EASY_RSA/whichopensslcnf $EASY_RSA`</div><div class=\"line\">export KEY_DIR=&quot;$EASY_RSA/keys&quot;</div><div class=\"line\">echo NOTE: If you run ./clean-all, I will be doing a rm -rf on $KEY_DIR</div><div class=\"line\">export PKCS11_MODULE_PATH=&quot;dummy&quot;</div><div class=\"line\">export PKCS11_PIN=&quot;dummy&quot;</div><div class=\"line\">export KEY_SIZE=2048</div><div class=\"line\">export CA_EXPIRE=3650</div><div class=\"line\">export KEY_EXPIRE=3650</div><div class=\"line\">export KEY_COUNTRY=&quot;CN&quot;</div><div class=\"line\">export KEY_PROVINCE=&quot;CA&quot;</div><div class=\"line\">export KEY_CITY=&quot;Bei Jing&quot;</div><div class=\"line\">export KEY_ORG=&quot;Fort-Funston&quot;</div><div class=\"line\">export KEY_EMAIL=&quot;me@myhost.mydomain&quot;</div><div class=\"line\">export KEY_OU=&quot;MyOrganizationalUnit&quot;</div><div class=\"line\">export KEY_NAME=&quot;EasyRSA&quot;       </div><div class=\"line\"></div><div class=\"line\">**copy easy_rsa目录**</div><div class=\"line\"></div><div class=\"line\">cp -r /usr/share/easy-rsa/2.0/* /etc/openvpn/</div></pre></td></tr></table></figure>\n<p>初始化环境变量<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">source vars</div></pre></td></tr></table></figure></p>\n<p>清除keys目录下所有与证书相关的文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./clean-all</div></pre></td></tr></table></figure>\n<p>生成根证书ca.crt 根秘钥ca.key（一路回车）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./build-ca</div></pre></td></tr></table></figure>\n<p>为服务端生成证书秘钥（一路回车）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./build-key-server server</div></pre></td></tr></table></figure>\n<p>创建迪菲·赫尔曼密钥，会生成dh2048.pem文件（过程比较慢）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./build-dh</div></pre></td></tr></table></figure>\n<p>生成ta.key（防DOS攻击，等）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">openvpn --genkey --secret keys/ta.key</div></pre></td></tr></table></figure>\n<p>创建服务端配置文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">在openvpn目录下创建一个keys目录</div><div class=\"line\">mkdir /etc/openvpn/keys</div></pre></td></tr></table></figure>\n<p>复制一份刚创建好的证书秘钥到新创建的keys</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp /usr/share/easy-rsa/2.0/keys/&#123;ca.crt,server.&#123;crt,key&#125;,dh2048.pem,ta.key&#125; /etc/openvpn/keys/</div></pre></td></tr></table></figure>\n<p>复制一份配置文件模板到/etc/openvpn/</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp /usr/share/doc/openvpn-2.3.12/sample/sample-config-files/server.conf /etc/openvpn/</div></pre></td></tr></table></figure>\n<p>修改一下配置文件(这里使用的udp,会比tcp更快一下)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@vpn ~]# cat /etc/openvpn/server.conf | grep -Ev &quot;^#|;|^$&quot;</div><div class=\"line\">port 1194</div><div class=\"line\">proto udp</div><div class=\"line\">dev tun</div><div class=\"line\">ca keys/ca.crt</div><div class=\"line\">cert keys/server.crt</div><div class=\"line\">key keys/server.key  # This file should be kept secret</div><div class=\"line\">dh keys/dh2048.pem</div><div class=\"line\">server 10.8.3.0 255.255.255.0</div><div class=\"line\">ifconfig-pool-persist ipp.txt</div><div class=\"line\">push &quot;route 10.0.0.0 255.0.0.0&quot;</div><div class=\"line\">keepalive 10 120</div><div class=\"line\">tls-auth keys/ta.key 0 # This file is secret</div><div class=\"line\">comp-lzo</div><div class=\"line\">persist-key</div><div class=\"line\">persist-tun</div><div class=\"line\">status openvpn-status.log</div><div class=\"line\">log         openvpn.log</div><div class=\"line\">verb 5</div></pre></td></tr></table></figure></p>\n<h2 id=\"openvpn启动\"><a href=\"#openvpn启动\" class=\"headerlink\" title=\"openvpn启动\"></a>openvpn启动</h2><p>systemctl -f enable openvpn@server.service<br>systemctl start openvpn@server.service</p>\n<h2 id=\"添加-删除用户\"><a href=\"#添加-删除用户\" class=\"headerlink\" title=\"添加|删除用户\"></a>添加|删除用户</h2><p><strong>添加用户脚本</strong>(可以使用它自动添加用户)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/bash</div><div class=\"line\">vpnServer1=10.9.104.39</div><div class=\"line\">#vpnServer2=10.12.1.28</div><div class=\"line\"># a. 在vpnserver01中创建新vpn用户</div><div class=\"line\">if [ -z $1 ]</div><div class=\"line\">then</div><div class=\"line\">  echo &quot;Error:请在脚本后添加用户名作为参数，例如：&apos;./01_addUser.sh zhangsan&apos;&quot;</div><div class=\"line\">else</div><div class=\"line\">  cp /etc/openvpn/keys/$1.crt ./ &gt; /dev/null 2&gt;&amp;1</div><div class=\"line\">  if [ -f $1.crt ]</div><div class=\"line\">  then</div><div class=\"line\">    echo &quot;$1 用户已存在，请检查！&quot;</div><div class=\"line\">    rm -f *.crt</div><div class=\"line\">  else</div><div class=\"line\"></div><div class=\"line\">    cd /etc/openvpn/ &amp;&amp; pwd &amp;&amp; source /etc/openvpn/vars &amp;&amp; ./build-key --batch $1</div><div class=\"line\">#    cd /etc/openvpn/ &amp;&amp; pwd &amp;&amp; source /usr/share/easy-rsa/2.0/vars &amp;&amp; ./build-key --batch $1</div><div class=\"line\">    # b. 新用户配置文件修改以及打包发送mail到用户</div><div class=\"line\">    cd -</div><div class=\"line\">    mkdir -p $1</div><div class=\"line\">cat &lt;&lt; EOF &gt;&gt; ./$1/$1.ovpn</div><div class=\"line\">client</div><div class=\"line\">dev tun</div><div class=\"line\">proto udp</div><div class=\"line\">remote ****** 1194</div><div class=\"line\">remote-random</div><div class=\"line\">resolv-retry 10</div><div class=\"line\">nobind</div><div class=\"line\">persist-key</div><div class=\"line\">persist-tun</div><div class=\"line\">ca ca.crt</div><div class=\"line\">cert $1.crt</div><div class=\"line\">key $1.key</div><div class=\"line\">remote-cert-tls server</div><div class=\"line\">tls-auth ta.key 1</div><div class=\"line\">comp-lzo</div><div class=\"line\">verb 3</div><div class=\"line\">EOF</div><div class=\"line\"></div><div class=\"line\">    cp /etc/openvpn/keys/&#123;ca.crt,$1.&#123;crt,key&#125;,ta.key&#125; ./$1/</div><div class=\"line\"></div><div class=\"line\">#    cp /etc/openvpn/keys/$1.&#123;crt,key&#125; /home/chunyu_sys/workspace/cy_ansible/roles/vpn_agent/files/</div><div class=\"line\">    cp README.txt ./$1/;cp openVPN-clinet-config-for-Mac.pdf ./$1/</div><div class=\"line\">    cp /etc/hosts ./$1/chunyu_hosts</div><div class=\"line\">    tar czf $1.tar.gz $1/</div><div class=\"line\">    rm -fr $1/</div><div class=\"line\">#    python ./send_mail.py $1@chunyu.me &quot;[运维][vpn申请]openVPN configuration files&quot; $1.tar.gz</div><div class=\"line\">#    mutt -s &quot;openVPN configuration files&quot; -a $1.tar.gz -- xiepengcheng@chunyu.me &lt; $1.tar.gz</div><div class=\"line\">    #rm -f $1.tar.gz</div><div class=\"line\">    echo &quot;用户 $1 创建完毕&quot;</div><div class=\"line\">  fi</div><div class=\"line\">fi</div></pre></td></tr></table></figure></p>\n<p><strong>删除用户脚本</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/bash</div><div class=\"line\">vpnServer1=host01</div><div class=\"line\"></div><div class=\"line\">if [ -z $1 ]</div><div class=\"line\">then</div><div class=\"line\">  echo &quot;Error:请在脚本后添加用户名作为参数，例如：&apos;./02_delUser.sh zhangsan&apos;&quot;</div><div class=\"line\">else</div><div class=\"line\">  cp /etc/openvpn/keys/$1.crt ./</div><div class=\"line\">  if [ -f $1.crt ]</div><div class=\"line\">  then</div><div class=\"line\">  cd /etc/openvpn &amp;&amp; source vars &amp;&amp; ./revoke-full $1</div><div class=\"line\">  rm -rf /etc/openvpn/keys/$1.*</div><div class=\"line\">  echo &quot;用户 $1 删除完毕&quot;</div><div class=\"line\">  cd -</div><div class=\"line\">  rm -f $1.crt</div><div class=\"line\">  else</div><div class=\"line\">    echo &quot;$1 此VPN用户不存在，请检查!&quot;</div><div class=\"line\">  fi</div><div class=\"line\">fi</div></pre></td></tr></table></figure>\n<h2 id=\"使用TC进行限速\"><a href=\"#使用TC进行限速\" class=\"headerlink\" title=\"使用TC进行限速\"></a>使用TC进行限速</h2><p>因为大家都不遵守规则，总是把vpn带宽占满，影响别的用户使用，所以必须加以限制</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">tc qdisc add dev tun0 root handle 1:0 htb default 10</div><div class=\"line\"></div><div class=\"line\">tc class add dev tun0 parent 1:0 classid 1:1 htb rate 10Mbit burst 15k</div><div class=\"line\"></div><div class=\"line\">tc class add dev tun0 parent 1:1 classid 1:10 htb rate 640kbit ceil 640kbit burst 15k</div><div class=\"line\"></div><div class=\"line\">tc qdisc add dev tun0 parent 1:10 handle 10: sfq perturb 10</div><div class=\"line\"></div><div class=\"line\">tc filter add dev tun0 protocol ip parent 1:0 prio 3 u32 match ip dst 10.0.0.6 flowid 1:10</div></pre></td></tr></table></figure>\n<p>上面规则可以控制10.0.0.6这个用户的下载带宽为:80KB/s,以此类推限制其它用户.如果会写shell,可以作一个程序,加到openvpn的拨入脚本中.</p>\n<p>上传是在eth0(假如外网卡是eth0)上做.</p>\n<p>总结：<br>如果iptables关了，openvpn服务起了，客户端还是连不上，telnet 1194端口也不通，记得把云主机外网防火墙改一下。</p>\n"},{"title":"shell脚本检测硬盘","date":"2017-06-25T01:53:32.000Z","_content":"\n> 这个脚本是依赖dell提供的megacli工具写的，使用了一段时间，但是之后就使用了falcon的硬件监控工具，包括主板，风扇，硬盘，raid卡等比这个方便。\n\n```\n#!/bin/sh\nallhosts=\"host01 \"\n\nlog_dir=/home/chunyu_sys/disklog/\nlog_name=_raid_disk_monitor\nlogtime=$(date +%Y%m%d --date='1 days ago')\nfix=.log\n\nfor i in $allhosts;do\n\nhost=`ssh $i \"hostname\"`\necho  \"Checking RAID status on $host\" >> $log_dir$logtime$log_name$fix\necho -e \"\\033[31m $host \\033[0m\"\necho \"$host\" >>$log_dir$logtime$log_name$fix\nRAID_Contrller=`ssh $i 'megacli -AdpAllInfo -aALL |grep \"Product Name\" | cut -d: -f2'`\necho \"Controller : $RAID_Contrller\" >> $log_dir$logtime$log_name$fix\n\nOnline_disk_num=`ssh $i 'megacli  -PDList -aALL | grep Online | wc -l'`\n\necho \"Totall number of Physical disks online : $Online_disk_num\" >> $log_dir$logtime$log_name$fix\nDegrade_disk=`ssh $i 'megacli -AdpAllInfo -a0 |grep \"Degrade\"'`\necho  \"$Degrade_disk\"  >>$log_dir$logtime$log_name$fix\nFailed_disk=`ssh $i 'megacli -AdpAllInfo -a0 |grep \"Failed Disks\"'`\necho \"$Failed_disk \" >>$log_dir$logtime$log_name$fix\n\n#Failed_disk_num=`ssh $i 'echo $Failed_disk |cut -d \" \" -f4'`\ndone\n```\n","source":"_posts/shell脚本检测硬盘.md","raw":"---\ntitle: shell脚本检测硬盘\ndate: 2017-06-25 09:53:32\ntags: shell, 脚本\ncategories: shell\n---\n\n> 这个脚本是依赖dell提供的megacli工具写的，使用了一段时间，但是之后就使用了falcon的硬件监控工具，包括主板，风扇，硬盘，raid卡等比这个方便。\n\n```\n#!/bin/sh\nallhosts=\"host01 \"\n\nlog_dir=/home/chunyu_sys/disklog/\nlog_name=_raid_disk_monitor\nlogtime=$(date +%Y%m%d --date='1 days ago')\nfix=.log\n\nfor i in $allhosts;do\n\nhost=`ssh $i \"hostname\"`\necho  \"Checking RAID status on $host\" >> $log_dir$logtime$log_name$fix\necho -e \"\\033[31m $host \\033[0m\"\necho \"$host\" >>$log_dir$logtime$log_name$fix\nRAID_Contrller=`ssh $i 'megacli -AdpAllInfo -aALL |grep \"Product Name\" | cut -d: -f2'`\necho \"Controller : $RAID_Contrller\" >> $log_dir$logtime$log_name$fix\n\nOnline_disk_num=`ssh $i 'megacli  -PDList -aALL | grep Online | wc -l'`\n\necho \"Totall number of Physical disks online : $Online_disk_num\" >> $log_dir$logtime$log_name$fix\nDegrade_disk=`ssh $i 'megacli -AdpAllInfo -a0 |grep \"Degrade\"'`\necho  \"$Degrade_disk\"  >>$log_dir$logtime$log_name$fix\nFailed_disk=`ssh $i 'megacli -AdpAllInfo -a0 |grep \"Failed Disks\"'`\necho \"$Failed_disk \" >>$log_dir$logtime$log_name$fix\n\n#Failed_disk_num=`ssh $i 'echo $Failed_disk |cut -d \" \" -f4'`\ndone\n```\n","slug":"shell脚本检测硬盘","published":1,"updated":"2017-06-25T01:57:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbt00348tzz9in1tbzy","content":"<blockquote>\n<p>这个脚本是依赖dell提供的megacli工具写的，使用了一段时间，但是之后就使用了falcon的硬件监控工具，包括主板，风扇，硬盘，raid卡等比这个方便。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/sh</div><div class=\"line\">allhosts=&quot;host01 &quot;</div><div class=\"line\"></div><div class=\"line\">log_dir=/home/chunyu_sys/disklog/</div><div class=\"line\">log_name=_raid_disk_monitor</div><div class=\"line\">logtime=$(date +%Y%m%d --date=&apos;1 days ago&apos;)</div><div class=\"line\">fix=.log</div><div class=\"line\"></div><div class=\"line\">for i in $allhosts;do</div><div class=\"line\"></div><div class=\"line\">host=`ssh $i &quot;hostname&quot;`</div><div class=\"line\">echo  &quot;Checking RAID status on $host&quot; &gt;&gt; $log_dir$logtime$log_name$fix</div><div class=\"line\">echo -e &quot;\\033[31m $host \\033[0m&quot;</div><div class=\"line\">echo &quot;$host&quot; &gt;&gt;$log_dir$logtime$log_name$fix</div><div class=\"line\">RAID_Contrller=`ssh $i &apos;megacli -AdpAllInfo -aALL |grep &quot;Product Name&quot; | cut -d: -f2&apos;`</div><div class=\"line\">echo &quot;Controller : $RAID_Contrller&quot; &gt;&gt; $log_dir$logtime$log_name$fix</div><div class=\"line\"></div><div class=\"line\">Online_disk_num=`ssh $i &apos;megacli  -PDList -aALL | grep Online | wc -l&apos;`</div><div class=\"line\"></div><div class=\"line\">echo &quot;Totall number of Physical disks online : $Online_disk_num&quot; &gt;&gt; $log_dir$logtime$log_name$fix</div><div class=\"line\">Degrade_disk=`ssh $i &apos;megacli -AdpAllInfo -a0 |grep &quot;Degrade&quot;&apos;`</div><div class=\"line\">echo  &quot;$Degrade_disk&quot;  &gt;&gt;$log_dir$logtime$log_name$fix</div><div class=\"line\">Failed_disk=`ssh $i &apos;megacli -AdpAllInfo -a0 |grep &quot;Failed Disks&quot;&apos;`</div><div class=\"line\">echo &quot;$Failed_disk &quot; &gt;&gt;$log_dir$logtime$log_name$fix</div><div class=\"line\"></div><div class=\"line\">#Failed_disk_num=`ssh $i &apos;echo $Failed_disk |cut -d &quot; &quot; -f4&apos;`</div><div class=\"line\">done</div></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>这个脚本是依赖dell提供的megacli工具写的，使用了一段时间，但是之后就使用了falcon的硬件监控工具，包括主板，风扇，硬盘，raid卡等比这个方便。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/bin/sh</div><div class=\"line\">allhosts=&quot;host01 &quot;</div><div class=\"line\"></div><div class=\"line\">log_dir=/home/chunyu_sys/disklog/</div><div class=\"line\">log_name=_raid_disk_monitor</div><div class=\"line\">logtime=$(date +%Y%m%d --date=&apos;1 days ago&apos;)</div><div class=\"line\">fix=.log</div><div class=\"line\"></div><div class=\"line\">for i in $allhosts;do</div><div class=\"line\"></div><div class=\"line\">host=`ssh $i &quot;hostname&quot;`</div><div class=\"line\">echo  &quot;Checking RAID status on $host&quot; &gt;&gt; $log_dir$logtime$log_name$fix</div><div class=\"line\">echo -e &quot;\\033[31m $host \\033[0m&quot;</div><div class=\"line\">echo &quot;$host&quot; &gt;&gt;$log_dir$logtime$log_name$fix</div><div class=\"line\">RAID_Contrller=`ssh $i &apos;megacli -AdpAllInfo -aALL |grep &quot;Product Name&quot; | cut -d: -f2&apos;`</div><div class=\"line\">echo &quot;Controller : $RAID_Contrller&quot; &gt;&gt; $log_dir$logtime$log_name$fix</div><div class=\"line\"></div><div class=\"line\">Online_disk_num=`ssh $i &apos;megacli  -PDList -aALL | grep Online | wc -l&apos;`</div><div class=\"line\"></div><div class=\"line\">echo &quot;Totall number of Physical disks online : $Online_disk_num&quot; &gt;&gt; $log_dir$logtime$log_name$fix</div><div class=\"line\">Degrade_disk=`ssh $i &apos;megacli -AdpAllInfo -a0 |grep &quot;Degrade&quot;&apos;`</div><div class=\"line\">echo  &quot;$Degrade_disk&quot;  &gt;&gt;$log_dir$logtime$log_name$fix</div><div class=\"line\">Failed_disk=`ssh $i &apos;megacli -AdpAllInfo -a0 |grep &quot;Failed Disks&quot;&apos;`</div><div class=\"line\">echo &quot;$Failed_disk &quot; &gt;&gt;$log_dir$logtime$log_name$fix</div><div class=\"line\"></div><div class=\"line\">#Failed_disk_num=`ssh $i &apos;echo $Failed_disk |cut -d &quot; &quot; -f4&apos;`</div><div class=\"line\">done</div></pre></td></tr></table></figure>\n"},{"title":"shell脚本自动安装zabbix_agent","date":"2017-06-25T01:43:10.000Z","_content":"> 现在公司都用ansible替换zabbix了，之前写的安装zabbix_agent脚本，在这儿记录一下，以备不时之需。\n\n`zabbix_agent_install.sh`\n```\n#!/usr/bin/bash\n#allhosts=\"mysql1 mysql2 mysql3\"\n#可以执行远端命令\nfor host in $allhosts\ndo\n\necho $host\nssh root@$host \"mkdir -p /usr/local/zabbix/etc/\"\nssh root@$host \"mkdir -p /root/soft/\"\nssh root@$host \"mkdir -p /var/log/zabbix/\"\n\nsed -i \"s/unknown/$host/g\" ./zabbix_agentd.conf\n\ncat ./zabbix_agentd.conf\n\n\nscp ./zabbix_agentd.conf root@$host:/usr/local/zabbix/etc/\n\nsed -i \"s/$host/unknown/g\" ./zabbix_agentd.conf\n\n\nscp ./zabbix-2.4.2.tar.gz root@$host:/root/soft/\nscp ./install_zabbix_agent_impl.sh root@$host:/root/soft/\nssh root@$host \"bash /root/soft/install_zabbix_agent_impl.sh\"\n\n\ndone\n```\n\n`zabbix_agent_install_impl.sh`\n```\n#!/usr/bin/bash\n\ncd /root/soft\ntar zxvf ./zabbix-2.4.2.tar.gz\ncd /root/soft/zabbix-2.4.2\n./configure --prefix=/usr/local/zabbix --enable-agent\nmake;make install\ngroupadd zabbix\nuseradd -g zabbix -s /sbin/nologin zabbix\nchown zabbix:zabbix /var/log/zabbix\nchown zabbix:zabbix /var/log/zabbix\n/usr/local/zabbix/sbin/zabbix_agentd -c /usr/local/zabbix/etc/zabbix_agentd.conf\necho \"/usr/local/zabbix/sbin/zabbix_agentd -c /usr/local/zabbix/etc/zabbix_agentd.conf\" >>/etc/rc.local\n```\n\n`zabbix_agent.conf`\n\n```\nPidFile=/var/log/zabbix/zabbix_agentd.pid\nLogFile=/var/log/zabbix/zabbix_agentd.log\n#server 为zabbix_server地址\nServer=192.168.0.1\nListenPort=10050\nServerActive=192.168.0.1\nHostname=unknown\n#HostnameItem=system.hostname\nRefreshActiveChecks=60\nBufferSize=1024\nUnsafeUserParameters=1\nInclude=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf\nTimeout=20\nAllowRoot=1\n```\n\n记得把安装包也放在脚本目录下\n","source":"_posts/shell脚本自动安装zabbix-agent.md","raw":"---\ntitle: shell脚本自动安装zabbix_agent\ndate: 2017-06-25 09:43:10\ntags: shell, 脚本\ncategories: shell\n---\n> 现在公司都用ansible替换zabbix了，之前写的安装zabbix_agent脚本，在这儿记录一下，以备不时之需。\n\n`zabbix_agent_install.sh`\n```\n#!/usr/bin/bash\n#allhosts=\"mysql1 mysql2 mysql3\"\n#可以执行远端命令\nfor host in $allhosts\ndo\n\necho $host\nssh root@$host \"mkdir -p /usr/local/zabbix/etc/\"\nssh root@$host \"mkdir -p /root/soft/\"\nssh root@$host \"mkdir -p /var/log/zabbix/\"\n\nsed -i \"s/unknown/$host/g\" ./zabbix_agentd.conf\n\ncat ./zabbix_agentd.conf\n\n\nscp ./zabbix_agentd.conf root@$host:/usr/local/zabbix/etc/\n\nsed -i \"s/$host/unknown/g\" ./zabbix_agentd.conf\n\n\nscp ./zabbix-2.4.2.tar.gz root@$host:/root/soft/\nscp ./install_zabbix_agent_impl.sh root@$host:/root/soft/\nssh root@$host \"bash /root/soft/install_zabbix_agent_impl.sh\"\n\n\ndone\n```\n\n`zabbix_agent_install_impl.sh`\n```\n#!/usr/bin/bash\n\ncd /root/soft\ntar zxvf ./zabbix-2.4.2.tar.gz\ncd /root/soft/zabbix-2.4.2\n./configure --prefix=/usr/local/zabbix --enable-agent\nmake;make install\ngroupadd zabbix\nuseradd -g zabbix -s /sbin/nologin zabbix\nchown zabbix:zabbix /var/log/zabbix\nchown zabbix:zabbix /var/log/zabbix\n/usr/local/zabbix/sbin/zabbix_agentd -c /usr/local/zabbix/etc/zabbix_agentd.conf\necho \"/usr/local/zabbix/sbin/zabbix_agentd -c /usr/local/zabbix/etc/zabbix_agentd.conf\" >>/etc/rc.local\n```\n\n`zabbix_agent.conf`\n\n```\nPidFile=/var/log/zabbix/zabbix_agentd.pid\nLogFile=/var/log/zabbix/zabbix_agentd.log\n#server 为zabbix_server地址\nServer=192.168.0.1\nListenPort=10050\nServerActive=192.168.0.1\nHostname=unknown\n#HostnameItem=system.hostname\nRefreshActiveChecks=60\nBufferSize=1024\nUnsafeUserParameters=1\nInclude=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf\nTimeout=20\nAllowRoot=1\n```\n\n记得把安装包也放在脚本目录下\n","slug":"shell脚本自动安装zabbix-agent","published":1,"updated":"2017-06-25T01:52:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbx00378tzz382ls6cw","content":"<blockquote>\n<p>现在公司都用ansible替换zabbix了，之前写的安装zabbix_agent脚本，在这儿记录一下，以备不时之需。</p>\n</blockquote>\n<p><code>zabbix_agent_install.sh</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/bash</div><div class=\"line\">#allhosts=&quot;mysql1 mysql2 mysql3&quot;</div><div class=\"line\">#可以执行远端命令</div><div class=\"line\">for host in $allhosts</div><div class=\"line\">do</div><div class=\"line\"></div><div class=\"line\">echo $host</div><div class=\"line\">ssh root@$host &quot;mkdir -p /usr/local/zabbix/etc/&quot;</div><div class=\"line\">ssh root@$host &quot;mkdir -p /root/soft/&quot;</div><div class=\"line\">ssh root@$host &quot;mkdir -p /var/log/zabbix/&quot;</div><div class=\"line\"></div><div class=\"line\">sed -i &quot;s/unknown/$host/g&quot; ./zabbix_agentd.conf</div><div class=\"line\"></div><div class=\"line\">cat ./zabbix_agentd.conf</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">scp ./zabbix_agentd.conf root@$host:/usr/local/zabbix/etc/</div><div class=\"line\"></div><div class=\"line\">sed -i &quot;s/$host/unknown/g&quot; ./zabbix_agentd.conf</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">scp ./zabbix-2.4.2.tar.gz root@$host:/root/soft/</div><div class=\"line\">scp ./install_zabbix_agent_impl.sh root@$host:/root/soft/</div><div class=\"line\">ssh root@$host &quot;bash /root/soft/install_zabbix_agent_impl.sh&quot;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">done</div></pre></td></tr></table></figure></p>\n<p><code>zabbix_agent_install_impl.sh</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/bash</div><div class=\"line\"></div><div class=\"line\">cd /root/soft</div><div class=\"line\">tar zxvf ./zabbix-2.4.2.tar.gz</div><div class=\"line\">cd /root/soft/zabbix-2.4.2</div><div class=\"line\">./configure --prefix=/usr/local/zabbix --enable-agent</div><div class=\"line\">make;make install</div><div class=\"line\">groupadd zabbix</div><div class=\"line\">useradd -g zabbix -s /sbin/nologin zabbix</div><div class=\"line\">chown zabbix:zabbix /var/log/zabbix</div><div class=\"line\">chown zabbix:zabbix /var/log/zabbix</div><div class=\"line\">/usr/local/zabbix/sbin/zabbix_agentd -c /usr/local/zabbix/etc/zabbix_agentd.conf</div><div class=\"line\">echo &quot;/usr/local/zabbix/sbin/zabbix_agentd -c /usr/local/zabbix/etc/zabbix_agentd.conf&quot; &gt;&gt;/etc/rc.local</div></pre></td></tr></table></figure></p>\n<p><code>zabbix_agent.conf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">PidFile=/var/log/zabbix/zabbix_agentd.pid</div><div class=\"line\">LogFile=/var/log/zabbix/zabbix_agentd.log</div><div class=\"line\">#server 为zabbix_server地址</div><div class=\"line\">Server=192.168.0.1</div><div class=\"line\">ListenPort=10050</div><div class=\"line\">ServerActive=192.168.0.1</div><div class=\"line\">Hostname=unknown</div><div class=\"line\">#HostnameItem=system.hostname</div><div class=\"line\">RefreshActiveChecks=60</div><div class=\"line\">BufferSize=1024</div><div class=\"line\">UnsafeUserParameters=1</div><div class=\"line\">Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf</div><div class=\"line\">Timeout=20</div><div class=\"line\">AllowRoot=1</div></pre></td></tr></table></figure>\n<p>记得把安装包也放在脚本目录下</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>现在公司都用ansible替换zabbix了，之前写的安装zabbix_agent脚本，在这儿记录一下，以备不时之需。</p>\n</blockquote>\n<p><code>zabbix_agent_install.sh</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/bash</div><div class=\"line\">#allhosts=&quot;mysql1 mysql2 mysql3&quot;</div><div class=\"line\">#可以执行远端命令</div><div class=\"line\">for host in $allhosts</div><div class=\"line\">do</div><div class=\"line\"></div><div class=\"line\">echo $host</div><div class=\"line\">ssh root@$host &quot;mkdir -p /usr/local/zabbix/etc/&quot;</div><div class=\"line\">ssh root@$host &quot;mkdir -p /root/soft/&quot;</div><div class=\"line\">ssh root@$host &quot;mkdir -p /var/log/zabbix/&quot;</div><div class=\"line\"></div><div class=\"line\">sed -i &quot;s/unknown/$host/g&quot; ./zabbix_agentd.conf</div><div class=\"line\"></div><div class=\"line\">cat ./zabbix_agentd.conf</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">scp ./zabbix_agentd.conf root@$host:/usr/local/zabbix/etc/</div><div class=\"line\"></div><div class=\"line\">sed -i &quot;s/$host/unknown/g&quot; ./zabbix_agentd.conf</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">scp ./zabbix-2.4.2.tar.gz root@$host:/root/soft/</div><div class=\"line\">scp ./install_zabbix_agent_impl.sh root@$host:/root/soft/</div><div class=\"line\">ssh root@$host &quot;bash /root/soft/install_zabbix_agent_impl.sh&quot;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">done</div></pre></td></tr></table></figure></p>\n<p><code>zabbix_agent_install_impl.sh</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/bash</div><div class=\"line\"></div><div class=\"line\">cd /root/soft</div><div class=\"line\">tar zxvf ./zabbix-2.4.2.tar.gz</div><div class=\"line\">cd /root/soft/zabbix-2.4.2</div><div class=\"line\">./configure --prefix=/usr/local/zabbix --enable-agent</div><div class=\"line\">make;make install</div><div class=\"line\">groupadd zabbix</div><div class=\"line\">useradd -g zabbix -s /sbin/nologin zabbix</div><div class=\"line\">chown zabbix:zabbix /var/log/zabbix</div><div class=\"line\">chown zabbix:zabbix /var/log/zabbix</div><div class=\"line\">/usr/local/zabbix/sbin/zabbix_agentd -c /usr/local/zabbix/etc/zabbix_agentd.conf</div><div class=\"line\">echo &quot;/usr/local/zabbix/sbin/zabbix_agentd -c /usr/local/zabbix/etc/zabbix_agentd.conf&quot; &gt;&gt;/etc/rc.local</div></pre></td></tr></table></figure></p>\n<p><code>zabbix_agent.conf</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">PidFile=/var/log/zabbix/zabbix_agentd.pid</div><div class=\"line\">LogFile=/var/log/zabbix/zabbix_agentd.log</div><div class=\"line\">#server 为zabbix_server地址</div><div class=\"line\">Server=192.168.0.1</div><div class=\"line\">ListenPort=10050</div><div class=\"line\">ServerActive=192.168.0.1</div><div class=\"line\">Hostname=unknown</div><div class=\"line\">#HostnameItem=system.hostname</div><div class=\"line\">RefreshActiveChecks=60</div><div class=\"line\">BufferSize=1024</div><div class=\"line\">UnsafeUserParameters=1</div><div class=\"line\">Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf</div><div class=\"line\">Timeout=20</div><div class=\"line\">AllowRoot=1</div></pre></td></tr></table></figure>\n<p>记得把安装包也放在脚本目录下</p>\n"},{"title":"shell命令之xargs与exec","date":"2017-06-23T03:18:55.000Z","_content":"\n## exec \n看起来就是执行某动作的命令\n格式为 -exec echo {} \\; \n其中 `echo` 为动作, `{}` 为参数(即为之前找到的文件) `\\` 转义 `;` 是结束符\n\n示例\n```\nfind ./ -name \\*.yml -exec echo {} \\;\n./logrotate_conf.yml\n./filebeat.yml\n./group_vars/all.yml\n./group_vars/ehr.yml\n./group_vars/http_proxy.yml\n./group_vars/medweb.yml\n```\n\n\n## xargs \nxargs依赖管道,下边直接写了几个个实例\n\n`基本使用`\n\n把多行文件合并成一行 或者每行指定元素个数(-n 参数) 格式输出\n\n```\n[root@md6 ~]# cat test.txt\na b c d e f\n g h i j k l\n m n o p q r s\nt u v w x y z\n\n[root@md6 ~]# cat test.txt | xargs echo\na b c d e f g h i j k l m n o p q r s t u v w x y z\n[root@md6 ~]# cat test.txt | xargs echo > test1.txt\n[root@md6 ~]# cat test1.txt\na b c d e f g h i j k l m n o p q r s t u v w x y z\n\n[root@md6 ~]# cat test.txt | xargs -n 4\na b c d\ne f g h\ni j k l\nm n o p\nq r s t\nu v w x\ny z\n[root@md6 ~]# cat test.txt | xargs -n 3\na b c\nd e f\ng h i\nj k l\nm n o\np q r\ns t u\nv w x\ny z\n```\n\n- 实例1 直接打印\n```\nfind ./ -name \\*.yml | xargs echo\n./logrotate_conf.yml ./filebeat.yml ./group_vars/all.yml ./group_vars/ehr.yml ./group_vars/http_proxy.yml ./group_vars/medweb.yml\n```\n\n- 实例2 查找文件内容中带hostname的\n```\nfind . -type f -print | xargs grep -n \"hostname\" (-n输出行号)\n```\n\n- 实例3 mv 或者 cp 使用-i参数 -p 打印过程(交互确认)\n```\nls  *.txt | xargs -n1 -i -p cp {} /var/tmp/\n```\n\n- 实例4 查找当下文件按大小排序\n```\nfind . -maxdepth 1 ! -name \".\" -print0 | xargs -0 du -b | sort -nr | head -10 | nl\n```\n\n- 实例5 结合sed替换\n```\nfind . -name \"*.txt\" -print0 | xargs -0 sed -i 's/aaa/bbb/g'\n```\n\n\n## 总结\n\n首先使用方式不一样，exec操作麻烦些 xargs更简单直接方法多样\n另外从输出结果看得出  exec是遇到一个找到的文件就执行一次命令，xargs是把结果放到一起，执行一次。(这样可以使用在 把多行文件合并成一行的特定场景中)\n需要强调xargs遇到文件名中有空格的行为是处理不了的。\n这种情况可以这样\n\n```\nfind . -name \\*.txt -print0 | xargs -0 rm \n```\n其中find找到每个文件定义以null字符结尾  xargs找文件定义null分割文件 就可以了 \n\n\n\n\n","source":"_posts/shell命令之xargs与exec.md","raw":"---\ntitle: shell命令之xargs与exec\ndate: 2017-06-23 11:18:55\ntags: shell\ncategories: 基础运维\n---\n\n## exec \n看起来就是执行某动作的命令\n格式为 -exec echo {} \\; \n其中 `echo` 为动作, `{}` 为参数(即为之前找到的文件) `\\` 转义 `;` 是结束符\n\n示例\n```\nfind ./ -name \\*.yml -exec echo {} \\;\n./logrotate_conf.yml\n./filebeat.yml\n./group_vars/all.yml\n./group_vars/ehr.yml\n./group_vars/http_proxy.yml\n./group_vars/medweb.yml\n```\n\n\n## xargs \nxargs依赖管道,下边直接写了几个个实例\n\n`基本使用`\n\n把多行文件合并成一行 或者每行指定元素个数(-n 参数) 格式输出\n\n```\n[root@md6 ~]# cat test.txt\na b c d e f\n g h i j k l\n m n o p q r s\nt u v w x y z\n\n[root@md6 ~]# cat test.txt | xargs echo\na b c d e f g h i j k l m n o p q r s t u v w x y z\n[root@md6 ~]# cat test.txt | xargs echo > test1.txt\n[root@md6 ~]# cat test1.txt\na b c d e f g h i j k l m n o p q r s t u v w x y z\n\n[root@md6 ~]# cat test.txt | xargs -n 4\na b c d\ne f g h\ni j k l\nm n o p\nq r s t\nu v w x\ny z\n[root@md6 ~]# cat test.txt | xargs -n 3\na b c\nd e f\ng h i\nj k l\nm n o\np q r\ns t u\nv w x\ny z\n```\n\n- 实例1 直接打印\n```\nfind ./ -name \\*.yml | xargs echo\n./logrotate_conf.yml ./filebeat.yml ./group_vars/all.yml ./group_vars/ehr.yml ./group_vars/http_proxy.yml ./group_vars/medweb.yml\n```\n\n- 实例2 查找文件内容中带hostname的\n```\nfind . -type f -print | xargs grep -n \"hostname\" (-n输出行号)\n```\n\n- 实例3 mv 或者 cp 使用-i参数 -p 打印过程(交互确认)\n```\nls  *.txt | xargs -n1 -i -p cp {} /var/tmp/\n```\n\n- 实例4 查找当下文件按大小排序\n```\nfind . -maxdepth 1 ! -name \".\" -print0 | xargs -0 du -b | sort -nr | head -10 | nl\n```\n\n- 实例5 结合sed替换\n```\nfind . -name \"*.txt\" -print0 | xargs -0 sed -i 's/aaa/bbb/g'\n```\n\n\n## 总结\n\n首先使用方式不一样，exec操作麻烦些 xargs更简单直接方法多样\n另外从输出结果看得出  exec是遇到一个找到的文件就执行一次命令，xargs是把结果放到一起，执行一次。(这样可以使用在 把多行文件合并成一行的特定场景中)\n需要强调xargs遇到文件名中有空格的行为是处理不了的。\n这种情况可以这样\n\n```\nfind . -name \\*.txt -print0 | xargs -0 rm \n```\n其中find找到每个文件定义以null字符结尾  xargs找文件定义null分割文件 就可以了 \n\n\n\n\n","slug":"shell命令之xargs与exec","published":1,"updated":"2017-06-27T07:41:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvbz003a8tzzzhcfizqi","content":"<h2 id=\"exec\"><a href=\"#exec\" class=\"headerlink\" title=\"exec\"></a>exec</h2><p>看起来就是执行某动作的命令<br>格式为 -exec echo {} \\;<br>其中 <code>echo</code> 为动作, <code>{}</code> 为参数(即为之前找到的文件) <code>\\</code> 转义 <code>;</code> 是结束符</p>\n<p>示例<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">find ./ -name \\*.yml -exec echo &#123;&#125; \\;</div><div class=\"line\">./logrotate_conf.yml</div><div class=\"line\">./filebeat.yml</div><div class=\"line\">./group_vars/all.yml</div><div class=\"line\">./group_vars/ehr.yml</div><div class=\"line\">./group_vars/http_proxy.yml</div><div class=\"line\">./group_vars/medweb.yml</div></pre></td></tr></table></figure></p>\n<h2 id=\"xargs\"><a href=\"#xargs\" class=\"headerlink\" title=\"xargs\"></a>xargs</h2><p>xargs依赖管道,下边直接写了几个个实例</p>\n<p><code>基本使用</code></p>\n<p>把多行文件合并成一行 或者每行指定元素个数(-n 参数) 格式输出</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@md6 ~]# cat test.txt</div><div class=\"line\">a b c d e f</div><div class=\"line\"> g h i j k l</div><div class=\"line\"> m n o p q r s</div><div class=\"line\">t u v w x y z</div><div class=\"line\"></div><div class=\"line\">[root@md6 ~]# cat test.txt | xargs echo</div><div class=\"line\">a b c d e f g h i j k l m n o p q r s t u v w x y z</div><div class=\"line\">[root@md6 ~]# cat test.txt | xargs echo &gt; test1.txt</div><div class=\"line\">[root@md6 ~]# cat test1.txt</div><div class=\"line\">a b c d e f g h i j k l m n o p q r s t u v w x y z</div><div class=\"line\"></div><div class=\"line\">[root@md6 ~]# cat test.txt | xargs -n 4</div><div class=\"line\">a b c d</div><div class=\"line\">e f g h</div><div class=\"line\">i j k l</div><div class=\"line\">m n o p</div><div class=\"line\">q r s t</div><div class=\"line\">u v w x</div><div class=\"line\">y z</div><div class=\"line\">[root@md6 ~]# cat test.txt | xargs -n 3</div><div class=\"line\">a b c</div><div class=\"line\">d e f</div><div class=\"line\">g h i</div><div class=\"line\">j k l</div><div class=\"line\">m n o</div><div class=\"line\">p q r</div><div class=\"line\">s t u</div><div class=\"line\">v w x</div><div class=\"line\">y z</div></pre></td></tr></table></figure>\n<ul>\n<li><p>实例1 直接打印</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">find ./ -name \\*.yml | xargs echo</div><div class=\"line\">./logrotate_conf.yml ./filebeat.yml ./group_vars/all.yml ./group_vars/ehr.yml ./group_vars/http_proxy.yml ./group_vars/medweb.yml</div></pre></td></tr></table></figure>\n</li>\n<li><p>实例2 查找文件内容中带hostname的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -type f -print | xargs grep -n &quot;hostname&quot; (-n输出行号)</div></pre></td></tr></table></figure>\n</li>\n<li><p>实例3 mv 或者 cp 使用-i参数 -p 打印过程(交互确认)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ls  *.txt | xargs -n1 -i -p cp &#123;&#125; /var/tmp/</div></pre></td></tr></table></figure>\n</li>\n<li><p>实例4 查找当下文件按大小排序</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -maxdepth 1 ! -name &quot;.&quot; -print0 | xargs -0 du -b | sort -nr | head -10 | nl</div></pre></td></tr></table></figure>\n</li>\n<li><p>实例5 结合sed替换</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -name &quot;*.txt&quot; -print0 | xargs -0 sed -i &apos;s/aaa/bbb/g&apos;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>首先使用方式不一样，exec操作麻烦些 xargs更简单直接方法多样<br>另外从输出结果看得出  exec是遇到一个找到的文件就执行一次命令，xargs是把结果放到一起，执行一次。(这样可以使用在 把多行文件合并成一行的特定场景中)<br>需要强调xargs遇到文件名中有空格的行为是处理不了的。<br>这种情况可以这样</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -name \\*.txt -print0 | xargs -0 rm</div></pre></td></tr></table></figure>\n<p>其中find找到每个文件定义以null字符结尾  xargs找文件定义null分割文件 就可以了</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"exec\"><a href=\"#exec\" class=\"headerlink\" title=\"exec\"></a>exec</h2><p>看起来就是执行某动作的命令<br>格式为 -exec echo {} \\;<br>其中 <code>echo</code> 为动作, <code>{}</code> 为参数(即为之前找到的文件) <code>\\</code> 转义 <code>;</code> 是结束符</p>\n<p>示例<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">find ./ -name \\*.yml -exec echo &#123;&#125; \\;</div><div class=\"line\">./logrotate_conf.yml</div><div class=\"line\">./filebeat.yml</div><div class=\"line\">./group_vars/all.yml</div><div class=\"line\">./group_vars/ehr.yml</div><div class=\"line\">./group_vars/http_proxy.yml</div><div class=\"line\">./group_vars/medweb.yml</div></pre></td></tr></table></figure></p>\n<h2 id=\"xargs\"><a href=\"#xargs\" class=\"headerlink\" title=\"xargs\"></a>xargs</h2><p>xargs依赖管道,下边直接写了几个个实例</p>\n<p><code>基本使用</code></p>\n<p>把多行文件合并成一行 或者每行指定元素个数(-n 参数) 格式输出</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@md6 ~]# cat test.txt</div><div class=\"line\">a b c d e f</div><div class=\"line\"> g h i j k l</div><div class=\"line\"> m n o p q r s</div><div class=\"line\">t u v w x y z</div><div class=\"line\"></div><div class=\"line\">[root@md6 ~]# cat test.txt | xargs echo</div><div class=\"line\">a b c d e f g h i j k l m n o p q r s t u v w x y z</div><div class=\"line\">[root@md6 ~]# cat test.txt | xargs echo &gt; test1.txt</div><div class=\"line\">[root@md6 ~]# cat test1.txt</div><div class=\"line\">a b c d e f g h i j k l m n o p q r s t u v w x y z</div><div class=\"line\"></div><div class=\"line\">[root@md6 ~]# cat test.txt | xargs -n 4</div><div class=\"line\">a b c d</div><div class=\"line\">e f g h</div><div class=\"line\">i j k l</div><div class=\"line\">m n o p</div><div class=\"line\">q r s t</div><div class=\"line\">u v w x</div><div class=\"line\">y z</div><div class=\"line\">[root@md6 ~]# cat test.txt | xargs -n 3</div><div class=\"line\">a b c</div><div class=\"line\">d e f</div><div class=\"line\">g h i</div><div class=\"line\">j k l</div><div class=\"line\">m n o</div><div class=\"line\">p q r</div><div class=\"line\">s t u</div><div class=\"line\">v w x</div><div class=\"line\">y z</div></pre></td></tr></table></figure>\n<ul>\n<li><p>实例1 直接打印</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">find ./ -name \\*.yml | xargs echo</div><div class=\"line\">./logrotate_conf.yml ./filebeat.yml ./group_vars/all.yml ./group_vars/ehr.yml ./group_vars/http_proxy.yml ./group_vars/medweb.yml</div></pre></td></tr></table></figure>\n</li>\n<li><p>实例2 查找文件内容中带hostname的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -type f -print | xargs grep -n &quot;hostname&quot; (-n输出行号)</div></pre></td></tr></table></figure>\n</li>\n<li><p>实例3 mv 或者 cp 使用-i参数 -p 打印过程(交互确认)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ls  *.txt | xargs -n1 -i -p cp &#123;&#125; /var/tmp/</div></pre></td></tr></table></figure>\n</li>\n<li><p>实例4 查找当下文件按大小排序</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -maxdepth 1 ! -name &quot;.&quot; -print0 | xargs -0 du -b | sort -nr | head -10 | nl</div></pre></td></tr></table></figure>\n</li>\n<li><p>实例5 结合sed替换</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -name &quot;*.txt&quot; -print0 | xargs -0 sed -i &apos;s/aaa/bbb/g&apos;</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>首先使用方式不一样，exec操作麻烦些 xargs更简单直接方法多样<br>另外从输出结果看得出  exec是遇到一个找到的文件就执行一次命令，xargs是把结果放到一起，执行一次。(这样可以使用在 把多行文件合并成一行的特定场景中)<br>需要强调xargs遇到文件名中有空格的行为是处理不了的。<br>这种情况可以这样</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">find . -name \\*.txt -print0 | xargs -0 rm</div></pre></td></tr></table></figure>\n<p>其中find找到每个文件定义以null字符结尾  xargs找文件定义null分割文件 就可以了</p>\n"},{"title":"socket解读","date":"2017-07-18T02:24:52.000Z","_content":"\n# 前言\n> 之前一直部署各种开源软件，包括很多RPC服务，其中很多都会有一个socket，但是很多地方可以用地址加端口替代，我虽然说做运维也将近两年了，但是毕竟大学是数学专业，不是计算机科班出身，对什么TCP/IP啊socket啊，都得是自己看书了解。so，抽个空补习了一下。\n\n用廖雪峰老师的话说\n> Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。\n\n# TCP/IP\n要理解socket首先要理解TCP/IP，面试过程当中我们经常被问到ISO七层模型相关的知识，类似TCP/IP工作在第几层？\nTCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，定义了主机如何连入因特网及数据如何再它们之间传输的标准，\n\n从字面意思来看TCP/IP是TCP和IP协议的合称，但实际上TCP/IP协议是指因特网整个TCP/IP协议簇。不同于ISO模型的七个分层，TCP/IP协议参考模型把所有的TCP/IP系列协议归类到四个抽象层中\n\n应用层：TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 等等\n\n传输层：TCP，UDP\n\n网络层：IP，ICMP，OSPF，EIGRP，IGMP\n\n数据链路层：SLIP，CSLIP，PPP，MTU\n\n每一层都是建立在下一层提供的服务上，为上一层提供服务\n\n\n\npython socket客户端编写(down 新浪首页)\n```\n# -*- coding:utf-8 -*-\nimport socket\n\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\ns.connect(('www.sina.com',80))\n\ns.send('GET / HTTP/1.1\\r\\nHost: www.sina.com.cn\\r\\nConnection: close\\r\\n\\r\\n')\n\nbuffer = []\nwhile True:\n\n    d = s.recv(2048)\n    if d:\n        buffer.append(d)\n    else:\n        break\n\ndata=''.join(buffer)\ns.close\nheader, html = data.split('\\r\\n\\r\\n',1)\nprint header\n```\n\nserver端编写\n","source":"_posts/socket解读.md","raw":"---\ntitle: socket解读\ndate: 2017-07-18 10:24:52\ntags: socket\ncategories: 基础运维\n---\n\n# 前言\n> 之前一直部署各种开源软件，包括很多RPC服务，其中很多都会有一个socket，但是很多地方可以用地址加端口替代，我虽然说做运维也将近两年了，但是毕竟大学是数学专业，不是计算机科班出身，对什么TCP/IP啊socket啊，都得是自己看书了解。so，抽个空补习了一下。\n\n用廖雪峰老师的话说\n> Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。\n\n# TCP/IP\n要理解socket首先要理解TCP/IP，面试过程当中我们经常被问到ISO七层模型相关的知识，类似TCP/IP工作在第几层？\nTCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，定义了主机如何连入因特网及数据如何再它们之间传输的标准，\n\n从字面意思来看TCP/IP是TCP和IP协议的合称，但实际上TCP/IP协议是指因特网整个TCP/IP协议簇。不同于ISO模型的七个分层，TCP/IP协议参考模型把所有的TCP/IP系列协议归类到四个抽象层中\n\n应用层：TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 等等\n\n传输层：TCP，UDP\n\n网络层：IP，ICMP，OSPF，EIGRP，IGMP\n\n数据链路层：SLIP，CSLIP，PPP，MTU\n\n每一层都是建立在下一层提供的服务上，为上一层提供服务\n\n\n\npython socket客户端编写(down 新浪首页)\n```\n# -*- coding:utf-8 -*-\nimport socket\n\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\ns.connect(('www.sina.com',80))\n\ns.send('GET / HTTP/1.1\\r\\nHost: www.sina.com.cn\\r\\nConnection: close\\r\\n\\r\\n')\n\nbuffer = []\nwhile True:\n\n    d = s.recv(2048)\n    if d:\n        buffer.append(d)\n    else:\n        break\n\ndata=''.join(buffer)\ns.close\nheader, html = data.split('\\r\\n\\r\\n',1)\nprint header\n```\n\nserver端编写\n","slug":"socket解读","published":1,"updated":"2017-08-07T09:26:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvc0003d8tzzjzpeoinb","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><blockquote>\n<p>之前一直部署各种开源软件，包括很多RPC服务，其中很多都会有一个socket，但是很多地方可以用地址加端口替代，我虽然说做运维也将近两年了，但是毕竟大学是数学专业，不是计算机科班出身，对什么TCP/IP啊socket啊，都得是自己看书了解。so，抽个空补习了一下。</p>\n</blockquote>\n<p>用廖雪峰老师的话说</p>\n<blockquote>\n<p>Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。</p>\n</blockquote>\n<h1 id=\"tcpip\"><a href=\"#TCP-IP\" class=\"headerlink\" title=\"TCP/IP\"></a>TCP/IP</h1><p>要理解socket首先要理解TCP/IP，面试过程当中我们经常被问到ISO七层模型相关的知识，类似TCP/IP工作在第几层？<br>TCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，定义了主机如何连入因特网及数据如何再它们之间传输的标准，</p>\n<p>从字面意思来看TCP/IP是TCP和IP协议的合称，但实际上TCP/IP协议是指因特网整个TCP/IP协议簇。不同于ISO模型的七个分层，TCP/IP协议参考模型把所有的TCP/IP系列协议归类到四个抽象层中</p>\n<p>应用层：TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 等等</p>\n<p>传输层：TCP，UDP</p>\n<p>网络层：IP，ICMP，OSPF，EIGRP，IGMP</p>\n<p>数据链路层：SLIP，CSLIP，PPP，MTU</p>\n<p>每一层都是建立在下一层提供的服务上，为上一层提供服务</p>\n<p>python socket客户端编写(down 新浪首页)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"># -*- coding:utf-8 -*-</div><div class=\"line\">import socket</div><div class=\"line\"></div><div class=\"line\">s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</div><div class=\"line\"></div><div class=\"line\">s.connect((&apos;www.sina.com&apos;,80))</div><div class=\"line\"></div><div class=\"line\">s.send(&apos;GET / HTTP/1.1\\r\\nHost: www.sina.com.cn\\r\\nConnection: close\\r\\n\\r\\n&apos;)</div><div class=\"line\"></div><div class=\"line\">buffer = []</div><div class=\"line\">while True:</div><div class=\"line\"></div><div class=\"line\">    d = s.recv(2048)</div><div class=\"line\">    if d:</div><div class=\"line\">        buffer.append(d)</div><div class=\"line\">    else:</div><div class=\"line\">        break</div><div class=\"line\"></div><div class=\"line\">data=&apos;&apos;.join(buffer)</div><div class=\"line\">s.close</div><div class=\"line\">header, html = data.split(&apos;\\r\\n\\r\\n&apos;,1)</div><div class=\"line\">print header</div></pre></td></tr></table></figure></p>\n<p>server端编写</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><blockquote>\n<p>之前一直部署各种开源软件，包括很多RPC服务，其中很多都会有一个socket，但是很多地方可以用地址加端口替代，我虽然说做运维也将近两年了，但是毕竟大学是数学专业，不是计算机科班出身，对什么TCP/IP啊socket啊，都得是自己看书了解。so，抽个空补习了一下。</p>\n</blockquote>\n<p>用廖雪峰老师的话说</p>\n<blockquote>\n<p>Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。</p>\n</blockquote>\n<h1 id=\"TCP-IP\"><a href=\"#TCP-IP\" class=\"headerlink\" title=\"TCP/IP\"></a>TCP/IP</h1><p>要理解socket首先要理解TCP/IP，面试过程当中我们经常被问到ISO七层模型相关的知识，类似TCP/IP工作在第几层？<br>TCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，定义了主机如何连入因特网及数据如何再它们之间传输的标准，</p>\n<p>从字面意思来看TCP/IP是TCP和IP协议的合称，但实际上TCP/IP协议是指因特网整个TCP/IP协议簇。不同于ISO模型的七个分层，TCP/IP协议参考模型把所有的TCP/IP系列协议归类到四个抽象层中</p>\n<p>应用层：TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 等等</p>\n<p>传输层：TCP，UDP</p>\n<p>网络层：IP，ICMP，OSPF，EIGRP，IGMP</p>\n<p>数据链路层：SLIP，CSLIP，PPP，MTU</p>\n<p>每一层都是建立在下一层提供的服务上，为上一层提供服务</p>\n<p>python socket客户端编写(down 新浪首页)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"># -*- coding:utf-8 -*-</div><div class=\"line\">import socket</div><div class=\"line\"></div><div class=\"line\">s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</div><div class=\"line\"></div><div class=\"line\">s.connect((&apos;www.sina.com&apos;,80))</div><div class=\"line\"></div><div class=\"line\">s.send(&apos;GET / HTTP/1.1\\r\\nHost: www.sina.com.cn\\r\\nConnection: close\\r\\n\\r\\n&apos;)</div><div class=\"line\"></div><div class=\"line\">buffer = []</div><div class=\"line\">while True:</div><div class=\"line\"></div><div class=\"line\">    d = s.recv(2048)</div><div class=\"line\">    if d:</div><div class=\"line\">        buffer.append(d)</div><div class=\"line\">    else:</div><div class=\"line\">        break</div><div class=\"line\"></div><div class=\"line\">data=&apos;&apos;.join(buffer)</div><div class=\"line\">s.close</div><div class=\"line\">header, html = data.split(&apos;\\r\\n\\r\\n&apos;,1)</div><div class=\"line\">print header</div></pre></td></tr></table></figure></p>\n<p>server端编写</p>\n"},{"title":"sublime使用","date":"2017-06-08T07:37:27.000Z","_content":"\n## mac下zsh直接用sublime打开文件夹\n建一个软链\n```\nln -s /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl /usr/bin/subl\nsubl workspace/medweb 会直接打开medweb工程，很方便\n```\n\n## 配置文件\n\n> 建议直接传github 这样之后换电脑或者离职之后就很方便了。\n\n\n","source":"_posts/sublime使用.md","raw":"---\ntitle: sublime使用\ndate: 2017-06-08 15:37:27\ntags: sublime\ncategories: 运维工具\n---\n\n## mac下zsh直接用sublime打开文件夹\n建一个软链\n```\nln -s /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl /usr/bin/subl\nsubl workspace/medweb 会直接打开medweb工程，很方便\n```\n\n## 配置文件\n\n> 建议直接传github 这样之后换电脑或者离职之后就很方便了。\n\n\n","slug":"sublime使用","published":1,"updated":"2017-06-09T08:59:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvc2003e8tzzej897eh8","content":"<h2 id=\"mac下zsh直接用sublime打开文件夹\"><a href=\"#mac下zsh直接用sublime打开文件夹\" class=\"headerlink\" title=\"mac下zsh直接用sublime打开文件夹\"></a>mac下zsh直接用sublime打开文件夹</h2><p>建一个软链<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ln -s /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl /usr/bin/subl</div><div class=\"line\">subl workspace/medweb 会直接打开medweb工程，很方便</div></pre></td></tr></table></figure></p>\n<h2 id=\"配置文件\"><a href=\"#配置文件\" class=\"headerlink\" title=\"配置文件\"></a>配置文件</h2><blockquote>\n<p>建议直接传github 这样之后换电脑或者离职之后就很方便了。</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"mac下zsh直接用sublime打开文件夹\"><a href=\"#mac下zsh直接用sublime打开文件夹\" class=\"headerlink\" title=\"mac下zsh直接用sublime打开文件夹\"></a>mac下zsh直接用sublime打开文件夹</h2><p>建一个软链<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">ln -s /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl /usr/bin/subl</div><div class=\"line\">subl workspace/medweb 会直接打开medweb工程，很方便</div></pre></td></tr></table></figure></p>\n<h2 id=\"配置文件\"><a href=\"#配置文件\" class=\"headerlink\" title=\"配置文件\"></a>配置文件</h2><blockquote>\n<p>建议直接传github 这样之后换电脑或者离职之后就很方便了。</p>\n</blockquote>\n"},{"title":"uwsgi_worker监控脚本","date":"2017-06-12T06:58:24.000Z","_content":"> 该脚本为falcon上报uwsgi的监控数据，总worker数，busy_worker数，busy率。 需要写到cron中定时去跑。push过程忽略，使用的为内部封装的op_tools包。\n\n\n```\n# Ansible managed: /data/home/chunyu_sys/workspace/cy_ansible/roles/zabbix_agent/templates/uwsgi_busy_count.py.j2 modified on 2016-09-14 23:41:10 by chunyu_sys on control\n# Do NOT modify this file by hand!\nimport socket\nimport json\nimport sys\nfrom op_tools import falcon\n\nproject_or_socket = \"medweb\"\n\nuwsgi_map = {}\n\nuwsgi_map['medweb']='/home/chunyu/workspace/medweb/log/uwsgi_stats.socket'\nuwsgi_map['cmsapi']='/tmp/stats_cmsapi.socket'\n\naddr = uwsgi_map.get(project_or_socket, project_or_socket)\ndata_type = \"busy\"\n\nsfamily = socket.AF_UNIX\ns = socket.socket(sfamily, socket.SOCK_STREAM)\ns.connect(addr)\n\njs = \"\"\n\nwhile True:\n    data = s.recv(4096)\n    if len(data) < 1:\n        break\n    js += data.decode('utf8')\n\ndd = json.loads(js)\nworkers = dd[\"workers\"]\nbusy_count = 0\ntotal_count = len(workers)\n\nfor worker in workers:\n   if worker[\"status\"] == \"busy\":\n       busy_count += 1\n\nbusy_rate = busy_count/float(total_count or 1)\n\n\ndic_count = {\n    'busy_count' : busy_count,\n    'busy_rate' : busy_rate,\n    'total_count' : total_count,\n    }\n\nmetric = \"medweb_uwsgi_busy_worker\"\ncollect_step = 60\ncounter_type = falcon.CounterType.GAUGE\n\nfor key  in dic_count:\n    tag = \"type=\" + key\n\n    value = dic_count.get(key)\n    info = falcon.build_metric_info(metric, value, collect_step, counter_type, tags=tag)\n    print info\n    falcon.push_metric_info_list_to_falcon([info])\n```\n","source":"_posts/uwsgi-worker监控脚本.md","raw":"---\ntitle: uwsgi_worker监控脚本\ndate: 2017-06-12 14:58:24\ntags: scripts, 监控\ncategories: 脚本\n---\n> 该脚本为falcon上报uwsgi的监控数据，总worker数，busy_worker数，busy率。 需要写到cron中定时去跑。push过程忽略，使用的为内部封装的op_tools包。\n\n\n```\n# Ansible managed: /data/home/chunyu_sys/workspace/cy_ansible/roles/zabbix_agent/templates/uwsgi_busy_count.py.j2 modified on 2016-09-14 23:41:10 by chunyu_sys on control\n# Do NOT modify this file by hand!\nimport socket\nimport json\nimport sys\nfrom op_tools import falcon\n\nproject_or_socket = \"medweb\"\n\nuwsgi_map = {}\n\nuwsgi_map['medweb']='/home/chunyu/workspace/medweb/log/uwsgi_stats.socket'\nuwsgi_map['cmsapi']='/tmp/stats_cmsapi.socket'\n\naddr = uwsgi_map.get(project_or_socket, project_or_socket)\ndata_type = \"busy\"\n\nsfamily = socket.AF_UNIX\ns = socket.socket(sfamily, socket.SOCK_STREAM)\ns.connect(addr)\n\njs = \"\"\n\nwhile True:\n    data = s.recv(4096)\n    if len(data) < 1:\n        break\n    js += data.decode('utf8')\n\ndd = json.loads(js)\nworkers = dd[\"workers\"]\nbusy_count = 0\ntotal_count = len(workers)\n\nfor worker in workers:\n   if worker[\"status\"] == \"busy\":\n       busy_count += 1\n\nbusy_rate = busy_count/float(total_count or 1)\n\n\ndic_count = {\n    'busy_count' : busy_count,\n    'busy_rate' : busy_rate,\n    'total_count' : total_count,\n    }\n\nmetric = \"medweb_uwsgi_busy_worker\"\ncollect_step = 60\ncounter_type = falcon.CounterType.GAUGE\n\nfor key  in dic_count:\n    tag = \"type=\" + key\n\n    value = dic_count.get(key)\n    info = falcon.build_metric_info(metric, value, collect_step, counter_type, tags=tag)\n    print info\n    falcon.push_metric_info_list_to_falcon([info])\n```\n","slug":"uwsgi-worker监控脚本","published":1,"updated":"2017-06-12T07:03:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvc4003j8tzzzbkb09mz","content":"<blockquote>\n<p>该脚本为falcon上报uwsgi的监控数据，总worker数，busy_worker数，busy率。 需要写到cron中定时去跑。push过程忽略，使用的为内部封装的op_tools包。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Ansible managed: /data/home/chunyu_sys/workspace/cy_ansible/roles/zabbix_agent/templates/uwsgi_busy_count.py.j2 modified on 2016-09-14 23:41:10 by chunyu_sys on control</div><div class=\"line\"># Do NOT modify this file by hand!</div><div class=\"line\">import socket</div><div class=\"line\">import json</div><div class=\"line\">import sys</div><div class=\"line\">from op_tools import falcon</div><div class=\"line\"></div><div class=\"line\">project_or_socket = &quot;medweb&quot;</div><div class=\"line\"></div><div class=\"line\">uwsgi_map = &#123;&#125;</div><div class=\"line\"></div><div class=\"line\">uwsgi_map[&apos;medweb&apos;]=&apos;/home/chunyu/workspace/medweb/log/uwsgi_stats.socket&apos;</div><div class=\"line\">uwsgi_map[&apos;cmsapi&apos;]=&apos;/tmp/stats_cmsapi.socket&apos;</div><div class=\"line\"></div><div class=\"line\">addr = uwsgi_map.get(project_or_socket, project_or_socket)</div><div class=\"line\">data_type = &quot;busy&quot;</div><div class=\"line\"></div><div class=\"line\">sfamily = socket.AF_UNIX</div><div class=\"line\">s = socket.socket(sfamily, socket.SOCK_STREAM)</div><div class=\"line\">s.connect(addr)</div><div class=\"line\"></div><div class=\"line\">js = &quot;&quot;</div><div class=\"line\"></div><div class=\"line\">while True:</div><div class=\"line\">    data = s.recv(4096)</div><div class=\"line\">    if len(data) &lt; 1:</div><div class=\"line\">        break</div><div class=\"line\">    js += data.decode(&apos;utf8&apos;)</div><div class=\"line\"></div><div class=\"line\">dd = json.loads(js)</div><div class=\"line\">workers = dd[&quot;workers&quot;]</div><div class=\"line\">busy_count = 0</div><div class=\"line\">total_count = len(workers)</div><div class=\"line\"></div><div class=\"line\">for worker in workers:</div><div class=\"line\">   if worker[&quot;status&quot;] == &quot;busy&quot;:</div><div class=\"line\">       busy_count += 1</div><div class=\"line\"></div><div class=\"line\">busy_rate = busy_count/float(total_count or 1)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">dic_count = &#123;</div><div class=\"line\">    &apos;busy_count&apos; : busy_count,</div><div class=\"line\">    &apos;busy_rate&apos; : busy_rate,</div><div class=\"line\">    &apos;total_count&apos; : total_count,</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">metric = &quot;medweb_uwsgi_busy_worker&quot;</div><div class=\"line\">collect_step = 60</div><div class=\"line\">counter_type = falcon.CounterType.GAUGE</div><div class=\"line\"></div><div class=\"line\">for key  in dic_count:</div><div class=\"line\">    tag = &quot;type=&quot; + key</div><div class=\"line\"></div><div class=\"line\">    value = dic_count.get(key)</div><div class=\"line\">    info = falcon.build_metric_info(metric, value, collect_step, counter_type, tags=tag)</div><div class=\"line\">    print info</div><div class=\"line\">    falcon.push_metric_info_list_to_falcon([info])</div></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>该脚本为falcon上报uwsgi的监控数据，总worker数，busy_worker数，busy率。 需要写到cron中定时去跑。push过程忽略，使用的为内部封装的op_tools包。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Ansible managed: /data/home/chunyu_sys/workspace/cy_ansible/roles/zabbix_agent/templates/uwsgi_busy_count.py.j2 modified on 2016-09-14 23:41:10 by chunyu_sys on control</div><div class=\"line\"># Do NOT modify this file by hand!</div><div class=\"line\">import socket</div><div class=\"line\">import json</div><div class=\"line\">import sys</div><div class=\"line\">from op_tools import falcon</div><div class=\"line\"></div><div class=\"line\">project_or_socket = &quot;medweb&quot;</div><div class=\"line\"></div><div class=\"line\">uwsgi_map = &#123;&#125;</div><div class=\"line\"></div><div class=\"line\">uwsgi_map[&apos;medweb&apos;]=&apos;/home/chunyu/workspace/medweb/log/uwsgi_stats.socket&apos;</div><div class=\"line\">uwsgi_map[&apos;cmsapi&apos;]=&apos;/tmp/stats_cmsapi.socket&apos;</div><div class=\"line\"></div><div class=\"line\">addr = uwsgi_map.get(project_or_socket, project_or_socket)</div><div class=\"line\">data_type = &quot;busy&quot;</div><div class=\"line\"></div><div class=\"line\">sfamily = socket.AF_UNIX</div><div class=\"line\">s = socket.socket(sfamily, socket.SOCK_STREAM)</div><div class=\"line\">s.connect(addr)</div><div class=\"line\"></div><div class=\"line\">js = &quot;&quot;</div><div class=\"line\"></div><div class=\"line\">while True:</div><div class=\"line\">    data = s.recv(4096)</div><div class=\"line\">    if len(data) &lt; 1:</div><div class=\"line\">        break</div><div class=\"line\">    js += data.decode(&apos;utf8&apos;)</div><div class=\"line\"></div><div class=\"line\">dd = json.loads(js)</div><div class=\"line\">workers = dd[&quot;workers&quot;]</div><div class=\"line\">busy_count = 0</div><div class=\"line\">total_count = len(workers)</div><div class=\"line\"></div><div class=\"line\">for worker in workers:</div><div class=\"line\">   if worker[&quot;status&quot;] == &quot;busy&quot;:</div><div class=\"line\">       busy_count += 1</div><div class=\"line\"></div><div class=\"line\">busy_rate = busy_count/float(total_count or 1)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">dic_count = &#123;</div><div class=\"line\">    &apos;busy_count&apos; : busy_count,</div><div class=\"line\">    &apos;busy_rate&apos; : busy_rate,</div><div class=\"line\">    &apos;total_count&apos; : total_count,</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">metric = &quot;medweb_uwsgi_busy_worker&quot;</div><div class=\"line\">collect_step = 60</div><div class=\"line\">counter_type = falcon.CounterType.GAUGE</div><div class=\"line\"></div><div class=\"line\">for key  in dic_count:</div><div class=\"line\">    tag = &quot;type=&quot; + key</div><div class=\"line\"></div><div class=\"line\">    value = dic_count.get(key)</div><div class=\"line\">    info = falcon.build_metric_info(metric, value, collect_step, counter_type, tags=tag)</div><div class=\"line\">    print info</div><div class=\"line\">    falcon.push_metric_info_list_to_falcon([info])</div></pre></td></tr></table></figure>\n"},{"title":"uwsgi笔记","date":"2017-07-13T06:38:09.000Z","_content":"\n> 前言，来公司一年了，对uwsgi的操作，只停留在部署，或者restart，并没有主动配置过，今天看nginx的时候看到nginx(我们的nginx是只转发)的请求是转发的本地某个端口，是个uwsgi提供的fastrouter服务。在此记录一下。\n\n由于我们后端使用的都是Django项目，所以整体都是这个架构`nginx`-->`uwsgi`-->`django`.所以对uwsgi的了解也很重要。\nfastrouter使用放到后面先说，uwsgi的普通配置。\n\n版本：uWSGI==2.0.12\n\n## 简介\n\nWSGI（Python Web Server Gateway Interface，缩写为WSGI） 是一种 Web 服务器网关接口。它是一个 Web 服务器（如 Nginx）与应用服务器（如 uWSGI 服务器）通信的一种规范。\nuwsgi 是一种协议\nuWSGI uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。uWSGI，既不用wsgi协议也不用FastCGI协议，而是自创了一个uwsgi的协议，uwsgi协议是一个uWSGI服务器自有的协议，它用于定义传输信息的类型（type of information），每一个uwsgi packet前4byte为传输信息类型描述，它与WSGI相比是两样东西。据说该协议大约是fcgi协议的10倍那么快。\n\n优点：\n- 超快的性能。\n- 低内存占用（实测为apache2的mod_wsgi的一半左右）。\n- 多app管理。\n- 详尽的日志功能（可以用来分析app性能和瓶颈）。\n- 高度可定制（内存大小限制，服务一定次数后重启等）。\n\n版本：uWSGI==2.0.12\n\n## 安装配置\n\n安装就是直接在virtualenv中pip安装就好了\npip install uWSGI\n \n\n\n\n## uwsgitop\n\n> 监控工具\n\n### 部署\n\npip install uwsgitop \n\n### 使用\nuwsgitop /tmp/stats.sock\n\n\n## plugins使用\n\n### fastrouter\n这是一个负载均衡插件，比如说四个uwsgi节点提供服务，这样在nginx上面可以配置成upstream，分流到四个uwsgi服务上，但是如果是上线，或者有一个节点挂掉了怎么办，只能是收到500报警在手动剔除吗？ to yung to sample!! 当然不是，这个时候就用到fastrouter了。\n看[官网](http://uwsgi-docs-cn.readthedocs.io/zh_CN/latest/Fastrouter.html?highlight=fast)\n\n> For advanced setups uWSGI includes the “fastrouter” plugin, a proxy/load-balancer/router speaking the uwsgi protocol. It is built in by default. You can put it between your webserver and real uWSGI instances to have more control over the routing of HTTP requests to your application servers.\n\n它的功能proxy/load-banlance/router\n简述一下配置：\n\n**nginx配置**\n```\nlocation /test {\n        include    uwsgi_params;\n        uwsgi_pass 127.0.0.1:3030;\n    }\n```\n\n**fastrouter-server端配置**\n```\n<uwsgi id = \"fastrouter\">\n    <fastrouter>127.0.0.1:3030</fastrouter>\n    <fastrouter-subscription-server>127.0.0.1:3131</fastrouter-subscription-server>\n    <enable-threads/>\n    <master/>\n    <fastrouter-stats>127.0.0.1:9595</fastrouter-stats>\n</uwsgi>\n```\n\n - 3030为当前uWSGI fastrouter server的端口，前面的空代表当前主机地址。（nginx会用到这个端口）\n - 3131fastrouter-subscription-server 表示当前uWSGI fastrouter server的订阅地址。（web应用服务会用到）\n - stats：uWSGI的统计服务机制，访问会返回一个json对象，都是[状态统计信息](http://uwsgi-docs.readthedocs.io/en/latest/StatsServer.html) 格式可以是一个端口，也可以是一个socket\n\n**uwsgi实例配置**\n\n实例1\n```\n<uwsgi id = \"subserver1\">\n    <stats>127.0.0.1:9393</stats>\n    <processes>4</processes>\n    <enable-threads/>\n    <memory-report/>\n    <subscribe-to>127.0.0.1:3131:test</subscribe-to>\n    <socket>127.0.0.1:3232</socket>\n    <file>./server.py</file>\n    <master/>\n    <weight>8</weight>\n</uwsgi>\n```\n实例2\n```\n<uwsgi id = \"subserver2\">\n    <stats>127.0.0.1:9494</stats>\n    <processes>4</processes>\n    <enable-threads/>\n    <memory-report/>\n    <subscribe-to>127.0.0.1:3131:test</subscribe-to>\n    <socket>127.0.0.1:3333</socket>\n    <file>./server.py</file>\n    <master/>\n    <weight>2</weight>\n</uwsgi>\n```\n\n- <stats>127.0.0.1:9494</stats> 这个可以把9494改为0 则为自动分配 也可以改成socket\n- 我们通过subscribe-to变量来订阅fastrouter server（127.0.0.1:3131）,冒号后跟着的是对应请求的域名，只有来自当前域名的请求才会进入当前web节点。当然这个可以设置多个subscribe-to，例如：subscribe-to=127.0.0.1:3131:test1\n\n- weight 权重分配\n\n由于我们线上使用的是fastrouter,所以在这儿就只说了这个，其实uwsgi的负载均衡使用不只有这一种手段\n有兴趣可以看下[这篇博文](http://www.cnblogs.com/codeape/p/4064815.html)\n\n### harakiri\n\n\n","source":"_posts/uwsgi笔记.md","raw":"---\ntitle: uwsgi笔记\ndate: 2017-07-13 14:38:09\ntags: uwsgi\ncategories: 基础运维\n---\n\n> 前言，来公司一年了，对uwsgi的操作，只停留在部署，或者restart，并没有主动配置过，今天看nginx的时候看到nginx(我们的nginx是只转发)的请求是转发的本地某个端口，是个uwsgi提供的fastrouter服务。在此记录一下。\n\n由于我们后端使用的都是Django项目，所以整体都是这个架构`nginx`-->`uwsgi`-->`django`.所以对uwsgi的了解也很重要。\nfastrouter使用放到后面先说，uwsgi的普通配置。\n\n版本：uWSGI==2.0.12\n\n## 简介\n\nWSGI（Python Web Server Gateway Interface，缩写为WSGI） 是一种 Web 服务器网关接口。它是一个 Web 服务器（如 Nginx）与应用服务器（如 uWSGI 服务器）通信的一种规范。\nuwsgi 是一种协议\nuWSGI uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。uWSGI，既不用wsgi协议也不用FastCGI协议，而是自创了一个uwsgi的协议，uwsgi协议是一个uWSGI服务器自有的协议，它用于定义传输信息的类型（type of information），每一个uwsgi packet前4byte为传输信息类型描述，它与WSGI相比是两样东西。据说该协议大约是fcgi协议的10倍那么快。\n\n优点：\n- 超快的性能。\n- 低内存占用（实测为apache2的mod_wsgi的一半左右）。\n- 多app管理。\n- 详尽的日志功能（可以用来分析app性能和瓶颈）。\n- 高度可定制（内存大小限制，服务一定次数后重启等）。\n\n版本：uWSGI==2.0.12\n\n## 安装配置\n\n安装就是直接在virtualenv中pip安装就好了\npip install uWSGI\n \n\n\n\n## uwsgitop\n\n> 监控工具\n\n### 部署\n\npip install uwsgitop \n\n### 使用\nuwsgitop /tmp/stats.sock\n\n\n## plugins使用\n\n### fastrouter\n这是一个负载均衡插件，比如说四个uwsgi节点提供服务，这样在nginx上面可以配置成upstream，分流到四个uwsgi服务上，但是如果是上线，或者有一个节点挂掉了怎么办，只能是收到500报警在手动剔除吗？ to yung to sample!! 当然不是，这个时候就用到fastrouter了。\n看[官网](http://uwsgi-docs-cn.readthedocs.io/zh_CN/latest/Fastrouter.html?highlight=fast)\n\n> For advanced setups uWSGI includes the “fastrouter” plugin, a proxy/load-balancer/router speaking the uwsgi protocol. It is built in by default. You can put it between your webserver and real uWSGI instances to have more control over the routing of HTTP requests to your application servers.\n\n它的功能proxy/load-banlance/router\n简述一下配置：\n\n**nginx配置**\n```\nlocation /test {\n        include    uwsgi_params;\n        uwsgi_pass 127.0.0.1:3030;\n    }\n```\n\n**fastrouter-server端配置**\n```\n<uwsgi id = \"fastrouter\">\n    <fastrouter>127.0.0.1:3030</fastrouter>\n    <fastrouter-subscription-server>127.0.0.1:3131</fastrouter-subscription-server>\n    <enable-threads/>\n    <master/>\n    <fastrouter-stats>127.0.0.1:9595</fastrouter-stats>\n</uwsgi>\n```\n\n - 3030为当前uWSGI fastrouter server的端口，前面的空代表当前主机地址。（nginx会用到这个端口）\n - 3131fastrouter-subscription-server 表示当前uWSGI fastrouter server的订阅地址。（web应用服务会用到）\n - stats：uWSGI的统计服务机制，访问会返回一个json对象，都是[状态统计信息](http://uwsgi-docs.readthedocs.io/en/latest/StatsServer.html) 格式可以是一个端口，也可以是一个socket\n\n**uwsgi实例配置**\n\n实例1\n```\n<uwsgi id = \"subserver1\">\n    <stats>127.0.0.1:9393</stats>\n    <processes>4</processes>\n    <enable-threads/>\n    <memory-report/>\n    <subscribe-to>127.0.0.1:3131:test</subscribe-to>\n    <socket>127.0.0.1:3232</socket>\n    <file>./server.py</file>\n    <master/>\n    <weight>8</weight>\n</uwsgi>\n```\n实例2\n```\n<uwsgi id = \"subserver2\">\n    <stats>127.0.0.1:9494</stats>\n    <processes>4</processes>\n    <enable-threads/>\n    <memory-report/>\n    <subscribe-to>127.0.0.1:3131:test</subscribe-to>\n    <socket>127.0.0.1:3333</socket>\n    <file>./server.py</file>\n    <master/>\n    <weight>2</weight>\n</uwsgi>\n```\n\n- <stats>127.0.0.1:9494</stats> 这个可以把9494改为0 则为自动分配 也可以改成socket\n- 我们通过subscribe-to变量来订阅fastrouter server（127.0.0.1:3131）,冒号后跟着的是对应请求的域名，只有来自当前域名的请求才会进入当前web节点。当然这个可以设置多个subscribe-to，例如：subscribe-to=127.0.0.1:3131:test1\n\n- weight 权重分配\n\n由于我们线上使用的是fastrouter,所以在这儿就只说了这个，其实uwsgi的负载均衡使用不只有这一种手段\n有兴趣可以看下[这篇博文](http://www.cnblogs.com/codeape/p/4064815.html)\n\n### harakiri\n\n\n","slug":"uwsgi笔记","published":1,"updated":"2017-07-19T08:09:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvc7003l8tzzancb2knd","content":"<blockquote>\n<p>前言，来公司一年了，对uwsgi的操作，只停留在部署，或者restart，并没有主动配置过，今天看nginx的时候看到nginx(我们的nginx是只转发)的请求是转发的本地某个端口，是个uwsgi提供的fastrouter服务。在此记录一下。</p>\n</blockquote>\n<p>由于我们后端使用的都是Django项目，所以整体都是这个架构<code>nginx</code>–&gt;<code>uwsgi</code>–&gt;<code>django</code>.所以对uwsgi的了解也很重要。<br>fastrouter使用放到后面先说，uwsgi的普通配置。</p>\n<p>版本：uWSGI==2.0.12</p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>WSGI（Python Web Server Gateway Interface，缩写为WSGI） 是一种 Web 服务器网关接口。它是一个 Web 服务器（如 Nginx）与应用服务器（如 uWSGI 服务器）通信的一种规范。<br>uwsgi 是一种协议<br>uWSGI uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。uWSGI，既不用wsgi协议也不用FastCGI协议，而是自创了一个uwsgi的协议，uwsgi协议是一个uWSGI服务器自有的协议，它用于定义传输信息的类型（type of information），每一个uwsgi packet前4byte为传输信息类型描述，它与WSGI相比是两样东西。据说该协议大约是fcgi协议的10倍那么快。</p>\n<p>优点：</p>\n<ul>\n<li>超快的性能。</li>\n<li>低内存占用（实测为apache2的mod_wsgi的一半左右）。</li>\n<li>多app管理。</li>\n<li>详尽的日志功能（可以用来分析app性能和瓶颈）。</li>\n<li>高度可定制（内存大小限制，服务一定次数后重启等）。</li>\n</ul>\n<p>版本：uWSGI==2.0.12</p>\n<h2 id=\"安装配置\"><a href=\"#安装配置\" class=\"headerlink\" title=\"安装配置\"></a>安装配置</h2><p>安装就是直接在virtualenv中pip安装就好了<br>pip install uWSGI</p>\n<h2 id=\"uwsgitop\"><a href=\"#uwsgitop\" class=\"headerlink\" title=\"uwsgitop\"></a>uwsgitop</h2><blockquote>\n<p>监控工具</p>\n</blockquote>\n<h3 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h3><p>pip install uwsgitop </p>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><p>uwsgitop /tmp/stats.sock</p>\n<h2 id=\"plugins使用\"><a href=\"#plugins使用\" class=\"headerlink\" title=\"plugins使用\"></a>plugins使用</h2><h3 id=\"fastrouter\"><a href=\"#fastrouter\" class=\"headerlink\" title=\"fastrouter\"></a>fastrouter</h3><p>这是一个负载均衡插件，比如说四个uwsgi节点提供服务，这样在nginx上面可以配置成upstream，分流到四个uwsgi服务上，但是如果是上线，或者有一个节点挂掉了怎么办，只能是收到500报警在手动剔除吗？ to yung to sample!! 当然不是，这个时候就用到fastrouter了。<br>看<a href=\"http://uwsgi-docs-cn.readthedocs.io/zh_CN/latest/Fastrouter.html?highlight=fast\" target=\"_blank\" rel=\"external\">官网</a></p>\n<blockquote>\n<p>For advanced setups uWSGI includes the “fastrouter” plugin, a proxy/load-balancer/router speaking the uwsgi protocol. It is built in by default. You can put it between your webserver and real uWSGI instances to have more control over the routing of HTTP requests to your application servers.</p>\n</blockquote>\n<p>它的功能proxy/load-banlance/router<br>简述一下配置：</p>\n<p><strong>nginx配置</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">location /test &#123;</div><div class=\"line\">        include    uwsgi_params;</div><div class=\"line\">        uwsgi_pass 127.0.0.1:3030;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure></p>\n<p><strong>fastrouter-server端配置</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;uwsgi id = &quot;fastrouter&quot;&gt;</div><div class=\"line\">    &lt;fastrouter&gt;127.0.0.1:3030&lt;/fastrouter&gt;</div><div class=\"line\">    &lt;fastrouter-subscription-server&gt;127.0.0.1:3131&lt;/fastrouter-subscription-server&gt;</div><div class=\"line\">    &lt;enable-threads/&gt;</div><div class=\"line\">    &lt;master/&gt;</div><div class=\"line\">    &lt;fastrouter-stats&gt;127.0.0.1:9595&lt;/fastrouter-stats&gt;</div><div class=\"line\">&lt;/uwsgi&gt;</div></pre></td></tr></table></figure></p>\n<ul>\n<li>3030为当前uWSGI fastrouter server的端口，前面的空代表当前主机地址。（nginx会用到这个端口）</li>\n<li>3131fastrouter-subscription-server 表示当前uWSGI fastrouter server的订阅地址。（web应用服务会用到）</li>\n<li>stats：uWSGI的统计服务机制，访问会返回一个json对象，都是<a href=\"http://uwsgi-docs.readthedocs.io/en/latest/StatsServer.html\" target=\"_blank\" rel=\"external\">状态统计信息</a> 格式可以是一个端口，也可以是一个socket</li>\n</ul>\n<p><strong>uwsgi实例配置</strong></p>\n<p>实例1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;uwsgi id = &quot;subserver1&quot;&gt;</div><div class=\"line\">    &lt;stats&gt;127.0.0.1:9393&lt;/stats&gt;</div><div class=\"line\">    &lt;processes&gt;4&lt;/processes&gt;</div><div class=\"line\">    &lt;enable-threads/&gt;</div><div class=\"line\">    &lt;memory-report/&gt;</div><div class=\"line\">    &lt;subscribe-to&gt;127.0.0.1:3131:test&lt;/subscribe-to&gt;</div><div class=\"line\">    &lt;socket&gt;127.0.0.1:3232&lt;/socket&gt;</div><div class=\"line\">    &lt;file&gt;./server.py&lt;/file&gt;</div><div class=\"line\">    &lt;master/&gt;</div><div class=\"line\">    &lt;weight&gt;8&lt;/weight&gt;</div><div class=\"line\">&lt;/uwsgi&gt;</div></pre></td></tr></table></figure></p>\n<p>实例2<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;uwsgi id = &quot;subserver2&quot;&gt;</div><div class=\"line\">    &lt;stats&gt;127.0.0.1:9494&lt;/stats&gt;</div><div class=\"line\">    &lt;processes&gt;4&lt;/processes&gt;</div><div class=\"line\">    &lt;enable-threads/&gt;</div><div class=\"line\">    &lt;memory-report/&gt;</div><div class=\"line\">    &lt;subscribe-to&gt;127.0.0.1:3131:test&lt;/subscribe-to&gt;</div><div class=\"line\">    &lt;socket&gt;127.0.0.1:3333&lt;/socket&gt;</div><div class=\"line\">    &lt;file&gt;./server.py&lt;/file&gt;</div><div class=\"line\">    &lt;master/&gt;</div><div class=\"line\">    &lt;weight&gt;2&lt;/weight&gt;</div><div class=\"line\">&lt;/uwsgi&gt;</div></pre></td></tr></table></figure></p>\n<ul>\n<li><stats>127.0.0.1:9494</stats> 这个可以把9494改为0 则为自动分配 也可以改成socket</li>\n<li><p>我们通过subscribe-to变量来订阅fastrouter server（127.0.0.1:3131）,冒号后跟着的是对应请求的域名，只有来自当前域名的请求才会进入当前web节点。当然这个可以设置多个subscribe-to，例如：subscribe-to=127.0.0.1:3131:test1</p>\n</li>\n<li><p>weight 权重分配</p>\n</li>\n</ul>\n<p>由于我们线上使用的是fastrouter,所以在这儿就只说了这个，其实uwsgi的负载均衡使用不只有这一种手段<br>有兴趣可以看下<a href=\"http://www.cnblogs.com/codeape/p/4064815.html\" target=\"_blank\" rel=\"external\">这篇博文</a></p>\n<h3 id=\"harakiri\"><a href=\"#harakiri\" class=\"headerlink\" title=\"harakiri\"></a>harakiri</h3>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>前言，来公司一年了，对uwsgi的操作，只停留在部署，或者restart，并没有主动配置过，今天看nginx的时候看到nginx(我们的nginx是只转发)的请求是转发的本地某个端口，是个uwsgi提供的fastrouter服务。在此记录一下。</p>\n</blockquote>\n<p>由于我们后端使用的都是Django项目，所以整体都是这个架构<code>nginx</code>–&gt;<code>uwsgi</code>–&gt;<code>django</code>.所以对uwsgi的了解也很重要。<br>fastrouter使用放到后面先说，uwsgi的普通配置。</p>\n<p>版本：uWSGI==2.0.12</p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>WSGI（Python Web Server Gateway Interface，缩写为WSGI） 是一种 Web 服务器网关接口。它是一个 Web 服务器（如 Nginx）与应用服务器（如 uWSGI 服务器）通信的一种规范。<br>uwsgi 是一种协议<br>uWSGI uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。uWSGI，既不用wsgi协议也不用FastCGI协议，而是自创了一个uwsgi的协议，uwsgi协议是一个uWSGI服务器自有的协议，它用于定义传输信息的类型（type of information），每一个uwsgi packet前4byte为传输信息类型描述，它与WSGI相比是两样东西。据说该协议大约是fcgi协议的10倍那么快。</p>\n<p>优点：</p>\n<ul>\n<li>超快的性能。</li>\n<li>低内存占用（实测为apache2的mod_wsgi的一半左右）。</li>\n<li>多app管理。</li>\n<li>详尽的日志功能（可以用来分析app性能和瓶颈）。</li>\n<li>高度可定制（内存大小限制，服务一定次数后重启等）。</li>\n</ul>\n<p>版本：uWSGI==2.0.12</p>\n<h2 id=\"安装配置\"><a href=\"#安装配置\" class=\"headerlink\" title=\"安装配置\"></a>安装配置</h2><p>安装就是直接在virtualenv中pip安装就好了<br>pip install uWSGI</p>\n<h2 id=\"uwsgitop\"><a href=\"#uwsgitop\" class=\"headerlink\" title=\"uwsgitop\"></a>uwsgitop</h2><blockquote>\n<p>监控工具</p>\n</blockquote>\n<h3 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h3><p>pip install uwsgitop </p>\n<h3 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h3><p>uwsgitop /tmp/stats.sock</p>\n<h2 id=\"plugins使用\"><a href=\"#plugins使用\" class=\"headerlink\" title=\"plugins使用\"></a>plugins使用</h2><h3 id=\"fastrouter\"><a href=\"#fastrouter\" class=\"headerlink\" title=\"fastrouter\"></a>fastrouter</h3><p>这是一个负载均衡插件，比如说四个uwsgi节点提供服务，这样在nginx上面可以配置成upstream，分流到四个uwsgi服务上，但是如果是上线，或者有一个节点挂掉了怎么办，只能是收到500报警在手动剔除吗？ to yung to sample!! 当然不是，这个时候就用到fastrouter了。<br>看<a href=\"http://uwsgi-docs-cn.readthedocs.io/zh_CN/latest/Fastrouter.html?highlight=fast\" target=\"_blank\" rel=\"external\">官网</a></p>\n<blockquote>\n<p>For advanced setups uWSGI includes the “fastrouter” plugin, a proxy/load-balancer/router speaking the uwsgi protocol. It is built in by default. You can put it between your webserver and real uWSGI instances to have more control over the routing of HTTP requests to your application servers.</p>\n</blockquote>\n<p>它的功能proxy/load-banlance/router<br>简述一下配置：</p>\n<p><strong>nginx配置</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">location /test &#123;</div><div class=\"line\">        include    uwsgi_params;</div><div class=\"line\">        uwsgi_pass 127.0.0.1:3030;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure></p>\n<p><strong>fastrouter-server端配置</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;uwsgi id = &quot;fastrouter&quot;&gt;</div><div class=\"line\">    &lt;fastrouter&gt;127.0.0.1:3030&lt;/fastrouter&gt;</div><div class=\"line\">    &lt;fastrouter-subscription-server&gt;127.0.0.1:3131&lt;/fastrouter-subscription-server&gt;</div><div class=\"line\">    &lt;enable-threads/&gt;</div><div class=\"line\">    &lt;master/&gt;</div><div class=\"line\">    &lt;fastrouter-stats&gt;127.0.0.1:9595&lt;/fastrouter-stats&gt;</div><div class=\"line\">&lt;/uwsgi&gt;</div></pre></td></tr></table></figure></p>\n<ul>\n<li>3030为当前uWSGI fastrouter server的端口，前面的空代表当前主机地址。（nginx会用到这个端口）</li>\n<li>3131fastrouter-subscription-server 表示当前uWSGI fastrouter server的订阅地址。（web应用服务会用到）</li>\n<li>stats：uWSGI的统计服务机制，访问会返回一个json对象，都是<a href=\"http://uwsgi-docs.readthedocs.io/en/latest/StatsServer.html\" target=\"_blank\" rel=\"external\">状态统计信息</a> 格式可以是一个端口，也可以是一个socket</li>\n</ul>\n<p><strong>uwsgi实例配置</strong></p>\n<p>实例1<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;uwsgi id = &quot;subserver1&quot;&gt;</div><div class=\"line\">    &lt;stats&gt;127.0.0.1:9393&lt;/stats&gt;</div><div class=\"line\">    &lt;processes&gt;4&lt;/processes&gt;</div><div class=\"line\">    &lt;enable-threads/&gt;</div><div class=\"line\">    &lt;memory-report/&gt;</div><div class=\"line\">    &lt;subscribe-to&gt;127.0.0.1:3131:test&lt;/subscribe-to&gt;</div><div class=\"line\">    &lt;socket&gt;127.0.0.1:3232&lt;/socket&gt;</div><div class=\"line\">    &lt;file&gt;./server.py&lt;/file&gt;</div><div class=\"line\">    &lt;master/&gt;</div><div class=\"line\">    &lt;weight&gt;8&lt;/weight&gt;</div><div class=\"line\">&lt;/uwsgi&gt;</div></pre></td></tr></table></figure></p>\n<p>实例2<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;uwsgi id = &quot;subserver2&quot;&gt;</div><div class=\"line\">    &lt;stats&gt;127.0.0.1:9494&lt;/stats&gt;</div><div class=\"line\">    &lt;processes&gt;4&lt;/processes&gt;</div><div class=\"line\">    &lt;enable-threads/&gt;</div><div class=\"line\">    &lt;memory-report/&gt;</div><div class=\"line\">    &lt;subscribe-to&gt;127.0.0.1:3131:test&lt;/subscribe-to&gt;</div><div class=\"line\">    &lt;socket&gt;127.0.0.1:3333&lt;/socket&gt;</div><div class=\"line\">    &lt;file&gt;./server.py&lt;/file&gt;</div><div class=\"line\">    &lt;master/&gt;</div><div class=\"line\">    &lt;weight&gt;2&lt;/weight&gt;</div><div class=\"line\">&lt;/uwsgi&gt;</div></pre></td></tr></table></figure></p>\n<ul>\n<li><stats>127.0.0.1:9494</stats> 这个可以把9494改为0 则为自动分配 也可以改成socket</li>\n<li><p>我们通过subscribe-to变量来订阅fastrouter server（127.0.0.1:3131）,冒号后跟着的是对应请求的域名，只有来自当前域名的请求才会进入当前web节点。当然这个可以设置多个subscribe-to，例如：subscribe-to=127.0.0.1:3131:test1</p>\n</li>\n<li><p>weight 权重分配</p>\n</li>\n</ul>\n<p>由于我们线上使用的是fastrouter,所以在这儿就只说了这个，其实uwsgi的负载均衡使用不只有这一种手段<br>有兴趣可以看下<a href=\"http://www.cnblogs.com/codeape/p/4064815.html\" target=\"_blank\" rel=\"external\">这篇博文</a></p>\n<h3 id=\"harakiri\"><a href=\"#harakiri\" class=\"headerlink\" title=\"harakiri\"></a>harakiri</h3>"},{"title":"zabbix迁移到open-falcon","date":"2017-06-06T09:53:38.000Z","_content":"# falcon 介绍\n>由于zabbix监控的可拓展性不是很高，业务的监控并不是很灵活，所以运维打算换成灵活度更好的open-falcon，他是小米公司推出的一款开源软件，基于go语言开发，安装比较方便。因为有着比较好看及灵活UI所以我们使用起来也是十分方便。但是社区相比zabbix小很多，坑也多一点，毕竟第一个吃螃蟹的人得付出点勇气。\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-06%20%E4%B8%8B%E5%8D%885.57.09.png)\n\n## 优点说明\n\n* 水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询\n\n* 高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用\n\n* 人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值\n\n* 高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟）\n\n* 高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据\n\n* dashboard：多维度的数据展示，用户自定义Screen\n\n* 高可用：整个系统无核心单点，易运维，易部署，可水平扩展\n\n* 开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。\n\n## 组件介绍\n\n### **agent 组件**\n\n    * 监控客户端 相当于zabbix_agent 收集监控数据，提供接口供我们写脚本上传数据\n    * 支持自发现，默认自带很多基本监控，它的自定义监控指标通过HBS（HBS读取portal数据库）获得\n    * 每隔60秒push给Transfer。agent与Transfer建立了长连接，数据发送速度比较快，agent提供了一个http接口/v1/push用于接收用户手工push的一些数据，然后通过长连接迅速转发给Transfer。\n\n### **Aggregater组件**   集群聚合模块。（目前我们还没有应用）\n\n    * 聚合某集群下的所有机器的某个指标的值，比如所有机器的qps加和才是整个集群的qps，所有机器的request_fail数量 ÷ 所有机器的request_total数量=整个集群的请求失败率然后push回监控server端。\n\n### **hbs**（heartbeat Server）组件\n     心跳服务器，公司所有agent都会连到HBS，每分钟发一次心跳请求。\n     agent发送心跳信息给HBS的时候，会把hostname、ip、agent version、plugin version等信息告诉HBS，HBS负责更新host表。 插入到portal数据库中\n \n### **portal组件**\n     Portal是用来配置报警策略的，策略存放于数据库中，通过hbs的读取传递到agent端\n\n### **transfer组件**\n     transfer是数据转发服务。它接收agent上报的数据，然后按照哈希规则进行数据分片、并将分片后的数据分别push给graph&judge等组件。\n\n### **judge组件**\n     Judge用于告警判断，agent将数据push给Transfer，Transfer不但会转发给Graph组件来绘图，还会转发给Judge用于判断是否触发告警。\n\n### **alarm组件**\n     alarm模块是处理报警event的，judge产生的报警event写入redis，alarm从redis读取处理\n\n### **graph组件**\n     graph是存储绘图数据的组件。graph组件 接收transfer组件推送上来的监控数据，同时处理query组件的查询请求、返回绘图数据。\n\n### **query组件**\n     提供统一的绘图数据查询入口。query组件接收查询请求，根据一致性哈希算法去相应的graph实例查询不同metric的数据，然后汇总拿到的数据，最后统一返回给用户。\n\n### **dashboard组件**\n     dashboard是面向用户的查询界面。在这里，用户可以看到push到graph中的所有数据，并查看其趋势图。\n\n### **fe组件**\n     导航界面\n\n### **nodata组件**\n     nodata用于检测监控数据的上报异常。nodata和实时报警judge模块协同工作，过程为: 配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据；用户配置相应的报警策略，收到mock数据就产生报警。采集项上报异常检测，作为judge模块的一个必要补充，能够使judge的实时报警功能更加可靠、完善\n\n### **task组件**\n     task是监控系统一个必要的辅助模块。定时任务，实现了如下几个功能：\n     index更新。包括图表索引的全量更新 和 垃圾索引清理。\n     falcon服务组件的自身状态数据采集。定时任务了采集了transfer、graph、task这三个服务的内部状态数据。\n     falcon自检控任务。\n\n\n# 部署\n> 部署使用的二进制包部署，方便快捷，agent使用ansible安装到所有机器上，设置systemctl启动。其他组件包括redis安装到运维机器上。\n\n参照官网的部署\n这里略过\n\n# 数据采集\n>falcon 数据采集分为以下三种方式\n\n* =基础库= 业务代码加载基础库、服务实例在运行过程中主动采集并push相关数据到agent\n* =nginx_lua_module= 嵌在nginx中主动采集业务相关指标 如状态码次数，QPS，服务可用度等\n* =自定义数据采集=  自己通过脚本push到agent，查看https://git.chunyu.me/op/op_tools/blob/master/op_tools/falcon.py 这个很灵活 可以采集很多东西\n\n## 数据模型\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-09%20%E4%B8%8B%E5%8D%886.27.47.png)\n\n* metric: \n    * 最核心的字段，代表这个数据采集项具体度量的是什么东西，比如内存的使用量、某个接口的调用次数\n* endpoint: \n    * 监控实体，代表metric的主体，比如metric是内存使用量，那么endpoint就表示该metric属于哪台机器，也可以表示某个业务比如medweb，其实endpoint是一个特殊的tag。\n* tags: \n    * 这是一组逗号分隔的键值对，用来对metric进行进一步的描述，比如service=falcon,location=beijing\n* timestamp: \n    * UNIX时间戳，表示产生该数据的时间\n* value: \n    * 整型或者浮点型，代表该metric在指定时间点的取值\n* step: \n    * 整型，表示该数据采集项的汇报周期，这对于后续的监控策略配置、图表展示很重要，必须明确指定\n* counterType: \n    * 只能是COUNTER或者GAUGE二选一，前者表示该采集项为计数器类型，后者表示其为原值；对于计数器类型，告警判定以及图表展示前，会被先计算为速率\n\n\n","source":"_posts/zabbix迁移到open-falcon.md","raw":"---\ntitle: zabbix迁移到open-falcon\ndate: 2017-06-06 17:53:38\ntags: falcon, 监控\ncategories: 监控\n---\n# falcon 介绍\n>由于zabbix监控的可拓展性不是很高，业务的监控并不是很灵活，所以运维打算换成灵活度更好的open-falcon，他是小米公司推出的一款开源软件，基于go语言开发，安装比较方便。因为有着比较好看及灵活UI所以我们使用起来也是十分方便。但是社区相比zabbix小很多，坑也多一点，毕竟第一个吃螃蟹的人得付出点勇气。\n\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-06%20%E4%B8%8B%E5%8D%885.57.09.png)\n\n## 优点说明\n\n* 水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询\n\n* 高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用\n\n* 人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值\n\n* 高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟）\n\n* 高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据\n\n* dashboard：多维度的数据展示，用户自定义Screen\n\n* 高可用：整个系统无核心单点，易运维，易部署，可水平扩展\n\n* 开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。\n\n## 组件介绍\n\n### **agent 组件**\n\n    * 监控客户端 相当于zabbix_agent 收集监控数据，提供接口供我们写脚本上传数据\n    * 支持自发现，默认自带很多基本监控，它的自定义监控指标通过HBS（HBS读取portal数据库）获得\n    * 每隔60秒push给Transfer。agent与Transfer建立了长连接，数据发送速度比较快，agent提供了一个http接口/v1/push用于接收用户手工push的一些数据，然后通过长连接迅速转发给Transfer。\n\n### **Aggregater组件**   集群聚合模块。（目前我们还没有应用）\n\n    * 聚合某集群下的所有机器的某个指标的值，比如所有机器的qps加和才是整个集群的qps，所有机器的request_fail数量 ÷ 所有机器的request_total数量=整个集群的请求失败率然后push回监控server端。\n\n### **hbs**（heartbeat Server）组件\n     心跳服务器，公司所有agent都会连到HBS，每分钟发一次心跳请求。\n     agent发送心跳信息给HBS的时候，会把hostname、ip、agent version、plugin version等信息告诉HBS，HBS负责更新host表。 插入到portal数据库中\n \n### **portal组件**\n     Portal是用来配置报警策略的，策略存放于数据库中，通过hbs的读取传递到agent端\n\n### **transfer组件**\n     transfer是数据转发服务。它接收agent上报的数据，然后按照哈希规则进行数据分片、并将分片后的数据分别push给graph&judge等组件。\n\n### **judge组件**\n     Judge用于告警判断，agent将数据push给Transfer，Transfer不但会转发给Graph组件来绘图，还会转发给Judge用于判断是否触发告警。\n\n### **alarm组件**\n     alarm模块是处理报警event的，judge产生的报警event写入redis，alarm从redis读取处理\n\n### **graph组件**\n     graph是存储绘图数据的组件。graph组件 接收transfer组件推送上来的监控数据，同时处理query组件的查询请求、返回绘图数据。\n\n### **query组件**\n     提供统一的绘图数据查询入口。query组件接收查询请求，根据一致性哈希算法去相应的graph实例查询不同metric的数据，然后汇总拿到的数据，最后统一返回给用户。\n\n### **dashboard组件**\n     dashboard是面向用户的查询界面。在这里，用户可以看到push到graph中的所有数据，并查看其趋势图。\n\n### **fe组件**\n     导航界面\n\n### **nodata组件**\n     nodata用于检测监控数据的上报异常。nodata和实时报警judge模块协同工作，过程为: 配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据；用户配置相应的报警策略，收到mock数据就产生报警。采集项上报异常检测，作为judge模块的一个必要补充，能够使judge的实时报警功能更加可靠、完善\n\n### **task组件**\n     task是监控系统一个必要的辅助模块。定时任务，实现了如下几个功能：\n     index更新。包括图表索引的全量更新 和 垃圾索引清理。\n     falcon服务组件的自身状态数据采集。定时任务了采集了transfer、graph、task这三个服务的内部状态数据。\n     falcon自检控任务。\n\n\n# 部署\n> 部署使用的二进制包部署，方便快捷，agent使用ansible安装到所有机器上，设置systemctl启动。其他组件包括redis安装到运维机器上。\n\n参照官网的部署\n这里略过\n\n# 数据采集\n>falcon 数据采集分为以下三种方式\n\n* =基础库= 业务代码加载基础库、服务实例在运行过程中主动采集并push相关数据到agent\n* =nginx_lua_module= 嵌在nginx中主动采集业务相关指标 如状态码次数，QPS，服务可用度等\n* =自定义数据采集=  自己通过脚本push到agent，查看https://git.chunyu.me/op/op_tools/blob/master/op_tools/falcon.py 这个很灵活 可以采集很多东西\n\n## 数据模型\n![](http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-09%20%E4%B8%8B%E5%8D%886.27.47.png)\n\n* metric: \n    * 最核心的字段，代表这个数据采集项具体度量的是什么东西，比如内存的使用量、某个接口的调用次数\n* endpoint: \n    * 监控实体，代表metric的主体，比如metric是内存使用量，那么endpoint就表示该metric属于哪台机器，也可以表示某个业务比如medweb，其实endpoint是一个特殊的tag。\n* tags: \n    * 这是一组逗号分隔的键值对，用来对metric进行进一步的描述，比如service=falcon,location=beijing\n* timestamp: \n    * UNIX时间戳，表示产生该数据的时间\n* value: \n    * 整型或者浮点型，代表该metric在指定时间点的取值\n* step: \n    * 整型，表示该数据采集项的汇报周期，这对于后续的监控策略配置、图表展示很重要，必须明确指定\n* counterType: \n    * 只能是COUNTER或者GAUGE二选一，前者表示该采集项为计数器类型，后者表示其为原值；对于计数器类型，告警判定以及图表展示前，会被先计算为速率\n\n\n","slug":"zabbix迁移到open-falcon","published":1,"updated":"2017-08-03T07:42:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvcb003p8tzzyx8ozi67","content":"<h1 id=\"falcon-介绍\"><a href=\"#falcon-介绍\" class=\"headerlink\" title=\"falcon 介绍\"></a>falcon 介绍</h1><blockquote>\n<p>由于zabbix监控的可拓展性不是很高，业务的监控并不是很灵活，所以运维打算换成灵活度更好的open-falcon，他是小米公司推出的一款开源软件，基于go语言开发，安装比较方便。因为有着比较好看及灵活UI所以我们使用起来也是十分方便。但是社区相比zabbix小很多，坑也多一点，毕竟第一个吃螃蟹的人得付出点勇气。</p>\n</blockquote>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-06%20%E4%B8%8B%E5%8D%885.57.09.png\" alt=\"\"></p>\n<h2 id=\"优点说明\"><a href=\"#优点说明\" class=\"headerlink\" title=\"优点说明\"></a>优点说明</h2><ul>\n<li><p>水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询</p>\n</li>\n<li><p>高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用</p>\n</li>\n<li><p>人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值</p>\n</li>\n<li><p>高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟）</p>\n</li>\n<li><p>高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据</p>\n</li>\n<li><p>dashboard：多维度的数据展示，用户自定义Screen</p>\n</li>\n<li><p>高可用：整个系统无核心单点，易运维，易部署，可水平扩展</p>\n</li>\n<li><p>开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。</p>\n</li>\n</ul>\n<h2 id=\"组件介绍\"><a href=\"#组件介绍\" class=\"headerlink\" title=\"组件介绍\"></a>组件介绍</h2><h3 id=\"agent-组件\"><a href=\"#agent-组件\" class=\"headerlink\" title=\"agent 组件\"></a><strong>agent 组件</strong></h3><pre><code>* 监控客户端 相当于zabbix_agent 收集监控数据，提供接口供我们写脚本上传数据\n* 支持自发现，默认自带很多基本监控，它的自定义监控指标通过HBS（HBS读取portal数据库）获得\n* 每隔60秒push给Transfer。agent与Transfer建立了长连接，数据发送速度比较快，agent提供了一个http接口/v1/push用于接收用户手工push的一些数据，然后通过长连接迅速转发给Transfer。\n</code></pre><h3 id=\"aggregater组件-集群聚合模块-目前我们还没有应用\"><a href=\"#Aggregater组件-集群聚合模块。（目前我们还没有应用）\" class=\"headerlink\" title=\"Aggregater组件   集群聚合模块。（目前我们还没有应用）\"></a><strong>Aggregater组件</strong>   集群聚合模块。（目前我们还没有应用）</h3><pre><code>* 聚合某集群下的所有机器的某个指标的值，比如所有机器的qps加和才是整个集群的qps，所有机器的request_fail数量 ÷ 所有机器的request_total数量=整个集群的请求失败率然后push回监控server端。\n</code></pre><h3 id=\"hbsheartbeat-server组件\"><a href=\"#hbs（heartbeat-Server）组件\" class=\"headerlink\" title=\"hbs（heartbeat Server）组件\"></a><strong>hbs</strong>（heartbeat Server）组件</h3><pre><code>心跳服务器，公司所有agent都会连到HBS，每分钟发一次心跳请求。\nagent发送心跳信息给HBS的时候，会把hostname、ip、agent version、plugin version等信息告诉HBS，HBS负责更新host表。 插入到portal数据库中\n</code></pre><h3 id=\"portal组件\"><a href=\"#portal组件\" class=\"headerlink\" title=\"portal组件\"></a><strong>portal组件</strong></h3><pre><code>Portal是用来配置报警策略的，策略存放于数据库中，通过hbs的读取传递到agent端\n</code></pre><h3 id=\"transfer组件\"><a href=\"#transfer组件\" class=\"headerlink\" title=\"transfer组件\"></a><strong>transfer组件</strong></h3><pre><code>transfer是数据转发服务。它接收agent上报的数据，然后按照哈希规则进行数据分片、并将分片后的数据分别push给graph&amp;judge等组件。\n</code></pre><h3 id=\"judge组件\"><a href=\"#judge组件\" class=\"headerlink\" title=\"judge组件\"></a><strong>judge组件</strong></h3><pre><code>Judge用于告警判断，agent将数据push给Transfer，Transfer不但会转发给Graph组件来绘图，还会转发给Judge用于判断是否触发告警。\n</code></pre><h3 id=\"alarm组件\"><a href=\"#alarm组件\" class=\"headerlink\" title=\"alarm组件\"></a><strong>alarm组件</strong></h3><pre><code>alarm模块是处理报警event的，judge产生的报警event写入redis，alarm从redis读取处理\n</code></pre><h3 id=\"graph组件\"><a href=\"#graph组件\" class=\"headerlink\" title=\"graph组件\"></a><strong>graph组件</strong></h3><pre><code>graph是存储绘图数据的组件。graph组件 接收transfer组件推送上来的监控数据，同时处理query组件的查询请求、返回绘图数据。\n</code></pre><h3 id=\"query组件\"><a href=\"#query组件\" class=\"headerlink\" title=\"query组件\"></a><strong>query组件</strong></h3><pre><code>提供统一的绘图数据查询入口。query组件接收查询请求，根据一致性哈希算法去相应的graph实例查询不同metric的数据，然后汇总拿到的数据，最后统一返回给用户。\n</code></pre><h3 id=\"dashboard组件\"><a href=\"#dashboard组件\" class=\"headerlink\" title=\"dashboard组件\"></a><strong>dashboard组件</strong></h3><pre><code>dashboard是面向用户的查询界面。在这里，用户可以看到push到graph中的所有数据，并查看其趋势图。\n</code></pre><h3 id=\"fe组件\"><a href=\"#fe组件\" class=\"headerlink\" title=\"fe组件\"></a><strong>fe组件</strong></h3><pre><code>导航界面\n</code></pre><h3 id=\"nodata组件\"><a href=\"#nodata组件\" class=\"headerlink\" title=\"nodata组件\"></a><strong>nodata组件</strong></h3><pre><code>nodata用于检测监控数据的上报异常。nodata和实时报警judge模块协同工作，过程为: 配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据；用户配置相应的报警策略，收到mock数据就产生报警。采集项上报异常检测，作为judge模块的一个必要补充，能够使judge的实时报警功能更加可靠、完善\n</code></pre><h3 id=\"task组件\"><a href=\"#task组件\" class=\"headerlink\" title=\"task组件\"></a><strong>task组件</strong></h3><pre><code>task是监控系统一个必要的辅助模块。定时任务，实现了如下几个功能：\nindex更新。包括图表索引的全量更新 和 垃圾索引清理。\nfalcon服务组件的自身状态数据采集。定时任务了采集了transfer、graph、task这三个服务的内部状态数据。\nfalcon自检控任务。\n</code></pre><h1 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h1><blockquote>\n<p>部署使用的二进制包部署，方便快捷，agent使用ansible安装到所有机器上，设置systemctl启动。其他组件包括redis安装到运维机器上。</p>\n</blockquote>\n<p>参照官网的部署<br>这里略过</p>\n<h1 id=\"数据采集\"><a href=\"#数据采集\" class=\"headerlink\" title=\"数据采集\"></a>数据采集</h1><blockquote>\n<p>falcon 数据采集分为以下三种方式</p>\n</blockquote>\n<ul>\n<li>=基础库= 业务代码加载基础库、服务实例在运行过程中主动采集并push相关数据到agent</li>\n<li>=nginx_lua_module= 嵌在nginx中主动采集业务相关指标 如状态码次数，QPS，服务可用度等</li>\n<li>=自定义数据采集=  自己通过脚本push到agent，查看<a href=\"https://git.chunyu.me/op/op_tools/blob/master/op_tools/falcon.py\" target=\"_blank\" rel=\"external\">https://git.chunyu.me/op/op_tools/blob/master/op_tools/falcon.py</a> 这个很灵活 可以采集很多东西</li>\n</ul>\n<h2 id=\"数据模型\"><a href=\"#数据模型\" class=\"headerlink\" title=\"数据模型\"></a>数据模型</h2><p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-09%20%E4%B8%8B%E5%8D%886.27.47.png\" alt=\"\"></p>\n<ul>\n<li>metric: <ul>\n<li>最核心的字段，代表这个数据采集项具体度量的是什么东西，比如内存的使用量、某个接口的调用次数</li>\n</ul>\n</li>\n<li>endpoint: <ul>\n<li>监控实体，代表metric的主体，比如metric是内存使用量，那么endpoint就表示该metric属于哪台机器，也可以表示某个业务比如medweb，其实endpoint是一个特殊的tag。</li>\n</ul>\n</li>\n<li>tags: <ul>\n<li>这是一组逗号分隔的键值对，用来对metric进行进一步的描述，比如service=falcon,location=beijing</li>\n</ul>\n</li>\n<li>timestamp: <ul>\n<li>UNIX时间戳，表示产生该数据的时间</li>\n</ul>\n</li>\n<li>value: <ul>\n<li>整型或者浮点型，代表该metric在指定时间点的取值</li>\n</ul>\n</li>\n<li>step: <ul>\n<li>整型，表示该数据采集项的汇报周期，这对于后续的监控策略配置、图表展示很重要，必须明确指定</li>\n</ul>\n</li>\n<li>counterType: <ul>\n<li>只能是COUNTER或者GAUGE二选一，前者表示该采集项为计数器类型，后者表示其为原值；对于计数器类型，告警判定以及图表展示前，会被先计算为速率</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"falcon-介绍\"><a href=\"#falcon-介绍\" class=\"headerlink\" title=\"falcon 介绍\"></a>falcon 介绍</h1><blockquote>\n<p>由于zabbix监控的可拓展性不是很高，业务的监控并不是很灵活，所以运维打算换成灵活度更好的open-falcon，他是小米公司推出的一款开源软件，基于go语言开发，安装比较方便。因为有着比较好看及灵活UI所以我们使用起来也是十分方便。但是社区相比zabbix小很多，坑也多一点，毕竟第一个吃螃蟹的人得付出点勇气。</p>\n</blockquote>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-06%20%E4%B8%8B%E5%8D%885.57.09.png\" alt=\"\"></p>\n<h2 id=\"优点说明\"><a href=\"#优点说明\" class=\"headerlink\" title=\"优点说明\"></a>优点说明</h2><ul>\n<li><p>水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询</p>\n</li>\n<li><p>高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用</p>\n</li>\n<li><p>人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值</p>\n</li>\n<li><p>高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟）</p>\n</li>\n<li><p>高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据</p>\n</li>\n<li><p>dashboard：多维度的数据展示，用户自定义Screen</p>\n</li>\n<li><p>高可用：整个系统无核心单点，易运维，易部署，可水平扩展</p>\n</li>\n<li><p>开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。</p>\n</li>\n</ul>\n<h2 id=\"组件介绍\"><a href=\"#组件介绍\" class=\"headerlink\" title=\"组件介绍\"></a>组件介绍</h2><h3 id=\"agent-组件\"><a href=\"#agent-组件\" class=\"headerlink\" title=\"agent 组件\"></a><strong>agent 组件</strong></h3><pre><code>* 监控客户端 相当于zabbix_agent 收集监控数据，提供接口供我们写脚本上传数据\n* 支持自发现，默认自带很多基本监控，它的自定义监控指标通过HBS（HBS读取portal数据库）获得\n* 每隔60秒push给Transfer。agent与Transfer建立了长连接，数据发送速度比较快，agent提供了一个http接口/v1/push用于接收用户手工push的一些数据，然后通过长连接迅速转发给Transfer。\n</code></pre><h3 id=\"Aggregater组件-集群聚合模块。（目前我们还没有应用）\"><a href=\"#Aggregater组件-集群聚合模块。（目前我们还没有应用）\" class=\"headerlink\" title=\"Aggregater组件   集群聚合模块。（目前我们还没有应用）\"></a><strong>Aggregater组件</strong>   集群聚合模块。（目前我们还没有应用）</h3><pre><code>* 聚合某集群下的所有机器的某个指标的值，比如所有机器的qps加和才是整个集群的qps，所有机器的request_fail数量 ÷ 所有机器的request_total数量=整个集群的请求失败率然后push回监控server端。\n</code></pre><h3 id=\"hbs（heartbeat-Server）组件\"><a href=\"#hbs（heartbeat-Server）组件\" class=\"headerlink\" title=\"hbs（heartbeat Server）组件\"></a><strong>hbs</strong>（heartbeat Server）组件</h3><pre><code>心跳服务器，公司所有agent都会连到HBS，每分钟发一次心跳请求。\nagent发送心跳信息给HBS的时候，会把hostname、ip、agent version、plugin version等信息告诉HBS，HBS负责更新host表。 插入到portal数据库中\n</code></pre><h3 id=\"portal组件\"><a href=\"#portal组件\" class=\"headerlink\" title=\"portal组件\"></a><strong>portal组件</strong></h3><pre><code>Portal是用来配置报警策略的，策略存放于数据库中，通过hbs的读取传递到agent端\n</code></pre><h3 id=\"transfer组件\"><a href=\"#transfer组件\" class=\"headerlink\" title=\"transfer组件\"></a><strong>transfer组件</strong></h3><pre><code>transfer是数据转发服务。它接收agent上报的数据，然后按照哈希规则进行数据分片、并将分片后的数据分别push给graph&amp;judge等组件。\n</code></pre><h3 id=\"judge组件\"><a href=\"#judge组件\" class=\"headerlink\" title=\"judge组件\"></a><strong>judge组件</strong></h3><pre><code>Judge用于告警判断，agent将数据push给Transfer，Transfer不但会转发给Graph组件来绘图，还会转发给Judge用于判断是否触发告警。\n</code></pre><h3 id=\"alarm组件\"><a href=\"#alarm组件\" class=\"headerlink\" title=\"alarm组件\"></a><strong>alarm组件</strong></h3><pre><code>alarm模块是处理报警event的，judge产生的报警event写入redis，alarm从redis读取处理\n</code></pre><h3 id=\"graph组件\"><a href=\"#graph组件\" class=\"headerlink\" title=\"graph组件\"></a><strong>graph组件</strong></h3><pre><code>graph是存储绘图数据的组件。graph组件 接收transfer组件推送上来的监控数据，同时处理query组件的查询请求、返回绘图数据。\n</code></pre><h3 id=\"query组件\"><a href=\"#query组件\" class=\"headerlink\" title=\"query组件\"></a><strong>query组件</strong></h3><pre><code>提供统一的绘图数据查询入口。query组件接收查询请求，根据一致性哈希算法去相应的graph实例查询不同metric的数据，然后汇总拿到的数据，最后统一返回给用户。\n</code></pre><h3 id=\"dashboard组件\"><a href=\"#dashboard组件\" class=\"headerlink\" title=\"dashboard组件\"></a><strong>dashboard组件</strong></h3><pre><code>dashboard是面向用户的查询界面。在这里，用户可以看到push到graph中的所有数据，并查看其趋势图。\n</code></pre><h3 id=\"fe组件\"><a href=\"#fe组件\" class=\"headerlink\" title=\"fe组件\"></a><strong>fe组件</strong></h3><pre><code>导航界面\n</code></pre><h3 id=\"nodata组件\"><a href=\"#nodata组件\" class=\"headerlink\" title=\"nodata组件\"></a><strong>nodata组件</strong></h3><pre><code>nodata用于检测监控数据的上报异常。nodata和实时报警judge模块协同工作，过程为: 配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据；用户配置相应的报警策略，收到mock数据就产生报警。采集项上报异常检测，作为judge模块的一个必要补充，能够使judge的实时报警功能更加可靠、完善\n</code></pre><h3 id=\"task组件\"><a href=\"#task组件\" class=\"headerlink\" title=\"task组件\"></a><strong>task组件</strong></h3><pre><code>task是监控系统一个必要的辅助模块。定时任务，实现了如下几个功能：\nindex更新。包括图表索引的全量更新 和 垃圾索引清理。\nfalcon服务组件的自身状态数据采集。定时任务了采集了transfer、graph、task这三个服务的内部状态数据。\nfalcon自检控任务。\n</code></pre><h1 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h1><blockquote>\n<p>部署使用的二进制包部署，方便快捷，agent使用ansible安装到所有机器上，设置systemctl启动。其他组件包括redis安装到运维机器上。</p>\n</blockquote>\n<p>参照官网的部署<br>这里略过</p>\n<h1 id=\"数据采集\"><a href=\"#数据采集\" class=\"headerlink\" title=\"数据采集\"></a>数据采集</h1><blockquote>\n<p>falcon 数据采集分为以下三种方式</p>\n</blockquote>\n<ul>\n<li>=基础库= 业务代码加载基础库、服务实例在运行过程中主动采集并push相关数据到agent</li>\n<li>=nginx_lua_module= 嵌在nginx中主动采集业务相关指标 如状态码次数，QPS，服务可用度等</li>\n<li>=自定义数据采集=  自己通过脚本push到agent，查看<a href=\"https://git.chunyu.me/op/op_tools/blob/master/op_tools/falcon.py\" target=\"_blank\" rel=\"external\">https://git.chunyu.me/op/op_tools/blob/master/op_tools/falcon.py</a> 这个很灵活 可以采集很多东西</li>\n</ul>\n<h2 id=\"数据模型\"><a href=\"#数据模型\" class=\"headerlink\" title=\"数据模型\"></a>数据模型</h2><p><img src=\"http://or2jd66dq.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-09%20%E4%B8%8B%E5%8D%886.27.47.png\" alt=\"\"></p>\n<ul>\n<li>metric: <ul>\n<li>最核心的字段，代表这个数据采集项具体度量的是什么东西，比如内存的使用量、某个接口的调用次数</li>\n</ul>\n</li>\n<li>endpoint: <ul>\n<li>监控实体，代表metric的主体，比如metric是内存使用量，那么endpoint就表示该metric属于哪台机器，也可以表示某个业务比如medweb，其实endpoint是一个特殊的tag。</li>\n</ul>\n</li>\n<li>tags: <ul>\n<li>这是一组逗号分隔的键值对，用来对metric进行进一步的描述，比如service=falcon,location=beijing</li>\n</ul>\n</li>\n<li>timestamp: <ul>\n<li>UNIX时间戳，表示产生该数据的时间</li>\n</ul>\n</li>\n<li>value: <ul>\n<li>整型或者浮点型，代表该metric在指定时间点的取值</li>\n</ul>\n</li>\n<li>step: <ul>\n<li>整型，表示该数据采集项的汇报周期，这对于后续的监控策略配置、图表展示很重要，必须明确指定</li>\n</ul>\n</li>\n<li>counterType: <ul>\n<li>只能是COUNTER或者GAUGE二选一，前者表示该采集项为计数器类型，后者表示其为原值；对于计数器类型，告警判定以及图表展示前，会被先计算为速率</li>\n</ul>\n</li>\n</ul>\n"},{"title":"几种mysql迁移","date":"2017-06-16T04:12:23.000Z","_content":"\n> 运维在日常免不了迁移服务，而迁移服务又免不了迁移数据库。 通常情况下数据库还比较重要，所以怎么样平滑的迁移数据库就显得很重要。\n> 我在前段时间迁移了青云几台机器的服务，其中涉及到一些MySQL数据库的操作，做了些记录。\n\n-------\n\n## mysqldump\n\n> 这是比较常见，一般数据库数据量很小的时候，首要我们就会考虑这个。\n`优点`:在于能够与正在运行的 MySQL 自动协同工作，支持备份 InnoDB 以及 MyISAM 表；锁表既是优点又是缺点，看怎么看待；\n`缺点`:在于数据量大，备份速度慢；\n\n这次服务迁移 中涉及到我们的OA系统，之前是部署在一个windows-server上的。\n### 需求\n1. windows 上mysql迁移到 centos7  \n2. 之前单实例换为双主(haproxy代理)\n\n### 迁移具体过程\n在centos7机器 \n直接远程dump\n```\n mysqldump -h117.******* -uoa -p oa --flush-logs --single-transaction | mysql -h localhost -uoa -p -P3314 -S /home/mysql/3314/mysql.sock v50\n```\n\n`--flush-logs`\n在开始导出前刷新服务器的日志文件。注意，如果你一次性导出很多数据库（使用 -databases=或--all-databases选项），导出每个库时都会触发日志刷新。例外是当使用了--lock-all-tables或--master-data时：日志只会被刷新一次，那个时候所有表都会被锁住。所以如果你希望你的导出和日志刷新发生在同一个确定的时刻，你需要使用--lock-all-tables，或者--master-data配合--flush-logs。\n\n`--single-transaction`\nInnoDB 表在备份时，通常启用选项 --single-transaction 来保证备份的一致性，实际上它的工作原理是设定本次会话的隔离级别为：REPEATABLE READ，以确保本次会话(dump)时，不会看到其他会话已经提交了的数据。\n\n之后查看windows机器的bin-log日志，查看在备份时间节点新的bin-log文件\n![](http://or2jd66dq.bkt.clouddn.com/windows_binlog.png)\n\n之后建立两个mysql主从(期间我centos7机器的mysql双主已经使用ansible搭建成功在此省略)\n\nwindows——MySQL 授权\n```\n设置chunyu账号负责数据同步\nGRANT REPLICATION SLAVE,RELOAD,SUPER ON *.* TO 'chunyu'@'%' IDENTIFIED BY '123';\nFLUSH PRIVILEGES ;\n```\n\ncentos7_1 停掉双主中自己slave角色，重新设置master\n```\nSTOP SLAVE;\nRESET SLAVE;\nchange master to master_host='117.****',master_port=3306,master_user='chunyu',master_password='123',master_log_file='mysql-bin.000008',master_log_pos=120;\nstart slave;\nshow slave status;\n```\n\n因为centos是双主，所以需要先断掉这台机的slave，另一台centos不用操作，这样双主变成了主从，在设置windows——MySQL为主此时关系应该是:\nwin_mysql(master) centos7_1(slave)\ncentos7_1(master) centos7_2(slave)\n\n之后服务迁移完之后，可以再设置回双主此处省略。\n\n\n\n## percona-xtrabackup\n\n> 这台是redmine的数据库数据比较多，部署在ubuntu上。数据量大可以使用xtrabackup 热备份。\n\n`优点`: 可靠高效的备份DB;备份过程中不中断事务处理，热备份;快速进行恢复等。\n`缺点`:\n\n### 需求\n1. ubuntu上mysql迁移到centos7 mysql\n2. 之前单实例换为双主(haproxy代理)\n\n### 操作过程\n\n> 也是先备份传输，建立主从，恢复双主。\n\n\nubuntu上 备份\n```\napt-get install percona-xtrabackup\ninnobackupex --user=root --password=123 ./\ntar -czvf mysql_back.tar.gz 2017-04-25_10-58-40\n```\n\ncentos7 传输 解压 放到相应目录\n```\nrsync -auvzP --bwlimit=5000 root@117.****:/mnt/sdc/mysql_back.tar.gz ./\ncd /home/mysql/ && mv data/data_back\ntar -zxvf mysql_back.tar.gz \nmv 2017-04-25_10-58-40/ data\nchown -R mysql:mysql data\n```\n\npostion点查看:\n```\n[root@test_biz 2017-06-16_15-39-01]# cat xtrabackup_binlog_info\nmysql-bin.000054    57952335\n```\n\n\n之后主从设置 迁移完服务之后恢复双主。\n\n\n\n\n\n","source":"_posts/几种mysql迁移.md","raw":"---\ntitle: 几种mysql迁移\ndate: 2017-06-16 12:12:23\ntags: MySQL\ncategories: 数据库\n---\n\n> 运维在日常免不了迁移服务，而迁移服务又免不了迁移数据库。 通常情况下数据库还比较重要，所以怎么样平滑的迁移数据库就显得很重要。\n> 我在前段时间迁移了青云几台机器的服务，其中涉及到一些MySQL数据库的操作，做了些记录。\n\n-------\n\n## mysqldump\n\n> 这是比较常见，一般数据库数据量很小的时候，首要我们就会考虑这个。\n`优点`:在于能够与正在运行的 MySQL 自动协同工作，支持备份 InnoDB 以及 MyISAM 表；锁表既是优点又是缺点，看怎么看待；\n`缺点`:在于数据量大，备份速度慢；\n\n这次服务迁移 中涉及到我们的OA系统，之前是部署在一个windows-server上的。\n### 需求\n1. windows 上mysql迁移到 centos7  \n2. 之前单实例换为双主(haproxy代理)\n\n### 迁移具体过程\n在centos7机器 \n直接远程dump\n```\n mysqldump -h117.******* -uoa -p oa --flush-logs --single-transaction | mysql -h localhost -uoa -p -P3314 -S /home/mysql/3314/mysql.sock v50\n```\n\n`--flush-logs`\n在开始导出前刷新服务器的日志文件。注意，如果你一次性导出很多数据库（使用 -databases=或--all-databases选项），导出每个库时都会触发日志刷新。例外是当使用了--lock-all-tables或--master-data时：日志只会被刷新一次，那个时候所有表都会被锁住。所以如果你希望你的导出和日志刷新发生在同一个确定的时刻，你需要使用--lock-all-tables，或者--master-data配合--flush-logs。\n\n`--single-transaction`\nInnoDB 表在备份时，通常启用选项 --single-transaction 来保证备份的一致性，实际上它的工作原理是设定本次会话的隔离级别为：REPEATABLE READ，以确保本次会话(dump)时，不会看到其他会话已经提交了的数据。\n\n之后查看windows机器的bin-log日志，查看在备份时间节点新的bin-log文件\n![](http://or2jd66dq.bkt.clouddn.com/windows_binlog.png)\n\n之后建立两个mysql主从(期间我centos7机器的mysql双主已经使用ansible搭建成功在此省略)\n\nwindows——MySQL 授权\n```\n设置chunyu账号负责数据同步\nGRANT REPLICATION SLAVE,RELOAD,SUPER ON *.* TO 'chunyu'@'%' IDENTIFIED BY '123';\nFLUSH PRIVILEGES ;\n```\n\ncentos7_1 停掉双主中自己slave角色，重新设置master\n```\nSTOP SLAVE;\nRESET SLAVE;\nchange master to master_host='117.****',master_port=3306,master_user='chunyu',master_password='123',master_log_file='mysql-bin.000008',master_log_pos=120;\nstart slave;\nshow slave status;\n```\n\n因为centos是双主，所以需要先断掉这台机的slave，另一台centos不用操作，这样双主变成了主从，在设置windows——MySQL为主此时关系应该是:\nwin_mysql(master) centos7_1(slave)\ncentos7_1(master) centos7_2(slave)\n\n之后服务迁移完之后，可以再设置回双主此处省略。\n\n\n\n## percona-xtrabackup\n\n> 这台是redmine的数据库数据比较多，部署在ubuntu上。数据量大可以使用xtrabackup 热备份。\n\n`优点`: 可靠高效的备份DB;备份过程中不中断事务处理，热备份;快速进行恢复等。\n`缺点`:\n\n### 需求\n1. ubuntu上mysql迁移到centos7 mysql\n2. 之前单实例换为双主(haproxy代理)\n\n### 操作过程\n\n> 也是先备份传输，建立主从，恢复双主。\n\n\nubuntu上 备份\n```\napt-get install percona-xtrabackup\ninnobackupex --user=root --password=123 ./\ntar -czvf mysql_back.tar.gz 2017-04-25_10-58-40\n```\n\ncentos7 传输 解压 放到相应目录\n```\nrsync -auvzP --bwlimit=5000 root@117.****:/mnt/sdc/mysql_back.tar.gz ./\ncd /home/mysql/ && mv data/data_back\ntar -zxvf mysql_back.tar.gz \nmv 2017-04-25_10-58-40/ data\nchown -R mysql:mysql data\n```\n\npostion点查看:\n```\n[root@test_biz 2017-06-16_15-39-01]# cat xtrabackup_binlog_info\nmysql-bin.000054    57952335\n```\n\n\n之后主从设置 迁移完服务之后恢复双主。\n\n\n\n\n\n","slug":"几种mysql迁移","published":1,"updated":"2017-06-30T08:06:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvcc003s8tzzr6zfv426","content":"<blockquote>\n<p>运维在日常免不了迁移服务，而迁移服务又免不了迁移数据库。 通常情况下数据库还比较重要，所以怎么样平滑的迁移数据库就显得很重要。<br>我在前段时间迁移了青云几台机器的服务，其中涉及到一些MySQL数据库的操作，做了些记录。</p>\n</blockquote>\n<hr>\n<h2 id=\"mysqldump\"><a href=\"#mysqldump\" class=\"headerlink\" title=\"mysqldump\"></a>mysqldump</h2><blockquote>\n<p>这是比较常见，一般数据库数据量很小的时候，首要我们就会考虑这个。<br><code>优点</code>:在于能够与正在运行的 MySQL 自动协同工作，支持备份 InnoDB 以及 MyISAM 表；锁表既是优点又是缺点，看怎么看待；<br><code>缺点</code>:在于数据量大，备份速度慢；</p>\n</blockquote>\n<p>这次服务迁移 中涉及到我们的OA系统，之前是部署在一个windows-server上的。</p>\n<h3 id=\"需求\"><a href=\"#需求\" class=\"headerlink\" title=\"需求\"></a>需求</h3><ol>\n<li>windows 上mysql迁移到 centos7  </li>\n<li>之前单实例换为双主(haproxy代理)</li>\n</ol>\n<h3 id=\"迁移具体过程\"><a href=\"#迁移具体过程\" class=\"headerlink\" title=\"迁移具体过程\"></a>迁移具体过程</h3><p>在centos7机器<br>直接远程dump<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysqldump -h117.******* -uoa -p oa --flush-logs --single-transaction | mysql -h localhost -uoa -p -P3314 -S /home/mysql/3314/mysql.sock v50</div></pre></td></tr></table></figure></p>\n<p><code>--flush-logs</code><br>在开始导出前刷新服务器的日志文件。注意，如果你一次性导出很多数据库（使用 -databases=或–all-databases选项），导出每个库时都会触发日志刷新。例外是当使用了–lock-all-tables或–master-data时：日志只会被刷新一次，那个时候所有表都会被锁住。所以如果你希望你的导出和日志刷新发生在同一个确定的时刻，你需要使用–lock-all-tables，或者–master-data配合–flush-logs。</p>\n<p><code>--single-transaction</code><br>InnoDB 表在备份时，通常启用选项 –single-transaction 来保证备份的一致性，实际上它的工作原理是设定本次会话的隔离级别为：REPEATABLE READ，以确保本次会话(dump)时，不会看到其他会话已经提交了的数据。</p>\n<p>之后查看windows机器的bin-log日志，查看在备份时间节点新的bin-log文件<br><img src=\"http://or2jd66dq.bkt.clouddn.com/windows_binlog.png\" alt=\"\"></p>\n<p>之后建立两个mysql主从(期间我centos7机器的mysql双主已经使用ansible搭建成功在此省略)</p>\n<p>windows——MySQL 授权<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">设置chunyu账号负责数据同步</div><div class=\"line\">GRANT REPLICATION SLAVE,RELOAD,SUPER ON *.* TO &apos;chunyu&apos;@&apos;%&apos; IDENTIFIED BY &apos;123&apos;;</div><div class=\"line\">FLUSH PRIVILEGES ;</div></pre></td></tr></table></figure></p>\n<p>centos7_1 停掉双主中自己slave角色，重新设置master<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">STOP SLAVE;</div><div class=\"line\">RESET SLAVE;</div><div class=\"line\">change master to master_host=&apos;117.****&apos;,master_port=3306,master_user=&apos;chunyu&apos;,master_password=&apos;123&apos;,master_log_file=&apos;mysql-bin.000008&apos;,master_log_pos=120;</div><div class=\"line\">start slave;</div><div class=\"line\">show slave status;</div></pre></td></tr></table></figure></p>\n<p>因为centos是双主，所以需要先断掉这台机的slave，另一台centos不用操作，这样双主变成了主从，在设置windows——MySQL为主此时关系应该是:<br>win_mysql(master) centos7_1(slave)<br>centos7_1(master) centos7_2(slave)</p>\n<p>之后服务迁移完之后，可以再设置回双主此处省略。</p>\n<h2 id=\"percona-xtrabackup\"><a href=\"#percona-xtrabackup\" class=\"headerlink\" title=\"percona-xtrabackup\"></a>percona-xtrabackup</h2><blockquote>\n<p>这台是redmine的数据库数据比较多，部署在ubuntu上。数据量大可以使用xtrabackup 热备份。</p>\n</blockquote>\n<p><code>优点</code>: 可靠高效的备份DB;备份过程中不中断事务处理，热备份;快速进行恢复等。<br><code>缺点</code>:</p>\n<h3 id=\"需求\"><a href=\"#需求-1\" class=\"headerlink\" title=\"需求\"></a>需求</h3><ol>\n<li>ubuntu上mysql迁移到centos7 mysql</li>\n<li>之前单实例换为双主(haproxy代理)</li>\n</ol>\n<h3 id=\"操作过程\"><a href=\"#操作过程\" class=\"headerlink\" title=\"操作过程\"></a>操作过程</h3><blockquote>\n<p>也是先备份传输，建立主从，恢复双主。</p>\n</blockquote>\n<p>ubuntu上 备份<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">apt-get install percona-xtrabackup</div><div class=\"line\">innobackupex --user=root --password=123 ./</div><div class=\"line\">tar -czvf mysql_back.tar.gz 2017-04-25_10-58-40</div></pre></td></tr></table></figure></p>\n<p>centos7 传输 解压 放到相应目录<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">rsync -auvzP --bwlimit=5000 root@117.****:/mnt/sdc/mysql_back.tar.gz ./</div><div class=\"line\">cd /home/mysql/ &amp;&amp; mv data/data_back</div><div class=\"line\">tar -zxvf mysql_back.tar.gz </div><div class=\"line\">mv 2017-04-25_10-58-40/ data</div><div class=\"line\">chown -R mysql:mysql data</div></pre></td></tr></table></figure></p>\n<p>postion点查看:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@test_biz 2017-06-16_15-39-01]# cat xtrabackup_binlog_info</div><div class=\"line\">mysql-bin.000054    57952335</div></pre></td></tr></table></figure></p>\n<p>之后主从设置 迁移完服务之后恢复双主。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>运维在日常免不了迁移服务，而迁移服务又免不了迁移数据库。 通常情况下数据库还比较重要，所以怎么样平滑的迁移数据库就显得很重要。<br>我在前段时间迁移了青云几台机器的服务，其中涉及到一些MySQL数据库的操作，做了些记录。</p>\n</blockquote>\n<hr>\n<h2 id=\"mysqldump\"><a href=\"#mysqldump\" class=\"headerlink\" title=\"mysqldump\"></a>mysqldump</h2><blockquote>\n<p>这是比较常见，一般数据库数据量很小的时候，首要我们就会考虑这个。<br><code>优点</code>:在于能够与正在运行的 MySQL 自动协同工作，支持备份 InnoDB 以及 MyISAM 表；锁表既是优点又是缺点，看怎么看待；<br><code>缺点</code>:在于数据量大，备份速度慢；</p>\n</blockquote>\n<p>这次服务迁移 中涉及到我们的OA系统，之前是部署在一个windows-server上的。</p>\n<h3 id=\"需求\"><a href=\"#需求\" class=\"headerlink\" title=\"需求\"></a>需求</h3><ol>\n<li>windows 上mysql迁移到 centos7  </li>\n<li>之前单实例换为双主(haproxy代理)</li>\n</ol>\n<h3 id=\"迁移具体过程\"><a href=\"#迁移具体过程\" class=\"headerlink\" title=\"迁移具体过程\"></a>迁移具体过程</h3><p>在centos7机器<br>直接远程dump<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysqldump -h117.******* -uoa -p oa --flush-logs --single-transaction | mysql -h localhost -uoa -p -P3314 -S /home/mysql/3314/mysql.sock v50</div></pre></td></tr></table></figure></p>\n<p><code>--flush-logs</code><br>在开始导出前刷新服务器的日志文件。注意，如果你一次性导出很多数据库（使用 -databases=或–all-databases选项），导出每个库时都会触发日志刷新。例外是当使用了–lock-all-tables或–master-data时：日志只会被刷新一次，那个时候所有表都会被锁住。所以如果你希望你的导出和日志刷新发生在同一个确定的时刻，你需要使用–lock-all-tables，或者–master-data配合–flush-logs。</p>\n<p><code>--single-transaction</code><br>InnoDB 表在备份时，通常启用选项 –single-transaction 来保证备份的一致性，实际上它的工作原理是设定本次会话的隔离级别为：REPEATABLE READ，以确保本次会话(dump)时，不会看到其他会话已经提交了的数据。</p>\n<p>之后查看windows机器的bin-log日志，查看在备份时间节点新的bin-log文件<br><img src=\"http://or2jd66dq.bkt.clouddn.com/windows_binlog.png\" alt=\"\"></p>\n<p>之后建立两个mysql主从(期间我centos7机器的mysql双主已经使用ansible搭建成功在此省略)</p>\n<p>windows——MySQL 授权<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">设置chunyu账号负责数据同步</div><div class=\"line\">GRANT REPLICATION SLAVE,RELOAD,SUPER ON *.* TO &apos;chunyu&apos;@&apos;%&apos; IDENTIFIED BY &apos;123&apos;;</div><div class=\"line\">FLUSH PRIVILEGES ;</div></pre></td></tr></table></figure></p>\n<p>centos7_1 停掉双主中自己slave角色，重新设置master<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">STOP SLAVE;</div><div class=\"line\">RESET SLAVE;</div><div class=\"line\">change master to master_host=&apos;117.****&apos;,master_port=3306,master_user=&apos;chunyu&apos;,master_password=&apos;123&apos;,master_log_file=&apos;mysql-bin.000008&apos;,master_log_pos=120;</div><div class=\"line\">start slave;</div><div class=\"line\">show slave status;</div></pre></td></tr></table></figure></p>\n<p>因为centos是双主，所以需要先断掉这台机的slave，另一台centos不用操作，这样双主变成了主从，在设置windows——MySQL为主此时关系应该是:<br>win_mysql(master) centos7_1(slave)<br>centos7_1(master) centos7_2(slave)</p>\n<p>之后服务迁移完之后，可以再设置回双主此处省略。</p>\n<h2 id=\"percona-xtrabackup\"><a href=\"#percona-xtrabackup\" class=\"headerlink\" title=\"percona-xtrabackup\"></a>percona-xtrabackup</h2><blockquote>\n<p>这台是redmine的数据库数据比较多，部署在ubuntu上。数据量大可以使用xtrabackup 热备份。</p>\n</blockquote>\n<p><code>优点</code>: 可靠高效的备份DB;备份过程中不中断事务处理，热备份;快速进行恢复等。<br><code>缺点</code>:</p>\n<h3 id=\"需求-1\"><a href=\"#需求-1\" class=\"headerlink\" title=\"需求\"></a>需求</h3><ol>\n<li>ubuntu上mysql迁移到centos7 mysql</li>\n<li>之前单实例换为双主(haproxy代理)</li>\n</ol>\n<h3 id=\"操作过程\"><a href=\"#操作过程\" class=\"headerlink\" title=\"操作过程\"></a>操作过程</h3><blockquote>\n<p>也是先备份传输，建立主从，恢复双主。</p>\n</blockquote>\n<p>ubuntu上 备份<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">apt-get install percona-xtrabackup</div><div class=\"line\">innobackupex --user=root --password=123 ./</div><div class=\"line\">tar -czvf mysql_back.tar.gz 2017-04-25_10-58-40</div></pre></td></tr></table></figure></p>\n<p>centos7 传输 解压 放到相应目录<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">rsync -auvzP --bwlimit=5000 root@117.****:/mnt/sdc/mysql_back.tar.gz ./</div><div class=\"line\">cd /home/mysql/ &amp;&amp; mv data/data_back</div><div class=\"line\">tar -zxvf mysql_back.tar.gz </div><div class=\"line\">mv 2017-04-25_10-58-40/ data</div><div class=\"line\">chown -R mysql:mysql data</div></pre></td></tr></table></figure></p>\n<p>postion点查看:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@test_biz 2017-06-16_15-39-01]# cat xtrabackup_binlog_info</div><div class=\"line\">mysql-bin.000054    57952335</div></pre></td></tr></table></figure></p>\n<p>之后主从设置 迁移完服务之后恢复双主。</p>\n"},{"title":"通过ucloud_API查看资源价格","date":"2017-07-11T09:34:50.000Z","_content":"\n> 我们公司有些服务使用ucloud主机，付费等问题都是我负责，前一段时间跟他们的架构沟通了一下，发现他们的API还是很方便的，尤其他们提供弹性IP可以自由伸缩，我们完全可以写个脚本统计带宽，实时调整。如果在云上跑docker，完全可以直接通过流量挥着访问量实时业务扩容。运维真的做到自动化。\n\n    ucloud提供了官方的`apk`[链接](https://github.com/ucloud-web/python-sdk-v2.git)\n有的同学直接把它写成了python命令 [链接](https://pypi.python.org/pypi/ucli/)\n\n本来只是想做一个统计价格的工具，写着写着，就像反正收集实例信息还不如都挨个统计一下展示出来，\n因为：\n\n1. ucloud信息展示的并不清晰  \n2. 如果看到价格有异常肯定第一时间想知道到底哪个贵些，贵在哪里，更方便直观一些\n\n我在下边主要展示一下自己手写的几个脚本通过API获取实例信息，再通过实例信息获取实例价格，最后统一发送到influxDB中去到grafana上呈现。定时每天跑一次。代码水平有限，大家请不要嘲笑。\n\n\n先来看下他的apk和配置文件\n他的public_key 和 private_key 涉及到自己独特的加秘方式。可以去ucloud官网看看 \n\n\n## `apk.py`\n\n```\n# -*- coding: utf-8 -*-\nimport hashlib, json, httplib\nimport urlparse\nimport urllib\nimport sys\nfrom config import *\n\n\nclass UCLOUDException(Exception):\n    def __str__(self):\n        return \"Error\"\n\n\ndef _verfy_ac(private_key, params):\n    items = params.items()\n    items.sort()\n\n    params_data = \"\"\n    for key, value in items:\n        params_data = params_data + str(key) + str(value)\n\n    params_data = params_data+private_key\n\n    '''use sha1 to encode keys'''\n    hash_new = hashlib.sha1()\n    hash_new.update(params_data)\n    hash_value = hash_new.hexdigest()\n    return hash_value\n\n\nclass UConnection(object):\n    def __init__(self, base_url):\n        self.base_url = base_url\n        o = urlparse.urlsplit(base_url)\n        if o.scheme == 'https':\n            self.conn = httplib.HTTPSConnection(o.netloc)\n        else:\n            self.conn = httplib.HTTPConnection(o.netloc)\n\n    def __del__(self):\n        self.conn.close()\n\n    def get(self, resouse, params):\n        resouse += \"?\" + urllib.urlencode(params)\n        print(\"%s%s\" % (self.base_url, resouse))\n        self.conn.request(\"GET\", resouse)\n        response = json.loads(self.conn.getresponse().read())\n        return response\n\n\nclass UcloudApiClient(object):\n    # 添加 设置 数据中心和  zone 参数\n    def __init__(self, base_url, public_key, private_key):\n        self.g_params = {}\n        self.g_params['PublicKey'] = public_key\n        self.private_key = private_keyurl\n        self.conn = UConnection(base_url)\n\n    def get(self, uri, params):\n        # print params\n        _params = dict(self.g_params, **params)\n\n        if project_id :\n            _params[\"ProjectId\"] = project_id\n\n        _params[\"Signature\"] = _verfy_ac(self.private_key, _params)\n        return self.conn.get(uri, _params)\n\n```\n\n## `conf.py`\n```\n#-*- encoding: utf-8 -*-\n#配置公私钥\"\"\"\npublic_key  = \"at************************\"\nprivate_key = \"e7***************\"\n#project_id = \"******\" # 项目ID 请在Dashbord 上获取\n\nbase_url    = \"https://api.ucloud.cn\"\n\n```\n\n\n## collect_uhost_price.py\n> 通过查看机器示例，按付费方式查看机器价格。\n具体查看[ucloud uhost API](https://docs.ucloud.cn/api/uhost-api/index)\n```\n#!/usr/bin/python\n#-*- coding:utf-8 -*-\n\n# author:fanquanqing\n# collect ucloud uhost price\nfrom sdk import UcloudApiClient\nfrom config import *\nfrom collections import Iterable\nimport sys\nimport json\n\n\n#host_list = []\n\n# 收集uhost信息\ndef collect_uhost_info(Regions_list,ProjectId):\n    '''\n    包含 hostname, ip, region, cpu, mem, diskspace, chargetype, count, ImageId, osname.\n    '''\n    host_info_list = []\n    for Region in Regions_list:\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\n        \"Action\":\"DescribeUHostInstance\",\n        \"Region\":Region,\n        \"ProjectId\":ProjectId,\n        \"Limit\":\"1000\"\n        }\n        response = ApiClient.get(\"/\", Parameters);\n        length = response['TotalCount']\n        for i in range(length):\n            host_info = {}\n            #ImageId = response[\"UHostSet\"][i][\"BasicImageId\"].encode(\"utf-8\")\n            ChargeType = response[\"UHostSet\"][i][\"ChargeType\"].encode(\"utf-8\")\n            #host_info[\"Action\"] = \"GetUHostInstancePrice\"\n            host_info[\"Region\"] = Region\n            host_info[\"ImageId\"] = \"uimage-kg0w4u\"\n            host_info[\"Hostname\"] = response[\"UHostSet\"][i][\"Name\"]\n            host_info[\"CPU\"] = response[\"UHostSet\"][i][\"CPU\"]\n            host_info[\"Memory\"] = response[\"UHostSet\"][i][\"Memory\"]\n\n            if len(response[\"UHostSet\"][i][\"DiskSet\"]) > 1:\n                host_info[\"DiskSpace\"] = response[\"UHostSet\"][i][\"DiskSet\"][1][\"Size\"]\n            else:\n                host_info[\"DiskSpace\"]=0\n            host_info[\"Count\"] = 1\n            host_info[\"ChargeType\"] = ChargeType\n            host_info[\"OsName\"] = response[\"UHostSet\"][i][\"OsName\"].split()[0]\n            host_info[\"loaclIP\"] = response[\"UHostSet\"][i][\"IPSet\"][0][\"IP\"]\n            if len(response[\"UHostSet\"][i][\"IPSet\"])>1:\n                host_info[\"EIP\"]=response[\"UHostSet\"][i][\"IPSet\"][1][\"IP\"]\n            else:\n                host_info[\"EIP\"]=\"none\"\n\n            host_info_list.append(host_info)\n    #print host_info_list\n    return host_info_list\n\n\n#通过机器配置得到某一台机器价格\ndef get_uhost_price(host_instance_info):\n    ApiClient = UcloudApiClient(base_url, public_key, private_key)\n    Parameters= host_instance_info\n    response = ApiClient.get(\"/\", Parameters );\n#    print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n    price = float(response[\"PriceSet\"][0].values()[0])\n    return price\n\n#通过机器配置信息得到所有机器价格\ndef get_all_uhost_price(host_info_list):\n\n    for host_info in host_info_list:\n        host_params={}\n        host_params[\"Action\"]=\"GetUHostInstancePrice\"\n        host_params[\"ImageId\"]=host_info[\"ImageId\"]\n        host_params[\"CPU\"]=host_info[\"CPU\"]\n        host_params[\"Memory\"]=host_info[\"Memory\"]\n        host_params[\"Count\"]=host_info[\"Count\"]\n        host_params[\"DiskSpace\"]=host_info[\"DiskSpace\"]\n        host_params[\"Region\"]=\"cn-bj2\"\n        host_params[\"ChargeType\"]=host_info[\"ChargeType\"]\n        if host_params[\"ChargeType\"]==\"Year\":\n            price = get_uhost_price(host_params)\n        elif host_params[\"ChargeType\"]==\"Month\":\n            price = get_uhost_price(host_params)*12\n        else:\n            price=0\n            print \"有临时机器请排查。\"\n        host_info[\"Price\"]=price\n\n    return host_info_list\n\ndef collect_uhost_price(setting_info):\n\n    host_info_total = []\n    for Projectname in setting_info:\n        for ProjectId in setting_info[Projectname]:\n            Regions_list = setting_info[Projectname][ProjectId]\n            host_info_list = collect_uhost_info(Regions_list,ProjectId)\n            project_host_list = get_all_uhost_price(host_info_list)\n            host_info_total.extend(project_host_list)\n    return host_info_total\n\n\n\nif __name__ == '__main__':\n    host_info_list = collect_uhost_info(['cn-bj2','hk'],\"org-oddm1w\")\n    host_price_list = get_all_uhost_price(host_info_list)\n    #print host_price_list\n```\n\n## collect_eip_price.py\n\n> 收集弹性IP信息\n```\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n# author:fanquanqing\n# collect ucloud eip price\nfrom sdk import UcloudApiClient\nfrom config import *\nimport sys\nimport json\n\n# 得到所有的EIP实例信息\ndef get_eip_instance(Regions_list,ProjectId):\n    eip_all = []\n    for Region in Regions_list:\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\"Action\":\"DescribeEIP\", \"Region\":Region, \"ProjectId\":ProjectId}\n        response = ApiClient.get(\"/\", Parameters );\n        for eip in response['EIPSet']:\n            eip_instance = {}\n            # 地域\n            eip_instance['Region']=Region\n            # IP\n            eip_instance['IP']=eip['EIPAddr'][0]['IP']\n\n            # 运营商线路\n            eip_instance['OperatorName']=eip['EIPAddr'][0]['OperatorName'].encode('utf-8')\n            # 带宽\n            eip_instance['Bandwidth']=eip['Bandwidth']\n            # 付费周期\n            eip_instance['ChargeType']=eip['ChargeType'].encode('utf-8')\n            # 付费方式(是否绑定共享带宽)\n            eip_instance['PayMode']=eip['PayMode'].encode('utf-8')\n            eip_all.append(eip_instance)\n\n    return eip_all\n    #print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n\n# 查看单个EIP实例价格\ndef get_eip_price(eip):\n    ApiClient = UcloudApiClient(base_url, public_key, private_key)\n    Parameters=eip\n    response = ApiClient.get(\"/\", Parameters );\n    #print response\n    price = response['PriceSet'][0]['Price']\n    return price\n\n\n# 获取所有EIP价格\ndef get_all_eip_price(eip_all):\n\n    for eip_info in eip_all:\n        eip_params={}\n        eip_params['Action']=\"GetEIPPrice\"\n        eip_params['Region']=eip_info['Region']\n        eip_params['OperatorName']=eip_info['OperatorName']\n        eip_params['Bandwidth']=eip_info['Bandwidth']\n        eip_params['ChargeType']=eip_info['ChargeType']\n        eip_params['PayMode']=eip_info['PayMode']\n        if eip_params['ChargeType']==\"Year\":\n            price = get_eip_price(eip_params)\n        elif eip_params['ChargeType']==\"Month\":\n            price = get_eip_price(eip_params)*12\n        else:\n            price=0\n            print \"有临时EIP请排查\"\n        eip_info[\"Price\"]=price\n    return eip_all\n\n\ndef collect_eip_price(setting_info):\n    eip_info_total = []\n    for Projectname in setting_info:\n        for ProjectId in setting_info[Projectname]:\n            Regions_list = setting_info[Projectname][ProjectId]\n            eip_all=get_eip_instance(Regions_list,ProjectId)\n            price_all=get_all_eip_price(eip_all)\n            eip_info_total.extend(price_all)\n    #print eip_info_total\n    return eip_info_total\n\nif __name__ == '__main__':\n    collect_eip_price({\"chunyu\":{\"org-oddm1w\":['cn-bj2','hk']}, \"uhs\":{\"org-shbbct\":[\"cn-bj2\"]}})\n\n\n\n```\n\n## collect_udisk_price.py\n\n> 收集云硬盘信息，这个只是取到实例自己手动算的价格\n```\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n\n# author: fanquanqing\n# 收集ucloud云硬盘信息 及价格\n\nfrom sdk import UcloudApiClient\nfrom config import *\nimport sys\nimport json\n\n# 获取udisk 信息\ndef get_udisk_info(Regions_list,ProjectId):\n    udisk_list = []\n    for Region in Regions_list:\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\"Action\":\"DescribeUDisk\", \"Region\":Region, \"ProjectId\":ProjectId}\n        response = ApiClient.get(\"/\", Parameters );\n        for udisk in response['DataSet']:\n            udisk_dic = {}\n            udisk_dic['Region'] = Region\n            #udisk_dic['Action'] = \"DescribeUDiskPrice\"\n            udisk_dic['Size'] = udisk['Size']\n            udisk_dic['ChargeType'] = udisk['ChargeType'].encode('utf-8')\n            udisk_dic['UHostName'] = udisk['UHostName']\n            udisk_dic['Quantity'] = 1\n            udisk_dic['Zone'] = \"cn-bj2-02\"\n            udisk_list.append(udisk_dic)\n    return udisk_list\n\n# 通过udisk信息获取价格\ndef get_udisk_price(udisk_list):\n    for udisk in udisk_list:\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        udisk_params={}\n        udisk_params['Action']=\"DescribeUDiskPrice\"\n        udisk_params['Region']=udisk['Region']\n        udisk_params['Size']=udisk['Size']\n        udisk_params['ChargeType']=udisk['ChargeType']\n        udisk_params['Quantity']=udisk['Quantity']\n        udisk_params['Zone']=udisk['Zone']\n        Parameters = udisk_params\n        response = ApiClient.get(\"/\", Parameters );\n        if udisk_params['ChargeType']==\"Year\":\n            price = response['DataSet'][0]['Price']/100\n        elif udisk_params['ChargeType']==\"Month\":\n            price = response['DataSet'][0]['Price']/10\n        else:\n            print \"有付费方式异常的云硬盘，请排查。\"\n        udisk[\"Price\"]=price\n    return udisk_list\n\n# 通过付费周期获取udisk价格\ndef collect_udisk_price(setting_info):\n    udisk_price_info = []\n    for Projectname in setting_info:\n        for ProjectId in setting_info[Projectname]:\n            Regions_list = setting_info[Projectname][ProjectId]\n            udisk_list = get_udisk_info(Regions_list,ProjectId)\n            udisk_price_info.extend(get_udisk_price(udisk_list))\n    return udisk_price_info\n\n\n\nif __name__ == '__main__':\n    collect_udisk_price({\"chunyu\":{\"org-oddm1w\":['cn-bj2','hk']}, \"uhs\":{\"org-shbbct\":[\"cn-bj2\"]}})\n\n```\n\n## collect_sharebandwidth_price.py\n> 收集共享带宽信息,因为没有计算价格的API这个价格也是手动算的。\n\n```\n#!/usr/bin/python\n# -*- coding: utf-8 -*-\n#author fanquanqing\n#收集共享带宽信息获取每年消费情况\nfrom sdk import UcloudApiClient\nfrom config import *\nimport sys\nimport json\n\ndef get_bandwidth_info(Regions_list,ProjectId):\n    bandwidth = []\n    for Region in Regions_list:\n\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\"Action\":\"DescribeShareBandwidth\",\"Region\":Region,\"ProjectId\":ProjectId}\n        response = ApiClient.get(\"/\", Parameters );\n        #print response\n        for bw in response['DataSet']:\n            bw_instance = {}\n            bw_instance['ShareBandwidth'] =  bw['ShareBandwidth']\n            bw_instance['ChargeType'] = bw['ChargeType']\n            bw_instance['Name']=bw['Name']\n            bandwidth.append(bw_instance)\n    return bandwidth\n#   print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n\ndef get_price(bandwidth):\n    '''\n    价格计算说明:ucloud没有提供API查询共享带宽价格，所有的共享带宽价格都是90/M/月 月付*12,年付*10\n    '''\n    price_list = []\n    for bw in bandwidth:\n        if bw['ChargeType']==\"Month\":\n            price = bw['ShareBandwidth']*90*12\n            bw[\"Price\"]=price\n        else:\n            price = bw['ShareBandwidrh']\n            bw[\"Price\"]=price\n    return bandwidth\n\ndef collect_sharebandwidth_price(setting_info):\n    bw_price_info = []\n    for Projectname in setting_info:\n        for ProjectId in setting_info[Projectname]:\n            Regions_list = setting_info[Projectname][ProjectId]\n            bw_info = get_bandwidth_info(Regions_list,ProjectId)\n            bw_price_info.extend(get_price(bw_info))\n    #print bw_price_info\n    return bw_price_info\n\n\nif __name__ == '__main__':\n    collect_sharebandwidth_price({\"chunyu\":{\"org-oddm1w\":['cn-bj2','hk']}, \"uhs\":{\"org-shbbct\":[\"cn-bj2\"]}})\n\n```\n\n## get_all_price.py\n\n> 给各实例价格求和，发送到influxdb。可以每天跑一下cron更新下内容。**里面发送的influxDB是事先封装好的包直接导入的，并不是官方包**\n```\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n\n# author: fanquanqing\n#import datatime\nfrom collect_eip_price import collect_eip_price\nfrom collect_uhost_price import collect_uhost_price\nfrom collect_sharebandwidth_price import collect_sharebandwidth_price\nfrom collect_udisk_price import collect_udisk_price\nfrom op_tools.api_influxdb import write_data_to_influxdb\n\ndef get_price(setting_info):\n    '''\n    各个实例price求和,并把实例信息发送到influxdb\n    '''\n    eip_price=0\n    uhost_price=0\n    sharebw_price=0\n    udisk_price=0\n    eip_price_info_list = collect_eip_price(setting_info)\n    for eip_info in eip_price_info_list:\n        eip_headers = eip_info.keys()\n        eip_rows = []\n        eip_rows.append(eip_info.values())\n        #print eip_headers, eip_rows\n        # 发送EIP数据到influxdb\n        write_data_to_influxdb('EIP_info_daliy', eip_headers, eip_rows, ['IP', 'OperatorName', 'ChargeType'])\n        eip_price += round(eip_info['Price'])\n\n    uhost_price_info_list = collect_uhost_price(setting_info)\n    for uhost_info in uhost_price_info_list:\n        uhost_headers=uhost_info.keys()\n        uhost_rows=[]\n        uhost_rows.append(uhost_info.values())\n        #print uhost_headers, uhost_rows\n        # 发送云主机信息到influxdb\n        write_data_to_influxdb('Uhost_info_daliy', uhost_headers, uhost_rows, ['Hostname','ChargeType'])\n        uhost_price += round(uhost_info['Price'])\n\n    sharebandwidth_info_list = collect_sharebandwidth_price(setting_info)\n    for sharebandwidth_info in sharebandwidth_info_list:\n        sharebw_headers=sharebandwidth_info.keys()\n        sharebw_rows=[]\n        sharebw_rows.append(sharebandwidth_info.values())\n        #print sharebw_headers, sharebw_rows\n        # 发送共享带宽信息到influxdb\n        write_data_to_influxdb('ShareBandwidth_info_daliy',sharebw_headers,sharebw_rows,[])\n        sharebw_price += round(sharebandwidth_info['Price'])\n\n    udisk_info_list=collect_udisk_price(setting_info)\n    for udisk_info in udisk_info_list:\n        udisk_headers=udisk_info.keys()\n        udisk_rows=[]\n        udisk_rows.append(udisk_info.values())\n        #print udisk_headers, udisk_rows\n        write_data_to_influxdb('Udisk_info_daliy', udisk_headers,udisk_rows,['UHostName','Region'])\n        udisk_price += round(udisk_info['Price'])\n    # 托管机房价格\n    physical_price = get_physical_host_price()\n    total_price=eip_price+uhost_price+sharebw_price+udisk_price+physical_price\n    # 价格列表\n    price_list=[eip_price,uhost_price,sharebw_price,udisk_price,total_price]\n    price_headers=['eip_price','uhost_price','sharebw_price','udisk_price','total_price']\n    price_rows=[]\n    price_rows.append(price_list)\n    write_data_to_influxdb('Ucloud_price_total_daliy',price_headers,price_rows,[])\n\n    #print uhost_price\n    return uhost_price\n\n# 托管机器价格(两个机柜一个10M外网)\ndef get_physical_host_price():\n    host_price = 9000*2*12\n    tg_cloud_switch_port_price = (288*2+217)*12\n    tg_bandwidth_price = 10*90*12\n    physical_price = host_price+tg_bandwidth_price+tg_cloud_switch_port_price\n    return physical_price\n\nif __name__ == '__main__':\n    # 可用区列表\n    #Regions_list = ['cn-bj2','hk']\n    # 项目ID列表\n    #Project_Id_list = ['org-shbbct','org-oddm1w']\n    # 项目ID对应关系\n    setting_info = {\"chunyu\":{\"org-oddm1w\":['cn-bj2','hk']}, \"uhs\":{\"org-shbbct\":[\"cn-bj2\"]}}\n    get_price(setting_info)\n\n```\n\n## grafana效果展示\n\n> grafana跟influxDB配合的非常好，设置也非常简单。下面我在下面放几张效果图。\n\n**简单查询语句**\n![](http://or2jd66dq.bkt.clouddn.com/grafana_influxdb.png)\n\n**table展示效果**\n![](http://or2jd66dq.bkt.clouddn.com/grafana_ucloud_eip.png)\n\n**价格图展示**\n![](http://or2jd66dq.bkt.clouddn.com/grafana_ucloud_price.png)\n\n\n\n## 获取实时带宽信息并发送报警到钉钉\n\n> 这个跟上面的脚本没有关联，只是获取实时带宽使用量的报警脚本。\n\n\n```\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom sdk import UcloudApiClient\nfrom config import *\nimport sys\nimport json\nimport urllib2\nimport time\n#from op_tools import falcon\n\n#实例化 API 句柄\nlocaltime = time.asctime( time.localtime(time.time()) )\n\ndef get_eip_info():\n    '''\n    获取EIP对应的主机名，以及EIP信息返回\n    '''\n    arg_length = len(sys.argv)\n    ApiClient = UcloudApiClient(base_url, public_key, private_key)\n    Parameters={\"Action\":\"DescribeEIP\", \"Region\":\"cn-bj2\"}\n    response = ApiClient.get(\"/\", Parameters );\n    eip_info_list = response['EIPSet']\n    eip_dic = {}\n    for eip_info in eip_info_list:\n        # EIP绑定主机名\n        eip_host = eip_info['Resource']['ResourceName']\n        eip_ip = eip_info['EIPAddr'][0]['IP'].encode('utf-8')\n        eip_id = eip_info['EIPId']\n        dic = {}\n        dic[eip_ip] = eip_id\n        #print \"eip_host:%s,dic:%s\" % (eip_host,dic)\n        eip_dic[eip_host] = dic\n    #print len(eip_dic)\n    eip_dic['nginx-online1'] = {'106.75.28.177': u'eip-00gv0l'}\n    return eip_dic\n\ndef get_eip_usage(eip_dic):\n    '''\n    获取每个EIP的实时用量(要求EIPid),\n    return list:[{ip:usage}...]\n    '''\n    eip_usage_dic = {}\n    for eip_host in eip_dic:\n        #eip_useage_dic = {}\n        eip_id=eip_dic[eip_host].values()[0].encode(\"utf-8\")\n        #print eip_id\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\n                    \"Action\":\"DescribeBandwidthUsage\",\n                    \"Region\":\"cn-bj2\",\n                    \"EIPIds.1\":eip_id,\n                }\n        response = ApiClient.get(\"/\", Parameters);\n        #print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n        #print response\n        eip_usage = response['EIPSet'][0]['CurBandwidth']\n        eip_usage_dic[eip_host]=eip_usage\n        #eip_usage_list.append(eip_useage_dic)\n    return eip_usage_dic\n\ndef sendto_falcon(eip_usage_list):\n    '''\n    报警发送到falcon\n    '''\n    collect_step = 60\n    counter_type = falcon.CounterType.GAUGE\n    metric = \"bandwidthusage\"\n    for eip_usage in eip_usage_list:\n        tags=\"host=\" + eip_usage.keys()[0]\n        value=eip_usage.values()[0]\n        #print value\n\ndef get_sharebw_info():\n    '''\n    获取共享带宽的带宽大小，以及所包含的EIP,\n    return list:[{'eiplist':[ip1,ip1],'bandwidth':20}...]\n    '''\n\n    ApiClient = UcloudApiClient(base_url, public_key, private_key)\n    Parameters={\"Action\":\"DescribeShareBandwidth\", \"Region\":\"cn-bj2\"}\n    response = ApiClient.get(\"/\", Parameters );\n    #print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n    share_bw_list = response['DataSet']\n    share_bw_info = []\n    for share_bw in share_bw_list:\n        share_bw_dic = {}\n        bandwidth = share_bw['ShareBandwidth']\n        eip_list = []\n        for eip_dic in share_bw['EIPSet']:\n            ip = eip_dic['EIPAddr'][0]['IP']\n            eip_list.append(ip)\n        share_bw_dic['bandwidth']=bandwidth\n        share_bw_dic['eiplist']=eip_list\n        share_bw_info.append(share_bw_dic)\n    return share_bw_info\n\ndef sum():\n    '''\n    返回比值，并简单记录log到/var/log/ubandwidth.log\n    '''\n    eip_dic = get_eip_info()\n    #print eip_dic\n    eip_to_host = {}\n    # 通过eip_dic获取IP-host对此应关系dic\n    for host in eip_dic:\n        eip = eip_dic[host].keys()[0]\n        eip_to_host[eip]=host\n    #print eip_to_host\n    eip_usage_dic = get_eip_usage(eip_dic)\n    #print eip_usage_dic\n    share_bw_info = get_sharebw_info()\n    #print share_bw_info\n    #各带宽和与带宽比值\n    ratios = {}\n    for share_bandwidth in share_bw_info:\n        bandwidth = share_bandwidth['bandwidth']\n        sum = 0\n        for eip in share_bandwidth['eiplist']:\n            host = eip_to_host[eip]\n            usage = eip_usage_dic[host]\n            sum += usage\n        #带宽用量与带宽的比值\n        ratio = sum/bandwidth\n        parts = [str(bandwidth),str(sum),str(ratio)]\n        log =localtime + ' ' + ','.join(parts) + '\\n'\n        with open('/var/log/ubandwidth.log','a') as f:\n            f.write(log)\n            f.close()\n\n        ratios[bandwidth]=ratio\n\n    return ratios\n\n\ndef send_to_dingtalk(content):\n\n    url = \"https://oapi.dingtalk.com/robot/send?access_token=17cf865229a63452ff411243b53d64949d5a54b1ee8774e20e1ec7d4c5d60f43\"\n    #con={\"msgtype\":\"text\",\"text\":{\"content\":content},\"isAtAll\": \"true\"}\n    con={\"msgtype\":\"markdown\",\"markdown\":{\"title\":\"ucloud共享带宽报警\",\"text\":content},\"isAtAll\": \"ture\"}\n    jd=json.dumps(con)\n    req=urllib2.Request(url,jd)\n    req.add_header('Content-Type', 'application/json')\n    response=urllib2.urlopen(req)\n\nif __name__ == '__main__':\n    ratios=sum()\n    localtime = time.asctime( time.localtime(time.time()) )\n    for bw in ratios:\n        if ratios[bw] > 0.8:\n            content = u\"# **ucloud共享带宽报警** - %d兆那个。。。\\n\\n - 用量超过百分之80 \\n - **值**:%f \\n > [请排查...](https://console.ucloud.cn/unet/sharebandwidth)\" % (bw,ratios[bw])\n            send_to_dingtalk(content)\n```\n\n\n\n\n","source":"_posts/ucloud-API使用.md","raw":"---\ntitle: 通过ucloud_API查看资源价格\ndate: 2017-07-11 17:34:50\ntags: python \ncategories: python\n---\n\n> 我们公司有些服务使用ucloud主机，付费等问题都是我负责，前一段时间跟他们的架构沟通了一下，发现他们的API还是很方便的，尤其他们提供弹性IP可以自由伸缩，我们完全可以写个脚本统计带宽，实时调整。如果在云上跑docker，完全可以直接通过流量挥着访问量实时业务扩容。运维真的做到自动化。\n\n    ucloud提供了官方的`apk`[链接](https://github.com/ucloud-web/python-sdk-v2.git)\n有的同学直接把它写成了python命令 [链接](https://pypi.python.org/pypi/ucli/)\n\n本来只是想做一个统计价格的工具，写着写着，就像反正收集实例信息还不如都挨个统计一下展示出来，\n因为：\n\n1. ucloud信息展示的并不清晰  \n2. 如果看到价格有异常肯定第一时间想知道到底哪个贵些，贵在哪里，更方便直观一些\n\n我在下边主要展示一下自己手写的几个脚本通过API获取实例信息，再通过实例信息获取实例价格，最后统一发送到influxDB中去到grafana上呈现。定时每天跑一次。代码水平有限，大家请不要嘲笑。\n\n\n先来看下他的apk和配置文件\n他的public_key 和 private_key 涉及到自己独特的加秘方式。可以去ucloud官网看看 \n\n\n## `apk.py`\n\n```\n# -*- coding: utf-8 -*-\nimport hashlib, json, httplib\nimport urlparse\nimport urllib\nimport sys\nfrom config import *\n\n\nclass UCLOUDException(Exception):\n    def __str__(self):\n        return \"Error\"\n\n\ndef _verfy_ac(private_key, params):\n    items = params.items()\n    items.sort()\n\n    params_data = \"\"\n    for key, value in items:\n        params_data = params_data + str(key) + str(value)\n\n    params_data = params_data+private_key\n\n    '''use sha1 to encode keys'''\n    hash_new = hashlib.sha1()\n    hash_new.update(params_data)\n    hash_value = hash_new.hexdigest()\n    return hash_value\n\n\nclass UConnection(object):\n    def __init__(self, base_url):\n        self.base_url = base_url\n        o = urlparse.urlsplit(base_url)\n        if o.scheme == 'https':\n            self.conn = httplib.HTTPSConnection(o.netloc)\n        else:\n            self.conn = httplib.HTTPConnection(o.netloc)\n\n    def __del__(self):\n        self.conn.close()\n\n    def get(self, resouse, params):\n        resouse += \"?\" + urllib.urlencode(params)\n        print(\"%s%s\" % (self.base_url, resouse))\n        self.conn.request(\"GET\", resouse)\n        response = json.loads(self.conn.getresponse().read())\n        return response\n\n\nclass UcloudApiClient(object):\n    # 添加 设置 数据中心和  zone 参数\n    def __init__(self, base_url, public_key, private_key):\n        self.g_params = {}\n        self.g_params['PublicKey'] = public_key\n        self.private_key = private_keyurl\n        self.conn = UConnection(base_url)\n\n    def get(self, uri, params):\n        # print params\n        _params = dict(self.g_params, **params)\n\n        if project_id :\n            _params[\"ProjectId\"] = project_id\n\n        _params[\"Signature\"] = _verfy_ac(self.private_key, _params)\n        return self.conn.get(uri, _params)\n\n```\n\n## `conf.py`\n```\n#-*- encoding: utf-8 -*-\n#配置公私钥\"\"\"\npublic_key  = \"at************************\"\nprivate_key = \"e7***************\"\n#project_id = \"******\" # 项目ID 请在Dashbord 上获取\n\nbase_url    = \"https://api.ucloud.cn\"\n\n```\n\n\n## collect_uhost_price.py\n> 通过查看机器示例，按付费方式查看机器价格。\n具体查看[ucloud uhost API](https://docs.ucloud.cn/api/uhost-api/index)\n```\n#!/usr/bin/python\n#-*- coding:utf-8 -*-\n\n# author:fanquanqing\n# collect ucloud uhost price\nfrom sdk import UcloudApiClient\nfrom config import *\nfrom collections import Iterable\nimport sys\nimport json\n\n\n#host_list = []\n\n# 收集uhost信息\ndef collect_uhost_info(Regions_list,ProjectId):\n    '''\n    包含 hostname, ip, region, cpu, mem, diskspace, chargetype, count, ImageId, osname.\n    '''\n    host_info_list = []\n    for Region in Regions_list:\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\n        \"Action\":\"DescribeUHostInstance\",\n        \"Region\":Region,\n        \"ProjectId\":ProjectId,\n        \"Limit\":\"1000\"\n        }\n        response = ApiClient.get(\"/\", Parameters);\n        length = response['TotalCount']\n        for i in range(length):\n            host_info = {}\n            #ImageId = response[\"UHostSet\"][i][\"BasicImageId\"].encode(\"utf-8\")\n            ChargeType = response[\"UHostSet\"][i][\"ChargeType\"].encode(\"utf-8\")\n            #host_info[\"Action\"] = \"GetUHostInstancePrice\"\n            host_info[\"Region\"] = Region\n            host_info[\"ImageId\"] = \"uimage-kg0w4u\"\n            host_info[\"Hostname\"] = response[\"UHostSet\"][i][\"Name\"]\n            host_info[\"CPU\"] = response[\"UHostSet\"][i][\"CPU\"]\n            host_info[\"Memory\"] = response[\"UHostSet\"][i][\"Memory\"]\n\n            if len(response[\"UHostSet\"][i][\"DiskSet\"]) > 1:\n                host_info[\"DiskSpace\"] = response[\"UHostSet\"][i][\"DiskSet\"][1][\"Size\"]\n            else:\n                host_info[\"DiskSpace\"]=0\n            host_info[\"Count\"] = 1\n            host_info[\"ChargeType\"] = ChargeType\n            host_info[\"OsName\"] = response[\"UHostSet\"][i][\"OsName\"].split()[0]\n            host_info[\"loaclIP\"] = response[\"UHostSet\"][i][\"IPSet\"][0][\"IP\"]\n            if len(response[\"UHostSet\"][i][\"IPSet\"])>1:\n                host_info[\"EIP\"]=response[\"UHostSet\"][i][\"IPSet\"][1][\"IP\"]\n            else:\n                host_info[\"EIP\"]=\"none\"\n\n            host_info_list.append(host_info)\n    #print host_info_list\n    return host_info_list\n\n\n#通过机器配置得到某一台机器价格\ndef get_uhost_price(host_instance_info):\n    ApiClient = UcloudApiClient(base_url, public_key, private_key)\n    Parameters= host_instance_info\n    response = ApiClient.get(\"/\", Parameters );\n#    print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n    price = float(response[\"PriceSet\"][0].values()[0])\n    return price\n\n#通过机器配置信息得到所有机器价格\ndef get_all_uhost_price(host_info_list):\n\n    for host_info in host_info_list:\n        host_params={}\n        host_params[\"Action\"]=\"GetUHostInstancePrice\"\n        host_params[\"ImageId\"]=host_info[\"ImageId\"]\n        host_params[\"CPU\"]=host_info[\"CPU\"]\n        host_params[\"Memory\"]=host_info[\"Memory\"]\n        host_params[\"Count\"]=host_info[\"Count\"]\n        host_params[\"DiskSpace\"]=host_info[\"DiskSpace\"]\n        host_params[\"Region\"]=\"cn-bj2\"\n        host_params[\"ChargeType\"]=host_info[\"ChargeType\"]\n        if host_params[\"ChargeType\"]==\"Year\":\n            price = get_uhost_price(host_params)\n        elif host_params[\"ChargeType\"]==\"Month\":\n            price = get_uhost_price(host_params)*12\n        else:\n            price=0\n            print \"有临时机器请排查。\"\n        host_info[\"Price\"]=price\n\n    return host_info_list\n\ndef collect_uhost_price(setting_info):\n\n    host_info_total = []\n    for Projectname in setting_info:\n        for ProjectId in setting_info[Projectname]:\n            Regions_list = setting_info[Projectname][ProjectId]\n            host_info_list = collect_uhost_info(Regions_list,ProjectId)\n            project_host_list = get_all_uhost_price(host_info_list)\n            host_info_total.extend(project_host_list)\n    return host_info_total\n\n\n\nif __name__ == '__main__':\n    host_info_list = collect_uhost_info(['cn-bj2','hk'],\"org-oddm1w\")\n    host_price_list = get_all_uhost_price(host_info_list)\n    #print host_price_list\n```\n\n## collect_eip_price.py\n\n> 收集弹性IP信息\n```\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n# author:fanquanqing\n# collect ucloud eip price\nfrom sdk import UcloudApiClient\nfrom config import *\nimport sys\nimport json\n\n# 得到所有的EIP实例信息\ndef get_eip_instance(Regions_list,ProjectId):\n    eip_all = []\n    for Region in Regions_list:\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\"Action\":\"DescribeEIP\", \"Region\":Region, \"ProjectId\":ProjectId}\n        response = ApiClient.get(\"/\", Parameters );\n        for eip in response['EIPSet']:\n            eip_instance = {}\n            # 地域\n            eip_instance['Region']=Region\n            # IP\n            eip_instance['IP']=eip['EIPAddr'][0]['IP']\n\n            # 运营商线路\n            eip_instance['OperatorName']=eip['EIPAddr'][0]['OperatorName'].encode('utf-8')\n            # 带宽\n            eip_instance['Bandwidth']=eip['Bandwidth']\n            # 付费周期\n            eip_instance['ChargeType']=eip['ChargeType'].encode('utf-8')\n            # 付费方式(是否绑定共享带宽)\n            eip_instance['PayMode']=eip['PayMode'].encode('utf-8')\n            eip_all.append(eip_instance)\n\n    return eip_all\n    #print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n\n# 查看单个EIP实例价格\ndef get_eip_price(eip):\n    ApiClient = UcloudApiClient(base_url, public_key, private_key)\n    Parameters=eip\n    response = ApiClient.get(\"/\", Parameters );\n    #print response\n    price = response['PriceSet'][0]['Price']\n    return price\n\n\n# 获取所有EIP价格\ndef get_all_eip_price(eip_all):\n\n    for eip_info in eip_all:\n        eip_params={}\n        eip_params['Action']=\"GetEIPPrice\"\n        eip_params['Region']=eip_info['Region']\n        eip_params['OperatorName']=eip_info['OperatorName']\n        eip_params['Bandwidth']=eip_info['Bandwidth']\n        eip_params['ChargeType']=eip_info['ChargeType']\n        eip_params['PayMode']=eip_info['PayMode']\n        if eip_params['ChargeType']==\"Year\":\n            price = get_eip_price(eip_params)\n        elif eip_params['ChargeType']==\"Month\":\n            price = get_eip_price(eip_params)*12\n        else:\n            price=0\n            print \"有临时EIP请排查\"\n        eip_info[\"Price\"]=price\n    return eip_all\n\n\ndef collect_eip_price(setting_info):\n    eip_info_total = []\n    for Projectname in setting_info:\n        for ProjectId in setting_info[Projectname]:\n            Regions_list = setting_info[Projectname][ProjectId]\n            eip_all=get_eip_instance(Regions_list,ProjectId)\n            price_all=get_all_eip_price(eip_all)\n            eip_info_total.extend(price_all)\n    #print eip_info_total\n    return eip_info_total\n\nif __name__ == '__main__':\n    collect_eip_price({\"chunyu\":{\"org-oddm1w\":['cn-bj2','hk']}, \"uhs\":{\"org-shbbct\":[\"cn-bj2\"]}})\n\n\n\n```\n\n## collect_udisk_price.py\n\n> 收集云硬盘信息，这个只是取到实例自己手动算的价格\n```\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n\n# author: fanquanqing\n# 收集ucloud云硬盘信息 及价格\n\nfrom sdk import UcloudApiClient\nfrom config import *\nimport sys\nimport json\n\n# 获取udisk 信息\ndef get_udisk_info(Regions_list,ProjectId):\n    udisk_list = []\n    for Region in Regions_list:\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\"Action\":\"DescribeUDisk\", \"Region\":Region, \"ProjectId\":ProjectId}\n        response = ApiClient.get(\"/\", Parameters );\n        for udisk in response['DataSet']:\n            udisk_dic = {}\n            udisk_dic['Region'] = Region\n            #udisk_dic['Action'] = \"DescribeUDiskPrice\"\n            udisk_dic['Size'] = udisk['Size']\n            udisk_dic['ChargeType'] = udisk['ChargeType'].encode('utf-8')\n            udisk_dic['UHostName'] = udisk['UHostName']\n            udisk_dic['Quantity'] = 1\n            udisk_dic['Zone'] = \"cn-bj2-02\"\n            udisk_list.append(udisk_dic)\n    return udisk_list\n\n# 通过udisk信息获取价格\ndef get_udisk_price(udisk_list):\n    for udisk in udisk_list:\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        udisk_params={}\n        udisk_params['Action']=\"DescribeUDiskPrice\"\n        udisk_params['Region']=udisk['Region']\n        udisk_params['Size']=udisk['Size']\n        udisk_params['ChargeType']=udisk['ChargeType']\n        udisk_params['Quantity']=udisk['Quantity']\n        udisk_params['Zone']=udisk['Zone']\n        Parameters = udisk_params\n        response = ApiClient.get(\"/\", Parameters );\n        if udisk_params['ChargeType']==\"Year\":\n            price = response['DataSet'][0]['Price']/100\n        elif udisk_params['ChargeType']==\"Month\":\n            price = response['DataSet'][0]['Price']/10\n        else:\n            print \"有付费方式异常的云硬盘，请排查。\"\n        udisk[\"Price\"]=price\n    return udisk_list\n\n# 通过付费周期获取udisk价格\ndef collect_udisk_price(setting_info):\n    udisk_price_info = []\n    for Projectname in setting_info:\n        for ProjectId in setting_info[Projectname]:\n            Regions_list = setting_info[Projectname][ProjectId]\n            udisk_list = get_udisk_info(Regions_list,ProjectId)\n            udisk_price_info.extend(get_udisk_price(udisk_list))\n    return udisk_price_info\n\n\n\nif __name__ == '__main__':\n    collect_udisk_price({\"chunyu\":{\"org-oddm1w\":['cn-bj2','hk']}, \"uhs\":{\"org-shbbct\":[\"cn-bj2\"]}})\n\n```\n\n## collect_sharebandwidth_price.py\n> 收集共享带宽信息,因为没有计算价格的API这个价格也是手动算的。\n\n```\n#!/usr/bin/python\n# -*- coding: utf-8 -*-\n#author fanquanqing\n#收集共享带宽信息获取每年消费情况\nfrom sdk import UcloudApiClient\nfrom config import *\nimport sys\nimport json\n\ndef get_bandwidth_info(Regions_list,ProjectId):\n    bandwidth = []\n    for Region in Regions_list:\n\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\"Action\":\"DescribeShareBandwidth\",\"Region\":Region,\"ProjectId\":ProjectId}\n        response = ApiClient.get(\"/\", Parameters );\n        #print response\n        for bw in response['DataSet']:\n            bw_instance = {}\n            bw_instance['ShareBandwidth'] =  bw['ShareBandwidth']\n            bw_instance['ChargeType'] = bw['ChargeType']\n            bw_instance['Name']=bw['Name']\n            bandwidth.append(bw_instance)\n    return bandwidth\n#   print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n\ndef get_price(bandwidth):\n    '''\n    价格计算说明:ucloud没有提供API查询共享带宽价格，所有的共享带宽价格都是90/M/月 月付*12,年付*10\n    '''\n    price_list = []\n    for bw in bandwidth:\n        if bw['ChargeType']==\"Month\":\n            price = bw['ShareBandwidth']*90*12\n            bw[\"Price\"]=price\n        else:\n            price = bw['ShareBandwidrh']\n            bw[\"Price\"]=price\n    return bandwidth\n\ndef collect_sharebandwidth_price(setting_info):\n    bw_price_info = []\n    for Projectname in setting_info:\n        for ProjectId in setting_info[Projectname]:\n            Regions_list = setting_info[Projectname][ProjectId]\n            bw_info = get_bandwidth_info(Regions_list,ProjectId)\n            bw_price_info.extend(get_price(bw_info))\n    #print bw_price_info\n    return bw_price_info\n\n\nif __name__ == '__main__':\n    collect_sharebandwidth_price({\"chunyu\":{\"org-oddm1w\":['cn-bj2','hk']}, \"uhs\":{\"org-shbbct\":[\"cn-bj2\"]}})\n\n```\n\n## get_all_price.py\n\n> 给各实例价格求和，发送到influxdb。可以每天跑一下cron更新下内容。**里面发送的influxDB是事先封装好的包直接导入的，并不是官方包**\n```\n#!/usr/bin/env python\n# -*- coding:utf-8 -*-\n\n# author: fanquanqing\n#import datatime\nfrom collect_eip_price import collect_eip_price\nfrom collect_uhost_price import collect_uhost_price\nfrom collect_sharebandwidth_price import collect_sharebandwidth_price\nfrom collect_udisk_price import collect_udisk_price\nfrom op_tools.api_influxdb import write_data_to_influxdb\n\ndef get_price(setting_info):\n    '''\n    各个实例price求和,并把实例信息发送到influxdb\n    '''\n    eip_price=0\n    uhost_price=0\n    sharebw_price=0\n    udisk_price=0\n    eip_price_info_list = collect_eip_price(setting_info)\n    for eip_info in eip_price_info_list:\n        eip_headers = eip_info.keys()\n        eip_rows = []\n        eip_rows.append(eip_info.values())\n        #print eip_headers, eip_rows\n        # 发送EIP数据到influxdb\n        write_data_to_influxdb('EIP_info_daliy', eip_headers, eip_rows, ['IP', 'OperatorName', 'ChargeType'])\n        eip_price += round(eip_info['Price'])\n\n    uhost_price_info_list = collect_uhost_price(setting_info)\n    for uhost_info in uhost_price_info_list:\n        uhost_headers=uhost_info.keys()\n        uhost_rows=[]\n        uhost_rows.append(uhost_info.values())\n        #print uhost_headers, uhost_rows\n        # 发送云主机信息到influxdb\n        write_data_to_influxdb('Uhost_info_daliy', uhost_headers, uhost_rows, ['Hostname','ChargeType'])\n        uhost_price += round(uhost_info['Price'])\n\n    sharebandwidth_info_list = collect_sharebandwidth_price(setting_info)\n    for sharebandwidth_info in sharebandwidth_info_list:\n        sharebw_headers=sharebandwidth_info.keys()\n        sharebw_rows=[]\n        sharebw_rows.append(sharebandwidth_info.values())\n        #print sharebw_headers, sharebw_rows\n        # 发送共享带宽信息到influxdb\n        write_data_to_influxdb('ShareBandwidth_info_daliy',sharebw_headers,sharebw_rows,[])\n        sharebw_price += round(sharebandwidth_info['Price'])\n\n    udisk_info_list=collect_udisk_price(setting_info)\n    for udisk_info in udisk_info_list:\n        udisk_headers=udisk_info.keys()\n        udisk_rows=[]\n        udisk_rows.append(udisk_info.values())\n        #print udisk_headers, udisk_rows\n        write_data_to_influxdb('Udisk_info_daliy', udisk_headers,udisk_rows,['UHostName','Region'])\n        udisk_price += round(udisk_info['Price'])\n    # 托管机房价格\n    physical_price = get_physical_host_price()\n    total_price=eip_price+uhost_price+sharebw_price+udisk_price+physical_price\n    # 价格列表\n    price_list=[eip_price,uhost_price,sharebw_price,udisk_price,total_price]\n    price_headers=['eip_price','uhost_price','sharebw_price','udisk_price','total_price']\n    price_rows=[]\n    price_rows.append(price_list)\n    write_data_to_influxdb('Ucloud_price_total_daliy',price_headers,price_rows,[])\n\n    #print uhost_price\n    return uhost_price\n\n# 托管机器价格(两个机柜一个10M外网)\ndef get_physical_host_price():\n    host_price = 9000*2*12\n    tg_cloud_switch_port_price = (288*2+217)*12\n    tg_bandwidth_price = 10*90*12\n    physical_price = host_price+tg_bandwidth_price+tg_cloud_switch_port_price\n    return physical_price\n\nif __name__ == '__main__':\n    # 可用区列表\n    #Regions_list = ['cn-bj2','hk']\n    # 项目ID列表\n    #Project_Id_list = ['org-shbbct','org-oddm1w']\n    # 项目ID对应关系\n    setting_info = {\"chunyu\":{\"org-oddm1w\":['cn-bj2','hk']}, \"uhs\":{\"org-shbbct\":[\"cn-bj2\"]}}\n    get_price(setting_info)\n\n```\n\n## grafana效果展示\n\n> grafana跟influxDB配合的非常好，设置也非常简单。下面我在下面放几张效果图。\n\n**简单查询语句**\n![](http://or2jd66dq.bkt.clouddn.com/grafana_influxdb.png)\n\n**table展示效果**\n![](http://or2jd66dq.bkt.clouddn.com/grafana_ucloud_eip.png)\n\n**价格图展示**\n![](http://or2jd66dq.bkt.clouddn.com/grafana_ucloud_price.png)\n\n\n\n## 获取实时带宽信息并发送报警到钉钉\n\n> 这个跟上面的脚本没有关联，只是获取实时带宽使用量的报警脚本。\n\n\n```\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom sdk import UcloudApiClient\nfrom config import *\nimport sys\nimport json\nimport urllib2\nimport time\n#from op_tools import falcon\n\n#实例化 API 句柄\nlocaltime = time.asctime( time.localtime(time.time()) )\n\ndef get_eip_info():\n    '''\n    获取EIP对应的主机名，以及EIP信息返回\n    '''\n    arg_length = len(sys.argv)\n    ApiClient = UcloudApiClient(base_url, public_key, private_key)\n    Parameters={\"Action\":\"DescribeEIP\", \"Region\":\"cn-bj2\"}\n    response = ApiClient.get(\"/\", Parameters );\n    eip_info_list = response['EIPSet']\n    eip_dic = {}\n    for eip_info in eip_info_list:\n        # EIP绑定主机名\n        eip_host = eip_info['Resource']['ResourceName']\n        eip_ip = eip_info['EIPAddr'][0]['IP'].encode('utf-8')\n        eip_id = eip_info['EIPId']\n        dic = {}\n        dic[eip_ip] = eip_id\n        #print \"eip_host:%s,dic:%s\" % (eip_host,dic)\n        eip_dic[eip_host] = dic\n    #print len(eip_dic)\n    eip_dic['nginx-online1'] = {'106.75.28.177': u'eip-00gv0l'}\n    return eip_dic\n\ndef get_eip_usage(eip_dic):\n    '''\n    获取每个EIP的实时用量(要求EIPid),\n    return list:[{ip:usage}...]\n    '''\n    eip_usage_dic = {}\n    for eip_host in eip_dic:\n        #eip_useage_dic = {}\n        eip_id=eip_dic[eip_host].values()[0].encode(\"utf-8\")\n        #print eip_id\n        ApiClient = UcloudApiClient(base_url, public_key, private_key)\n        Parameters={\n                    \"Action\":\"DescribeBandwidthUsage\",\n                    \"Region\":\"cn-bj2\",\n                    \"EIPIds.1\":eip_id,\n                }\n        response = ApiClient.get(\"/\", Parameters);\n        #print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n        #print response\n        eip_usage = response['EIPSet'][0]['CurBandwidth']\n        eip_usage_dic[eip_host]=eip_usage\n        #eip_usage_list.append(eip_useage_dic)\n    return eip_usage_dic\n\ndef sendto_falcon(eip_usage_list):\n    '''\n    报警发送到falcon\n    '''\n    collect_step = 60\n    counter_type = falcon.CounterType.GAUGE\n    metric = \"bandwidthusage\"\n    for eip_usage in eip_usage_list:\n        tags=\"host=\" + eip_usage.keys()[0]\n        value=eip_usage.values()[0]\n        #print value\n\ndef get_sharebw_info():\n    '''\n    获取共享带宽的带宽大小，以及所包含的EIP,\n    return list:[{'eiplist':[ip1,ip1],'bandwidth':20}...]\n    '''\n\n    ApiClient = UcloudApiClient(base_url, public_key, private_key)\n    Parameters={\"Action\":\"DescribeShareBandwidth\", \"Region\":\"cn-bj2\"}\n    response = ApiClient.get(\"/\", Parameters );\n    #print json.dumps(response, sort_keys=True, indent=4, separators=(',', ': '))\n    share_bw_list = response['DataSet']\n    share_bw_info = []\n    for share_bw in share_bw_list:\n        share_bw_dic = {}\n        bandwidth = share_bw['ShareBandwidth']\n        eip_list = []\n        for eip_dic in share_bw['EIPSet']:\n            ip = eip_dic['EIPAddr'][0]['IP']\n            eip_list.append(ip)\n        share_bw_dic['bandwidth']=bandwidth\n        share_bw_dic['eiplist']=eip_list\n        share_bw_info.append(share_bw_dic)\n    return share_bw_info\n\ndef sum():\n    '''\n    返回比值，并简单记录log到/var/log/ubandwidth.log\n    '''\n    eip_dic = get_eip_info()\n    #print eip_dic\n    eip_to_host = {}\n    # 通过eip_dic获取IP-host对此应关系dic\n    for host in eip_dic:\n        eip = eip_dic[host].keys()[0]\n        eip_to_host[eip]=host\n    #print eip_to_host\n    eip_usage_dic = get_eip_usage(eip_dic)\n    #print eip_usage_dic\n    share_bw_info = get_sharebw_info()\n    #print share_bw_info\n    #各带宽和与带宽比值\n    ratios = {}\n    for share_bandwidth in share_bw_info:\n        bandwidth = share_bandwidth['bandwidth']\n        sum = 0\n        for eip in share_bandwidth['eiplist']:\n            host = eip_to_host[eip]\n            usage = eip_usage_dic[host]\n            sum += usage\n        #带宽用量与带宽的比值\n        ratio = sum/bandwidth\n        parts = [str(bandwidth),str(sum),str(ratio)]\n        log =localtime + ' ' + ','.join(parts) + '\\n'\n        with open('/var/log/ubandwidth.log','a') as f:\n            f.write(log)\n            f.close()\n\n        ratios[bandwidth]=ratio\n\n    return ratios\n\n\ndef send_to_dingtalk(content):\n\n    url = \"https://oapi.dingtalk.com/robot/send?access_token=17cf865229a63452ff411243b53d64949d5a54b1ee8774e20e1ec7d4c5d60f43\"\n    #con={\"msgtype\":\"text\",\"text\":{\"content\":content},\"isAtAll\": \"true\"}\n    con={\"msgtype\":\"markdown\",\"markdown\":{\"title\":\"ucloud共享带宽报警\",\"text\":content},\"isAtAll\": \"ture\"}\n    jd=json.dumps(con)\n    req=urllib2.Request(url,jd)\n    req.add_header('Content-Type', 'application/json')\n    response=urllib2.urlopen(req)\n\nif __name__ == '__main__':\n    ratios=sum()\n    localtime = time.asctime( time.localtime(time.time()) )\n    for bw in ratios:\n        if ratios[bw] > 0.8:\n            content = u\"# **ucloud共享带宽报警** - %d兆那个。。。\\n\\n - 用量超过百分之80 \\n - **值**:%f \\n > [请排查...](https://console.ucloud.cn/unet/sharebandwidth)\" % (bw,ratios[bw])\n            send_to_dingtalk(content)\n```\n\n\n\n\n","slug":"ucloud-API使用","published":1,"updated":"2017-08-03T07:46:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvce003w8tzzi57bitit","content":"<blockquote>\n<p>我们公司有些服务使用ucloud主机，付费等问题都是我负责，前一段时间跟他们的架构沟通了一下，发现他们的API还是很方便的，尤其他们提供弹性IP可以自由伸缩，我们完全可以写个脚本统计带宽，实时调整。如果在云上跑docker，完全可以直接通过流量挥着访问量实时业务扩容。运维真的做到自动化。</p>\n</blockquote>\n<pre><code>ucloud提供了官方的`apk`[链接](https://github.com/ucloud-web/python-sdk-v2.git)\n</code></pre><p>有的同学直接把它写成了python命令 <a href=\"https://pypi.python.org/pypi/ucli/\" target=\"_blank\" rel=\"external\">链接</a></p>\n<p>本来只是想做一个统计价格的工具，写着写着，就像反正收集实例信息还不如都挨个统计一下展示出来，<br>因为：</p>\n<ol>\n<li>ucloud信息展示的并不清晰  </li>\n<li>如果看到价格有异常肯定第一时间想知道到底哪个贵些，贵在哪里，更方便直观一些</li>\n</ol>\n<p>我在下边主要展示一下自己手写的几个脚本通过API获取实例信息，再通过实例信息获取实例价格，最后统一发送到influxDB中去到grafana上呈现。定时每天跑一次。代码水平有限，大家请不要嘲笑。</p>\n<p>先来看下他的apk和配置文件<br>他的public_key 和 private_key 涉及到自己独特的加秘方式。可以去ucloud官网看看 </p>\n<h2 id=\"apkpy\"><a href=\"#apk-py\" class=\"headerlink\" title=\"apk.py\"></a><code>apk.py</code></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div></pre></td><td class=\"code\"><pre><div class=\"line\"># -*- coding: utf-8 -*-</div><div class=\"line\">import hashlib, json, httplib</div><div class=\"line\">import urlparse</div><div class=\"line\">import urllib</div><div class=\"line\">import sys</div><div class=\"line\">from config import *</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">class UCLOUDException(Exception):</div><div class=\"line\">    def __str__(self):</div><div class=\"line\">        return &quot;Error&quot;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">def _verfy_ac(private_key, params):</div><div class=\"line\">    items = params.items()</div><div class=\"line\">    items.sort()</div><div class=\"line\"></div><div class=\"line\">    params_data = &quot;&quot;</div><div class=\"line\">    for key, value in items:</div><div class=\"line\">        params_data = params_data + str(key) + str(value)</div><div class=\"line\"></div><div class=\"line\">    params_data = params_data+private_key</div><div class=\"line\"></div><div class=\"line\">    &apos;&apos;&apos;use sha1 to encode keys&apos;&apos;&apos;</div><div class=\"line\">    hash_new = hashlib.sha1()</div><div class=\"line\">    hash_new.update(params_data)</div><div class=\"line\">    hash_value = hash_new.hexdigest()</div><div class=\"line\">    return hash_value</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">class UConnection(object):</div><div class=\"line\">    def __init__(self, base_url):</div><div class=\"line\">        self.base_url = base_url</div><div class=\"line\">        o = urlparse.urlsplit(base_url)</div><div class=\"line\">        if o.scheme == &apos;https&apos;:</div><div class=\"line\">            self.conn = httplib.HTTPSConnection(o.netloc)</div><div class=\"line\">        else:</div><div class=\"line\">            self.conn = httplib.HTTPConnection(o.netloc)</div><div class=\"line\"></div><div class=\"line\">    def __del__(self):</div><div class=\"line\">        self.conn.close()</div><div class=\"line\"></div><div class=\"line\">    def get(self, resouse, params):</div><div class=\"line\">        resouse += &quot;?&quot; + urllib.urlencode(params)</div><div class=\"line\">        print(&quot;%s%s&quot; % (self.base_url, resouse))</div><div class=\"line\">        self.conn.request(&quot;GET&quot;, resouse)</div><div class=\"line\">        response = json.loads(self.conn.getresponse().read())</div><div class=\"line\">        return response</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">class UcloudApiClient(object):</div><div class=\"line\">    # 添加 设置 数据中心和  zone 参数</div><div class=\"line\">    def __init__(self, base_url, public_key, private_key):</div><div class=\"line\">        self.g_params = &#123;&#125;</div><div class=\"line\">        self.g_params[&apos;PublicKey&apos;] = public_key</div><div class=\"line\">        self.private_key = private_keyurl</div><div class=\"line\">        self.conn = UConnection(base_url)</div><div class=\"line\"></div><div class=\"line\">    def get(self, uri, params):</div><div class=\"line\">        # print params</div><div class=\"line\">        _params = dict(self.g_params, **params)</div><div class=\"line\"></div><div class=\"line\">        if project_id :</div><div class=\"line\">            _params[&quot;ProjectId&quot;] = project_id</div><div class=\"line\"></div><div class=\"line\">        _params[&quot;Signature&quot;] = _verfy_ac(self.private_key, _params)</div><div class=\"line\">        return self.conn.get(uri, _params)</div></pre></td></tr></table></figure>\n<h2 id=\"confpy\"><a href=\"#conf-py\" class=\"headerlink\" title=\"conf.py\"></a><code>conf.py</code></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">#-*- encoding: utf-8 -*-</div><div class=\"line\">#配置公私钥&quot;&quot;&quot;</div><div class=\"line\">public_key  = &quot;at************************&quot;</div><div class=\"line\">private_key = &quot;e7***************&quot;</div><div class=\"line\">#project_id = &quot;******&quot; # 项目ID 请在Dashbord 上获取</div><div class=\"line\"></div><div class=\"line\">base_url    = &quot;https://api.ucloud.cn&quot;</div></pre></td></tr></table></figure>\n<h2 id=\"collect_uhost_pricepy\"><a href=\"#collect-uhost-price-py\" class=\"headerlink\" title=\"collect_uhost_price.py\"></a>collect_uhost_price.py</h2><blockquote>\n<p>通过查看机器示例，按付费方式查看机器价格。<br>具体查看<a href=\"https://docs.ucloud.cn/api/uhost-api/index\" target=\"_blank\" rel=\"external\">ucloud uhost API</a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/python</div><div class=\"line\">#-*- coding:utf-8 -*-</div><div class=\"line\"></div><div class=\"line\"># author:fanquanqing</div><div class=\"line\"># collect ucloud uhost price</div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">from collections import Iterable</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">#host_list = []</div><div class=\"line\"></div><div class=\"line\"># 收集uhost信息</div><div class=\"line\">def collect_uhost_info(Regions_list,ProjectId):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    包含 hostname, ip, region, cpu, mem, diskspace, chargetype, count, ImageId, osname.</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    host_info_list = []</div><div class=\"line\">    for Region in Regions_list:</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;</div><div class=\"line\">        &quot;Action&quot;:&quot;DescribeUHostInstance&quot;,</div><div class=\"line\">        &quot;Region&quot;:Region,</div><div class=\"line\">        &quot;ProjectId&quot;:ProjectId,</div><div class=\"line\">        &quot;Limit&quot;:&quot;1000&quot;</div><div class=\"line\">        &#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters);</div><div class=\"line\">        length = response[&apos;TotalCount&apos;]</div><div class=\"line\">        for i in range(length):</div><div class=\"line\">            host_info = &#123;&#125;</div><div class=\"line\">            #ImageId = response[&quot;UHostSet&quot;][i][&quot;BasicImageId&quot;].encode(&quot;utf-8&quot;)</div><div class=\"line\">            ChargeType = response[&quot;UHostSet&quot;][i][&quot;ChargeType&quot;].encode(&quot;utf-8&quot;)</div><div class=\"line\">            #host_info[&quot;Action&quot;] = &quot;GetUHostInstancePrice&quot;</div><div class=\"line\">            host_info[&quot;Region&quot;] = Region</div><div class=\"line\">            host_info[&quot;ImageId&quot;] = &quot;uimage-kg0w4u&quot;</div><div class=\"line\">            host_info[&quot;Hostname&quot;] = response[&quot;UHostSet&quot;][i][&quot;Name&quot;]</div><div class=\"line\">            host_info[&quot;CPU&quot;] = response[&quot;UHostSet&quot;][i][&quot;CPU&quot;]</div><div class=\"line\">            host_info[&quot;Memory&quot;] = response[&quot;UHostSet&quot;][i][&quot;Memory&quot;]</div><div class=\"line\"></div><div class=\"line\">            if len(response[&quot;UHostSet&quot;][i][&quot;DiskSet&quot;]) &gt; 1:</div><div class=\"line\">                host_info[&quot;DiskSpace&quot;] = response[&quot;UHostSet&quot;][i][&quot;DiskSet&quot;][1][&quot;Size&quot;]</div><div class=\"line\">            else:</div><div class=\"line\">                host_info[&quot;DiskSpace&quot;]=0</div><div class=\"line\">            host_info[&quot;Count&quot;] = 1</div><div class=\"line\">            host_info[&quot;ChargeType&quot;] = ChargeType</div><div class=\"line\">            host_info[&quot;OsName&quot;] = response[&quot;UHostSet&quot;][i][&quot;OsName&quot;].split()[0]</div><div class=\"line\">            host_info[&quot;loaclIP&quot;] = response[&quot;UHostSet&quot;][i][&quot;IPSet&quot;][0][&quot;IP&quot;]</div><div class=\"line\">            if len(response[&quot;UHostSet&quot;][i][&quot;IPSet&quot;])&gt;1:</div><div class=\"line\">                host_info[&quot;EIP&quot;]=response[&quot;UHostSet&quot;][i][&quot;IPSet&quot;][1][&quot;IP&quot;]</div><div class=\"line\">            else:</div><div class=\"line\">                host_info[&quot;EIP&quot;]=&quot;none&quot;</div><div class=\"line\"></div><div class=\"line\">            host_info_list.append(host_info)</div><div class=\"line\">    #print host_info_list</div><div class=\"line\">    return host_info_list</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">#通过机器配置得到某一台机器价格</div><div class=\"line\">def get_uhost_price(host_instance_info):</div><div class=\"line\">    ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">    Parameters= host_instance_info</div><div class=\"line\">    response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">#    print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\">    price = float(response[&quot;PriceSet&quot;][0].values()[0])</div><div class=\"line\">    return price</div><div class=\"line\"></div><div class=\"line\">#通过机器配置信息得到所有机器价格</div><div class=\"line\">def get_all_uhost_price(host_info_list):</div><div class=\"line\"></div><div class=\"line\">    for host_info in host_info_list:</div><div class=\"line\">        host_params=&#123;&#125;</div><div class=\"line\">        host_params[&quot;Action&quot;]=&quot;GetUHostInstancePrice&quot;</div><div class=\"line\">        host_params[&quot;ImageId&quot;]=host_info[&quot;ImageId&quot;]</div><div class=\"line\">        host_params[&quot;CPU&quot;]=host_info[&quot;CPU&quot;]</div><div class=\"line\">        host_params[&quot;Memory&quot;]=host_info[&quot;Memory&quot;]</div><div class=\"line\">        host_params[&quot;Count&quot;]=host_info[&quot;Count&quot;]</div><div class=\"line\">        host_params[&quot;DiskSpace&quot;]=host_info[&quot;DiskSpace&quot;]</div><div class=\"line\">        host_params[&quot;Region&quot;]=&quot;cn-bj2&quot;</div><div class=\"line\">        host_params[&quot;ChargeType&quot;]=host_info[&quot;ChargeType&quot;]</div><div class=\"line\">        if host_params[&quot;ChargeType&quot;]==&quot;Year&quot;:</div><div class=\"line\">            price = get_uhost_price(host_params)</div><div class=\"line\">        elif host_params[&quot;ChargeType&quot;]==&quot;Month&quot;:</div><div class=\"line\">            price = get_uhost_price(host_params)*12</div><div class=\"line\">        else:</div><div class=\"line\">            price=0</div><div class=\"line\">            print &quot;有临时机器请排查。&quot;</div><div class=\"line\">        host_info[&quot;Price&quot;]=price</div><div class=\"line\"></div><div class=\"line\">    return host_info_list</div><div class=\"line\"></div><div class=\"line\">def collect_uhost_price(setting_info):</div><div class=\"line\"></div><div class=\"line\">    host_info_total = []</div><div class=\"line\">    for Projectname in setting_info:</div><div class=\"line\">        for ProjectId in setting_info[Projectname]:</div><div class=\"line\">            Regions_list = setting_info[Projectname][ProjectId]</div><div class=\"line\">            host_info_list = collect_uhost_info(Regions_list,ProjectId)</div><div class=\"line\">            project_host_list = get_all_uhost_price(host_info_list)</div><div class=\"line\">            host_info_total.extend(project_host_list)</div><div class=\"line\">    return host_info_total</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    host_info_list = collect_uhost_info([&apos;cn-bj2&apos;,&apos;hk&apos;],&quot;org-oddm1w&quot;)</div><div class=\"line\">    host_price_list = get_all_uhost_price(host_info_list)</div><div class=\"line\">    #print host_price_list</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h2 id=\"collect_eip_pricepy\"><a href=\"#collect-eip-price-py\" class=\"headerlink\" title=\"collect_eip_price.py\"></a>collect_eip_price.py</h2><blockquote>\n<p>收集弹性IP信息<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env python</div><div class=\"line\"># -*- coding:utf-8 -*-</div><div class=\"line\"># author:fanquanqing</div><div class=\"line\"># collect ucloud eip price</div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\"></div><div class=\"line\"># 得到所有的EIP实例信息</div><div class=\"line\">def get_eip_instance(Regions_list,ProjectId):</div><div class=\"line\">    eip_all = []</div><div class=\"line\">    for Region in Regions_list:</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;&quot;Action&quot;:&quot;DescribeEIP&quot;, &quot;Region&quot;:Region, &quot;ProjectId&quot;:ProjectId&#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">        for eip in response[&apos;EIPSet&apos;]:</div><div class=\"line\">            eip_instance = &#123;&#125;</div><div class=\"line\">            # 地域</div><div class=\"line\">            eip_instance[&apos;Region&apos;]=Region</div><div class=\"line\">            # IP</div><div class=\"line\">            eip_instance[&apos;IP&apos;]=eip[&apos;EIPAddr&apos;][0][&apos;IP&apos;]</div><div class=\"line\"></div><div class=\"line\">            # 运营商线路</div><div class=\"line\">            eip_instance[&apos;OperatorName&apos;]=eip[&apos;EIPAddr&apos;][0][&apos;OperatorName&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">            # 带宽</div><div class=\"line\">            eip_instance[&apos;Bandwidth&apos;]=eip[&apos;Bandwidth&apos;]</div><div class=\"line\">            # 付费周期</div><div class=\"line\">            eip_instance[&apos;ChargeType&apos;]=eip[&apos;ChargeType&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">            # 付费方式(是否绑定共享带宽)</div><div class=\"line\">            eip_instance[&apos;PayMode&apos;]=eip[&apos;PayMode&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">            eip_all.append(eip_instance)</div><div class=\"line\"></div><div class=\"line\">    return eip_all</div><div class=\"line\">    #print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\"></div><div class=\"line\"># 查看单个EIP实例价格</div><div class=\"line\">def get_eip_price(eip):</div><div class=\"line\">    ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">    Parameters=eip</div><div class=\"line\">    response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">    #print response</div><div class=\"line\">    price = response[&apos;PriceSet&apos;][0][&apos;Price&apos;]</div><div class=\"line\">    return price</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># 获取所有EIP价格</div><div class=\"line\">def get_all_eip_price(eip_all):</div><div class=\"line\"></div><div class=\"line\">    for eip_info in eip_all:</div><div class=\"line\">        eip_params=&#123;&#125;</div><div class=\"line\">        eip_params[&apos;Action&apos;]=&quot;GetEIPPrice&quot;</div><div class=\"line\">        eip_params[&apos;Region&apos;]=eip_info[&apos;Region&apos;]</div><div class=\"line\">        eip_params[&apos;OperatorName&apos;]=eip_info[&apos;OperatorName&apos;]</div><div class=\"line\">        eip_params[&apos;Bandwidth&apos;]=eip_info[&apos;Bandwidth&apos;]</div><div class=\"line\">        eip_params[&apos;ChargeType&apos;]=eip_info[&apos;ChargeType&apos;]</div><div class=\"line\">        eip_params[&apos;PayMode&apos;]=eip_info[&apos;PayMode&apos;]</div><div class=\"line\">        if eip_params[&apos;ChargeType&apos;]==&quot;Year&quot;:</div><div class=\"line\">            price = get_eip_price(eip_params)</div><div class=\"line\">        elif eip_params[&apos;ChargeType&apos;]==&quot;Month&quot;:</div><div class=\"line\">            price = get_eip_price(eip_params)*12</div><div class=\"line\">        else:</div><div class=\"line\">            price=0</div><div class=\"line\">            print &quot;有临时EIP请排查&quot;</div><div class=\"line\">        eip_info[&quot;Price&quot;]=price</div><div class=\"line\">    return eip_all</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">def collect_eip_price(setting_info):</div><div class=\"line\">    eip_info_total = []</div><div class=\"line\">    for Projectname in setting_info:</div><div class=\"line\">        for ProjectId in setting_info[Projectname]:</div><div class=\"line\">            Regions_list = setting_info[Projectname][ProjectId]</div><div class=\"line\">            eip_all=get_eip_instance(Regions_list,ProjectId)</div><div class=\"line\">            price_all=get_all_eip_price(eip_all)</div><div class=\"line\">            eip_info_total.extend(price_all)</div><div class=\"line\">    #print eip_info_total</div><div class=\"line\">    return eip_info_total</div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    collect_eip_price(&#123;&quot;chunyu&quot;:&#123;&quot;org-oddm1w&quot;:[&apos;cn-bj2&apos;,&apos;hk&apos;]&#125;, &quot;uhs&quot;:&#123;&quot;org-shbbct&quot;:[&quot;cn-bj2&quot;]&#125;&#125;)</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h2 id=\"collect_udisk_pricepy\"><a href=\"#collect-udisk-price-py\" class=\"headerlink\" title=\"collect_udisk_price.py\"></a>collect_udisk_price.py</h2><blockquote>\n<p>收集云硬盘信息，这个只是取到实例自己手动算的价格<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env python</div><div class=\"line\"># -*- coding:utf-8 -*-</div><div class=\"line\"></div><div class=\"line\"># author: fanquanqing</div><div class=\"line\"># 收集ucloud云硬盘信息 及价格</div><div class=\"line\"></div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\"></div><div class=\"line\"># 获取udisk 信息</div><div class=\"line\">def get_udisk_info(Regions_list,ProjectId):</div><div class=\"line\">    udisk_list = []</div><div class=\"line\">    for Region in Regions_list:</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;&quot;Action&quot;:&quot;DescribeUDisk&quot;, &quot;Region&quot;:Region, &quot;ProjectId&quot;:ProjectId&#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">        for udisk in response[&apos;DataSet&apos;]:</div><div class=\"line\">            udisk_dic = &#123;&#125;</div><div class=\"line\">            udisk_dic[&apos;Region&apos;] = Region</div><div class=\"line\">            #udisk_dic[&apos;Action&apos;] = &quot;DescribeUDiskPrice&quot;</div><div class=\"line\">            udisk_dic[&apos;Size&apos;] = udisk[&apos;Size&apos;]</div><div class=\"line\">            udisk_dic[&apos;ChargeType&apos;] = udisk[&apos;ChargeType&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">            udisk_dic[&apos;UHostName&apos;] = udisk[&apos;UHostName&apos;]</div><div class=\"line\">            udisk_dic[&apos;Quantity&apos;] = 1</div><div class=\"line\">            udisk_dic[&apos;Zone&apos;] = &quot;cn-bj2-02&quot;</div><div class=\"line\">            udisk_list.append(udisk_dic)</div><div class=\"line\">    return udisk_list</div><div class=\"line\"></div><div class=\"line\"># 通过udisk信息获取价格</div><div class=\"line\">def get_udisk_price(udisk_list):</div><div class=\"line\">    for udisk in udisk_list:</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        udisk_params=&#123;&#125;</div><div class=\"line\">        udisk_params[&apos;Action&apos;]=&quot;DescribeUDiskPrice&quot;</div><div class=\"line\">        udisk_params[&apos;Region&apos;]=udisk[&apos;Region&apos;]</div><div class=\"line\">        udisk_params[&apos;Size&apos;]=udisk[&apos;Size&apos;]</div><div class=\"line\">        udisk_params[&apos;ChargeType&apos;]=udisk[&apos;ChargeType&apos;]</div><div class=\"line\">        udisk_params[&apos;Quantity&apos;]=udisk[&apos;Quantity&apos;]</div><div class=\"line\">        udisk_params[&apos;Zone&apos;]=udisk[&apos;Zone&apos;]</div><div class=\"line\">        Parameters = udisk_params</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">        if udisk_params[&apos;ChargeType&apos;]==&quot;Year&quot;:</div><div class=\"line\">            price = response[&apos;DataSet&apos;][0][&apos;Price&apos;]/100</div><div class=\"line\">        elif udisk_params[&apos;ChargeType&apos;]==&quot;Month&quot;:</div><div class=\"line\">            price = response[&apos;DataSet&apos;][0][&apos;Price&apos;]/10</div><div class=\"line\">        else:</div><div class=\"line\">            print &quot;有付费方式异常的云硬盘，请排查。&quot;</div><div class=\"line\">        udisk[&quot;Price&quot;]=price</div><div class=\"line\">    return udisk_list</div><div class=\"line\"></div><div class=\"line\"># 通过付费周期获取udisk价格</div><div class=\"line\">def collect_udisk_price(setting_info):</div><div class=\"line\">    udisk_price_info = []</div><div class=\"line\">    for Projectname in setting_info:</div><div class=\"line\">        for ProjectId in setting_info[Projectname]:</div><div class=\"line\">            Regions_list = setting_info[Projectname][ProjectId]</div><div class=\"line\">            udisk_list = get_udisk_info(Regions_list,ProjectId)</div><div class=\"line\">            udisk_price_info.extend(get_udisk_price(udisk_list))</div><div class=\"line\">    return udisk_price_info</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    collect_udisk_price(&#123;&quot;chunyu&quot;:&#123;&quot;org-oddm1w&quot;:[&apos;cn-bj2&apos;,&apos;hk&apos;]&#125;, &quot;uhs&quot;:&#123;&quot;org-shbbct&quot;:[&quot;cn-bj2&quot;]&#125;&#125;)</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h2 id=\"collect_sharebandwidth_pricepy\"><a href=\"#collect-sharebandwidth-price-py\" class=\"headerlink\" title=\"collect_sharebandwidth_price.py\"></a>collect_sharebandwidth_price.py</h2><blockquote>\n<p>收集共享带宽信息,因为没有计算价格的API这个价格也是手动算的。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/python</div><div class=\"line\"># -*- coding: utf-8 -*-</div><div class=\"line\">#author fanquanqing</div><div class=\"line\">#收集共享带宽信息获取每年消费情况</div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\"></div><div class=\"line\">def get_bandwidth_info(Regions_list,ProjectId):</div><div class=\"line\">    bandwidth = []</div><div class=\"line\">    for Region in Regions_list:</div><div class=\"line\"></div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;&quot;Action&quot;:&quot;DescribeShareBandwidth&quot;,&quot;Region&quot;:Region,&quot;ProjectId&quot;:ProjectId&#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">        #print response</div><div class=\"line\">        for bw in response[&apos;DataSet&apos;]:</div><div class=\"line\">            bw_instance = &#123;&#125;</div><div class=\"line\">            bw_instance[&apos;ShareBandwidth&apos;] =  bw[&apos;ShareBandwidth&apos;]</div><div class=\"line\">            bw_instance[&apos;ChargeType&apos;] = bw[&apos;ChargeType&apos;]</div><div class=\"line\">            bw_instance[&apos;Name&apos;]=bw[&apos;Name&apos;]</div><div class=\"line\">            bandwidth.append(bw_instance)</div><div class=\"line\">    return bandwidth</div><div class=\"line\">#   print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\"></div><div class=\"line\">def get_price(bandwidth):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    价格计算说明:ucloud没有提供API查询共享带宽价格，所有的共享带宽价格都是90/M/月 月付*12,年付*10</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    price_list = []</div><div class=\"line\">    for bw in bandwidth:</div><div class=\"line\">        if bw[&apos;ChargeType&apos;]==&quot;Month&quot;:</div><div class=\"line\">            price = bw[&apos;ShareBandwidth&apos;]*90*12</div><div class=\"line\">            bw[&quot;Price&quot;]=price</div><div class=\"line\">        else:</div><div class=\"line\">            price = bw[&apos;ShareBandwidrh&apos;]</div><div class=\"line\">            bw[&quot;Price&quot;]=price</div><div class=\"line\">    return bandwidth</div><div class=\"line\"></div><div class=\"line\">def collect_sharebandwidth_price(setting_info):</div><div class=\"line\">    bw_price_info = []</div><div class=\"line\">    for Projectname in setting_info:</div><div class=\"line\">        for ProjectId in setting_info[Projectname]:</div><div class=\"line\">            Regions_list = setting_info[Projectname][ProjectId]</div><div class=\"line\">            bw_info = get_bandwidth_info(Regions_list,ProjectId)</div><div class=\"line\">            bw_price_info.extend(get_price(bw_info))</div><div class=\"line\">    #print bw_price_info</div><div class=\"line\">    return bw_price_info</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    collect_sharebandwidth_price(&#123;&quot;chunyu&quot;:&#123;&quot;org-oddm1w&quot;:[&apos;cn-bj2&apos;,&apos;hk&apos;]&#125;, &quot;uhs&quot;:&#123;&quot;org-shbbct&quot;:[&quot;cn-bj2&quot;]&#125;&#125;)</div></pre></td></tr></table></figure>\n<h2 id=\"get_all_pricepy\"><a href=\"#get-all-price-py\" class=\"headerlink\" title=\"get_all_price.py\"></a>get_all_price.py</h2><blockquote>\n<p>给各实例价格求和，发送到influxdb。可以每天跑一下cron更新下内容。<strong>里面发送的influxDB是事先封装好的包直接导入的，并不是官方包</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env python</div><div class=\"line\"># -*- coding:utf-8 -*-</div><div class=\"line\"></div><div class=\"line\"># author: fanquanqing</div><div class=\"line\">#import datatime</div><div class=\"line\">from collect_eip_price import collect_eip_price</div><div class=\"line\">from collect_uhost_price import collect_uhost_price</div><div class=\"line\">from collect_sharebandwidth_price import collect_sharebandwidth_price</div><div class=\"line\">from collect_udisk_price import collect_udisk_price</div><div class=\"line\">from op_tools.api_influxdb import write_data_to_influxdb</div><div class=\"line\"></div><div class=\"line\">def get_price(setting_info):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    各个实例price求和,并把实例信息发送到influxdb</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    eip_price=0</div><div class=\"line\">    uhost_price=0</div><div class=\"line\">    sharebw_price=0</div><div class=\"line\">    udisk_price=0</div><div class=\"line\">    eip_price_info_list = collect_eip_price(setting_info)</div><div class=\"line\">    for eip_info in eip_price_info_list:</div><div class=\"line\">        eip_headers = eip_info.keys()</div><div class=\"line\">        eip_rows = []</div><div class=\"line\">        eip_rows.append(eip_info.values())</div><div class=\"line\">        #print eip_headers, eip_rows</div><div class=\"line\">        # 发送EIP数据到influxdb</div><div class=\"line\">        write_data_to_influxdb(&apos;EIP_info_daliy&apos;, eip_headers, eip_rows, [&apos;IP&apos;, &apos;OperatorName&apos;, &apos;ChargeType&apos;])</div><div class=\"line\">        eip_price += round(eip_info[&apos;Price&apos;])</div><div class=\"line\"></div><div class=\"line\">    uhost_price_info_list = collect_uhost_price(setting_info)</div><div class=\"line\">    for uhost_info in uhost_price_info_list:</div><div class=\"line\">        uhost_headers=uhost_info.keys()</div><div class=\"line\">        uhost_rows=[]</div><div class=\"line\">        uhost_rows.append(uhost_info.values())</div><div class=\"line\">        #print uhost_headers, uhost_rows</div><div class=\"line\">        # 发送云主机信息到influxdb</div><div class=\"line\">        write_data_to_influxdb(&apos;Uhost_info_daliy&apos;, uhost_headers, uhost_rows, [&apos;Hostname&apos;,&apos;ChargeType&apos;])</div><div class=\"line\">        uhost_price += round(uhost_info[&apos;Price&apos;])</div><div class=\"line\"></div><div class=\"line\">    sharebandwidth_info_list = collect_sharebandwidth_price(setting_info)</div><div class=\"line\">    for sharebandwidth_info in sharebandwidth_info_list:</div><div class=\"line\">        sharebw_headers=sharebandwidth_info.keys()</div><div class=\"line\">        sharebw_rows=[]</div><div class=\"line\">        sharebw_rows.append(sharebandwidth_info.values())</div><div class=\"line\">        #print sharebw_headers, sharebw_rows</div><div class=\"line\">        # 发送共享带宽信息到influxdb</div><div class=\"line\">        write_data_to_influxdb(&apos;ShareBandwidth_info_daliy&apos;,sharebw_headers,sharebw_rows,[])</div><div class=\"line\">        sharebw_price += round(sharebandwidth_info[&apos;Price&apos;])</div><div class=\"line\"></div><div class=\"line\">    udisk_info_list=collect_udisk_price(setting_info)</div><div class=\"line\">    for udisk_info in udisk_info_list:</div><div class=\"line\">        udisk_headers=udisk_info.keys()</div><div class=\"line\">        udisk_rows=[]</div><div class=\"line\">        udisk_rows.append(udisk_info.values())</div><div class=\"line\">        #print udisk_headers, udisk_rows</div><div class=\"line\">        write_data_to_influxdb(&apos;Udisk_info_daliy&apos;, udisk_headers,udisk_rows,[&apos;UHostName&apos;,&apos;Region&apos;])</div><div class=\"line\">        udisk_price += round(udisk_info[&apos;Price&apos;])</div><div class=\"line\">    # 托管机房价格</div><div class=\"line\">    physical_price = get_physical_host_price()</div><div class=\"line\">    total_price=eip_price+uhost_price+sharebw_price+udisk_price+physical_price</div><div class=\"line\">    # 价格列表</div><div class=\"line\">    price_list=[eip_price,uhost_price,sharebw_price,udisk_price,total_price]</div><div class=\"line\">    price_headers=[&apos;eip_price&apos;,&apos;uhost_price&apos;,&apos;sharebw_price&apos;,&apos;udisk_price&apos;,&apos;total_price&apos;]</div><div class=\"line\">    price_rows=[]</div><div class=\"line\">    price_rows.append(price_list)</div><div class=\"line\">    write_data_to_influxdb(&apos;Ucloud_price_total_daliy&apos;,price_headers,price_rows,[])</div><div class=\"line\"></div><div class=\"line\">    #print uhost_price</div><div class=\"line\">    return uhost_price</div><div class=\"line\"></div><div class=\"line\"># 托管机器价格(两个机柜一个10M外网)</div><div class=\"line\">def get_physical_host_price():</div><div class=\"line\">    host_price = 9000*2*12</div><div class=\"line\">    tg_cloud_switch_port_price = (288*2+217)*12</div><div class=\"line\">    tg_bandwidth_price = 10*90*12</div><div class=\"line\">    physical_price = host_price+tg_bandwidth_price+tg_cloud_switch_port_price</div><div class=\"line\">    return physical_price</div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    # 可用区列表</div><div class=\"line\">    #Regions_list = [&apos;cn-bj2&apos;,&apos;hk&apos;]</div><div class=\"line\">    # 项目ID列表</div><div class=\"line\">    #Project_Id_list = [&apos;org-shbbct&apos;,&apos;org-oddm1w&apos;]</div><div class=\"line\">    # 项目ID对应关系</div><div class=\"line\">    setting_info = &#123;&quot;chunyu&quot;:&#123;&quot;org-oddm1w&quot;:[&apos;cn-bj2&apos;,&apos;hk&apos;]&#125;, &quot;uhs&quot;:&#123;&quot;org-shbbct&quot;:[&quot;cn-bj2&quot;]&#125;&#125;</div><div class=\"line\">    get_price(setting_info)</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h2 id=\"grafana效果展示\"><a href=\"#grafana效果展示\" class=\"headerlink\" title=\"grafana效果展示\"></a>grafana效果展示</h2><blockquote>\n<p>grafana跟influxDB配合的非常好，设置也非常简单。下面我在下面放几张效果图。</p>\n</blockquote>\n<p><strong>简单查询语句</strong><br><img src=\"http://or2jd66dq.bkt.clouddn.com/grafana_influxdb.png\" alt=\"\"></p>\n<p><strong>table展示效果</strong><br><img src=\"http://or2jd66dq.bkt.clouddn.com/grafana_ucloud_eip.png\" alt=\"\"></p>\n<p><strong>价格图展示</strong><br><img src=\"http://or2jd66dq.bkt.clouddn.com/grafana_ucloud_price.png\" alt=\"\"></p>\n<h2 id=\"获取实时带宽信息并发送报警到钉钉\"><a href=\"#获取实时带宽信息并发送报警到钉钉\" class=\"headerlink\" title=\"获取实时带宽信息并发送报警到钉钉\"></a>获取实时带宽信息并发送报警到钉钉</h2><blockquote>\n<p>这个跟上面的脚本没有关联，只是获取实时带宽使用量的报警脚本。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env python</div><div class=\"line\"># -*- coding: utf-8 -*-</div><div class=\"line\"></div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\">import urllib2</div><div class=\"line\">import time</div><div class=\"line\">#from op_tools import falcon</div><div class=\"line\"></div><div class=\"line\">#实例化 API 句柄</div><div class=\"line\">localtime = time.asctime( time.localtime(time.time()) )</div><div class=\"line\"></div><div class=\"line\">def get_eip_info():</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    获取EIP对应的主机名，以及EIP信息返回</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    arg_length = len(sys.argv)</div><div class=\"line\">    ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">    Parameters=&#123;&quot;Action&quot;:&quot;DescribeEIP&quot;, &quot;Region&quot;:&quot;cn-bj2&quot;&#125;</div><div class=\"line\">    response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">    eip_info_list = response[&apos;EIPSet&apos;]</div><div class=\"line\">    eip_dic = &#123;&#125;</div><div class=\"line\">    for eip_info in eip_info_list:</div><div class=\"line\">        # EIP绑定主机名</div><div class=\"line\">        eip_host = eip_info[&apos;Resource&apos;][&apos;ResourceName&apos;]</div><div class=\"line\">        eip_ip = eip_info[&apos;EIPAddr&apos;][0][&apos;IP&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">        eip_id = eip_info[&apos;EIPId&apos;]</div><div class=\"line\">        dic = &#123;&#125;</div><div class=\"line\">        dic[eip_ip] = eip_id</div><div class=\"line\">        #print &quot;eip_host:%s,dic:%s&quot; % (eip_host,dic)</div><div class=\"line\">        eip_dic[eip_host] = dic</div><div class=\"line\">    #print len(eip_dic)</div><div class=\"line\">    eip_dic[&apos;nginx-online1&apos;] = &#123;&apos;106.75.28.177&apos;: u&apos;eip-00gv0l&apos;&#125;</div><div class=\"line\">    return eip_dic</div><div class=\"line\"></div><div class=\"line\">def get_eip_usage(eip_dic):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    获取每个EIP的实时用量(要求EIPid),</div><div class=\"line\">    return list:[&#123;ip:usage&#125;...]</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    eip_usage_dic = &#123;&#125;</div><div class=\"line\">    for eip_host in eip_dic:</div><div class=\"line\">        #eip_useage_dic = &#123;&#125;</div><div class=\"line\">        eip_id=eip_dic[eip_host].values()[0].encode(&quot;utf-8&quot;)</div><div class=\"line\">        #print eip_id</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;</div><div class=\"line\">                    &quot;Action&quot;:&quot;DescribeBandwidthUsage&quot;,</div><div class=\"line\">                    &quot;Region&quot;:&quot;cn-bj2&quot;,</div><div class=\"line\">                    &quot;EIPIds.1&quot;:eip_id,</div><div class=\"line\">                &#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters);</div><div class=\"line\">        #print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\">        #print response</div><div class=\"line\">        eip_usage = response[&apos;EIPSet&apos;][0][&apos;CurBandwidth&apos;]</div><div class=\"line\">        eip_usage_dic[eip_host]=eip_usage</div><div class=\"line\">        #eip_usage_list.append(eip_useage_dic)</div><div class=\"line\">    return eip_usage_dic</div><div class=\"line\"></div><div class=\"line\">def sendto_falcon(eip_usage_list):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    报警发送到falcon</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    collect_step = 60</div><div class=\"line\">    counter_type = falcon.CounterType.GAUGE</div><div class=\"line\">    metric = &quot;bandwidthusage&quot;</div><div class=\"line\">    for eip_usage in eip_usage_list:</div><div class=\"line\">        tags=&quot;host=&quot; + eip_usage.keys()[0]</div><div class=\"line\">        value=eip_usage.values()[0]</div><div class=\"line\">        #print value</div><div class=\"line\"></div><div class=\"line\">def get_sharebw_info():</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    获取共享带宽的带宽大小，以及所包含的EIP,</div><div class=\"line\">    return list:[&#123;&apos;eiplist&apos;:[ip1,ip1],&apos;bandwidth&apos;:20&#125;...]</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\"></div><div class=\"line\">    ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">    Parameters=&#123;&quot;Action&quot;:&quot;DescribeShareBandwidth&quot;, &quot;Region&quot;:&quot;cn-bj2&quot;&#125;</div><div class=\"line\">    response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">    #print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\">    share_bw_list = response[&apos;DataSet&apos;]</div><div class=\"line\">    share_bw_info = []</div><div class=\"line\">    for share_bw in share_bw_list:</div><div class=\"line\">        share_bw_dic = &#123;&#125;</div><div class=\"line\">        bandwidth = share_bw[&apos;ShareBandwidth&apos;]</div><div class=\"line\">        eip_list = []</div><div class=\"line\">        for eip_dic in share_bw[&apos;EIPSet&apos;]:</div><div class=\"line\">            ip = eip_dic[&apos;EIPAddr&apos;][0][&apos;IP&apos;]</div><div class=\"line\">            eip_list.append(ip)</div><div class=\"line\">        share_bw_dic[&apos;bandwidth&apos;]=bandwidth</div><div class=\"line\">        share_bw_dic[&apos;eiplist&apos;]=eip_list</div><div class=\"line\">        share_bw_info.append(share_bw_dic)</div><div class=\"line\">    return share_bw_info</div><div class=\"line\"></div><div class=\"line\">def sum():</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    返回比值，并简单记录log到/var/log/ubandwidth.log</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    eip_dic = get_eip_info()</div><div class=\"line\">    #print eip_dic</div><div class=\"line\">    eip_to_host = &#123;&#125;</div><div class=\"line\">    # 通过eip_dic获取IP-host对此应关系dic</div><div class=\"line\">    for host in eip_dic:</div><div class=\"line\">        eip = eip_dic[host].keys()[0]</div><div class=\"line\">        eip_to_host[eip]=host</div><div class=\"line\">    #print eip_to_host</div><div class=\"line\">    eip_usage_dic = get_eip_usage(eip_dic)</div><div class=\"line\">    #print eip_usage_dic</div><div class=\"line\">    share_bw_info = get_sharebw_info()</div><div class=\"line\">    #print share_bw_info</div><div class=\"line\">    #各带宽和与带宽比值</div><div class=\"line\">    ratios = &#123;&#125;</div><div class=\"line\">    for share_bandwidth in share_bw_info:</div><div class=\"line\">        bandwidth = share_bandwidth[&apos;bandwidth&apos;]</div><div class=\"line\">        sum = 0</div><div class=\"line\">        for eip in share_bandwidth[&apos;eiplist&apos;]:</div><div class=\"line\">            host = eip_to_host[eip]</div><div class=\"line\">            usage = eip_usage_dic[host]</div><div class=\"line\">            sum += usage</div><div class=\"line\">        #带宽用量与带宽的比值</div><div class=\"line\">        ratio = sum/bandwidth</div><div class=\"line\">        parts = [str(bandwidth),str(sum),str(ratio)]</div><div class=\"line\">        log =localtime + &apos; &apos; + &apos;,&apos;.join(parts) + &apos;\\n&apos;</div><div class=\"line\">        with open(&apos;/var/log/ubandwidth.log&apos;,&apos;a&apos;) as f:</div><div class=\"line\">            f.write(log)</div><div class=\"line\">            f.close()</div><div class=\"line\"></div><div class=\"line\">        ratios[bandwidth]=ratio</div><div class=\"line\"></div><div class=\"line\">    return ratios</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">def send_to_dingtalk(content):</div><div class=\"line\"></div><div class=\"line\">    url = &quot;https://oapi.dingtalk.com/robot/send?access_token=17cf865229a63452ff411243b53d64949d5a54b1ee8774e20e1ec7d4c5d60f43&quot;</div><div class=\"line\">    #con=&#123;&quot;msgtype&quot;:&quot;text&quot;,&quot;text&quot;:&#123;&quot;content&quot;:content&#125;,&quot;isAtAll&quot;: &quot;true&quot;&#125;</div><div class=\"line\">    con=&#123;&quot;msgtype&quot;:&quot;markdown&quot;,&quot;markdown&quot;:&#123;&quot;title&quot;:&quot;ucloud共享带宽报警&quot;,&quot;text&quot;:content&#125;,&quot;isAtAll&quot;: &quot;ture&quot;&#125;</div><div class=\"line\">    jd=json.dumps(con)</div><div class=\"line\">    req=urllib2.Request(url,jd)</div><div class=\"line\">    req.add_header(&apos;Content-Type&apos;, &apos;application/json&apos;)</div><div class=\"line\">    response=urllib2.urlopen(req)</div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    ratios=sum()</div><div class=\"line\">    localtime = time.asctime( time.localtime(time.time()) )</div><div class=\"line\">    for bw in ratios:</div><div class=\"line\">        if ratios[bw] &gt; 0.8:</div><div class=\"line\">            content = u&quot;# **ucloud共享带宽报警** - %d兆那个。。。\\n\\n - 用量超过百分之80 \\n - **值**:%f \\n &gt; [请排查...](https://console.ucloud.cn/unet/sharebandwidth)&quot; % (bw,ratios[bw])</div><div class=\"line\">            send_to_dingtalk(content)</div></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>我们公司有些服务使用ucloud主机，付费等问题都是我负责，前一段时间跟他们的架构沟通了一下，发现他们的API还是很方便的，尤其他们提供弹性IP可以自由伸缩，我们完全可以写个脚本统计带宽，实时调整。如果在云上跑docker，完全可以直接通过流量挥着访问量实时业务扩容。运维真的做到自动化。</p>\n</blockquote>\n<pre><code>ucloud提供了官方的`apk`[链接](https://github.com/ucloud-web/python-sdk-v2.git)\n</code></pre><p>有的同学直接把它写成了python命令 <a href=\"https://pypi.python.org/pypi/ucli/\" target=\"_blank\" rel=\"external\">链接</a></p>\n<p>本来只是想做一个统计价格的工具，写着写着，就像反正收集实例信息还不如都挨个统计一下展示出来，<br>因为：</p>\n<ol>\n<li>ucloud信息展示的并不清晰  </li>\n<li>如果看到价格有异常肯定第一时间想知道到底哪个贵些，贵在哪里，更方便直观一些</li>\n</ol>\n<p>我在下边主要展示一下自己手写的几个脚本通过API获取实例信息，再通过实例信息获取实例价格，最后统一发送到influxDB中去到grafana上呈现。定时每天跑一次。代码水平有限，大家请不要嘲笑。</p>\n<p>先来看下他的apk和配置文件<br>他的public_key 和 private_key 涉及到自己独特的加秘方式。可以去ucloud官网看看 </p>\n<h2 id=\"apk-py\"><a href=\"#apk-py\" class=\"headerlink\" title=\"apk.py\"></a><code>apk.py</code></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div></pre></td><td class=\"code\"><pre><div class=\"line\"># -*- coding: utf-8 -*-</div><div class=\"line\">import hashlib, json, httplib</div><div class=\"line\">import urlparse</div><div class=\"line\">import urllib</div><div class=\"line\">import sys</div><div class=\"line\">from config import *</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">class UCLOUDException(Exception):</div><div class=\"line\">    def __str__(self):</div><div class=\"line\">        return &quot;Error&quot;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">def _verfy_ac(private_key, params):</div><div class=\"line\">    items = params.items()</div><div class=\"line\">    items.sort()</div><div class=\"line\"></div><div class=\"line\">    params_data = &quot;&quot;</div><div class=\"line\">    for key, value in items:</div><div class=\"line\">        params_data = params_data + str(key) + str(value)</div><div class=\"line\"></div><div class=\"line\">    params_data = params_data+private_key</div><div class=\"line\"></div><div class=\"line\">    &apos;&apos;&apos;use sha1 to encode keys&apos;&apos;&apos;</div><div class=\"line\">    hash_new = hashlib.sha1()</div><div class=\"line\">    hash_new.update(params_data)</div><div class=\"line\">    hash_value = hash_new.hexdigest()</div><div class=\"line\">    return hash_value</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">class UConnection(object):</div><div class=\"line\">    def __init__(self, base_url):</div><div class=\"line\">        self.base_url = base_url</div><div class=\"line\">        o = urlparse.urlsplit(base_url)</div><div class=\"line\">        if o.scheme == &apos;https&apos;:</div><div class=\"line\">            self.conn = httplib.HTTPSConnection(o.netloc)</div><div class=\"line\">        else:</div><div class=\"line\">            self.conn = httplib.HTTPConnection(o.netloc)</div><div class=\"line\"></div><div class=\"line\">    def __del__(self):</div><div class=\"line\">        self.conn.close()</div><div class=\"line\"></div><div class=\"line\">    def get(self, resouse, params):</div><div class=\"line\">        resouse += &quot;?&quot; + urllib.urlencode(params)</div><div class=\"line\">        print(&quot;%s%s&quot; % (self.base_url, resouse))</div><div class=\"line\">        self.conn.request(&quot;GET&quot;, resouse)</div><div class=\"line\">        response = json.loads(self.conn.getresponse().read())</div><div class=\"line\">        return response</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">class UcloudApiClient(object):</div><div class=\"line\">    # 添加 设置 数据中心和  zone 参数</div><div class=\"line\">    def __init__(self, base_url, public_key, private_key):</div><div class=\"line\">        self.g_params = &#123;&#125;</div><div class=\"line\">        self.g_params[&apos;PublicKey&apos;] = public_key</div><div class=\"line\">        self.private_key = private_keyurl</div><div class=\"line\">        self.conn = UConnection(base_url)</div><div class=\"line\"></div><div class=\"line\">    def get(self, uri, params):</div><div class=\"line\">        # print params</div><div class=\"line\">        _params = dict(self.g_params, **params)</div><div class=\"line\"></div><div class=\"line\">        if project_id :</div><div class=\"line\">            _params[&quot;ProjectId&quot;] = project_id</div><div class=\"line\"></div><div class=\"line\">        _params[&quot;Signature&quot;] = _verfy_ac(self.private_key, _params)</div><div class=\"line\">        return self.conn.get(uri, _params)</div></pre></td></tr></table></figure>\n<h2 id=\"conf-py\"><a href=\"#conf-py\" class=\"headerlink\" title=\"conf.py\"></a><code>conf.py</code></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">#-*- encoding: utf-8 -*-</div><div class=\"line\">#配置公私钥&quot;&quot;&quot;</div><div class=\"line\">public_key  = &quot;at************************&quot;</div><div class=\"line\">private_key = &quot;e7***************&quot;</div><div class=\"line\">#project_id = &quot;******&quot; # 项目ID 请在Dashbord 上获取</div><div class=\"line\"></div><div class=\"line\">base_url    = &quot;https://api.ucloud.cn&quot;</div></pre></td></tr></table></figure>\n<h2 id=\"collect-uhost-price-py\"><a href=\"#collect-uhost-price-py\" class=\"headerlink\" title=\"collect_uhost_price.py\"></a>collect_uhost_price.py</h2><blockquote>\n<p>通过查看机器示例，按付费方式查看机器价格。<br>具体查看<a href=\"https://docs.ucloud.cn/api/uhost-api/index\" target=\"_blank\" rel=\"external\">ucloud uhost API</a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/python</div><div class=\"line\">#-*- coding:utf-8 -*-</div><div class=\"line\"></div><div class=\"line\"># author:fanquanqing</div><div class=\"line\"># collect ucloud uhost price</div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">from collections import Iterable</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">#host_list = []</div><div class=\"line\"></div><div class=\"line\"># 收集uhost信息</div><div class=\"line\">def collect_uhost_info(Regions_list,ProjectId):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    包含 hostname, ip, region, cpu, mem, diskspace, chargetype, count, ImageId, osname.</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    host_info_list = []</div><div class=\"line\">    for Region in Regions_list:</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;</div><div class=\"line\">        &quot;Action&quot;:&quot;DescribeUHostInstance&quot;,</div><div class=\"line\">        &quot;Region&quot;:Region,</div><div class=\"line\">        &quot;ProjectId&quot;:ProjectId,</div><div class=\"line\">        &quot;Limit&quot;:&quot;1000&quot;</div><div class=\"line\">        &#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters);</div><div class=\"line\">        length = response[&apos;TotalCount&apos;]</div><div class=\"line\">        for i in range(length):</div><div class=\"line\">            host_info = &#123;&#125;</div><div class=\"line\">            #ImageId = response[&quot;UHostSet&quot;][i][&quot;BasicImageId&quot;].encode(&quot;utf-8&quot;)</div><div class=\"line\">            ChargeType = response[&quot;UHostSet&quot;][i][&quot;ChargeType&quot;].encode(&quot;utf-8&quot;)</div><div class=\"line\">            #host_info[&quot;Action&quot;] = &quot;GetUHostInstancePrice&quot;</div><div class=\"line\">            host_info[&quot;Region&quot;] = Region</div><div class=\"line\">            host_info[&quot;ImageId&quot;] = &quot;uimage-kg0w4u&quot;</div><div class=\"line\">            host_info[&quot;Hostname&quot;] = response[&quot;UHostSet&quot;][i][&quot;Name&quot;]</div><div class=\"line\">            host_info[&quot;CPU&quot;] = response[&quot;UHostSet&quot;][i][&quot;CPU&quot;]</div><div class=\"line\">            host_info[&quot;Memory&quot;] = response[&quot;UHostSet&quot;][i][&quot;Memory&quot;]</div><div class=\"line\"></div><div class=\"line\">            if len(response[&quot;UHostSet&quot;][i][&quot;DiskSet&quot;]) &gt; 1:</div><div class=\"line\">                host_info[&quot;DiskSpace&quot;] = response[&quot;UHostSet&quot;][i][&quot;DiskSet&quot;][1][&quot;Size&quot;]</div><div class=\"line\">            else:</div><div class=\"line\">                host_info[&quot;DiskSpace&quot;]=0</div><div class=\"line\">            host_info[&quot;Count&quot;] = 1</div><div class=\"line\">            host_info[&quot;ChargeType&quot;] = ChargeType</div><div class=\"line\">            host_info[&quot;OsName&quot;] = response[&quot;UHostSet&quot;][i][&quot;OsName&quot;].split()[0]</div><div class=\"line\">            host_info[&quot;loaclIP&quot;] = response[&quot;UHostSet&quot;][i][&quot;IPSet&quot;][0][&quot;IP&quot;]</div><div class=\"line\">            if len(response[&quot;UHostSet&quot;][i][&quot;IPSet&quot;])&gt;1:</div><div class=\"line\">                host_info[&quot;EIP&quot;]=response[&quot;UHostSet&quot;][i][&quot;IPSet&quot;][1][&quot;IP&quot;]</div><div class=\"line\">            else:</div><div class=\"line\">                host_info[&quot;EIP&quot;]=&quot;none&quot;</div><div class=\"line\"></div><div class=\"line\">            host_info_list.append(host_info)</div><div class=\"line\">    #print host_info_list</div><div class=\"line\">    return host_info_list</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">#通过机器配置得到某一台机器价格</div><div class=\"line\">def get_uhost_price(host_instance_info):</div><div class=\"line\">    ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">    Parameters= host_instance_info</div><div class=\"line\">    response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">#    print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\">    price = float(response[&quot;PriceSet&quot;][0].values()[0])</div><div class=\"line\">    return price</div><div class=\"line\"></div><div class=\"line\">#通过机器配置信息得到所有机器价格</div><div class=\"line\">def get_all_uhost_price(host_info_list):</div><div class=\"line\"></div><div class=\"line\">    for host_info in host_info_list:</div><div class=\"line\">        host_params=&#123;&#125;</div><div class=\"line\">        host_params[&quot;Action&quot;]=&quot;GetUHostInstancePrice&quot;</div><div class=\"line\">        host_params[&quot;ImageId&quot;]=host_info[&quot;ImageId&quot;]</div><div class=\"line\">        host_params[&quot;CPU&quot;]=host_info[&quot;CPU&quot;]</div><div class=\"line\">        host_params[&quot;Memory&quot;]=host_info[&quot;Memory&quot;]</div><div class=\"line\">        host_params[&quot;Count&quot;]=host_info[&quot;Count&quot;]</div><div class=\"line\">        host_params[&quot;DiskSpace&quot;]=host_info[&quot;DiskSpace&quot;]</div><div class=\"line\">        host_params[&quot;Region&quot;]=&quot;cn-bj2&quot;</div><div class=\"line\">        host_params[&quot;ChargeType&quot;]=host_info[&quot;ChargeType&quot;]</div><div class=\"line\">        if host_params[&quot;ChargeType&quot;]==&quot;Year&quot;:</div><div class=\"line\">            price = get_uhost_price(host_params)</div><div class=\"line\">        elif host_params[&quot;ChargeType&quot;]==&quot;Month&quot;:</div><div class=\"line\">            price = get_uhost_price(host_params)*12</div><div class=\"line\">        else:</div><div class=\"line\">            price=0</div><div class=\"line\">            print &quot;有临时机器请排查。&quot;</div><div class=\"line\">        host_info[&quot;Price&quot;]=price</div><div class=\"line\"></div><div class=\"line\">    return host_info_list</div><div class=\"line\"></div><div class=\"line\">def collect_uhost_price(setting_info):</div><div class=\"line\"></div><div class=\"line\">    host_info_total = []</div><div class=\"line\">    for Projectname in setting_info:</div><div class=\"line\">        for ProjectId in setting_info[Projectname]:</div><div class=\"line\">            Regions_list = setting_info[Projectname][ProjectId]</div><div class=\"line\">            host_info_list = collect_uhost_info(Regions_list,ProjectId)</div><div class=\"line\">            project_host_list = get_all_uhost_price(host_info_list)</div><div class=\"line\">            host_info_total.extend(project_host_list)</div><div class=\"line\">    return host_info_total</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    host_info_list = collect_uhost_info([&apos;cn-bj2&apos;,&apos;hk&apos;],&quot;org-oddm1w&quot;)</div><div class=\"line\">    host_price_list = get_all_uhost_price(host_info_list)</div><div class=\"line\">    #print host_price_list</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h2 id=\"collect-eip-price-py\"><a href=\"#collect-eip-price-py\" class=\"headerlink\" title=\"collect_eip_price.py\"></a>collect_eip_price.py</h2><blockquote>\n<p>收集弹性IP信息<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env python</div><div class=\"line\"># -*- coding:utf-8 -*-</div><div class=\"line\"># author:fanquanqing</div><div class=\"line\"># collect ucloud eip price</div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\"></div><div class=\"line\"># 得到所有的EIP实例信息</div><div class=\"line\">def get_eip_instance(Regions_list,ProjectId):</div><div class=\"line\">    eip_all = []</div><div class=\"line\">    for Region in Regions_list:</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;&quot;Action&quot;:&quot;DescribeEIP&quot;, &quot;Region&quot;:Region, &quot;ProjectId&quot;:ProjectId&#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">        for eip in response[&apos;EIPSet&apos;]:</div><div class=\"line\">            eip_instance = &#123;&#125;</div><div class=\"line\">            # 地域</div><div class=\"line\">            eip_instance[&apos;Region&apos;]=Region</div><div class=\"line\">            # IP</div><div class=\"line\">            eip_instance[&apos;IP&apos;]=eip[&apos;EIPAddr&apos;][0][&apos;IP&apos;]</div><div class=\"line\"></div><div class=\"line\">            # 运营商线路</div><div class=\"line\">            eip_instance[&apos;OperatorName&apos;]=eip[&apos;EIPAddr&apos;][0][&apos;OperatorName&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">            # 带宽</div><div class=\"line\">            eip_instance[&apos;Bandwidth&apos;]=eip[&apos;Bandwidth&apos;]</div><div class=\"line\">            # 付费周期</div><div class=\"line\">            eip_instance[&apos;ChargeType&apos;]=eip[&apos;ChargeType&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">            # 付费方式(是否绑定共享带宽)</div><div class=\"line\">            eip_instance[&apos;PayMode&apos;]=eip[&apos;PayMode&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">            eip_all.append(eip_instance)</div><div class=\"line\"></div><div class=\"line\">    return eip_all</div><div class=\"line\">    #print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\"></div><div class=\"line\"># 查看单个EIP实例价格</div><div class=\"line\">def get_eip_price(eip):</div><div class=\"line\">    ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">    Parameters=eip</div><div class=\"line\">    response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">    #print response</div><div class=\"line\">    price = response[&apos;PriceSet&apos;][0][&apos;Price&apos;]</div><div class=\"line\">    return price</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"># 获取所有EIP价格</div><div class=\"line\">def get_all_eip_price(eip_all):</div><div class=\"line\"></div><div class=\"line\">    for eip_info in eip_all:</div><div class=\"line\">        eip_params=&#123;&#125;</div><div class=\"line\">        eip_params[&apos;Action&apos;]=&quot;GetEIPPrice&quot;</div><div class=\"line\">        eip_params[&apos;Region&apos;]=eip_info[&apos;Region&apos;]</div><div class=\"line\">        eip_params[&apos;OperatorName&apos;]=eip_info[&apos;OperatorName&apos;]</div><div class=\"line\">        eip_params[&apos;Bandwidth&apos;]=eip_info[&apos;Bandwidth&apos;]</div><div class=\"line\">        eip_params[&apos;ChargeType&apos;]=eip_info[&apos;ChargeType&apos;]</div><div class=\"line\">        eip_params[&apos;PayMode&apos;]=eip_info[&apos;PayMode&apos;]</div><div class=\"line\">        if eip_params[&apos;ChargeType&apos;]==&quot;Year&quot;:</div><div class=\"line\">            price = get_eip_price(eip_params)</div><div class=\"line\">        elif eip_params[&apos;ChargeType&apos;]==&quot;Month&quot;:</div><div class=\"line\">            price = get_eip_price(eip_params)*12</div><div class=\"line\">        else:</div><div class=\"line\">            price=0</div><div class=\"line\">            print &quot;有临时EIP请排查&quot;</div><div class=\"line\">        eip_info[&quot;Price&quot;]=price</div><div class=\"line\">    return eip_all</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">def collect_eip_price(setting_info):</div><div class=\"line\">    eip_info_total = []</div><div class=\"line\">    for Projectname in setting_info:</div><div class=\"line\">        for ProjectId in setting_info[Projectname]:</div><div class=\"line\">            Regions_list = setting_info[Projectname][ProjectId]</div><div class=\"line\">            eip_all=get_eip_instance(Regions_list,ProjectId)</div><div class=\"line\">            price_all=get_all_eip_price(eip_all)</div><div class=\"line\">            eip_info_total.extend(price_all)</div><div class=\"line\">    #print eip_info_total</div><div class=\"line\">    return eip_info_total</div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    collect_eip_price(&#123;&quot;chunyu&quot;:&#123;&quot;org-oddm1w&quot;:[&apos;cn-bj2&apos;,&apos;hk&apos;]&#125;, &quot;uhs&quot;:&#123;&quot;org-shbbct&quot;:[&quot;cn-bj2&quot;]&#125;&#125;)</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h2 id=\"collect-udisk-price-py\"><a href=\"#collect-udisk-price-py\" class=\"headerlink\" title=\"collect_udisk_price.py\"></a>collect_udisk_price.py</h2><blockquote>\n<p>收集云硬盘信息，这个只是取到实例自己手动算的价格<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env python</div><div class=\"line\"># -*- coding:utf-8 -*-</div><div class=\"line\"></div><div class=\"line\"># author: fanquanqing</div><div class=\"line\"># 收集ucloud云硬盘信息 及价格</div><div class=\"line\"></div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\"></div><div class=\"line\"># 获取udisk 信息</div><div class=\"line\">def get_udisk_info(Regions_list,ProjectId):</div><div class=\"line\">    udisk_list = []</div><div class=\"line\">    for Region in Regions_list:</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;&quot;Action&quot;:&quot;DescribeUDisk&quot;, &quot;Region&quot;:Region, &quot;ProjectId&quot;:ProjectId&#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">        for udisk in response[&apos;DataSet&apos;]:</div><div class=\"line\">            udisk_dic = &#123;&#125;</div><div class=\"line\">            udisk_dic[&apos;Region&apos;] = Region</div><div class=\"line\">            #udisk_dic[&apos;Action&apos;] = &quot;DescribeUDiskPrice&quot;</div><div class=\"line\">            udisk_dic[&apos;Size&apos;] = udisk[&apos;Size&apos;]</div><div class=\"line\">            udisk_dic[&apos;ChargeType&apos;] = udisk[&apos;ChargeType&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">            udisk_dic[&apos;UHostName&apos;] = udisk[&apos;UHostName&apos;]</div><div class=\"line\">            udisk_dic[&apos;Quantity&apos;] = 1</div><div class=\"line\">            udisk_dic[&apos;Zone&apos;] = &quot;cn-bj2-02&quot;</div><div class=\"line\">            udisk_list.append(udisk_dic)</div><div class=\"line\">    return udisk_list</div><div class=\"line\"></div><div class=\"line\"># 通过udisk信息获取价格</div><div class=\"line\">def get_udisk_price(udisk_list):</div><div class=\"line\">    for udisk in udisk_list:</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        udisk_params=&#123;&#125;</div><div class=\"line\">        udisk_params[&apos;Action&apos;]=&quot;DescribeUDiskPrice&quot;</div><div class=\"line\">        udisk_params[&apos;Region&apos;]=udisk[&apos;Region&apos;]</div><div class=\"line\">        udisk_params[&apos;Size&apos;]=udisk[&apos;Size&apos;]</div><div class=\"line\">        udisk_params[&apos;ChargeType&apos;]=udisk[&apos;ChargeType&apos;]</div><div class=\"line\">        udisk_params[&apos;Quantity&apos;]=udisk[&apos;Quantity&apos;]</div><div class=\"line\">        udisk_params[&apos;Zone&apos;]=udisk[&apos;Zone&apos;]</div><div class=\"line\">        Parameters = udisk_params</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">        if udisk_params[&apos;ChargeType&apos;]==&quot;Year&quot;:</div><div class=\"line\">            price = response[&apos;DataSet&apos;][0][&apos;Price&apos;]/100</div><div class=\"line\">        elif udisk_params[&apos;ChargeType&apos;]==&quot;Month&quot;:</div><div class=\"line\">            price = response[&apos;DataSet&apos;][0][&apos;Price&apos;]/10</div><div class=\"line\">        else:</div><div class=\"line\">            print &quot;有付费方式异常的云硬盘，请排查。&quot;</div><div class=\"line\">        udisk[&quot;Price&quot;]=price</div><div class=\"line\">    return udisk_list</div><div class=\"line\"></div><div class=\"line\"># 通过付费周期获取udisk价格</div><div class=\"line\">def collect_udisk_price(setting_info):</div><div class=\"line\">    udisk_price_info = []</div><div class=\"line\">    for Projectname in setting_info:</div><div class=\"line\">        for ProjectId in setting_info[Projectname]:</div><div class=\"line\">            Regions_list = setting_info[Projectname][ProjectId]</div><div class=\"line\">            udisk_list = get_udisk_info(Regions_list,ProjectId)</div><div class=\"line\">            udisk_price_info.extend(get_udisk_price(udisk_list))</div><div class=\"line\">    return udisk_price_info</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    collect_udisk_price(&#123;&quot;chunyu&quot;:&#123;&quot;org-oddm1w&quot;:[&apos;cn-bj2&apos;,&apos;hk&apos;]&#125;, &quot;uhs&quot;:&#123;&quot;org-shbbct&quot;:[&quot;cn-bj2&quot;]&#125;&#125;)</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h2 id=\"collect-sharebandwidth-price-py\"><a href=\"#collect-sharebandwidth-price-py\" class=\"headerlink\" title=\"collect_sharebandwidth_price.py\"></a>collect_sharebandwidth_price.py</h2><blockquote>\n<p>收集共享带宽信息,因为没有计算价格的API这个价格也是手动算的。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/python</div><div class=\"line\"># -*- coding: utf-8 -*-</div><div class=\"line\">#author fanquanqing</div><div class=\"line\">#收集共享带宽信息获取每年消费情况</div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\"></div><div class=\"line\">def get_bandwidth_info(Regions_list,ProjectId):</div><div class=\"line\">    bandwidth = []</div><div class=\"line\">    for Region in Regions_list:</div><div class=\"line\"></div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;&quot;Action&quot;:&quot;DescribeShareBandwidth&quot;,&quot;Region&quot;:Region,&quot;ProjectId&quot;:ProjectId&#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">        #print response</div><div class=\"line\">        for bw in response[&apos;DataSet&apos;]:</div><div class=\"line\">            bw_instance = &#123;&#125;</div><div class=\"line\">            bw_instance[&apos;ShareBandwidth&apos;] =  bw[&apos;ShareBandwidth&apos;]</div><div class=\"line\">            bw_instance[&apos;ChargeType&apos;] = bw[&apos;ChargeType&apos;]</div><div class=\"line\">            bw_instance[&apos;Name&apos;]=bw[&apos;Name&apos;]</div><div class=\"line\">            bandwidth.append(bw_instance)</div><div class=\"line\">    return bandwidth</div><div class=\"line\">#   print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\"></div><div class=\"line\">def get_price(bandwidth):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    价格计算说明:ucloud没有提供API查询共享带宽价格，所有的共享带宽价格都是90/M/月 月付*12,年付*10</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    price_list = []</div><div class=\"line\">    for bw in bandwidth:</div><div class=\"line\">        if bw[&apos;ChargeType&apos;]==&quot;Month&quot;:</div><div class=\"line\">            price = bw[&apos;ShareBandwidth&apos;]*90*12</div><div class=\"line\">            bw[&quot;Price&quot;]=price</div><div class=\"line\">        else:</div><div class=\"line\">            price = bw[&apos;ShareBandwidrh&apos;]</div><div class=\"line\">            bw[&quot;Price&quot;]=price</div><div class=\"line\">    return bandwidth</div><div class=\"line\"></div><div class=\"line\">def collect_sharebandwidth_price(setting_info):</div><div class=\"line\">    bw_price_info = []</div><div class=\"line\">    for Projectname in setting_info:</div><div class=\"line\">        for ProjectId in setting_info[Projectname]:</div><div class=\"line\">            Regions_list = setting_info[Projectname][ProjectId]</div><div class=\"line\">            bw_info = get_bandwidth_info(Regions_list,ProjectId)</div><div class=\"line\">            bw_price_info.extend(get_price(bw_info))</div><div class=\"line\">    #print bw_price_info</div><div class=\"line\">    return bw_price_info</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    collect_sharebandwidth_price(&#123;&quot;chunyu&quot;:&#123;&quot;org-oddm1w&quot;:[&apos;cn-bj2&apos;,&apos;hk&apos;]&#125;, &quot;uhs&quot;:&#123;&quot;org-shbbct&quot;:[&quot;cn-bj2&quot;]&#125;&#125;)</div></pre></td></tr></table></figure>\n<h2 id=\"get-all-price-py\"><a href=\"#get-all-price-py\" class=\"headerlink\" title=\"get_all_price.py\"></a>get_all_price.py</h2><blockquote>\n<p>给各实例价格求和，发送到influxdb。可以每天跑一下cron更新下内容。<strong>里面发送的influxDB是事先封装好的包直接导入的，并不是官方包</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env python</div><div class=\"line\"># -*- coding:utf-8 -*-</div><div class=\"line\"></div><div class=\"line\"># author: fanquanqing</div><div class=\"line\">#import datatime</div><div class=\"line\">from collect_eip_price import collect_eip_price</div><div class=\"line\">from collect_uhost_price import collect_uhost_price</div><div class=\"line\">from collect_sharebandwidth_price import collect_sharebandwidth_price</div><div class=\"line\">from collect_udisk_price import collect_udisk_price</div><div class=\"line\">from op_tools.api_influxdb import write_data_to_influxdb</div><div class=\"line\"></div><div class=\"line\">def get_price(setting_info):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    各个实例price求和,并把实例信息发送到influxdb</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    eip_price=0</div><div class=\"line\">    uhost_price=0</div><div class=\"line\">    sharebw_price=0</div><div class=\"line\">    udisk_price=0</div><div class=\"line\">    eip_price_info_list = collect_eip_price(setting_info)</div><div class=\"line\">    for eip_info in eip_price_info_list:</div><div class=\"line\">        eip_headers = eip_info.keys()</div><div class=\"line\">        eip_rows = []</div><div class=\"line\">        eip_rows.append(eip_info.values())</div><div class=\"line\">        #print eip_headers, eip_rows</div><div class=\"line\">        # 发送EIP数据到influxdb</div><div class=\"line\">        write_data_to_influxdb(&apos;EIP_info_daliy&apos;, eip_headers, eip_rows, [&apos;IP&apos;, &apos;OperatorName&apos;, &apos;ChargeType&apos;])</div><div class=\"line\">        eip_price += round(eip_info[&apos;Price&apos;])</div><div class=\"line\"></div><div class=\"line\">    uhost_price_info_list = collect_uhost_price(setting_info)</div><div class=\"line\">    for uhost_info in uhost_price_info_list:</div><div class=\"line\">        uhost_headers=uhost_info.keys()</div><div class=\"line\">        uhost_rows=[]</div><div class=\"line\">        uhost_rows.append(uhost_info.values())</div><div class=\"line\">        #print uhost_headers, uhost_rows</div><div class=\"line\">        # 发送云主机信息到influxdb</div><div class=\"line\">        write_data_to_influxdb(&apos;Uhost_info_daliy&apos;, uhost_headers, uhost_rows, [&apos;Hostname&apos;,&apos;ChargeType&apos;])</div><div class=\"line\">        uhost_price += round(uhost_info[&apos;Price&apos;])</div><div class=\"line\"></div><div class=\"line\">    sharebandwidth_info_list = collect_sharebandwidth_price(setting_info)</div><div class=\"line\">    for sharebandwidth_info in sharebandwidth_info_list:</div><div class=\"line\">        sharebw_headers=sharebandwidth_info.keys()</div><div class=\"line\">        sharebw_rows=[]</div><div class=\"line\">        sharebw_rows.append(sharebandwidth_info.values())</div><div class=\"line\">        #print sharebw_headers, sharebw_rows</div><div class=\"line\">        # 发送共享带宽信息到influxdb</div><div class=\"line\">        write_data_to_influxdb(&apos;ShareBandwidth_info_daliy&apos;,sharebw_headers,sharebw_rows,[])</div><div class=\"line\">        sharebw_price += round(sharebandwidth_info[&apos;Price&apos;])</div><div class=\"line\"></div><div class=\"line\">    udisk_info_list=collect_udisk_price(setting_info)</div><div class=\"line\">    for udisk_info in udisk_info_list:</div><div class=\"line\">        udisk_headers=udisk_info.keys()</div><div class=\"line\">        udisk_rows=[]</div><div class=\"line\">        udisk_rows.append(udisk_info.values())</div><div class=\"line\">        #print udisk_headers, udisk_rows</div><div class=\"line\">        write_data_to_influxdb(&apos;Udisk_info_daliy&apos;, udisk_headers,udisk_rows,[&apos;UHostName&apos;,&apos;Region&apos;])</div><div class=\"line\">        udisk_price += round(udisk_info[&apos;Price&apos;])</div><div class=\"line\">    # 托管机房价格</div><div class=\"line\">    physical_price = get_physical_host_price()</div><div class=\"line\">    total_price=eip_price+uhost_price+sharebw_price+udisk_price+physical_price</div><div class=\"line\">    # 价格列表</div><div class=\"line\">    price_list=[eip_price,uhost_price,sharebw_price,udisk_price,total_price]</div><div class=\"line\">    price_headers=[&apos;eip_price&apos;,&apos;uhost_price&apos;,&apos;sharebw_price&apos;,&apos;udisk_price&apos;,&apos;total_price&apos;]</div><div class=\"line\">    price_rows=[]</div><div class=\"line\">    price_rows.append(price_list)</div><div class=\"line\">    write_data_to_influxdb(&apos;Ucloud_price_total_daliy&apos;,price_headers,price_rows,[])</div><div class=\"line\"></div><div class=\"line\">    #print uhost_price</div><div class=\"line\">    return uhost_price</div><div class=\"line\"></div><div class=\"line\"># 托管机器价格(两个机柜一个10M外网)</div><div class=\"line\">def get_physical_host_price():</div><div class=\"line\">    host_price = 9000*2*12</div><div class=\"line\">    tg_cloud_switch_port_price = (288*2+217)*12</div><div class=\"line\">    tg_bandwidth_price = 10*90*12</div><div class=\"line\">    physical_price = host_price+tg_bandwidth_price+tg_cloud_switch_port_price</div><div class=\"line\">    return physical_price</div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    # 可用区列表</div><div class=\"line\">    #Regions_list = [&apos;cn-bj2&apos;,&apos;hk&apos;]</div><div class=\"line\">    # 项目ID列表</div><div class=\"line\">    #Project_Id_list = [&apos;org-shbbct&apos;,&apos;org-oddm1w&apos;]</div><div class=\"line\">    # 项目ID对应关系</div><div class=\"line\">    setting_info = &#123;&quot;chunyu&quot;:&#123;&quot;org-oddm1w&quot;:[&apos;cn-bj2&apos;,&apos;hk&apos;]&#125;, &quot;uhs&quot;:&#123;&quot;org-shbbct&quot;:[&quot;cn-bj2&quot;]&#125;&#125;</div><div class=\"line\">    get_price(setting_info)</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h2 id=\"grafana效果展示\"><a href=\"#grafana效果展示\" class=\"headerlink\" title=\"grafana效果展示\"></a>grafana效果展示</h2><blockquote>\n<p>grafana跟influxDB配合的非常好，设置也非常简单。下面我在下面放几张效果图。</p>\n</blockquote>\n<p><strong>简单查询语句</strong><br><img src=\"http://or2jd66dq.bkt.clouddn.com/grafana_influxdb.png\" alt=\"\"></p>\n<p><strong>table展示效果</strong><br><img src=\"http://or2jd66dq.bkt.clouddn.com/grafana_ucloud_eip.png\" alt=\"\"></p>\n<p><strong>价格图展示</strong><br><img src=\"http://or2jd66dq.bkt.clouddn.com/grafana_ucloud_price.png\" alt=\"\"></p>\n<h2 id=\"获取实时带宽信息并发送报警到钉钉\"><a href=\"#获取实时带宽信息并发送报警到钉钉\" class=\"headerlink\" title=\"获取实时带宽信息并发送报警到钉钉\"></a>获取实时带宽信息并发送报警到钉钉</h2><blockquote>\n<p>这个跟上面的脚本没有关联，只是获取实时带宽使用量的报警脚本。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div><div class=\"line\">122</div><div class=\"line\">123</div><div class=\"line\">124</div><div class=\"line\">125</div><div class=\"line\">126</div><div class=\"line\">127</div><div class=\"line\">128</div><div class=\"line\">129</div><div class=\"line\">130</div><div class=\"line\">131</div><div class=\"line\">132</div><div class=\"line\">133</div><div class=\"line\">134</div><div class=\"line\">135</div><div class=\"line\">136</div><div class=\"line\">137</div><div class=\"line\">138</div><div class=\"line\">139</div><div class=\"line\">140</div><div class=\"line\">141</div><div class=\"line\">142</div><div class=\"line\">143</div><div class=\"line\">144</div><div class=\"line\">145</div><div class=\"line\">146</div><div class=\"line\">147</div><div class=\"line\">148</div><div class=\"line\">149</div><div class=\"line\">150</div><div class=\"line\">151</div><div class=\"line\">152</div></pre></td><td class=\"code\"><pre><div class=\"line\">#!/usr/bin/env python</div><div class=\"line\"># -*- coding: utf-8 -*-</div><div class=\"line\"></div><div class=\"line\">from sdk import UcloudApiClient</div><div class=\"line\">from config import *</div><div class=\"line\">import sys</div><div class=\"line\">import json</div><div class=\"line\">import urllib2</div><div class=\"line\">import time</div><div class=\"line\">#from op_tools import falcon</div><div class=\"line\"></div><div class=\"line\">#实例化 API 句柄</div><div class=\"line\">localtime = time.asctime( time.localtime(time.time()) )</div><div class=\"line\"></div><div class=\"line\">def get_eip_info():</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    获取EIP对应的主机名，以及EIP信息返回</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    arg_length = len(sys.argv)</div><div class=\"line\">    ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">    Parameters=&#123;&quot;Action&quot;:&quot;DescribeEIP&quot;, &quot;Region&quot;:&quot;cn-bj2&quot;&#125;</div><div class=\"line\">    response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">    eip_info_list = response[&apos;EIPSet&apos;]</div><div class=\"line\">    eip_dic = &#123;&#125;</div><div class=\"line\">    for eip_info in eip_info_list:</div><div class=\"line\">        # EIP绑定主机名</div><div class=\"line\">        eip_host = eip_info[&apos;Resource&apos;][&apos;ResourceName&apos;]</div><div class=\"line\">        eip_ip = eip_info[&apos;EIPAddr&apos;][0][&apos;IP&apos;].encode(&apos;utf-8&apos;)</div><div class=\"line\">        eip_id = eip_info[&apos;EIPId&apos;]</div><div class=\"line\">        dic = &#123;&#125;</div><div class=\"line\">        dic[eip_ip] = eip_id</div><div class=\"line\">        #print &quot;eip_host:%s,dic:%s&quot; % (eip_host,dic)</div><div class=\"line\">        eip_dic[eip_host] = dic</div><div class=\"line\">    #print len(eip_dic)</div><div class=\"line\">    eip_dic[&apos;nginx-online1&apos;] = &#123;&apos;106.75.28.177&apos;: u&apos;eip-00gv0l&apos;&#125;</div><div class=\"line\">    return eip_dic</div><div class=\"line\"></div><div class=\"line\">def get_eip_usage(eip_dic):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    获取每个EIP的实时用量(要求EIPid),</div><div class=\"line\">    return list:[&#123;ip:usage&#125;...]</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    eip_usage_dic = &#123;&#125;</div><div class=\"line\">    for eip_host in eip_dic:</div><div class=\"line\">        #eip_useage_dic = &#123;&#125;</div><div class=\"line\">        eip_id=eip_dic[eip_host].values()[0].encode(&quot;utf-8&quot;)</div><div class=\"line\">        #print eip_id</div><div class=\"line\">        ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">        Parameters=&#123;</div><div class=\"line\">                    &quot;Action&quot;:&quot;DescribeBandwidthUsage&quot;,</div><div class=\"line\">                    &quot;Region&quot;:&quot;cn-bj2&quot;,</div><div class=\"line\">                    &quot;EIPIds.1&quot;:eip_id,</div><div class=\"line\">                &#125;</div><div class=\"line\">        response = ApiClient.get(&quot;/&quot;, Parameters);</div><div class=\"line\">        #print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\">        #print response</div><div class=\"line\">        eip_usage = response[&apos;EIPSet&apos;][0][&apos;CurBandwidth&apos;]</div><div class=\"line\">        eip_usage_dic[eip_host]=eip_usage</div><div class=\"line\">        #eip_usage_list.append(eip_useage_dic)</div><div class=\"line\">    return eip_usage_dic</div><div class=\"line\"></div><div class=\"line\">def sendto_falcon(eip_usage_list):</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    报警发送到falcon</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    collect_step = 60</div><div class=\"line\">    counter_type = falcon.CounterType.GAUGE</div><div class=\"line\">    metric = &quot;bandwidthusage&quot;</div><div class=\"line\">    for eip_usage in eip_usage_list:</div><div class=\"line\">        tags=&quot;host=&quot; + eip_usage.keys()[0]</div><div class=\"line\">        value=eip_usage.values()[0]</div><div class=\"line\">        #print value</div><div class=\"line\"></div><div class=\"line\">def get_sharebw_info():</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    获取共享带宽的带宽大小，以及所包含的EIP,</div><div class=\"line\">    return list:[&#123;&apos;eiplist&apos;:[ip1,ip1],&apos;bandwidth&apos;:20&#125;...]</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\"></div><div class=\"line\">    ApiClient = UcloudApiClient(base_url, public_key, private_key)</div><div class=\"line\">    Parameters=&#123;&quot;Action&quot;:&quot;DescribeShareBandwidth&quot;, &quot;Region&quot;:&quot;cn-bj2&quot;&#125;</div><div class=\"line\">    response = ApiClient.get(&quot;/&quot;, Parameters );</div><div class=\"line\">    #print json.dumps(response, sort_keys=True, indent=4, separators=(&apos;,&apos;, &apos;: &apos;))</div><div class=\"line\">    share_bw_list = response[&apos;DataSet&apos;]</div><div class=\"line\">    share_bw_info = []</div><div class=\"line\">    for share_bw in share_bw_list:</div><div class=\"line\">        share_bw_dic = &#123;&#125;</div><div class=\"line\">        bandwidth = share_bw[&apos;ShareBandwidth&apos;]</div><div class=\"line\">        eip_list = []</div><div class=\"line\">        for eip_dic in share_bw[&apos;EIPSet&apos;]:</div><div class=\"line\">            ip = eip_dic[&apos;EIPAddr&apos;][0][&apos;IP&apos;]</div><div class=\"line\">            eip_list.append(ip)</div><div class=\"line\">        share_bw_dic[&apos;bandwidth&apos;]=bandwidth</div><div class=\"line\">        share_bw_dic[&apos;eiplist&apos;]=eip_list</div><div class=\"line\">        share_bw_info.append(share_bw_dic)</div><div class=\"line\">    return share_bw_info</div><div class=\"line\"></div><div class=\"line\">def sum():</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    返回比值，并简单记录log到/var/log/ubandwidth.log</div><div class=\"line\">    &apos;&apos;&apos;</div><div class=\"line\">    eip_dic = get_eip_info()</div><div class=\"line\">    #print eip_dic</div><div class=\"line\">    eip_to_host = &#123;&#125;</div><div class=\"line\">    # 通过eip_dic获取IP-host对此应关系dic</div><div class=\"line\">    for host in eip_dic:</div><div class=\"line\">        eip = eip_dic[host].keys()[0]</div><div class=\"line\">        eip_to_host[eip]=host</div><div class=\"line\">    #print eip_to_host</div><div class=\"line\">    eip_usage_dic = get_eip_usage(eip_dic)</div><div class=\"line\">    #print eip_usage_dic</div><div class=\"line\">    share_bw_info = get_sharebw_info()</div><div class=\"line\">    #print share_bw_info</div><div class=\"line\">    #各带宽和与带宽比值</div><div class=\"line\">    ratios = &#123;&#125;</div><div class=\"line\">    for share_bandwidth in share_bw_info:</div><div class=\"line\">        bandwidth = share_bandwidth[&apos;bandwidth&apos;]</div><div class=\"line\">        sum = 0</div><div class=\"line\">        for eip in share_bandwidth[&apos;eiplist&apos;]:</div><div class=\"line\">            host = eip_to_host[eip]</div><div class=\"line\">            usage = eip_usage_dic[host]</div><div class=\"line\">            sum += usage</div><div class=\"line\">        #带宽用量与带宽的比值</div><div class=\"line\">        ratio = sum/bandwidth</div><div class=\"line\">        parts = [str(bandwidth),str(sum),str(ratio)]</div><div class=\"line\">        log =localtime + &apos; &apos; + &apos;,&apos;.join(parts) + &apos;\\n&apos;</div><div class=\"line\">        with open(&apos;/var/log/ubandwidth.log&apos;,&apos;a&apos;) as f:</div><div class=\"line\">            f.write(log)</div><div class=\"line\">            f.close()</div><div class=\"line\"></div><div class=\"line\">        ratios[bandwidth]=ratio</div><div class=\"line\"></div><div class=\"line\">    return ratios</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">def send_to_dingtalk(content):</div><div class=\"line\"></div><div class=\"line\">    url = &quot;https://oapi.dingtalk.com/robot/send?access_token=17cf865229a63452ff411243b53d64949d5a54b1ee8774e20e1ec7d4c5d60f43&quot;</div><div class=\"line\">    #con=&#123;&quot;msgtype&quot;:&quot;text&quot;,&quot;text&quot;:&#123;&quot;content&quot;:content&#125;,&quot;isAtAll&quot;: &quot;true&quot;&#125;</div><div class=\"line\">    con=&#123;&quot;msgtype&quot;:&quot;markdown&quot;,&quot;markdown&quot;:&#123;&quot;title&quot;:&quot;ucloud共享带宽报警&quot;,&quot;text&quot;:content&#125;,&quot;isAtAll&quot;: &quot;ture&quot;&#125;</div><div class=\"line\">    jd=json.dumps(con)</div><div class=\"line\">    req=urllib2.Request(url,jd)</div><div class=\"line\">    req.add_header(&apos;Content-Type&apos;, &apos;application/json&apos;)</div><div class=\"line\">    response=urllib2.urlopen(req)</div><div class=\"line\"></div><div class=\"line\">if __name__ == &apos;__main__&apos;:</div><div class=\"line\">    ratios=sum()</div><div class=\"line\">    localtime = time.asctime( time.localtime(time.time()) )</div><div class=\"line\">    for bw in ratios:</div><div class=\"line\">        if ratios[bw] &gt; 0.8:</div><div class=\"line\">            content = u&quot;# **ucloud共享带宽报警** - %d兆那个。。。\\n\\n - 用量超过百分之80 \\n - **值**:%f \\n &gt; [请排查...](https://console.ucloud.cn/unet/sharebandwidth)&quot; % (bw,ratios[bw])</div><div class=\"line\">            send_to_dingtalk(content)</div></pre></td></tr></table></figure>\n"},{"title":"效率神器Alfred使用","date":"2017-06-21T02:19:23.000Z","_content":"\n> 如果看过蝙蝠侠的同学可能会感觉到熟悉，Alfred明明是蝙蝠侠的管家嘛，是的，我严重怀疑开发者是蝙蝠侠的铁粉。这里这个Alfred也可以成为你的管家，简直无所不至。\n\n下载地址: https://xclient.info\n\n这里主要记录几个常用的功能。\n\n首先快捷键介绍(可以自定义)\n- alt + space         打开主应用\n- alt + command + c   粘贴板   \n\n## web search\n> 我们不需要打开浏览器 只需要在主应用中 输入\"Google keyword\" 回车 就可以Google你所想要的内容 默认给出Amazon Facebook等 可以自定义添加 \"百度\",\"知乎\"等 \n\n`使用方式`: 打开主应用 输入 Google keyword\n\n## file search \n> 本地文件搜索\n\n`使用方式`: 打开主应用 输入 'filename\n\n## 粘贴板\n> 可以记录一天的历史复制内容(可以灵活设置，默认一天)\n\n## 密码记录\n> 首先安装1password 配置(收费)\n\n## workflows\n> 工作流，类似TODOlist，据说很强大,感兴趣的可以学习下,我并没使用此功能。\n\n","source":"_posts/效率神器Alfred使用.md","raw":"---\ntitle: 效率神器Alfred使用\ndate: 2017-06-21 10:19:23\ntags: Mac\n---\n\n> 如果看过蝙蝠侠的同学可能会感觉到熟悉，Alfred明明是蝙蝠侠的管家嘛，是的，我严重怀疑开发者是蝙蝠侠的铁粉。这里这个Alfred也可以成为你的管家，简直无所不至。\n\n下载地址: https://xclient.info\n\n这里主要记录几个常用的功能。\n\n首先快捷键介绍(可以自定义)\n- alt + space         打开主应用\n- alt + command + c   粘贴板   \n\n## web search\n> 我们不需要打开浏览器 只需要在主应用中 输入\"Google keyword\" 回车 就可以Google你所想要的内容 默认给出Amazon Facebook等 可以自定义添加 \"百度\",\"知乎\"等 \n\n`使用方式`: 打开主应用 输入 Google keyword\n\n## file search \n> 本地文件搜索\n\n`使用方式`: 打开主应用 输入 'filename\n\n## 粘贴板\n> 可以记录一天的历史复制内容(可以灵活设置，默认一天)\n\n## 密码记录\n> 首先安装1password 配置(收费)\n\n## workflows\n> 工作流，类似TODOlist，据说很强大,感兴趣的可以学习下,我并没使用此功能。\n\n","slug":"效率神器Alfred使用","published":1,"updated":"2017-06-22T10:53:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvcg003z8tzzyvtx6o9a","content":"<blockquote>\n<p>如果看过蝙蝠侠的同学可能会感觉到熟悉，Alfred明明是蝙蝠侠的管家嘛，是的，我严重怀疑开发者是蝙蝠侠的铁粉。这里这个Alfred也可以成为你的管家，简直无所不至。</p>\n</blockquote>\n<p>下载地址: <a href=\"https://xclient.info\" target=\"_blank\" rel=\"external\">https://xclient.info</a></p>\n<p>这里主要记录几个常用的功能。</p>\n<p>首先快捷键介绍(可以自定义)</p>\n<ul>\n<li>alt + space         打开主应用</li>\n<li>alt + command + c   粘贴板   </li>\n</ul>\n<h2 id=\"web-search\"><a href=\"#web-search\" class=\"headerlink\" title=\"web search\"></a>web search</h2><blockquote>\n<p>我们不需要打开浏览器 只需要在主应用中 输入”Google keyword” 回车 就可以Google你所想要的内容 默认给出Amazon Facebook等 可以自定义添加 “百度”,”知乎”等 </p>\n</blockquote>\n<p><code>使用方式</code>: 打开主应用 输入 Google keyword</p>\n<h2 id=\"file-search\"><a href=\"#file-search\" class=\"headerlink\" title=\"file search\"></a>file search</h2><blockquote>\n<p>本地文件搜索</p>\n</blockquote>\n<p><code>使用方式</code>: 打开主应用 输入 ‘filename</p>\n<h2 id=\"粘贴板\"><a href=\"#粘贴板\" class=\"headerlink\" title=\"粘贴板\"></a>粘贴板</h2><blockquote>\n<p>可以记录一天的历史复制内容(可以灵活设置，默认一天)</p>\n</blockquote>\n<h2 id=\"密码记录\"><a href=\"#密码记录\" class=\"headerlink\" title=\"密码记录\"></a>密码记录</h2><blockquote>\n<p>首先安装1password 配置(收费)</p>\n</blockquote>\n<h2 id=\"workflows\"><a href=\"#workflows\" class=\"headerlink\" title=\"workflows\"></a>workflows</h2><blockquote>\n<p>工作流，类似TODOlist，据说很强大,感兴趣的可以学习下,我并没使用此功能。</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>如果看过蝙蝠侠的同学可能会感觉到熟悉，Alfred明明是蝙蝠侠的管家嘛，是的，我严重怀疑开发者是蝙蝠侠的铁粉。这里这个Alfred也可以成为你的管家，简直无所不至。</p>\n</blockquote>\n<p>下载地址: <a href=\"https://xclient.info\" target=\"_blank\" rel=\"external\">https://xclient.info</a></p>\n<p>这里主要记录几个常用的功能。</p>\n<p>首先快捷键介绍(可以自定义)</p>\n<ul>\n<li>alt + space         打开主应用</li>\n<li>alt + command + c   粘贴板   </li>\n</ul>\n<h2 id=\"web-search\"><a href=\"#web-search\" class=\"headerlink\" title=\"web search\"></a>web search</h2><blockquote>\n<p>我们不需要打开浏览器 只需要在主应用中 输入”Google keyword” 回车 就可以Google你所想要的内容 默认给出Amazon Facebook等 可以自定义添加 “百度”,”知乎”等 </p>\n</blockquote>\n<p><code>使用方式</code>: 打开主应用 输入 Google keyword</p>\n<h2 id=\"file-search\"><a href=\"#file-search\" class=\"headerlink\" title=\"file search\"></a>file search</h2><blockquote>\n<p>本地文件搜索</p>\n</blockquote>\n<p><code>使用方式</code>: 打开主应用 输入 ‘filename</p>\n<h2 id=\"粘贴板\"><a href=\"#粘贴板\" class=\"headerlink\" title=\"粘贴板\"></a>粘贴板</h2><blockquote>\n<p>可以记录一天的历史复制内容(可以灵活设置，默认一天)</p>\n</blockquote>\n<h2 id=\"密码记录\"><a href=\"#密码记录\" class=\"headerlink\" title=\"密码记录\"></a>密码记录</h2><blockquote>\n<p>首先安装1password 配置(收费)</p>\n</blockquote>\n<h2 id=\"workflows\"><a href=\"#workflows\" class=\"headerlink\" title=\"workflows\"></a>workflows</h2><blockquote>\n<p>工作流，类似TODOlist，据说很强大,感兴趣的可以学习下,我并没使用此功能。</p>\n</blockquote>\n"},{"title":"运维工具之sar命令","date":"2017-06-09T07:48:43.000Z","_content":"参考:http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/index.html\n\nsar是System Activity Reporter（系统活动情况报告）的缩写。sar工具将对系统当前的状态进行取样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统取样，获得大量的取样数据；取样数据和分析的结果都可以存入文件，所需的负载很小。sar是目前Linux上最为全面的系统性能分析工具之一，可以从14个大方面对系统的活动进行报告，包括文件的读写情况、系统调用的使用情况、串口、CPU效率、内存使用状况、进程活动及IPC有关的活动等，使用也是较为复杂。\n\nsar是查看操作系统报告指标的各种工具中，最为普遍和方便的；它有两种用法；\n\n1. 追溯过去的统计数据（默认）\n2. 周期性的查看当前数据\n\n","source":"_posts/运维工具之sar命令.md","raw":"---\ntitle: 运维工具之sar命令\ndate: 2017-06-09 15:48:43\ntags: sar\ncategories: 基础运维\n---\n参考:http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/index.html\n\nsar是System Activity Reporter（系统活动情况报告）的缩写。sar工具将对系统当前的状态进行取样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统取样，获得大量的取样数据；取样数据和分析的结果都可以存入文件，所需的负载很小。sar是目前Linux上最为全面的系统性能分析工具之一，可以从14个大方面对系统的活动进行报告，包括文件的读写情况、系统调用的使用情况、串口、CPU效率、内存使用状况、进程活动及IPC有关的活动等，使用也是较为复杂。\n\nsar是查看操作系统报告指标的各种工具中，最为普遍和方便的；它有两种用法；\n\n1. 追溯过去的统计数据（默认）\n2. 周期性的查看当前数据\n\n","slug":"运维工具之sar命令","published":1,"updated":"2017-06-23T06:04:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvci00448tzz4fypjolr","content":"<p>参考:<a href=\"http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/index.html\" target=\"_blank\" rel=\"external\">http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/index.html</a></p>\n<p>sar是System Activity Reporter（系统活动情况报告）的缩写。sar工具将对系统当前的状态进行取样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统取样，获得大量的取样数据；取样数据和分析的结果都可以存入文件，所需的负载很小。sar是目前Linux上最为全面的系统性能分析工具之一，可以从14个大方面对系统的活动进行报告，包括文件的读写情况、系统调用的使用情况、串口、CPU效率、内存使用状况、进程活动及IPC有关的活动等，使用也是较为复杂。</p>\n<p>sar是查看操作系统报告指标的各种工具中，最为普遍和方便的；它有两种用法；</p>\n<ol>\n<li>追溯过去的统计数据（默认）</li>\n<li>周期性的查看当前数据</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>参考:<a href=\"http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/index.html\" target=\"_blank\" rel=\"external\">http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/index.html</a></p>\n<p>sar是System Activity Reporter（系统活动情况报告）的缩写。sar工具将对系统当前的状态进行取样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统取样，获得大量的取样数据；取样数据和分析的结果都可以存入文件，所需的负载很小。sar是目前Linux上最为全面的系统性能分析工具之一，可以从14个大方面对系统的活动进行报告，包括文件的读写情况、系统调用的使用情况、串口、CPU效率、内存使用状况、进程活动及IPC有关的活动等，使用也是较为复杂。</p>\n<p>sar是查看操作系统报告指标的各种工具中，最为普遍和方便的；它有两种用法；</p>\n<ol>\n<li>追溯过去的统计数据（默认）</li>\n<li>周期性的查看当前数据</li>\n</ol>\n"},{"title":"记录主机history","date":"2017-07-12T06:10:20.000Z","_content":"> 起因，有个哥们儿要离职，直接上线上把他机器训练的东西拷贝到电脑本地，我们用的vpn，有些服务对此有点依赖，不详细说，总之影响到了一丢丢线上的情况，所以CTO很不高兴，机器历史记录也没有，啥都没有，多亏他承认了。但是我这个运维还是多少显得有点尴尬。\n\n下面说一些改进措施\n- 不准任何人直接登录线上机器，必须通过跳板机（上传现在文件也必须通过跳板机加以控制）\n- openvpn与线上带宽解耦\n- openvpn限速，线上加iptables阻止openvpn的地址，只接受跳板机(加一条运维通道，永远有B方案)\n- 历史记录需要详细记录\n\n前三条很好就解决了。\n下面内容详细记录下第四条的实现方法。\n\nbash是多数Linux发行版默认的shell，虽然不及zsh好用，但比其它的shell好太多。\n我们的生产服务器很多，没有用跳板机，又是多人共用root用户，为了审计用户操作，需要记录执行命令的用户、时间和ip等信息。本文之所以要优化，主要是因为bash默认配置存在以下几点不足：\n\n1. 历史记录保存数目有限，默认1000条\n\n2. 记录不详细，不记录命令执行时间/执行用户名/用户ip等\n\n3. 历史记录会丢失，主要有两种情况：\n    1. bash异常退出 \n    2. 同一用户多处登录或开了多个会话，只会记录最后退出的会话历史\n\n所以我决心自己记录下`bash_history` 并把它写到ES之中[传送门](https://fanquqi.github.io/2017/06/12/file-beat%E6%8E%A5%E5%85%A5ELK/),这样有人做了什么非法的事情，即使他清空了历史记录我的ES中也能存着他的罪证，除非他每条history都秒删，在速度上超过filebeat的读取的速度，事实证明不怎么可能。\n\n## 常规rsyslog实现\n> [参考链接](http://www.361way.com/history-log-audit/4147.html)\n### 配置全局bash历史记录格式\n在/etc/bashrc中写入\n```\nexport PROMPT_COMMAND='RETRN_VAL=$?;logger -p local6.debug \"$(who am i) [$$]: $(history 1 | sed \"s/^[ ]*[0-9]\\+[ ]*//\" ) [$RETRN_VAL]\"'\n```\n\n\n### 配置rsyslog\n新增文件/etc/rsyslog.d/bash.conf,内容\n```\nlocal6.*    /var/log/bash_history.log\n```\n\n### 重启rsyslogd\n```\nsystemctl restart rsyslogd\n```\n\n### ansible 脚本\n```\n---\n\n#- name: add scripts to bashrc\n#  lineinfile:\n#    dest=/etc/bashrc\n#    line={{item}}\n#  with_items: '{{bashrc_line}}'\n#  register: profile\n- name: copy file to /etc\n  copy: src=bash_log.conf dest=/var/tmp\n\n- name: echo to /etc/bashrc\n  shell: cat /var/tmp/bash_log.conf >> /etc/bashrc\n  register: bashrc\n\n- name: source file\n  shell: source /etc/bashrc\n  when: bashrc.changed\n\n\n- name: copy bash.conf to /etc/rsyslog.d\n  copy: src=bash.conf dest=/etc/rsyslog.d\n  register: rsyslog_conf\n\n- name: restart rsyslog\n  service: name=rsyslog.service state=restarted\n  when: rsyslog_conf.changed\n```\n刷到每个机器上就好了   注意最好配置下logrotate每天切割一下\n\n这样就可以在kibana中看到每个登录人员的操作情况了。\n![](http://or2jd66dq.bkt.clouddn.com/bash_history_kibana.png)\n\n## 查看用户痕迹过程展示\n\n上面中控机上是每个人对应一个自己名字拼音的用户，使用此用户跳到线上机器，但是测试环境是直接本地可以连，测试被人搞坏了进度delay怎么办？也需要查证，可以使用以下方法\n![](http://or2jd66dq.bkt.clouddn.com/bash_history_modify.png)\n","source":"_posts/记录主机history.md","raw":"---\ntitle: 记录主机history\ndate: 2017-07-12 14:10:20\ntags: bash\n---\n> 起因，有个哥们儿要离职，直接上线上把他机器训练的东西拷贝到电脑本地，我们用的vpn，有些服务对此有点依赖，不详细说，总之影响到了一丢丢线上的情况，所以CTO很不高兴，机器历史记录也没有，啥都没有，多亏他承认了。但是我这个运维还是多少显得有点尴尬。\n\n下面说一些改进措施\n- 不准任何人直接登录线上机器，必须通过跳板机（上传现在文件也必须通过跳板机加以控制）\n- openvpn与线上带宽解耦\n- openvpn限速，线上加iptables阻止openvpn的地址，只接受跳板机(加一条运维通道，永远有B方案)\n- 历史记录需要详细记录\n\n前三条很好就解决了。\n下面内容详细记录下第四条的实现方法。\n\nbash是多数Linux发行版默认的shell，虽然不及zsh好用，但比其它的shell好太多。\n我们的生产服务器很多，没有用跳板机，又是多人共用root用户，为了审计用户操作，需要记录执行命令的用户、时间和ip等信息。本文之所以要优化，主要是因为bash默认配置存在以下几点不足：\n\n1. 历史记录保存数目有限，默认1000条\n\n2. 记录不详细，不记录命令执行时间/执行用户名/用户ip等\n\n3. 历史记录会丢失，主要有两种情况：\n    1. bash异常退出 \n    2. 同一用户多处登录或开了多个会话，只会记录最后退出的会话历史\n\n所以我决心自己记录下`bash_history` 并把它写到ES之中[传送门](https://fanquqi.github.io/2017/06/12/file-beat%E6%8E%A5%E5%85%A5ELK/),这样有人做了什么非法的事情，即使他清空了历史记录我的ES中也能存着他的罪证，除非他每条history都秒删，在速度上超过filebeat的读取的速度，事实证明不怎么可能。\n\n## 常规rsyslog实现\n> [参考链接](http://www.361way.com/history-log-audit/4147.html)\n### 配置全局bash历史记录格式\n在/etc/bashrc中写入\n```\nexport PROMPT_COMMAND='RETRN_VAL=$?;logger -p local6.debug \"$(who am i) [$$]: $(history 1 | sed \"s/^[ ]*[0-9]\\+[ ]*//\" ) [$RETRN_VAL]\"'\n```\n\n\n### 配置rsyslog\n新增文件/etc/rsyslog.d/bash.conf,内容\n```\nlocal6.*    /var/log/bash_history.log\n```\n\n### 重启rsyslogd\n```\nsystemctl restart rsyslogd\n```\n\n### ansible 脚本\n```\n---\n\n#- name: add scripts to bashrc\n#  lineinfile:\n#    dest=/etc/bashrc\n#    line={{item}}\n#  with_items: '{{bashrc_line}}'\n#  register: profile\n- name: copy file to /etc\n  copy: src=bash_log.conf dest=/var/tmp\n\n- name: echo to /etc/bashrc\n  shell: cat /var/tmp/bash_log.conf >> /etc/bashrc\n  register: bashrc\n\n- name: source file\n  shell: source /etc/bashrc\n  when: bashrc.changed\n\n\n- name: copy bash.conf to /etc/rsyslog.d\n  copy: src=bash.conf dest=/etc/rsyslog.d\n  register: rsyslog_conf\n\n- name: restart rsyslog\n  service: name=rsyslog.service state=restarted\n  when: rsyslog_conf.changed\n```\n刷到每个机器上就好了   注意最好配置下logrotate每天切割一下\n\n这样就可以在kibana中看到每个登录人员的操作情况了。\n![](http://or2jd66dq.bkt.clouddn.com/bash_history_kibana.png)\n\n## 查看用户痕迹过程展示\n\n上面中控机上是每个人对应一个自己名字拼音的用户，使用此用户跳到线上机器，但是测试环境是直接本地可以连，测试被人搞坏了进度delay怎么办？也需要查证，可以使用以下方法\n![](http://or2jd66dq.bkt.clouddn.com/bash_history_modify.png)\n","slug":"记录主机history","published":1,"updated":"2017-08-02T08:42:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvck00478tzzkhhw1539","content":"<blockquote>\n<p>起因，有个哥们儿要离职，直接上线上把他机器训练的东西拷贝到电脑本地，我们用的vpn，有些服务对此有点依赖，不详细说，总之影响到了一丢丢线上的情况，所以CTO很不高兴，机器历史记录也没有，啥都没有，多亏他承认了。但是我这个运维还是多少显得有点尴尬。</p>\n</blockquote>\n<p>下面说一些改进措施</p>\n<ul>\n<li>不准任何人直接登录线上机器，必须通过跳板机（上传现在文件也必须通过跳板机加以控制）</li>\n<li>openvpn与线上带宽解耦</li>\n<li>openvpn限速，线上加iptables阻止openvpn的地址，只接受跳板机(加一条运维通道，永远有B方案)</li>\n<li>历史记录需要详细记录</li>\n</ul>\n<p>前三条很好就解决了。<br>下面内容详细记录下第四条的实现方法。</p>\n<p>bash是多数Linux发行版默认的shell，虽然不及zsh好用，但比其它的shell好太多。<br>我们的生产服务器很多，没有用跳板机，又是多人共用root用户，为了审计用户操作，需要记录执行命令的用户、时间和ip等信息。本文之所以要优化，主要是因为bash默认配置存在以下几点不足：</p>\n<ol>\n<li><p>历史记录保存数目有限，默认1000条</p>\n</li>\n<li><p>记录不详细，不记录命令执行时间/执行用户名/用户ip等</p>\n</li>\n<li><p>历史记录会丢失，主要有两种情况：</p>\n<ol>\n<li>bash异常退出 </li>\n<li>同一用户多处登录或开了多个会话，只会记录最后退出的会话历史</li>\n</ol>\n</li>\n</ol>\n<p>所以我决心自己记录下<code>bash_history</code> 并把它写到ES之中<a href=\"https://fanquqi.github.io/2017/06/12/file-beat%E6%8E%A5%E5%85%A5ELK/\" target=\"_blank\" rel=\"external\">传送门</a>,这样有人做了什么非法的事情，即使他清空了历史记录我的ES中也能存着他的罪证，除非他每条history都秒删，在速度上超过filebeat的读取的速度，事实证明不怎么可能。</p>\n<h2 id=\"常规rsyslog实现\"><a href=\"#常规rsyslog实现\" class=\"headerlink\" title=\"常规rsyslog实现\"></a>常规rsyslog实现</h2><blockquote>\n<p><a href=\"http://www.361way.com/history-log-audit/4147.html\" target=\"_blank\" rel=\"external\">参考链接</a></p>\n<h3 id=\"配置全局bash历史记录格式\"><a href=\"#配置全局bash历史记录格式\" class=\"headerlink\" title=\"配置全局bash历史记录格式\"></a>配置全局bash历史记录格式</h3><p>在/etc/bashrc中写入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">export PROMPT_COMMAND=&apos;RETRN_VAL=$?;logger -p local6.debug &quot;$(who am i) [$$]: $(history 1 | sed &quot;s/^[ ]*[0-9]\\+[ ]*//&quot; ) [$RETRN_VAL]&quot;&apos;</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h3 id=\"配置rsyslog\"><a href=\"#配置rsyslog\" class=\"headerlink\" title=\"配置rsyslog\"></a>配置rsyslog</h3><p>新增文件/etc/rsyslog.d/bash.conf,内容<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">local6.*    /var/log/bash_history.log</div></pre></td></tr></table></figure></p>\n<h3 id=\"重启rsyslogd\"><a href=\"#重启rsyslogd\" class=\"headerlink\" title=\"重启rsyslogd\"></a>重启rsyslogd</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">systemctl restart rsyslogd</div></pre></td></tr></table></figure>\n<h3 id=\"ansible-脚本\"><a href=\"#ansible-脚本\" class=\"headerlink\" title=\"ansible 脚本\"></a>ansible 脚本</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\"></div><div class=\"line\">#- name: add scripts to bashrc</div><div class=\"line\">#  lineinfile:</div><div class=\"line\">#    dest=/etc/bashrc</div><div class=\"line\">#    line=&#123;&#123;item&#125;&#125;</div><div class=\"line\">#  with_items: &apos;&#123;&#123;bashrc_line&#125;&#125;&apos;</div><div class=\"line\">#  register: profile</div><div class=\"line\">- name: copy file to /etc</div><div class=\"line\">  copy: src=bash_log.conf dest=/var/tmp</div><div class=\"line\"></div><div class=\"line\">- name: echo to /etc/bashrc</div><div class=\"line\">  shell: cat /var/tmp/bash_log.conf &gt;&gt; /etc/bashrc</div><div class=\"line\">  register: bashrc</div><div class=\"line\"></div><div class=\"line\">- name: source file</div><div class=\"line\">  shell: source /etc/bashrc</div><div class=\"line\">  when: bashrc.changed</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">- name: copy bash.conf to /etc/rsyslog.d</div><div class=\"line\">  copy: src=bash.conf dest=/etc/rsyslog.d</div><div class=\"line\">  register: rsyslog_conf</div><div class=\"line\"></div><div class=\"line\">- name: restart rsyslog</div><div class=\"line\">  service: name=rsyslog.service state=restarted</div><div class=\"line\">  when: rsyslog_conf.changed</div></pre></td></tr></table></figure>\n<p>刷到每个机器上就好了   注意最好配置下logrotate每天切割一下</p>\n<p>这样就可以在kibana中看到每个登录人员的操作情况了。<br><img src=\"http://or2jd66dq.bkt.clouddn.com/bash_history_kibana.png\" alt=\"\"></p>\n<h2 id=\"查看用户痕迹过程展示\"><a href=\"#查看用户痕迹过程展示\" class=\"headerlink\" title=\"查看用户痕迹过程展示\"></a>查看用户痕迹过程展示</h2><p>上面中控机上是每个人对应一个自己名字拼音的用户，使用此用户跳到线上机器，但是测试环境是直接本地可以连，测试被人搞坏了进度delay怎么办？也需要查证，可以使用以下方法<br><img src=\"http://or2jd66dq.bkt.clouddn.com/bash_history_modify.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>起因，有个哥们儿要离职，直接上线上把他机器训练的东西拷贝到电脑本地，我们用的vpn，有些服务对此有点依赖，不详细说，总之影响到了一丢丢线上的情况，所以CTO很不高兴，机器历史记录也没有，啥都没有，多亏他承认了。但是我这个运维还是多少显得有点尴尬。</p>\n</blockquote>\n<p>下面说一些改进措施</p>\n<ul>\n<li>不准任何人直接登录线上机器，必须通过跳板机（上传现在文件也必须通过跳板机加以控制）</li>\n<li>openvpn与线上带宽解耦</li>\n<li>openvpn限速，线上加iptables阻止openvpn的地址，只接受跳板机(加一条运维通道，永远有B方案)</li>\n<li>历史记录需要详细记录</li>\n</ul>\n<p>前三条很好就解决了。<br>下面内容详细记录下第四条的实现方法。</p>\n<p>bash是多数Linux发行版默认的shell，虽然不及zsh好用，但比其它的shell好太多。<br>我们的生产服务器很多，没有用跳板机，又是多人共用root用户，为了审计用户操作，需要记录执行命令的用户、时间和ip等信息。本文之所以要优化，主要是因为bash默认配置存在以下几点不足：</p>\n<ol>\n<li><p>历史记录保存数目有限，默认1000条</p>\n</li>\n<li><p>记录不详细，不记录命令执行时间/执行用户名/用户ip等</p>\n</li>\n<li><p>历史记录会丢失，主要有两种情况：</p>\n<ol>\n<li>bash异常退出 </li>\n<li>同一用户多处登录或开了多个会话，只会记录最后退出的会话历史</li>\n</ol>\n</li>\n</ol>\n<p>所以我决心自己记录下<code>bash_history</code> 并把它写到ES之中<a href=\"https://fanquqi.github.io/2017/06/12/file-beat%E6%8E%A5%E5%85%A5ELK/\" target=\"_blank\" rel=\"external\">传送门</a>,这样有人做了什么非法的事情，即使他清空了历史记录我的ES中也能存着他的罪证，除非他每条history都秒删，在速度上超过filebeat的读取的速度，事实证明不怎么可能。</p>\n<h2 id=\"常规rsyslog实现\"><a href=\"#常规rsyslog实现\" class=\"headerlink\" title=\"常规rsyslog实现\"></a>常规rsyslog实现</h2><blockquote>\n<p><a href=\"http://www.361way.com/history-log-audit/4147.html\" target=\"_blank\" rel=\"external\">参考链接</a></p>\n<h3 id=\"配置全局bash历史记录格式\"><a href=\"#配置全局bash历史记录格式\" class=\"headerlink\" title=\"配置全局bash历史记录格式\"></a>配置全局bash历史记录格式</h3><p>在/etc/bashrc中写入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">export PROMPT_COMMAND=&apos;RETRN_VAL=$?;logger -p local6.debug &quot;$(who am i) [$$]: $(history 1 | sed &quot;s/^[ ]*[0-9]\\+[ ]*//&quot; ) [$RETRN_VAL]&quot;&apos;</div></pre></td></tr></table></figure></p>\n</blockquote>\n<h3 id=\"配置rsyslog\"><a href=\"#配置rsyslog\" class=\"headerlink\" title=\"配置rsyslog\"></a>配置rsyslog</h3><p>新增文件/etc/rsyslog.d/bash.conf,内容<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">local6.*    /var/log/bash_history.log</div></pre></td></tr></table></figure></p>\n<h3 id=\"重启rsyslogd\"><a href=\"#重启rsyslogd\" class=\"headerlink\" title=\"重启rsyslogd\"></a>重启rsyslogd</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">systemctl restart rsyslogd</div></pre></td></tr></table></figure>\n<h3 id=\"ansible-脚本\"><a href=\"#ansible-脚本\" class=\"headerlink\" title=\"ansible 脚本\"></a>ansible 脚本</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\"></div><div class=\"line\">#- name: add scripts to bashrc</div><div class=\"line\">#  lineinfile:</div><div class=\"line\">#    dest=/etc/bashrc</div><div class=\"line\">#    line=&#123;&#123;item&#125;&#125;</div><div class=\"line\">#  with_items: &apos;&#123;&#123;bashrc_line&#125;&#125;&apos;</div><div class=\"line\">#  register: profile</div><div class=\"line\">- name: copy file to /etc</div><div class=\"line\">  copy: src=bash_log.conf dest=/var/tmp</div><div class=\"line\"></div><div class=\"line\">- name: echo to /etc/bashrc</div><div class=\"line\">  shell: cat /var/tmp/bash_log.conf &gt;&gt; /etc/bashrc</div><div class=\"line\">  register: bashrc</div><div class=\"line\"></div><div class=\"line\">- name: source file</div><div class=\"line\">  shell: source /etc/bashrc</div><div class=\"line\">  when: bashrc.changed</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">- name: copy bash.conf to /etc/rsyslog.d</div><div class=\"line\">  copy: src=bash.conf dest=/etc/rsyslog.d</div><div class=\"line\">  register: rsyslog_conf</div><div class=\"line\"></div><div class=\"line\">- name: restart rsyslog</div><div class=\"line\">  service: name=rsyslog.service state=restarted</div><div class=\"line\">  when: rsyslog_conf.changed</div></pre></td></tr></table></figure>\n<p>刷到每个机器上就好了   注意最好配置下logrotate每天切割一下</p>\n<p>这样就可以在kibana中看到每个登录人员的操作情况了。<br><img src=\"http://or2jd66dq.bkt.clouddn.com/bash_history_kibana.png\" alt=\"\"></p>\n<h2 id=\"查看用户痕迹过程展示\"><a href=\"#查看用户痕迹过程展示\" class=\"headerlink\" title=\"查看用户痕迹过程展示\"></a>查看用户痕迹过程展示</h2><p>上面中控机上是每个人对应一个自己名字拼音的用户，使用此用户跳到线上机器，但是测试环境是直接本地可以连，测试被人搞坏了进度delay怎么办？也需要查证，可以使用以下方法<br><img src=\"http://or2jd66dq.bkt.clouddn.com/bash_history_modify.png\" alt=\"\"></p>\n"},{"title":"记一次PHP服务部署","date":"2017-07-05T10:58:03.000Z","_content":"\n> 本来很少接触这门世界上最好的语言，公司里面也没有，但是这次有这个需求，考虑到fastcgi与uwsgi有这么一点点共同点，我就照葫芦画瓢，打算用我们测试的nginx做转发。但是踩到几个坑，听我带着悔恨一点一点的说。。。\n\n## nginx代理转发介绍\n我们的测试跟线上的服务都是用nginx做全职代理转发\n在nginx.conf 声明如下:\n```\nhttp {\n...\ninclude /usr/local/nginx/conf/servers/*/upstream.conf;\ninclude /usr/local/nginx/conf/servers/*/site.conf;\n...\n}\n```\n所以就可以在server目录下建立各种监听二级域名的目录。\n\n类似这种,`uwsgi`的转发使用`uwsgi_pass` ,`普通web代理`使用`proxy_pass`,`fastcgi`使用`fastcgi_pass`\n下面举例uwsgi转发配置说明一下。\n`/usr/local/nginx/conf/servers/dier/site.conf`\n```\nserver {\n    listen 443 ssl http2;\n    server_name dier.chunyu.me;\n\n    include /usr/local/nginx/conf/servers/common/ssl_config.location;\n    location / {\n        uwsgi_pass devops_uwsgi;\n        include uwsgi_params;\n    }\n}\n\n\nserver {\n    listen 80;\n    server_name .chunyu.me;\n# 强转https\n    rewrite  ^/(.*)$  https://devops.chunyu.me/$1  permanent;\n}\n```\n\n`/usr/local/nginx/conf/servers/dier/upstream.conf`\n```\nupstream devops_uwsgi {\n    server 10.9.77.8:5001;\n}\n```\n\n## PHP服务部署\n> 源码编译安装，全程Google教程,直接按照参考地址配置即可。\n\n\nPHP-FPM\nPHP-FPM是一个PHP FastCGI管理器，是只用于PHP的,可以在 http://php-fpm.org/download下载得到。PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。FPM（FastCGI 进程管理器）用于替换 PHP-CGI 的大部分附加功能，对于高负载网站是非常有用的。它的功能包括：\n1. 支持平滑停止/启动的高级进程管理功能；\n2. 可以工作于不同的 uid/gid/chroot 环境下，并监听不同的端口和使用不同的 php.ini 配置文件（可取代 safe_mode 的设置）；\n3. stdout 和 stderr 日志记录;\n4. 在发生意外情况的时候能够重新启动并缓存被破坏的 opcode;\n5. 文件上传优化支持;\n6. “慢日志” – 记录脚本（不仅记录文件名，还记录 PHP backtrace 信息，可以使用 ptrace或者类似工具读取和分析远程进程的运行数据）运行所导致的异常缓慢;\n7. fastcgi_finish_request() – 特殊功能：用于在请求完成和刷新数据后，继续在后台执行耗时的工作（录入视频转换、统计处理等）；\n8.动态／静态子进程产生 ；\n9. 基本 SAPI 运行状态信息（类似Apache的 mod_status）；\n10. 基于 php.ini 的配置文件。\n\n\n环境配置\n```\nyum -y install gcc gcc-c++\ngroupadd web\nuseradd -M -s /sbin/nologin -g web php\nyum -y install epel-release\nyum -y update\nyum -y install libmcrypt libmcrypt-devel mcrypt mhash\nyum -y install libxml2-devel libpng-devel libjpeg-devel zlib bzip2 bzip2-devel \\\nlibtool-ltdl-devel pcre-devel openssl-devel freetype-devel libcurl-devel icu \\\nperl-libintl postgresql libicu-devel\n```\n\n下载解压\n```\ncd /usr/local/src/\nwget http://cn2.php.net/distributions/php-5.6.27.tar.gz\ntar -zxvf php-5.6.27.tar.gz\ncd php-5.6.27/\n```\n\n编译安装\n```\n./configure \\\n--prefix=/usr/local/php5.6.27 \\\n--with-config-file-path=/usr/local/php5.6.27/etc/ \\\n--enable-inline-optimization \\\n--enable-shared \\\n--enable-opcache \\\n--enable-fpm \\\n--with-fpm-user=php \\\n--with-fpm-group=web \\\n--with-mysql=mysqlnd \\\n--with-mysqli=mysqlnd \\\n--with-pdo-mysql=mysqlnd \\\n--with-gettext \\\n--enable-mbstring \\\n--with-iconv \\\n--with-mcrypt \\\n--with-mhash \\\n--with-openssl \\\n--enable-bcmath \\\n--enable-soap \\\n--with-libxml-dir \\\n--enable-pcntl \\\n--enable-shmop \\\n--enable-sysvmsg \\\n--enable-sysvsem \\\n--enable-sysvshm \\\n--enable-sockets \\\n--enable-intl \\\n--with-curl \\\n--with-zlib \\\n--enable-zip \\\n--with-bz2 \\\n--enable-xml \\\n--with-pcre-dir \\\n--with-gd \\\n--enable-static \\\n--enable-wddx \\\n--with-xmlrpc \\\n--with-libdir=/usr/lib64 \\\n--with-jpeg-dir=/usr/lib64 \\\n--with-freetype-dir=/usr/lib64 \\\n--with-png-dir=/usr/lib64\n```\n```\nmake && make install\n```\n\n简单配置\n```\ncp php.ini-development /usr/local/php5.6.27/etc/php.ini\ncp /usr/local/php5.6.27/etc/php-fpm.conf.default /usr/local/php5.6.27/etc/php-fpm.conf\n```\n\n创建开机启动\n```\nvi /lib/systemd/system/php-fpmd.service\n```\n```\n[Unit]\nDescription=The PHP FastCGI Process Manager\nAfter=network.target\n\n[Service]\nType=forking\nPIDFile=/run/php-fpm.pid\nExecStart=/usr/local/php5.6.27/sbin/php-fpm --daemonize -g /run/php-fpm.pid\nExecReload=/bin/kill -USR2 $MAINPID\nExecStop=/bin/kill -SIGINT $MAINPID\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n```\n```\nsystemctl enable php-fpmd.service\nsystemctl start php-fpmd.service\n```\n\n\n`注意` \n\n**php.ini** 中设置`open_basedir=/usr/local/nginx/html/webapps`\n**php-frm.conf** 中`security.limit_extensions = .php .html .js .css .jpg .jpeg .gif .png .htm .txt` \n\n\n## mysql 安装\n\n> ansible 自动安装，脚本以后会附上，导入数据手动，没有任何问题\n\n## nginx 配置 \n> 我最开始的想法是，在起PHP这个服务的云主机上起一个nginx 做web服务器。但是我组大神告诉我，不用这么麻烦直接用测试服nginx代理就好。于是我没有反驳，毕竟这个看起来更简单更合理。于是我就开始配置。。。\n\n最开始配置,如下\n\n```\nserver {\n    listen 80;\n    server_name dier.chunyu.me;\n\n    location ~ [^.]+\\.php$ {\n        root   /usr/share/webapps;\n        fastcgi_pass 10.0.0.1:9000;\n        index index.html index.php;\n        #fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n        include fastcgi_params;\n\n    }\n}\n```\n写到一半，我突然发现静态文件怎么办，于是我直接把`location ~ [^.]+\\.php$`` 改成了 `location /` 所有文件都这么走。\n结果问题就出现了，如下图。css文件的请求头`Content_type`为`text/html` \n\n![](http://or2jd66dq.bkt.clouddn.com/css_error.png)\n我试着在测试服nginx上各种`add_header` 都不好使，于是请教之前大神，他一脸不屑的看着我，看了三秒。。。然后他解决，我看到机器上文件的修改，一次次add_header ,过了20多分钟，他扭头给我说，这个fastcgi好像不支持静态文件代理，而且他的代码里面没有加判断。你在这个机器上装个nginx吧。。。\n恩，于是我有用ansible跑了一遍安装nginx的脚本。\n配置如下:\n\n```\nlocation ~ [^.]+\\.php$ {\n    root           /usr/local/nginx/html/webapps;\n    fastcgi_pass   127.0.0.1:9000;\n    fastcgi_index  index.php;\n    #fastcgi_param  SCRIPT_FILENAME  /usr/local/nginx/html/webapps$fastcgi_script_name;\n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n    include        fastcgi.conf;\n }\n\nlocation ~* \\.(css|js|png|jpg|jpeg|gif|ico)$ {\n    expires max;\n    log_not_found off;\n }\n\n```\n问题解决。。。\n\n\n## 总结\n\n- 多学习，多看书，少说话\n- 如果说话学会和人一样说话\n- 多做总结，比如写博客加深一下印象，不太懂也没有关系，写着写着有可能就懂了。\n \n## 一台机器上启动两个PHP服务\n\n> SEO的哥们找我说克隆一个和之前一模一样的服务，我的原则是PHP这种漏洞比较多的服务最好还是给他们独立出来不要跟线上有联系，前不久让一个白帽子给我们扫了一下，我们才发现之前商务部门归到我们这边的一个提供PHP服务的机器直接被人拿到了root的shell，真可怕。于是，我这次把他们的数据库都从线上拆出来了。放在本地。\n\n**方法**\n\n直接再装一个php-fpm （我刚开始用一个PHP-fpm提供和两个PHP服务的动态处理在nginx中把他们的静态文件分开，事实证明不可以，会发生一些奇怪的情况，两个系统的各种配置，包括数据库都会混淆）换个端口启动就好了\n\n参考地址](https://my.oschina.net/yule526751/blog/795807)\n\n\n\n","source":"_posts/记一次PHP服务部署.md","raw":"---\ntitle: 记一次PHP服务部署\ndate: 2017-07-05 18:58:03\ntags: PHP\ncategories: 基础运维\n---\n\n> 本来很少接触这门世界上最好的语言，公司里面也没有，但是这次有这个需求，考虑到fastcgi与uwsgi有这么一点点共同点，我就照葫芦画瓢，打算用我们测试的nginx做转发。但是踩到几个坑，听我带着悔恨一点一点的说。。。\n\n## nginx代理转发介绍\n我们的测试跟线上的服务都是用nginx做全职代理转发\n在nginx.conf 声明如下:\n```\nhttp {\n...\ninclude /usr/local/nginx/conf/servers/*/upstream.conf;\ninclude /usr/local/nginx/conf/servers/*/site.conf;\n...\n}\n```\n所以就可以在server目录下建立各种监听二级域名的目录。\n\n类似这种,`uwsgi`的转发使用`uwsgi_pass` ,`普通web代理`使用`proxy_pass`,`fastcgi`使用`fastcgi_pass`\n下面举例uwsgi转发配置说明一下。\n`/usr/local/nginx/conf/servers/dier/site.conf`\n```\nserver {\n    listen 443 ssl http2;\n    server_name dier.chunyu.me;\n\n    include /usr/local/nginx/conf/servers/common/ssl_config.location;\n    location / {\n        uwsgi_pass devops_uwsgi;\n        include uwsgi_params;\n    }\n}\n\n\nserver {\n    listen 80;\n    server_name .chunyu.me;\n# 强转https\n    rewrite  ^/(.*)$  https://devops.chunyu.me/$1  permanent;\n}\n```\n\n`/usr/local/nginx/conf/servers/dier/upstream.conf`\n```\nupstream devops_uwsgi {\n    server 10.9.77.8:5001;\n}\n```\n\n## PHP服务部署\n> 源码编译安装，全程Google教程,直接按照参考地址配置即可。\n\n\nPHP-FPM\nPHP-FPM是一个PHP FastCGI管理器，是只用于PHP的,可以在 http://php-fpm.org/download下载得到。PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。FPM（FastCGI 进程管理器）用于替换 PHP-CGI 的大部分附加功能，对于高负载网站是非常有用的。它的功能包括：\n1. 支持平滑停止/启动的高级进程管理功能；\n2. 可以工作于不同的 uid/gid/chroot 环境下，并监听不同的端口和使用不同的 php.ini 配置文件（可取代 safe_mode 的设置）；\n3. stdout 和 stderr 日志记录;\n4. 在发生意外情况的时候能够重新启动并缓存被破坏的 opcode;\n5. 文件上传优化支持;\n6. “慢日志” – 记录脚本（不仅记录文件名，还记录 PHP backtrace 信息，可以使用 ptrace或者类似工具读取和分析远程进程的运行数据）运行所导致的异常缓慢;\n7. fastcgi_finish_request() – 特殊功能：用于在请求完成和刷新数据后，继续在后台执行耗时的工作（录入视频转换、统计处理等）；\n8.动态／静态子进程产生 ；\n9. 基本 SAPI 运行状态信息（类似Apache的 mod_status）；\n10. 基于 php.ini 的配置文件。\n\n\n环境配置\n```\nyum -y install gcc gcc-c++\ngroupadd web\nuseradd -M -s /sbin/nologin -g web php\nyum -y install epel-release\nyum -y update\nyum -y install libmcrypt libmcrypt-devel mcrypt mhash\nyum -y install libxml2-devel libpng-devel libjpeg-devel zlib bzip2 bzip2-devel \\\nlibtool-ltdl-devel pcre-devel openssl-devel freetype-devel libcurl-devel icu \\\nperl-libintl postgresql libicu-devel\n```\n\n下载解压\n```\ncd /usr/local/src/\nwget http://cn2.php.net/distributions/php-5.6.27.tar.gz\ntar -zxvf php-5.6.27.tar.gz\ncd php-5.6.27/\n```\n\n编译安装\n```\n./configure \\\n--prefix=/usr/local/php5.6.27 \\\n--with-config-file-path=/usr/local/php5.6.27/etc/ \\\n--enable-inline-optimization \\\n--enable-shared \\\n--enable-opcache \\\n--enable-fpm \\\n--with-fpm-user=php \\\n--with-fpm-group=web \\\n--with-mysql=mysqlnd \\\n--with-mysqli=mysqlnd \\\n--with-pdo-mysql=mysqlnd \\\n--with-gettext \\\n--enable-mbstring \\\n--with-iconv \\\n--with-mcrypt \\\n--with-mhash \\\n--with-openssl \\\n--enable-bcmath \\\n--enable-soap \\\n--with-libxml-dir \\\n--enable-pcntl \\\n--enable-shmop \\\n--enable-sysvmsg \\\n--enable-sysvsem \\\n--enable-sysvshm \\\n--enable-sockets \\\n--enable-intl \\\n--with-curl \\\n--with-zlib \\\n--enable-zip \\\n--with-bz2 \\\n--enable-xml \\\n--with-pcre-dir \\\n--with-gd \\\n--enable-static \\\n--enable-wddx \\\n--with-xmlrpc \\\n--with-libdir=/usr/lib64 \\\n--with-jpeg-dir=/usr/lib64 \\\n--with-freetype-dir=/usr/lib64 \\\n--with-png-dir=/usr/lib64\n```\n```\nmake && make install\n```\n\n简单配置\n```\ncp php.ini-development /usr/local/php5.6.27/etc/php.ini\ncp /usr/local/php5.6.27/etc/php-fpm.conf.default /usr/local/php5.6.27/etc/php-fpm.conf\n```\n\n创建开机启动\n```\nvi /lib/systemd/system/php-fpmd.service\n```\n```\n[Unit]\nDescription=The PHP FastCGI Process Manager\nAfter=network.target\n\n[Service]\nType=forking\nPIDFile=/run/php-fpm.pid\nExecStart=/usr/local/php5.6.27/sbin/php-fpm --daemonize -g /run/php-fpm.pid\nExecReload=/bin/kill -USR2 $MAINPID\nExecStop=/bin/kill -SIGINT $MAINPID\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n```\n```\nsystemctl enable php-fpmd.service\nsystemctl start php-fpmd.service\n```\n\n\n`注意` \n\n**php.ini** 中设置`open_basedir=/usr/local/nginx/html/webapps`\n**php-frm.conf** 中`security.limit_extensions = .php .html .js .css .jpg .jpeg .gif .png .htm .txt` \n\n\n## mysql 安装\n\n> ansible 自动安装，脚本以后会附上，导入数据手动，没有任何问题\n\n## nginx 配置 \n> 我最开始的想法是，在起PHP这个服务的云主机上起一个nginx 做web服务器。但是我组大神告诉我，不用这么麻烦直接用测试服nginx代理就好。于是我没有反驳，毕竟这个看起来更简单更合理。于是我就开始配置。。。\n\n最开始配置,如下\n\n```\nserver {\n    listen 80;\n    server_name dier.chunyu.me;\n\n    location ~ [^.]+\\.php$ {\n        root   /usr/share/webapps;\n        fastcgi_pass 10.0.0.1:9000;\n        index index.html index.php;\n        #fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n        include fastcgi_params;\n\n    }\n}\n```\n写到一半，我突然发现静态文件怎么办，于是我直接把`location ~ [^.]+\\.php$`` 改成了 `location /` 所有文件都这么走。\n结果问题就出现了，如下图。css文件的请求头`Content_type`为`text/html` \n\n![](http://or2jd66dq.bkt.clouddn.com/css_error.png)\n我试着在测试服nginx上各种`add_header` 都不好使，于是请教之前大神，他一脸不屑的看着我，看了三秒。。。然后他解决，我看到机器上文件的修改，一次次add_header ,过了20多分钟，他扭头给我说，这个fastcgi好像不支持静态文件代理，而且他的代码里面没有加判断。你在这个机器上装个nginx吧。。。\n恩，于是我有用ansible跑了一遍安装nginx的脚本。\n配置如下:\n\n```\nlocation ~ [^.]+\\.php$ {\n    root           /usr/local/nginx/html/webapps;\n    fastcgi_pass   127.0.0.1:9000;\n    fastcgi_index  index.php;\n    #fastcgi_param  SCRIPT_FILENAME  /usr/local/nginx/html/webapps$fastcgi_script_name;\n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n    include        fastcgi.conf;\n }\n\nlocation ~* \\.(css|js|png|jpg|jpeg|gif|ico)$ {\n    expires max;\n    log_not_found off;\n }\n\n```\n问题解决。。。\n\n\n## 总结\n\n- 多学习，多看书，少说话\n- 如果说话学会和人一样说话\n- 多做总结，比如写博客加深一下印象，不太懂也没有关系，写着写着有可能就懂了。\n \n## 一台机器上启动两个PHP服务\n\n> SEO的哥们找我说克隆一个和之前一模一样的服务，我的原则是PHP这种漏洞比较多的服务最好还是给他们独立出来不要跟线上有联系，前不久让一个白帽子给我们扫了一下，我们才发现之前商务部门归到我们这边的一个提供PHP服务的机器直接被人拿到了root的shell，真可怕。于是，我这次把他们的数据库都从线上拆出来了。放在本地。\n\n**方法**\n\n直接再装一个php-fpm （我刚开始用一个PHP-fpm提供和两个PHP服务的动态处理在nginx中把他们的静态文件分开，事实证明不可以，会发生一些奇怪的情况，两个系统的各种配置，包括数据库都会混淆）换个端口启动就好了\n\n参考地址](https://my.oschina.net/yule526751/blog/795807)\n\n\n\n","slug":"记一次PHP服务部署","published":1,"updated":"2017-07-25T08:19:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj64fxvco004b8tzzm509vrlf","content":"<blockquote>\n<p>本来很少接触这门世界上最好的语言，公司里面也没有，但是这次有这个需求，考虑到fastcgi与uwsgi有这么一点点共同点，我就照葫芦画瓢，打算用我们测试的nginx做转发。但是踩到几个坑，听我带着悔恨一点一点的说。。。</p>\n</blockquote>\n<h2 id=\"nginx代理转发介绍\"><a href=\"#nginx代理转发介绍\" class=\"headerlink\" title=\"nginx代理转发介绍\"></a>nginx代理转发介绍</h2><p>我们的测试跟线上的服务都是用nginx做全职代理转发<br>在nginx.conf 声明如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">http &#123;</div><div class=\"line\">...</div><div class=\"line\">include /usr/local/nginx/conf/servers/*/upstream.conf;</div><div class=\"line\">include /usr/local/nginx/conf/servers/*/site.conf;</div><div class=\"line\">...</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>所以就可以在server目录下建立各种监听二级域名的目录。</p>\n<p>类似这种,<code>uwsgi</code>的转发使用<code>uwsgi_pass</code> ,<code>普通web代理</code>使用<code>proxy_pass</code>,<code>fastcgi</code>使用<code>fastcgi_pass</code><br>下面举例uwsgi转发配置说明一下。<br><code>/usr/local/nginx/conf/servers/dier/site.conf</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">server &#123;</div><div class=\"line\">    listen 443 ssl http2;</div><div class=\"line\">    server_name dier.chunyu.me;</div><div class=\"line\"></div><div class=\"line\">    include /usr/local/nginx/conf/servers/common/ssl_config.location;</div><div class=\"line\">    location / &#123;</div><div class=\"line\">        uwsgi_pass devops_uwsgi;</div><div class=\"line\">        include uwsgi_params;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">server &#123;</div><div class=\"line\">    listen 80;</div><div class=\"line\">    server_name .chunyu.me;</div><div class=\"line\"># 强转https</div><div class=\"line\">    rewrite  ^/(.*)$  https://devops.chunyu.me/$1  permanent;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>/usr/local/nginx/conf/servers/dier/upstream.conf</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">upstream devops_uwsgi &#123;</div><div class=\"line\">    server 10.9.77.8:5001;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"php服务部署\"><a href=\"#PHP服务部署\" class=\"headerlink\" title=\"PHP服务部署\"></a>PHP服务部署</h2><blockquote>\n<p>源码编译安装，全程Google教程,直接按照参考地址配置即可。</p>\n</blockquote>\n<p>PHP-FPM<br>PHP-FPM是一个PHP FastCGI管理器，是只用于PHP的,可以在 <a href=\"http://php-fpm.org/download下载得到。PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。FPM（FastCGI\" target=\"_blank\" rel=\"external\">http://php-fpm.org/download下载得到。PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。FPM（FastCGI</a> 进程管理器）用于替换 PHP-CGI 的大部分附加功能，对于高负载网站是非常有用的。它的功能包括：</p>\n<ol>\n<li>支持平滑停止/启动的高级进程管理功能；</li>\n<li>可以工作于不同的 uid/gid/chroot 环境下，并监听不同的端口和使用不同的 php.ini 配置文件（可取代 safe_mode 的设置）；</li>\n<li>stdout 和 stderr 日志记录;</li>\n<li>在发生意外情况的时候能够重新启动并缓存被破坏的 opcode;</li>\n<li>文件上传优化支持;</li>\n<li>“慢日志” – 记录脚本（不仅记录文件名，还记录 PHP backtrace 信息，可以使用 ptrace或者类似工具读取和分析远程进程的运行数据）运行所导致的异常缓慢;</li>\n<li>fastcgi_finish_request() – 特殊功能：用于在请求完成和刷新数据后，继续在后台执行耗时的工作（录入视频转换、统计处理等）；<br>8.动态／静态子进程产生 ；</li>\n<li>基本 SAPI 运行状态信息（类似Apache的 mod_status）；</li>\n<li>基于 php.ini 的配置文件。</li>\n</ol>\n<p>环境配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum -y install gcc gcc-c++</div><div class=\"line\">groupadd web</div><div class=\"line\">useradd -M -s /sbin/nologin -g web php</div><div class=\"line\">yum -y install epel-release</div><div class=\"line\">yum -y update</div><div class=\"line\">yum -y install libmcrypt libmcrypt-devel mcrypt mhash</div><div class=\"line\">yum -y install libxml2-devel libpng-devel libjpeg-devel zlib bzip2 bzip2-devel \\</div><div class=\"line\">libtool-ltdl-devel pcre-devel openssl-devel freetype-devel libcurl-devel icu \\</div><div class=\"line\">perl-libintl postgresql libicu-devel</div></pre></td></tr></table></figure></p>\n<p>下载解压<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd /usr/local/src/</div><div class=\"line\">wget http://cn2.php.net/distributions/php-5.6.27.tar.gz</div><div class=\"line\">tar -zxvf php-5.6.27.tar.gz</div><div class=\"line\">cd php-5.6.27/</div></pre></td></tr></table></figure></p>\n<p>编译安装<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\">./configure \\</div><div class=\"line\">--prefix=/usr/local/php5.6.27 \\</div><div class=\"line\">--with-config-file-path=/usr/local/php5.6.27/etc/ \\</div><div class=\"line\">--enable-inline-optimization \\</div><div class=\"line\">--enable-shared \\</div><div class=\"line\">--enable-opcache \\</div><div class=\"line\">--enable-fpm \\</div><div class=\"line\">--with-fpm-user=php \\</div><div class=\"line\">--with-fpm-group=web \\</div><div class=\"line\">--with-mysql=mysqlnd \\</div><div class=\"line\">--with-mysqli=mysqlnd \\</div><div class=\"line\">--with-pdo-mysql=mysqlnd \\</div><div class=\"line\">--with-gettext \\</div><div class=\"line\">--enable-mbstring \\</div><div class=\"line\">--with-iconv \\</div><div class=\"line\">--with-mcrypt \\</div><div class=\"line\">--with-mhash \\</div><div class=\"line\">--with-openssl \\</div><div class=\"line\">--enable-bcmath \\</div><div class=\"line\">--enable-soap \\</div><div class=\"line\">--with-libxml-dir \\</div><div class=\"line\">--enable-pcntl \\</div><div class=\"line\">--enable-shmop \\</div><div class=\"line\">--enable-sysvmsg \\</div><div class=\"line\">--enable-sysvsem \\</div><div class=\"line\">--enable-sysvshm \\</div><div class=\"line\">--enable-sockets \\</div><div class=\"line\">--enable-intl \\</div><div class=\"line\">--with-curl \\</div><div class=\"line\">--with-zlib \\</div><div class=\"line\">--enable-zip \\</div><div class=\"line\">--with-bz2 \\</div><div class=\"line\">--enable-xml \\</div><div class=\"line\">--with-pcre-dir \\</div><div class=\"line\">--with-gd \\</div><div class=\"line\">--enable-static \\</div><div class=\"line\">--enable-wddx \\</div><div class=\"line\">--with-xmlrpc \\</div><div class=\"line\">--with-libdir=/usr/lib64 \\</div><div class=\"line\">--with-jpeg-dir=/usr/lib64 \\</div><div class=\"line\">--with-freetype-dir=/usr/lib64 \\</div><div class=\"line\">--with-png-dir=/usr/lib64</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">make &amp;&amp; make install</div></pre></td></tr></table></figure>\n<p>简单配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp php.ini-development /usr/local/php5.6.27/etc/php.ini</div><div class=\"line\">cp /usr/local/php5.6.27/etc/php-fpm.conf.default /usr/local/php5.6.27/etc/php-fpm.conf</div></pre></td></tr></table></figure></p>\n<p>创建开机启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vi /lib/systemd/system/php-fpmd.service</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">[Unit]</div><div class=\"line\">Description=The PHP FastCGI Process Manager</div><div class=\"line\">After=network.target</div><div class=\"line\"></div><div class=\"line\">[Service]</div><div class=\"line\">Type=forking</div><div class=\"line\">PIDFile=/run/php-fpm.pid</div><div class=\"line\">ExecStart=/usr/local/php5.6.27/sbin/php-fpm --daemonize -g /run/php-fpm.pid</div><div class=\"line\">ExecReload=/bin/kill -USR2 $MAINPID</div><div class=\"line\">ExecStop=/bin/kill -SIGINT $MAINPID</div><div class=\"line\">PrivateTmp=true</div><div class=\"line\"></div><div class=\"line\">[Install]</div><div class=\"line\">WantedBy=multi-user.target</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">systemctl enable php-fpmd.service</div><div class=\"line\">systemctl start php-fpmd.service</div></pre></td></tr></table></figure>\n<p><code>注意</code> </p>\n<p><strong>php.ini</strong> 中设置<code>open_basedir=/usr/local/nginx/html/webapps</code><br><strong>php-frm.conf</strong> 中<code>security.limit_extensions = .php .html .js .css .jpg .jpeg .gif .png .htm .txt</code> </p>\n<h2 id=\"mysql-安装\"><a href=\"#mysql-安装\" class=\"headerlink\" title=\"mysql 安装\"></a>mysql 安装</h2><blockquote>\n<p>ansible 自动安装，脚本以后会附上，导入数据手动，没有任何问题</p>\n</blockquote>\n<h2 id=\"nginx-配置\"><a href=\"#nginx-配置\" class=\"headerlink\" title=\"nginx 配置\"></a>nginx 配置</h2><blockquote>\n<p>我最开始的想法是，在起PHP这个服务的云主机上起一个nginx 做web服务器。但是我组大神告诉我，不用这么麻烦直接用测试服nginx代理就好。于是我没有反驳，毕竟这个看起来更简单更合理。于是我就开始配置。。。</p>\n</blockquote>\n<p>最开始配置,如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">server &#123;</div><div class=\"line\">    listen 80;</div><div class=\"line\">    server_name dier.chunyu.me;</div><div class=\"line\"></div><div class=\"line\">    location ~ [^.]+\\.php$ &#123;</div><div class=\"line\">        root   /usr/share/webapps;</div><div class=\"line\">        fastcgi_pass 10.0.0.1:9000;</div><div class=\"line\">        index index.html index.php;</div><div class=\"line\">        #fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;</div><div class=\"line\">        fastcgi_param SCRIPT_FILENAME  $document_root$fastcgi_script_name;</div><div class=\"line\">        include fastcgi_params;</div><div class=\"line\"></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>写到一半，我突然发现静态文件怎么办，于是我直接把<code>location ~ [^.]+\\.php$`` 改成了</code>location /<code>所有文件都这么走。\n结果问题就出现了，如下图。css文件的请求头</code>Content_type<code>为</code>text/html` </p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/css_error.png\" alt=\"\"><br>我试着在测试服nginx上各种<code>add_header</code> 都不好使，于是请教之前大神，他一脸不屑的看着我，看了三秒。。。然后他解决，我看到机器上文件的修改，一次次add_header ,过了20多分钟，他扭头给我说，这个fastcgi好像不支持静态文件代理，而且他的代码里面没有加判断。你在这个机器上装个nginx吧。。。<br>恩，于是我有用ansible跑了一遍安装nginx的脚本。<br>配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">location ~ [^.]+\\.php$ &#123;</div><div class=\"line\">    root           /usr/local/nginx/html/webapps;</div><div class=\"line\">    fastcgi_pass   127.0.0.1:9000;</div><div class=\"line\">    fastcgi_index  index.php;</div><div class=\"line\">    #fastcgi_param  SCRIPT_FILENAME  /usr/local/nginx/html/webapps$fastcgi_script_name;</div><div class=\"line\">    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;</div><div class=\"line\">    include        fastcgi.conf;</div><div class=\"line\"> &#125;</div><div class=\"line\"></div><div class=\"line\">location ~* \\.(css|js|png|jpg|jpeg|gif|ico)$ &#123;</div><div class=\"line\">    expires max;</div><div class=\"line\">    log_not_found off;</div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n<p>问题解决。。。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li>多学习，多看书，少说话</li>\n<li>如果说话学会和人一样说话</li>\n<li>多做总结，比如写博客加深一下印象，不太懂也没有关系，写着写着有可能就懂了。</li>\n</ul>\n<h2 id=\"一台机器上启动两个php服务\"><a href=\"#一台机器上启动两个PHP服务\" class=\"headerlink\" title=\"一台机器上启动两个PHP服务\"></a>一台机器上启动两个PHP服务</h2><blockquote>\n<p>SEO的哥们找我说克隆一个和之前一模一样的服务，我的原则是PHP这种漏洞比较多的服务最好还是给他们独立出来不要跟线上有联系，前不久让一个白帽子给我们扫了一下，我们才发现之前商务部门归到我们这边的一个提供PHP服务的机器直接被人拿到了root的shell，真可怕。于是，我这次把他们的数据库都从线上拆出来了。放在本地。</p>\n</blockquote>\n<p><strong>方法</strong></p>\n<p>直接再装一个php-fpm （我刚开始用一个PHP-fpm提供和两个PHP服务的动态处理在nginx中把他们的静态文件分开，事实证明不可以，会发生一些奇怪的情况，两个系统的各种配置，包括数据库都会混淆）换个端口启动就好了</p>\n<p>参考地址](<a href=\"https://my.oschina.net/yule526751/blog/795807\" target=\"_blank\" rel=\"external\">https://my.oschina.net/yule526751/blog/795807</a>)</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本来很少接触这门世界上最好的语言，公司里面也没有，但是这次有这个需求，考虑到fastcgi与uwsgi有这么一点点共同点，我就照葫芦画瓢，打算用我们测试的nginx做转发。但是踩到几个坑，听我带着悔恨一点一点的说。。。</p>\n</blockquote>\n<h2 id=\"nginx代理转发介绍\"><a href=\"#nginx代理转发介绍\" class=\"headerlink\" title=\"nginx代理转发介绍\"></a>nginx代理转发介绍</h2><p>我们的测试跟线上的服务都是用nginx做全职代理转发<br>在nginx.conf 声明如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">http &#123;</div><div class=\"line\">...</div><div class=\"line\">include /usr/local/nginx/conf/servers/*/upstream.conf;</div><div class=\"line\">include /usr/local/nginx/conf/servers/*/site.conf;</div><div class=\"line\">...</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>所以就可以在server目录下建立各种监听二级域名的目录。</p>\n<p>类似这种,<code>uwsgi</code>的转发使用<code>uwsgi_pass</code> ,<code>普通web代理</code>使用<code>proxy_pass</code>,<code>fastcgi</code>使用<code>fastcgi_pass</code><br>下面举例uwsgi转发配置说明一下。<br><code>/usr/local/nginx/conf/servers/dier/site.conf</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">server &#123;</div><div class=\"line\">    listen 443 ssl http2;</div><div class=\"line\">    server_name dier.chunyu.me;</div><div class=\"line\"></div><div class=\"line\">    include /usr/local/nginx/conf/servers/common/ssl_config.location;</div><div class=\"line\">    location / &#123;</div><div class=\"line\">        uwsgi_pass devops_uwsgi;</div><div class=\"line\">        include uwsgi_params;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">server &#123;</div><div class=\"line\">    listen 80;</div><div class=\"line\">    server_name .chunyu.me;</div><div class=\"line\"># 强转https</div><div class=\"line\">    rewrite  ^/(.*)$  https://devops.chunyu.me/$1  permanent;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>/usr/local/nginx/conf/servers/dier/upstream.conf</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">upstream devops_uwsgi &#123;</div><div class=\"line\">    server 10.9.77.8:5001;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"PHP服务部署\"><a href=\"#PHP服务部署\" class=\"headerlink\" title=\"PHP服务部署\"></a>PHP服务部署</h2><blockquote>\n<p>源码编译安装，全程Google教程,直接按照参考地址配置即可。</p>\n</blockquote>\n<p>PHP-FPM<br>PHP-FPM是一个PHP FastCGI管理器，是只用于PHP的,可以在 <a href=\"http://php-fpm.org/download下载得到。PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。FPM（FastCGI\" target=\"_blank\" rel=\"external\">http://php-fpm.org/download下载得到。PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。FPM（FastCGI</a> 进程管理器）用于替换 PHP-CGI 的大部分附加功能，对于高负载网站是非常有用的。它的功能包括：</p>\n<ol>\n<li>支持平滑停止/启动的高级进程管理功能；</li>\n<li>可以工作于不同的 uid/gid/chroot 环境下，并监听不同的端口和使用不同的 php.ini 配置文件（可取代 safe_mode 的设置）；</li>\n<li>stdout 和 stderr 日志记录;</li>\n<li>在发生意外情况的时候能够重新启动并缓存被破坏的 opcode;</li>\n<li>文件上传优化支持;</li>\n<li>“慢日志” – 记录脚本（不仅记录文件名，还记录 PHP backtrace 信息，可以使用 ptrace或者类似工具读取和分析远程进程的运行数据）运行所导致的异常缓慢;</li>\n<li>fastcgi_finish_request() – 特殊功能：用于在请求完成和刷新数据后，继续在后台执行耗时的工作（录入视频转换、统计处理等）；<br>8.动态／静态子进程产生 ；</li>\n<li>基本 SAPI 运行状态信息（类似Apache的 mod_status）；</li>\n<li>基于 php.ini 的配置文件。</li>\n</ol>\n<p>环境配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum -y install gcc gcc-c++</div><div class=\"line\">groupadd web</div><div class=\"line\">useradd -M -s /sbin/nologin -g web php</div><div class=\"line\">yum -y install epel-release</div><div class=\"line\">yum -y update</div><div class=\"line\">yum -y install libmcrypt libmcrypt-devel mcrypt mhash</div><div class=\"line\">yum -y install libxml2-devel libpng-devel libjpeg-devel zlib bzip2 bzip2-devel \\</div><div class=\"line\">libtool-ltdl-devel pcre-devel openssl-devel freetype-devel libcurl-devel icu \\</div><div class=\"line\">perl-libintl postgresql libicu-devel</div></pre></td></tr></table></figure></p>\n<p>下载解压<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd /usr/local/src/</div><div class=\"line\">wget http://cn2.php.net/distributions/php-5.6.27.tar.gz</div><div class=\"line\">tar -zxvf php-5.6.27.tar.gz</div><div class=\"line\">cd php-5.6.27/</div></pre></td></tr></table></figure></p>\n<p>编译安装<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div></pre></td><td class=\"code\"><pre><div class=\"line\">./configure \\</div><div class=\"line\">--prefix=/usr/local/php5.6.27 \\</div><div class=\"line\">--with-config-file-path=/usr/local/php5.6.27/etc/ \\</div><div class=\"line\">--enable-inline-optimization \\</div><div class=\"line\">--enable-shared \\</div><div class=\"line\">--enable-opcache \\</div><div class=\"line\">--enable-fpm \\</div><div class=\"line\">--with-fpm-user=php \\</div><div class=\"line\">--with-fpm-group=web \\</div><div class=\"line\">--with-mysql=mysqlnd \\</div><div class=\"line\">--with-mysqli=mysqlnd \\</div><div class=\"line\">--with-pdo-mysql=mysqlnd \\</div><div class=\"line\">--with-gettext \\</div><div class=\"line\">--enable-mbstring \\</div><div class=\"line\">--with-iconv \\</div><div class=\"line\">--with-mcrypt \\</div><div class=\"line\">--with-mhash \\</div><div class=\"line\">--with-openssl \\</div><div class=\"line\">--enable-bcmath \\</div><div class=\"line\">--enable-soap \\</div><div class=\"line\">--with-libxml-dir \\</div><div class=\"line\">--enable-pcntl \\</div><div class=\"line\">--enable-shmop \\</div><div class=\"line\">--enable-sysvmsg \\</div><div class=\"line\">--enable-sysvsem \\</div><div class=\"line\">--enable-sysvshm \\</div><div class=\"line\">--enable-sockets \\</div><div class=\"line\">--enable-intl \\</div><div class=\"line\">--with-curl \\</div><div class=\"line\">--with-zlib \\</div><div class=\"line\">--enable-zip \\</div><div class=\"line\">--with-bz2 \\</div><div class=\"line\">--enable-xml \\</div><div class=\"line\">--with-pcre-dir \\</div><div class=\"line\">--with-gd \\</div><div class=\"line\">--enable-static \\</div><div class=\"line\">--enable-wddx \\</div><div class=\"line\">--with-xmlrpc \\</div><div class=\"line\">--with-libdir=/usr/lib64 \\</div><div class=\"line\">--with-jpeg-dir=/usr/lib64 \\</div><div class=\"line\">--with-freetype-dir=/usr/lib64 \\</div><div class=\"line\">--with-png-dir=/usr/lib64</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">make &amp;&amp; make install</div></pre></td></tr></table></figure>\n<p>简单配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cp php.ini-development /usr/local/php5.6.27/etc/php.ini</div><div class=\"line\">cp /usr/local/php5.6.27/etc/php-fpm.conf.default /usr/local/php5.6.27/etc/php-fpm.conf</div></pre></td></tr></table></figure></p>\n<p>创建开机启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vi /lib/systemd/system/php-fpmd.service</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">[Unit]</div><div class=\"line\">Description=The PHP FastCGI Process Manager</div><div class=\"line\">After=network.target</div><div class=\"line\"></div><div class=\"line\">[Service]</div><div class=\"line\">Type=forking</div><div class=\"line\">PIDFile=/run/php-fpm.pid</div><div class=\"line\">ExecStart=/usr/local/php5.6.27/sbin/php-fpm --daemonize -g /run/php-fpm.pid</div><div class=\"line\">ExecReload=/bin/kill -USR2 $MAINPID</div><div class=\"line\">ExecStop=/bin/kill -SIGINT $MAINPID</div><div class=\"line\">PrivateTmp=true</div><div class=\"line\"></div><div class=\"line\">[Install]</div><div class=\"line\">WantedBy=multi-user.target</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">systemctl enable php-fpmd.service</div><div class=\"line\">systemctl start php-fpmd.service</div></pre></td></tr></table></figure>\n<p><code>注意</code> </p>\n<p><strong>php.ini</strong> 中设置<code>open_basedir=/usr/local/nginx/html/webapps</code><br><strong>php-frm.conf</strong> 中<code>security.limit_extensions = .php .html .js .css .jpg .jpeg .gif .png .htm .txt</code> </p>\n<h2 id=\"mysql-安装\"><a href=\"#mysql-安装\" class=\"headerlink\" title=\"mysql 安装\"></a>mysql 安装</h2><blockquote>\n<p>ansible 自动安装，脚本以后会附上，导入数据手动，没有任何问题</p>\n</blockquote>\n<h2 id=\"nginx-配置\"><a href=\"#nginx-配置\" class=\"headerlink\" title=\"nginx 配置\"></a>nginx 配置</h2><blockquote>\n<p>我最开始的想法是，在起PHP这个服务的云主机上起一个nginx 做web服务器。但是我组大神告诉我，不用这么麻烦直接用测试服nginx代理就好。于是我没有反驳，毕竟这个看起来更简单更合理。于是我就开始配置。。。</p>\n</blockquote>\n<p>最开始配置,如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">server &#123;</div><div class=\"line\">    listen 80;</div><div class=\"line\">    server_name dier.chunyu.me;</div><div class=\"line\"></div><div class=\"line\">    location ~ [^.]+\\.php$ &#123;</div><div class=\"line\">        root   /usr/share/webapps;</div><div class=\"line\">        fastcgi_pass 10.0.0.1:9000;</div><div class=\"line\">        index index.html index.php;</div><div class=\"line\">        #fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;</div><div class=\"line\">        fastcgi_param SCRIPT_FILENAME  $document_root$fastcgi_script_name;</div><div class=\"line\">        include fastcgi_params;</div><div class=\"line\"></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>写到一半，我突然发现静态文件怎么办，于是我直接把<code>location ~ [^.]+\\.php$`` 改成了</code>location /<code>所有文件都这么走。\n结果问题就出现了，如下图。css文件的请求头</code>Content_type<code>为</code>text/html` </p>\n<p><img src=\"http://or2jd66dq.bkt.clouddn.com/css_error.png\" alt=\"\"><br>我试着在测试服nginx上各种<code>add_header</code> 都不好使，于是请教之前大神，他一脸不屑的看着我，看了三秒。。。然后他解决，我看到机器上文件的修改，一次次add_header ,过了20多分钟，他扭头给我说，这个fastcgi好像不支持静态文件代理，而且他的代码里面没有加判断。你在这个机器上装个nginx吧。。。<br>恩，于是我有用ansible跑了一遍安装nginx的脚本。<br>配置如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">location ~ [^.]+\\.php$ &#123;</div><div class=\"line\">    root           /usr/local/nginx/html/webapps;</div><div class=\"line\">    fastcgi_pass   127.0.0.1:9000;</div><div class=\"line\">    fastcgi_index  index.php;</div><div class=\"line\">    #fastcgi_param  SCRIPT_FILENAME  /usr/local/nginx/html/webapps$fastcgi_script_name;</div><div class=\"line\">    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;</div><div class=\"line\">    include        fastcgi.conf;</div><div class=\"line\"> &#125;</div><div class=\"line\"></div><div class=\"line\">location ~* \\.(css|js|png|jpg|jpeg|gif|ico)$ &#123;</div><div class=\"line\">    expires max;</div><div class=\"line\">    log_not_found off;</div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n<p>问题解决。。。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li>多学习，多看书，少说话</li>\n<li>如果说话学会和人一样说话</li>\n<li>多做总结，比如写博客加深一下印象，不太懂也没有关系，写着写着有可能就懂了。</li>\n</ul>\n<h2 id=\"一台机器上启动两个PHP服务\"><a href=\"#一台机器上启动两个PHP服务\" class=\"headerlink\" title=\"一台机器上启动两个PHP服务\"></a>一台机器上启动两个PHP服务</h2><blockquote>\n<p>SEO的哥们找我说克隆一个和之前一模一样的服务，我的原则是PHP这种漏洞比较多的服务最好还是给他们独立出来不要跟线上有联系，前不久让一个白帽子给我们扫了一下，我们才发现之前商务部门归到我们这边的一个提供PHP服务的机器直接被人拿到了root的shell，真可怕。于是，我这次把他们的数据库都从线上拆出来了。放在本地。</p>\n</blockquote>\n<p><strong>方法</strong></p>\n<p>直接再装一个php-fpm （我刚开始用一个PHP-fpm提供和两个PHP服务的动态处理在nginx中把他们的静态文件分开，事实证明不可以，会发生一些奇怪的情况，两个系统的各种配置，包括数据库都会混淆）换个端口启动就好了</p>\n<p>参考地址](<a href=\"https://my.oschina.net/yule526751/blog/795807\" target=\"_blank\" rel=\"external\">https://my.oschina.net/yule526751/blog/795807</a>)</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cj64fxv4y00068tzznrkapc4c","category_id":"cj64fxv4q00038tzzpsq5ggav","_id":"cj64fxv58000c8tzzdk7czppf"},{"post_id":"cj64fxv4m00018tzzufuyrc7p","category_id":"cj64fxv4q00038tzzpsq5ggav","_id":"cj64fxv5a000g8tzzcsmk1q5s"},{"post_id":"cj64fxv4p00028tzzh90lobmp","category_id":"cj64fxv5300088tzznli09y2y","_id":"cj64fxv5e000k8tzzwc98dzjf"},{"post_id":"cj64fxv4v00058tzzp6fibc1h","category_id":"cj64fxv4q00038tzzpsq5ggav","_id":"cj64fxv5h000q8tzzlt19ga1c"},{"post_id":"cj64fxv55000b8tzz1gr9qpvg","category_id":"cj64fxv5e000l8tzz8zvdoiop","_id":"cj64fxv5n000w8tzzgl9j7czl"},{"post_id":"cj64fxv58000d8tzzrnlzzi7w","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxv5r00128tzz80v9md4u"},{"post_id":"cj64fxv5k000v8tzzht7mjw6n","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxv5u00168tzzvnbgzl1d"},{"post_id":"cj64fxv5o000z8tzze5d0bhee","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxv5v00198tzzmhar2hza"},{"post_id":"cj64fxv5b000h8tzzscancgx0","category_id":"cj64fxv5n000y8tzzu5xxkjo0","_id":"cj64fxv5w001c8tzzinr8kcgc"},{"post_id":"cj64fxv5f000n8tzzdhq9mi0a","category_id":"cj64fxv5t00158tzztgyp0ys5","_id":"cj64fxv5w001e8tzz7v6yuhru"},{"post_id":"cj64fxv5h000p8tzzkrdlmq12","category_id":"cj64fxv5w001b8tzz3afcjqsq","_id":"cj64fxv5x001i8tzzeafhmywl"},{"post_id":"cj64fxv5j000t8tzzhrf1ut1r","category_id":"cj64fxv5w001b8tzz3afcjqsq","_id":"cj64fxv5y001m8tzzmxldmpye"},{"post_id":"cj64fxv5p00118tzzo3t50av5","category_id":"cj64fxv5x001j8tzzt3h3inef","_id":"cj64fxv60001q8tzzkp8rvwx0"},{"post_id":"cj64fxv5s00148tzzskgm783w","category_id":"cj64fxv5y001n8tzzisceexlh","_id":"cj64fxv61001u8tzzdz9d7cay"},{"post_id":"cj64fxv5u00188tzz2wv4t9dl","category_id":"cj64fxv5x001j8tzzt3h3inef","_id":"cj64fxv62001x8tzz2v8zh7l1"},{"post_id":"cj64fxvay00278tzzcdsboojl","category_id":"cj64fxv5e000l8tzz8zvdoiop","_id":"cj64fxvba002d8tzza1gyqtx6"},{"post_id":"cj64fxvb100298tzzrmchgwu0","category_id":"cj64fxv4q00038tzzpsq5ggav","_id":"cj64fxvbc002f8tzzzbco2euw"},{"post_id":"cj64fxvb8002c8tzz6pkimzi9","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvbe002j8tzzlg8padrg"},{"post_id":"cj64fxvbc002g8tzzkuo958gz","category_id":"cj64fxv5w001b8tzz3afcjqsq","_id":"cj64fxvbh002p8tzzz03plqa0"},{"post_id":"cj64fxvbe002l8tzzujk62z2v","category_id":"cj64fxv4q00038tzzpsq5ggav","_id":"cj64fxvbj002s8tzz8oknnczu"},{"post_id":"cj64fxvbg002n8tzzcfxedlbh","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvbn002w8tzzjsgoptml"},{"post_id":"cj64fxvbb002e8tzzu9y3hvof","category_id":"cj64fxvbe002i8tzzjaxs1amo","_id":"cj64fxvbq002z8tzzfg50u0kd"},{"post_id":"cj64fxvbi002q8tzzaz5yj76f","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvbs00328tzzkhxl6f0y"},{"post_id":"cj64fxvbo002x8tzz2sq3d2eb","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvbw00368tzzk89cgmjy"},{"post_id":"cj64fxvbq00308tzzq9k1mgz6","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvby00398tzzogqzv0qg"},{"post_id":"cj64fxvbz003a8tzzzhcfizqi","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvc3003h8tzz54je42jf"},{"post_id":"cj64fxvc0003d8tzzjzpeoinb","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvc6003k8tzz91u1t9an"},{"post_id":"cj64fxvbt00348tzz9in1tbzy","category_id":"cj64fxvby00388tzzjq3o2uz1","_id":"cj64fxvca003o8tzzck6irxyn"},{"post_id":"cj64fxvc2003e8tzzej897eh8","category_id":"cj64fxv4q00038tzzpsq5ggav","_id":"cj64fxvcc003r8tzzciz5whrc"},{"post_id":"cj64fxvbx00378tzz382ls6cw","category_id":"cj64fxvby00388tzzjq3o2uz1","_id":"cj64fxvce003v8tzzuil3lvzd"},{"post_id":"cj64fxvc7003l8tzzancb2knd","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvcg003y8tzz1opssx9a"},{"post_id":"cj64fxvcb003p8tzzyx8ozi67","category_id":"cj64fxv5y001n8tzzisceexlh","_id":"cj64fxvci00428tzzsp4cnerv"},{"post_id":"cj64fxvcc003s8tzzr6zfv426","category_id":"cj64fxv5w001b8tzz3afcjqsq","_id":"cj64fxvck00468tzzg81yh9l3"},{"post_id":"cj64fxvc4003j8tzzzbkb09mz","category_id":"cj64fxvc9003n8tzzgrs5wnwm","_id":"cj64fxvcn00498tzz2krihlpe"},{"post_id":"cj64fxvci00448tzz4fypjolr","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvcp004d8tzze6nueaea"},{"post_id":"cj64fxvce003w8tzzi57bitit","category_id":"cj64fxvch00408tzznf0hywjn","_id":"cj64fxvcp004e8tzz5e6774am"},{"post_id":"cj64fxvco004b8tzzm509vrlf","category_id":"cj64fxv5i000r8tzzybcucdgw","_id":"cj64fxvcr004g8tzz3vsgs9ic"}],"PostTag":[{"post_id":"cj64fxv4m00018tzzufuyrc7p","tag_id":"cj64fxv4v00048tzz71bsd07q","_id":"cj64fxv55000a8tzzcso2115q"},{"post_id":"cj64fxv4p00028tzzh90lobmp","tag_id":"cj64fxv5400098tzzpdveqgnk","_id":"cj64fxv5c000i8tzzckcq3iwm"},{"post_id":"cj64fxv4v00058tzzp6fibc1h","tag_id":"cj64fxv4v00048tzz71bsd07q","_id":"cj64fxv5g000o8tzzupmxmp60"},{"post_id":"cj64fxv4y00068tzznrkapc4c","tag_id":"cj64fxv5f000m8tzzvbf9tnl2","_id":"cj64fxv5k000u8tzz6tg2p6tb"},{"post_id":"cj64fxv4z00078tzzmp2vfnxp","tag_id":"cj64fxv5f000m8tzzvbf9tnl2","_id":"cj64fxv5p00108tzz4rggccs1"},{"post_id":"cj64fxv55000b8tzz1gr9qpvg","tag_id":"cj64fxv5n000x8tzzelotgpc7","_id":"cj64fxv5u00178tzzz8v7jcv6"},{"post_id":"cj64fxv58000d8tzzrnlzzi7w","tag_id":"cj64fxv5r00138tzzuvjgw0dc","_id":"cj64fxv5w001d8tzzvykjoe3i"},{"post_id":"cj64fxv5b000h8tzzscancgx0","tag_id":"cj64fxv5v001a8tzzy6hlk5ms","_id":"cj64fxv5x001h8tzzbtr562jn"},{"post_id":"cj64fxv5d000j8tzzijorrmgk","tag_id":"cj64fxv5w001f8tzzaprfx4l9","_id":"cj64fxv5x001l8tzze221bquc"},{"post_id":"cj64fxv5f000n8tzzdhq9mi0a","tag_id":"cj64fxv5x001k8tzzon6he7yk","_id":"cj64fxv5z001p8tzzmgbuihn7"},{"post_id":"cj64fxv5h000p8tzzkrdlmq12","tag_id":"cj64fxv5z001o8tzz65sojffp","_id":"cj64fxv61001t8tzzk70k6wsn"},{"post_id":"cj64fxv5j000t8tzzhrf1ut1r","tag_id":"cj64fxv61001s8tzzpq1ydkgq","_id":"cj64fxv62001w8tzzavzqcrtn"},{"post_id":"cj64fxv5k000v8tzzht7mjw6n","tag_id":"cj64fxv62001v8tzz154q0ssc","_id":"cj64fxv63001z8tzzl0riyjeq"},{"post_id":"cj64fxv5o000z8tzze5d0bhee","tag_id":"cj64fxv62001y8tzzohmqcnm1","_id":"cj64fxv6300218tzz94j9on8r"},{"post_id":"cj64fxv5p00118tzzo3t50av5","tag_id":"cj64fxv6300208tzzcoewnyan","_id":"cj64fxv6400238tzzyu7ssxzc"},{"post_id":"cj64fxv5s00148tzzskgm783w","tag_id":"cj64fxv6300228tzzf7u5g8b2","_id":"cj64fxv6500258tzzpce95ozz"},{"post_id":"cj64fxv5u00188tzz2wv4t9dl","tag_id":"cj64fxv6300208tzzcoewnyan","_id":"cj64fxv6500268tzz1nd3nztv"},{"post_id":"cj64fxvay00278tzzcdsboojl","tag_id":"cj64fxvb8002b8tzz0zlmcotn","_id":"cj64fxvbe002k8tzzuszqb2pl"},{"post_id":"cj64fxvbc002g8tzzkuo958gz","tag_id":"cj64fxv5z001o8tzz65sojffp","_id":"cj64fxvbf002m8tzzplsz049j"},{"post_id":"cj64fxvb100298tzzrmchgwu0","tag_id":"cj64fxvbd002h8tzz0itcob6i","_id":"cj64fxvbj002r8tzzntzzlpph"},{"post_id":"cj64fxvbi002q8tzzaz5yj76f","tag_id":"cj64fxvbh002o8tzzaf4ys149","_id":"cj64fxvbn002v8tzz1zoteysf"},{"post_id":"cj64fxvb8002c8tzz6pkimzi9","tag_id":"cj64fxvbh002o8tzzaf4ys149","_id":"cj64fxvbq002y8tzz7dji2y7h"},{"post_id":"cj64fxvbj002t8tzzx8ar1ksj","tag_id":"cj64fxvbh002o8tzzaf4ys149","_id":"cj64fxvbs00318tzzn7igtkfn"},{"post_id":"cj64fxvbb002e8tzzu9y3hvof","tag_id":"cj64fxvbn002u8tzz4114fqx9","_id":"cj64fxvbv00358tzzzncl5ebl"},{"post_id":"cj64fxvbe002l8tzzujk62z2v","tag_id":"cj64fxvbs00338tzz27jkkcus","_id":"cj64fxvc0003c8tzzd8vregt0"},{"post_id":"cj64fxvbg002n8tzzcfxedlbh","tag_id":"cj64fxvbh002o8tzzaf4ys149","_id":"cj64fxvc4003i8tzzncg06n80"},{"post_id":"cj64fxvbo002x8tzz2sq3d2eb","tag_id":"cj64fxvc3003g8tzzdd3y0s73","_id":"cj64fxvcc003q8tzz41iqkopf"},{"post_id":"cj64fxvcb003p8tzzyx8ozi67","tag_id":"cj64fxv6300228tzzf7u5g8b2","_id":"cj64fxvce003u8tzzikahbvbn"},{"post_id":"cj64fxvbq00308tzzq9k1mgz6","tag_id":"cj64fxvc8003m8tzzzzlb8pxg","_id":"cj64fxvcg003x8tzzm0qxptzh"},{"post_id":"cj64fxvcc003s8tzzr6zfv426","tag_id":"cj64fxv5z001o8tzz65sojffp","_id":"cj64fxvci00418tzz1pjb5hnr"},{"post_id":"cj64fxvbt00348tzz9in1tbzy","tag_id":"cj64fxvce003t8tzzi1d87y4a","_id":"cj64fxvck00458tzzzm3rqs2u"},{"post_id":"cj64fxvcg003z8tzzyvtx6o9a","tag_id":"cj64fxv5w001f8tzzaprfx4l9","_id":"cj64fxvcn00488tzzklv0pj00"},{"post_id":"cj64fxvbx00378tzz382ls6cw","tag_id":"cj64fxvce003t8tzzi1d87y4a","_id":"cj64fxvcp004c8tzzum5da432"},{"post_id":"cj64fxvbz003a8tzzzhcfizqi","tag_id":"cj64fxvcn004a8tzz3znjkroh","_id":"cj64fxvcr004h8tzzkkoceqlf"},{"post_id":"cj64fxvc0003d8tzzjzpeoinb","tag_id":"cj64fxvcq004f8tzzjl7kyqif","_id":"cj64fxvcr004j8tzztclk73gn"},{"post_id":"cj64fxvc2003e8tzzej897eh8","tag_id":"cj64fxvcr004i8tzzskoz3f4d","_id":"cj64fxvcs004l8tzz2bg8uk2m"},{"post_id":"cj64fxvc4003j8tzzzbkb09mz","tag_id":"cj64fxvcr004k8tzz67dghluc","_id":"cj64fxvcs004n8tzz7e4thjrj"},{"post_id":"cj64fxvc7003l8tzzancb2knd","tag_id":"cj64fxvcs004m8tzz62nbwyos","_id":"cj64fxvct004p8tzziwczanmu"},{"post_id":"cj64fxvce003w8tzzi57bitit","tag_id":"cj64fxvcs004o8tzz6pfiqzse","_id":"cj64fxvcu004r8tzz822jmgz9"},{"post_id":"cj64fxvci00448tzz4fypjolr","tag_id":"cj64fxvct004q8tzz4abmt7hu","_id":"cj64fxvcv004t8tzz187gw7r2"},{"post_id":"cj64fxvck00478tzzkhhw1539","tag_id":"cj64fxvcv004s8tzzi76i1ebl","_id":"cj64fxvcw004v8tzz8kcqqsn1"},{"post_id":"cj64fxvco004b8tzzm509vrlf","tag_id":"cj64fxvcv004u8tzzgkmshte8","_id":"cj64fxvcw004w8tzzy3kd10tj"}],"Tag":[{"name":"ELK","_id":"cj64fxv4v00048tzz71bsd07q"},{"name":"Django","_id":"cj64fxv5400098tzzpdveqgnk"},{"name":"ElasticSearch","_id":"cj64fxv5f000m8tzzvbf9tnl2"},{"name":"HTML,CSS","_id":"cj64fxv5n000x8tzzelotgpc7"},{"name":"ELK, logstash","_id":"cj64fxv5r00138tzzuvjgw0dc"},{"name":"hexo","_id":"cj64fxv5v001a8tzzy6hlk5ms"},{"name":"Mac","_id":"cj64fxv5w001f8tzzaprfx4l9"},{"name":"git","_id":"cj64fxv5x001k8tzzon6he7yk"},{"name":"MySQL","_id":"cj64fxv5z001o8tzz65sojffp"},{"name":"mysql","_id":"cj64fxv61001s8tzzpq1ydkgq"},{"name":"PXE","_id":"cj64fxv62001v8tzz154q0ssc"},{"name":"curl","_id":"cj64fxv62001y8tzzohmqcnm1"},{"name":"docker","_id":"cj64fxv6300208tzzcoewnyan"},{"name":"falcon, 监控","_id":"cj64fxv6300228tzzf7u5g8b2"},{"name":"javascripts","_id":"cj64fxvb8002b8tzz0zlmcotn"},{"name":"ELK, filebeat, kafka","_id":"cj64fxvbd002h8tzz0itcob6i"},{"name":"nginx","_id":"cj64fxvbh002o8tzzaf4ys149"},{"name":"influxdb","_id":"cj64fxvbn002u8tzz4114fqx9"},{"name":"lsof","_id":"cj64fxvbs00338tzz27jkkcus"},{"name":"rpm","_id":"cj64fxvc3003g8tzzdd3y0s73"},{"name":"openvpn","_id":"cj64fxvc8003m8tzzzzlb8pxg"},{"name":"shell, 脚本","_id":"cj64fxvce003t8tzzi1d87y4a"},{"name":"shell","_id":"cj64fxvcn004a8tzz3znjkroh"},{"name":"socket","_id":"cj64fxvcq004f8tzzjl7kyqif"},{"name":"sublime","_id":"cj64fxvcr004i8tzzskoz3f4d"},{"name":"scripts, 监控","_id":"cj64fxvcr004k8tzz67dghluc"},{"name":"uwsgi","_id":"cj64fxvcs004m8tzz62nbwyos"},{"name":"python","_id":"cj64fxvcs004o8tzz6pfiqzse"},{"name":"sar","_id":"cj64fxvct004q8tzz4abmt7hu"},{"name":"bash","_id":"cj64fxvcv004s8tzzi76i1ebl"},{"name":"PHP","_id":"cj64fxvcv004u8tzzgkmshte8"}]}}